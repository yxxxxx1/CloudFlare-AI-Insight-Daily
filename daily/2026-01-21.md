## AI洞察日报 2026/1/21

>  `AI 日报` 

### 今日摘要

【1】agent-lightning
AI智能体的绝对训练器，点亮智能之光。

【2】AionUi
免费、本地、开源的多模型协作工具，支持Gemini CLI、Claude Code、Codex、Opencode、Qwen Code、Goose Cli、Auggie等 | 🌟 如果喜欢，欢迎加星！

【3】langextract
一个Python库，利用大语言模型从非结构化文本中提取结构化信息，具备精确的源定位和交互式可视化功能。

【4】go2rtc
终极摄像头流媒体应用，支持RTSP、RTMP、HTTP-FLV、WebRTC、MSE、HLS、MP4、MJPEG、HomeKit、FFmpeg等协议。

【5】awesome-remote-job
一份精心整理的远程工作和资源列表。灵感来源于https://github.com/vinta/awesome-python

【6】try
为每种氛围打造的全新目录

【7】Dario Amodei (Anthropic CEO)：AGI 不存在奇点，但能在两年内彻底甩开人类，中国模型还未追上，芯片管制应该加强！ 关于 AGI：不是"奇点”，而是"平滑指数曲...
Dario Amodei (Anthropic CEO)：AGI 不存在奇点，但能在两年内彻底甩开人类，中国模型还未追上，芯片管制应该加强！ 关于 AGI：不是"奇点”，而是"平滑指数曲线” Dario 反对将 AGI 视为某个突然的"神迹时刻”。他认为我们正处于一个 "智能摩尔定律” 的轨道上： · 认知能力倍增：模型的认知能力每 4-12 个月翻一番。 · 时间表：我们正处于"认知爬坡”的关键期，预计在未来 1-2 年内，模型能力将彻底超越人类。 · 实证：他提到 Claude Code，负责人 @bcherny 过去两个月几乎没亲手写过一行代码，全靠 AI 生成和审查。 泡沫论：技术是真，但节奏有"时差” · 技术端：他比以往任何时候都确信指数增长会持续，未来将创造数万亿的价值。 · 应用端：企业的采纳速度远慢于技术进步。现在的模型能力是企业实际利用能力的 10 倍。 · 泡沫风险：为了迎接未来的数万亿收入，科技巨头现在必须提前囤积算力。但由于企业应用跟不上，短期内可能会出现供需错配的财务泡沫。这就像"为了 5 年后的超级需求，现在就要建好工厂”，中间会有阵痛期。 中国模型并未真正赶上 针对 DeepSeek、MiniMax、GLM、Kimi 等中国模型的崛起，Dario 表现得非常自信： · 基准测试 vs 实战：他认为针对榜单优化很容易，但在真实的企业级竞标中，他几乎从未输给过中国模型。 · 算力禁令：他明确支持对华芯片出口管制。他将 AI 定义为"数据中心里的天才国家”，认为让这种级别的认知能力不受控扩散是极度危险的。 宏观经济："高增长 + 高失业”的怪圈 · GDP 飙升：AI 带来的生产力爆发将推高经济总量。 · 就业崩塌：白领工作（尤其是初级岗位）将面临"血洗”。 · 这种 "极度繁荣与极度失业并存” 的局面，将迫使社会进行某种形式的宏观干预，否则社会结构将难以支撑。 Anthropic 的定位：企业端与安全性 · 差异化：不同于追逐流量、广告和消费者时长的竞对（暗指 Google/OpenAI），Anthropic 专注企业与开发者生产力。 · 安全观：他强调 "可解释性研究”，即真正像做脑科学手术一样去观察模型内部运作，防止模型产生欺骗或勒索意图。 Youtube 视频 https://www.youtube.com/watch?v=Ckt1cj0xjRM [图片: https://pbs.twimg.com/media/G_JnsGGaIAAhKCc?format=jpg&#x26;name=orig] Thariq: if you only ever hear Dario via twitter soundbites, you're doing yourself a disservice he's one of the clearest thinkers and most thoughtful leaders I've ever encountered, it's worth watching the full thing https://www.youtube.com/watch?v=Ckt1cj0xjRM

【8】如何在大规模生产环境中理解 Agent 的行为？ 来自 Langchain 创始人 @hwchase17 的文章，他认为：传统的软件监控（看延迟、错误率）和人工抽查（看 Log）在面对...
如何在大规模生产环境中理解 Agent 的行为？ 来自 Langchain 创始人 @hwchase17 的文章，他认为：传统的软件监控（看延迟、错误率）和人工抽查（看 Log）在面对每天 10 万+ 条 Agent Traces 时已经完全失效。你需要一种新的分析工具，也就是 LangSmith Insights Agent。咱们先不局限于具体工具，一起看看这种从监控到洞察分析的思路。 为什么 Agent 监控如此困难？ Harrison 认为 Agent 和传统软件有三个本质区别，导致我们无法预测它的行为： · 非确定性：同样的输入，Agent 每次跑的路径可能都不一样。 · Prompt 敏感性：用户输入稍微变一点点，输出可能天差地别。 · 无限输入空间：传统软件用户只能点既定的按钮（有限选项），Agent 面对的是自然语言（无限可能）。 传统分析工具的局限性 · 指标监控：能告诉你"出事了”（比如延迟飙升、点踩率变高），但无法告诉你"为什么”。 · 在线评估：虽然能给对话打分（比如检测用户是否愤怒），但前提是你预先知道要测什么。如果你连用户怎么用都不知道，就无法写出评估脚本。 · 人工审查：根本看不过来。看 100 条还行，看 10 万条是不可能的。 LangSmith Insights Agent 的解决方案 核心逻辑是 聚类 和 模式发现 · 自动聚类：它不依赖预定义的规则，而是自动阅读成千上万条对话，把它们归类。比如自动发现"用户经常问 A 类问题”、"B 类错误经常在 C 场景下发生”。 · 层级化报告：提供从宏观（大类模式）到微观（具体对话 Trace）的层级视图，让你能由面到点地排查问题。 · 探索性分析： · 用法发现："用户到底在怎么用我的 Agent？”（往往和你想的不一样） · 故障归因："用户点踩的那些对话，到底有什么共同特征？” · 动态属性计算：你甚至可以问它"为什么用户感到沮丧？”，它会即时计算这个新属性并进行过滤和聚类分析。 [图片: https://pbs.twimg.com/media/G_Jk1JrWUAAX_kC?format=jpg&#x26;name=orig] Harrison Chase: http://x.com/i/article/2013639043775696897

【9】更适合小红书和公众号的多张图文信息卡，提示词我放在这了，感兴趣的朋友自取 🔽 如果想制作 X 的多图（2-4图），可以自行调整提示词种的输出比例，到「AI启蒙...
更适合小红书和公众号的多张图文信息卡，提示词我放在这了，感兴趣的朋友自取 🔽 如果想制作 X 的多图（2-4图），可以自行调整提示词种的输出比例，到「AI启蒙小伙伴」的小红书和公众号查看，或者下面链接 🔗 小红书： https://www.xiaohongshu.com/discovery/item/696f7693000000001a033c05?source=webshare&#x26;xhsshare=pc_web&#x26;xsec_token=YBfz7V32tindOdtNjro3RQ84qXQXqLun6pU0stYE43Zxk=&#x26;xsec_source=pc_share 公众号： https://mp.weixin.qq.com/s/XZ6obaWrsSxaEWzlRkANpg [图片: https://pbs.twimg.com/media/G_JblqeWgAAann_?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/G_JbmylX0AEfREG?format=jpg&#x26;name=orig]

【10】[开源推荐] Claude Code on WhatsApp：通过 @kapso_ai 和 @e2b，把 Claude Code 连接到 WhatsApp 里 能想象到的两个作用 · Vibe Coding 极致化：不再需要打开电...
[开源推荐] Claude Code on WhatsApp：通过 @kapso_ai 和 @e2b，把 Claude Code 连接到 WhatsApp 里 能想象到的两个作用 · Vibe Coding 极致化：不再需要打开电脑，甚至不需要打字。利用 WhatsApp 的语音消息功能，可以直接对着手机说出你的代码构思，系统会自动转录并执行。 · 移动端 Hotfix：当你不在电脑旁但需要紧急修复 Bug 或提交简单的 PR 时，这个工具提供了一个应急入口。 技术架构：四大支柱 · Claude Agent SDK：作为"大脑”，负责理解需求、编写代码和逻辑推理。 · Kapso：作为"嘴巴和耳朵”，处理 WhatsApp 的消息收发，简化了官方 WhatsApp API 的接入难度。 · E2B：作为"手脚”和"安全屋”。它为每个用户提供独立的云端沙箱。这一点至关重要，意味着 AI 生成的代码是在隔离环境中运行的，不会污染你的本地电脑或服务器。 · GitHub：作为"记忆和仓库”，用于拉取代码和提交变更。 工作流设计：安全且符合工程规范 · 隔离性：每个会话都有独立的 E2B 环境。 · 自动分支：每次会话会自动创建一个新的 Git 分支，这意味着你在 WhatsApp 上的操作不会直接破坏主分支（Main/Master），通过 PR 进行合并，符合标准开发流。 · 指令集：提供了 /reset 等指令来重置环境，防止上下文错乱。 开源地址 https://github.com/gokapso/claude-code-whatsapp [图片: https://pbs.twimg.com/media/G_JbUAraoAApuh0?format=jpg&#x26;name=orig] Andrés Matte: http://x.com/i/article/2013410299865444352

【11】The Agentic AI Handbook https://www.nibzard.com/agentic-handbook 很多 Claude Code/Skills 教程是在教我们"如何使用工具”，@nibzard 这篇手册在教我们"如...
The Agentic AI Handbook https://www.nibzard.com/agentic-handbook 很多 Claude Code/Skills 教程是在教我们"如何使用工具”，@nibzard 这篇手册在教我们"如何构建系统”。基于 113 个经过生产环境验证的设计模式，总结出 8 种模式类别。 8 个类别、113 个 Agentic Patterns · 大脑 (Orchestration &#x26; Control)：如何规划、决策和终止？ · 手脚 (Tool Use)：如何与 API、数据库和文件系统交互？ · 记忆 (Context &#x26; Memory)：如何在有限的窗口中管理长期知识？ · 成长 (Feedback Loops)：如何通过自我反思和反馈来修正错误？ · 协作 (UX &#x26; Collaboration)：人类何时介入，何时放手？ · 质检 (Reliability &#x26; Eval)：如何自动化测试 Agent 的产出？ · 进化 (Learning &#x26; Adaptation)：Agent 如何从经验中变强？ · 安全 (Security &#x26; Safety)：如何防止 Agent "暴走”或泄密？ 两个必须掌握的基础模式 A. 计划与执行分离 (Plan-Then-Execute) · 问题：如果让 Agent 边想边做，一旦中间出错，可能会引发连锁反应（类似 Prompt 注入风险）。 · 模式：强制分为两阶段。 · Plan Phase：生成完整的步骤清单，只看不做。 · Execute Phase：由一个无脑的执行器按部就班地运行，或者由人类审批后再运行。 · 应用：这正是 Claude Code 中 plan mode 的核心逻辑。它能将复杂任务的成功率提高 2-3 倍。 B. 控制反转 (Inversion of Control) · 问题：传统的 Prompt 像是在操纵木偶，"读取文件A，然后提取类B...”。这让你成为了瓶颈。 · 模式：给 Agent 工具 + 目标，而不是指令。 · Human：设定护栏（最初的 10%）和验收结果（最后的 3%）。 · Agent：自主决定中间 87% 的路径。 · 价值：这是从"辅助编程”到"Agent 编程”的思维跃迁。 关键洞察：致命三要素 (The Lethal Trifecta) 当一个 Agent 同时具备以下三个能力时，它是极度危险的： · 接触敏感数据（读私有库） · 接触不可信内容（读网页/用户输入） · 对外通讯能力（发 API 请求/Webhook） 解决方案：在架构设计时，必须打破这个三角形。比如，能读敏感数据的 Agent 绝对不能有对外通讯权限。 [图片: https://pbs.twimg.com/media/G_JZEgpWAAAz6dx?format=jpg&#x26;name=orig] Richard Seroter: "Each [agentic AI] pattern represented a battle-tested solution—something that worked outside the demo environment and in the messy reality of production code." https://www.nibzard.com/agentic-handbook &#x3C; 113 so far, across 8 categories.

【12】最近在看 Agent / LLM 的长期记忆方案时，发现一个挺有意思的项目：MemOS。它解决的不是「再塞更大的上下文窗口」或者「怎么更好的检索」，而是一个更基础的问题...
最近在看 Agent / LLM 的长期记忆方案时，发现一个挺有意思的项目：MemOS。它解决的不是「再塞更大的上下文窗口」或者「怎么更好的检索」，而是一个更基础的问题：记忆本身该怎么被管理。https://github.com/MemTensor/MemOS 做 AI Agent / 多轮问答的时候模型总是忘记上下文，用户的偏好、操作记录、上传的文档就像蒸发了一样。而 MemOS 通过核心的"共享记忆层”，不仅解决了这个问题，还让同一份记忆可以跨项目、跨多个Agent复用。 使用上支持把文件和URL直接接入知识库。对话过程中记忆会持续更新并随着增长逐渐形成偏好记忆，并且能把文本、图片、文件、工具调用等信息统一纳管，必要时还能使用自然语言对已有记忆做纠错和清理。有兴趣的小伙伴可以去项目里面玩玩看。 [图片: https://pbs.twimg.com/media/G_AP_9MXIAAS4JV?format=jpg&#x26;name=orig]

【13】🤦 Claude Code 终端闪烁修复补丁：缓解闪烁但破坏 Ghostty 原生 scrollback
原标题： 《Claude Chill: Fix Claude Code's Flickering in Terminal》 评分: 48 | 作者: behnamoh 💭 号称 AI 写代码，连闪烁都修不好？ 🎯 讨论背景 Claude Chill 是社区为 Anthropic 的命令行工具 Claude Code 提供的本地修复/代理，用来缓和在终端中出现的频繁闪烁。问题被指向原始 CLI 使用 Ink（一个 Node.js 的 TUI 渲染库）逐帧清空并重绘的实现；社区修复多采取在本地截取 PTY 输出流或对闭源 npm 包打补丁来平滑显示，但这会阻断 Ghostty（一个终端仿真器）的原生 scrollback 功能并破坏两指滚动等交互。评论围绕技术成因、不同终端（如 cursor terminal）上的表现差异、以及为何 Anthropic 还未在产品端修复展开讨论，同时把问题与使用 Rust/ratatui 的替代实现做对比，伴随对公司宣传与工程实践落差的讽刺和批评。 📌 讨论焦点 用户感谢与快速采纳 许多用户对 Claude Chill 的修复表达强烈感谢，称长期的终端闪烁令人头疼并迫切想要解决。评论里有人表示会立刻在自己的终端安装、测试和更新补丁，并用"你是传奇”"非常感谢”之类的字眼感谢作者。个别用户报告在特定终端（例如 cursor terminal）下闪烁显著减少但未完全消失，说明补丁在不同终端实现上的效果存在差异。总体语气是积极采纳且感激，用户更关心体验改善能否在自己环境稳定生效。 [来源1] [来源2] [来源3] [来源4] [来源5] 技术成因与修复方法 评论把闪烁的根本原因归结为 TUI 的渲染策略：使用 Ink（一个基于 Node.js 的终端 UI 库）会在每次更新时清屏并重绘，从而引发频繁闪烁。有人在 issue 中指出这一实现细节，并表示对闭源 npm CLI 包进行本地补丁可以部分缓解但并不完美。替代实现示例包括使用 Rust 的 ratatui（一个 Rust 的 TUI 库），采取更细粒度或增量渲染以避免全屏重绘，据称用 Rust 实现的 CLI 工具没有同样问题。社区修复通常通过在本地截取或代理 PTY 输出流来平滑更新，但这类方法本身也带来兼容性代价。 [来源1] [来源2] [来源3] [来源4] 兼容性与副作用（Ghostty 的 scrollback） 一个明确的副作用是通过 PTY 代理截取输出会阻断 Ghostty（一个终端仿真器）的原生 scrollback 缓冲，导致两指滚动等功能失效。具体表现是代理拦截输出流后，终端无法访问其内部的 scrollback buffer，因此依赖原生回滚功能的用户体验受损。部分用户表示他们更在意原生滚动而不愿牺牲它来换取更平滑的渲染，另有用户在不同终端上观测到不同程度的闪烁，说明兼容性高度依赖终端实现。社区因此在权衡平滑渲染与保持原生终端功能之间存在分歧。 [来源1] [来源2] [来源3] 对 Anthropic 的不满与开源质疑 多名评论者对 Anthropic 没有在官方修复该明显问题表示失望，认为公司宣称"大量代码将由 AI 编写”的言论与连闪烁这种显眼问题都迟迟未修的现实形成讽刺。有人直言不愿开源可能是因为代码库混乱，担心暴露大量糟糕 PR；也有调侃称公司"买了 Bun”来掩盖或加剧问题。评论还把 Claude Code 与其他没有此问题的 CLI（如 opencode、codex、gemini、droid）做对比，以此加重对 Anthropic 工程实践和优先级的批评。总体情绪为失望并带强烈讽刺和质疑开源透明度的诉求。 [来源1] [来源2] [来源3] [来源4] 讽刺与文化评论 部分用户以讽刺和幽默的口吻将此问题视为"vibe coding”文化的缩影，认为一家高调宣称 AI 驱动开发的公司竟被终端闪烁这样的细节难倒颇具讽刺意味。有人摘录了 Claude 本身的戏谑式回应（‘我们会稍后处理’），把公司宣传与产品细节之间的张力放大。讨论既有对工程质量的严肃批评，也用调侃来缓解不满，反映社区对科技话语与实际交付之间差距的敏感。总体上对这类"风格优先于工程细节”的文化持批评与嘲讽态度。 [来源1] [来源2] 📚 术语解释 PTY proxy（PTY 代理）: PTY（伪终端）负责终端与程序间的 I/O，'PTY 代理' 指在本地截取或代理该 I/O 流的工具。通过代理输出可以在客户端平滑渲染或修改输出，但会阻断终端仿真器访问其内部的 scrollback buffer，从而破坏原生滚动等功能。 Ink（Node.js 的 TUI 库）: Ink 是一个用 React 思想构建终端 UI 的 Node.js 库，常见实现是清屏并重绘屏幕以响应更新。这种逐帧清空重绘在某些终端或高频更新场景下会导致明显闪烁，改用增量渲染或更改渲染策略可避免该问题。 scrollback buffer（终端回滚/滚动缓冲）: 终端的 scrollback buffer 保存历史输出以供向上滚动查看，支持手势或键盘翻阅。若输出被代理或截断（例如通过 PTY 代理），终端可能无法访问这段历史，从而失去原生滚动行为和表现。 ratatui（Rust 的 TUI 库）: ratatui 是一个 Rust 语言的终端 UI 库，通常采用更细粒度或增量的渲染策略以避免全屏清空重绘。评论中提到采用 Rust/ratatui 实现的 CLI 在类似场景下不容易出现同样的闪烁问题。

【14】逛展新姿势:豆包首创 AI 视频通话导览，精准识别"撞脸”文物
据 AIbase 报道，字节跳动旗下 AI 助手"豆包”近日与上海浦东美术馆达成战略合作，正式成为"图案的奇迹:卢浮宫印度、伊朗与奥斯曼的艺术杰作”与"非常毕加索:保罗•史密斯的新视角”两大国际重磅展览的官方 AI 讲解员。这也是 AI 产品 首次 以官方身份介入美术馆导览场景，标志着"AI+艺术”体验的深度落地。 [图片: 豆包、Grace、字节跳动 https://pic.chinaz.com/picmap/202308181515111389_0.jpg] 首创视频通话导览，攻克"脸盲”难题 此次合作通过 独家 数据打通与定向搜索优化，显著提升了模型对艺术品的识别精度。展览期间，观众只需通过豆包 App 的"视频通话”或拍照功能，即可获取从艺术风格、历史背景到文化寓意的多维解读。针对外观高度相似的文物（如15世纪伊朗牡丹纹盘与明代青花瓷），豆包也能通过细节精准区分。此外，系统还贴心提供了"通用”与"亲子”两种解说风格，即便是轻声提问也能准确响应，满足不同人群的观展需求。 从"单向输出”到"共情对话” 在发布会上，字节跳动副总裁朱骏与 资深 媒体人陈鲁豫探讨了 AI 看展的深层价值。朱骏强调，AI 与用户的交互本质是对话体验。豆包不仅提供知识，更致力于通过共情式提问和启发式对话，调动观众的个人感知与经验，让艺术欣赏变成一种更有参与感的双向互动。 持续深耕文博数字化 此次牵手浦东美术馆并非豆包在文博领域的 首次 尝试。此前，豆包已先后与中国国家博物馆、南京博物院等七家国家一级博物馆合作打造数字化体验区。此次成为官方讲解员，是其在复杂线下场景中技术落地能力的又一次重要验证。

【15】​维基百科母公司达成 AI 数据授权协议：亚马逊、Meta 及 Perplexity 正式入场
在成立 25 周年之际， 维基百科 的母公司 Wikimedia 基金会宣布了一项重大的战略合作。该机构已与 亚马逊 、 Meta 以及新兴 AI 搜索公司 Perplexity 达成协议，这些技术巨头将通过付费方式访问 Wikimedia Enterprise 提供的官方数据接口。 这项合作旨在为大型语言模型的训练提供高质量、具有真实性保障的数据源。相比于传统大规模抓取网页数据的"网络爬虫”模式，Wikimedia Enterprise提供了一个更具规模化且经过人工治理的知识分发渠道。这不仅能确保 AI 平台在回答用户查询时引用更加准确的信息，也体现了在 AI 时代保护人类协作知识价值的重要性。 Wikimedia基金会首席产品与技术官Selena Deckelmann表示，在 AI 飞速发展的今天，维基百科所代表的人类智慧比以往任何时候都更加关键。通过这种商业化尝试，维基百科希望在未来 25 年甚至更久的时间里，继续保持全球人类知识协作核心枢纽的地位。 目前，这一合作伙伴名单已涵盖了谷歌、Nomic等多家行业巨头。虽然具体的财务条款尚未公开，但这标志着内容生产方在应对生成式 AI 冲击时，正积极寻求从数据授权中获取可持续发展的动力。

【16】三七互娱的 AI 大计：李逸飞如何布局未来科技 "硬核宇宙”？
在近期的科技投资舞台上，三七互娱的 掌门人 李逸飞成为了炙手可热的人物。这家以游戏起家的公司，竟然在 AI 领域悄然崛起，投资了众多前沿科技公司，包括国内大模型 "四小龙” 中的三家：智谱 AI、月之暗面和百川智能。李逸飞的目标是借助这些科技助力游戏行业，解决生产力焦虑。 2026 年初，智谱 AI 成功上市，成为 "全球大模型 第一 股”，市值迅速突破 578 亿港元，三七互娱作为早期股东，也因此获得了可观的回报。这一系列投资不仅让三七互娱的资金回流，更为其游戏制作过程带来了革命性变化。借助智谱 AI 的 GLM 大模型，游戏素材的生产周期显著缩短。同时，月之暗面的 Kimi 大模型也融入了公司的客服系统，提升了用户体验。 但李逸飞并不止步于此，他的 AI 投资帝国还涵盖了脑机接口和光刻机等 尖端 技术。2025 年，三七互娱向脑机接口独角兽强脑科技投资 2000 万美元，这一领域被认为是人机交互的未来。在这笔投资后，强脑科技迅速成长，成为仅次于马斯克的 Neuralink 的全球第二大脑机接口公司。 在芯片和半导体方面，李逸飞同样表现活跃。他投资了一系列相关企业，以确保未来 AI 游戏的核心技术不会受制于外部供应链。这些投资布局，为三七互娱打下了坚实的技术基础。 李逸飞的创业故事从一个热爱游戏的年轻人开始，到如今的 AI 投资大佬，他展现了非凡的战略眼光。从一开始的游戏代理商到如今的国际化企业，三七互娱经历了多次转型和挑战。在每一次风口之上，李逸飞总能以敏锐的嗅觉抓住机遇，带领公司走向新的高峰。

【17】🤦 Cloudflare 的 .well-known 特例导致 WAF 绕过争议：真是零日吗？
原标题： 《Cloudflare zero-day: Accessing any host globally》 评分: 30 | 作者: 2bluesc 💭 把 WAF 当零信任边界，还真靠得住？ 🎯 讨论背景 这场讨论围绕一篇称 Cloudflare 存在可被利用的例外路由（可"访问任意主机”）的文章展开。Cloudflare 是一家提供 CDN、DDoS 缓解与 WAF 的边缘服务商；文章用 Next.js（React 服务端框架）、Spring（Java 后端框架）等示例说明若源站配置不当可能被利用，但评论者指出该问题在披露前已修复且许多示例依赖错误配置。核心技术背景是 ACME（自动证书管理协议）的 http‑01 挑战需要通过 /.well‑known/acme‑challenge 在 HTTP 上让 CA 读取令牌，因而边缘通常要对该路径做例外处理，这种例外会使某些 WAF 规则失效。讨论聚焦于风险是否被夸大、实现细节（如 HTTP vs HTTPS、端口与缓存）以及应由源站还是边缘承担的防护责任。 📌 讨论焦点 文章夸大与已修复 多名评论认为原文把一个技术上有限且早已修复的问题渲染为"zero‑day”并有煽动性。文章通过设想最糟的源站配置（例如在 404 或默认错误响应中返回敏感环境变量）来展示后果，但这些示例依赖源站严重误配而非边缘服务无法修补的缺陷。评论指出真正的问题是把 Cloudflare 的 WAF 当作零信任边界使用，这是不现实的配置假设，因此报道在严重性和新颖性上被夸大。总体意见是这是一个有意思的实现细节，但不是未修补的高危零日漏洞。 [来源1] [来源2] [来源3] 技术根源：ACME http‑01 与 /.well‑known 的特例 评论中明确把问题的核心归结为 ACME 的 http‑01 域名验证和对 /.well‑known/acme‑challenge 路径的特殊处理。为了让证书颁发机构（CA）读取验证令牌，CDN/WAF 需要为该路径绕开 HTTPS 强制或某些边缘规则，Cloudflare 因此对该路径走了不同的路由，导致部分 WAF 规则未拦截就到达源站。讨论强调这并非 Cloudflare 专有的问题，任何实现 http‑01 的 ACME 客户端或边缘服务在做类似例外时都可能引入可被滥用的特殊代码路径。该机制解释了为什么看起来像是"绕过 WAF”，但本质上是为支持自动化证书验证而不得不开放的例外。 [来源1] [来源2] [来源3] 实际影响与缓解措施 多数评论认为实际危害取决于源站是否配置不当：只有当源站在默认错误页、SPA 响应或 404 页面泄露敏感信息时，绕过边缘才会造成数据泄露或触发漏洞利用。建议的缓解包括在 /.well‑known 路径返回空的 404、在边缘或使用像 Caddy（一个支持自动证书的 Web 服务器）这类软件自行处理该路径以避免转发到源站，或使用专门的零信任产品而非单靠 WAF。评论还提醒要注意缓存控制和 HTTPS 配置，责任更多在源站的安全配置而非边缘例外本身。 [来源1] [来源2] [来源3] [来源4] 对 HTTP/HTTPS 描述的混淆与端口问题 评论中指出原文在 CA 抓取验证令牌时是否使用 HTTPS 上存在表述不准确的地方：http‑01 挑战本质上通过 HTTP（通常是端口 80）完成验证，不能被简单地升级到 HTTPS。这一点很重要，因为是否必须为验证开例外、如何处理升级和缓存直接影响边缘服务为何要对该路径做特殊处理。对协议与端口的误解会导致对风险严重性的错误评估，因此评论里有人专门纠正了文中关于"通过 HTTPS 抓取”的说法。 [来源1] [来源2] [来源3] 📚 术语解释 WAF (Web Application Firewall): 位于边缘的应用层防火墙，用于检查和拦截恶意 HTTP 请求。WAF 可以屏蔽已知攻击模式，但不能自动替代零信任或修复源站配置错误，且可能因特殊路由例外而失效。 ACME http-01 challenge: ACME（自动证书管理环境）协议的一种域名验证方式，证书颁发机构通过 HTTP（通常端口 80）访问 /.well‑known/acme‑challenge 下的令牌来验证域名所有权。该流程要求对该路径绕开 HTTPS 强制或特殊缓存策略，因此在边缘可能形成例外通路。 .well-known/acme-challenge 路径: ACME 客户端将验证令牌放在该 URL 路径下以供 CA 读取；许多 CDN/WAF 会对该路径做特殊处理以保证证书颁发成功，但这种特殊处理可能导致安全策略的例外并被滥用。 Origin server（源站）: 托管真实应用或资源的后端服务器，位于 CDN/WAF 之后。如果源站的默认错误处理或页面包含敏感配置、环境变量或未修补的漏洞，绕过边缘就会直接暴露这些问题。 类别： Security | Web | Systems | Incident | Cloudflare | zero-day | ACME | WAF | http-01 | .well-known/acme-challenge | Next.js | Spring

【18】DeepSeek 秘密代码曝光:"MODEL1” 新架构剑指2月，编程能力再进化
据 AIbase 报道，正值 DeepSeek-R1发布一周年之际，DeepSeek 下一代旗舰模型的线索已悄然浮出水面。结合 The Information 的爆料，这款备受期待的新模型（或为 DeepSeek V4）最快有望于今年2月中旬(农历新年期间)正式登场，并预计带来更强悍的代码生成能力。 [图片: DeepSeek https://pic.chinaz.com/picmap/202502051558211433_3.jpg] 开发者在 DeepSeek 的 GitHub 仓库中发现，其更新的 FlashMLA 代码库中，横跨114个文件有多达28处引用了名为 "MODEL1” 的神秘标识符。代码逻辑显示，"MODEL1” 是一个区别于现有 "V32”（DeepSeek-V3.2）的全新架构。二者的关键差异体现在键值(KV)缓存布局、稀疏性处理方式以及 FP8数据格式的解码支持上，这表明新模型在内存优化和计算效率方面进行了针对性的底层重构。 此前，DeepSeek 团队已陆续发布了关于"优化残差连接（mHC）”和受生物学启发的"AI 记忆模块(Engram)”等技术论文。业界普遍猜测，这些 最新 的研究成果极有可能被整合进正在开发的"MODEL1”中，为这款即将发布的新旗舰提供核心技术支撑。

