## AI洞察日报 2026/2/25

>  `AI 日报` 

### 今日摘要

【1】skills


【2】Agent-Skills-for-Context-Engineering


【3】OpenBB


【4】ladybird


【5】system-prompts-and-models-of-ai-tools


【6】superpowers


【7】兄弟们，我试过了，前端审美太TMD丑了。 这个Skill匹配不上它的Star数量，UX还行。
兄弟们，我试过了，前端审美太TMD丑了。 这个Skill匹配不上它的Star数量，UX还行。 [图片: https://pbs.twimg.com/media/HB-Kx6ea8AAAuR1?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/HB-K2DWboAAKUnN?format=jpg&#x26;name=orig] 向阳乔木: 个人觉得这个UI和UX Skill比较靠谱，Github有3w多Star。 感觉有点东西，等我测试看实际效果如何。 地址见评论区 [图片: https://pbs.twimg.com/media/HB-FU3rbkAA3sXh?format=jpg&#x26;name=orig] [图片: https://pbs.twimg.com/media/HB-FkcFaMAIXqA5?format=jpg&#x26;name=orig]

【8】Karpathy: It's 2026. Build. For. Agents. 人类花了 40 年用 GUI 把终端藏起来，而现在 Claude Code/Codex 等却最喜欢 CLI 这种纯文本、stdin/stdout、管道可组...
Karpathy: It's 2026. Build. For. Agents. 人类花了 40 年用 GUI 把终端藏起来，而现在 Claude Code/Codex 等却最喜欢 CLI 这种纯文本、stdin/stdout、管道可组合的接口。 AI Agent 不需要漂亮的按钮和动画，它们只需要可编程、可脚本化的确定性接口，CLI 正适合！ Karpathy 给所有产品/开发者抛出一个系统性思考框架： · 你的文档（给人看的）能不能至少导出为 Markdown？ · 你有没有为产品写好 Skills？ · 你的产品能不能通过 CLI 或 MCP 被 Agent 使用？ [图片: https://pbs.twimg.com/media/HB96xBsa8AAVdGg?format=jpg&#x26;name=orig] Andrej Karpathy: CLIs are super exciting precisely because they are a "legacy" technology, which means AI agents can natively and easily use them, combine them, interact with them via the entire terminal toolkit. E.g ask your Claude/Codex agent to install this new Polymarket CLI and ask for any [图片: https://pbs.twimg.com/media/HB8UIepawAAbVKf?format=jpg&#x26;name=orig]

【9】This new paper on agent failure makes an interesting claim. This is particularly important for long-horizon agents. Many assume that agents collapse b...
This new paper on agent failure makes an interesting claim. This is particularly important for long-horizon agents. Many assume that agents collapse because they hit problems they can't solve, caused by insufficient model knowledge. It turns out that in the majority of cases, they collapse because they take one wrong step, and then another, which compounds quickly. Each off-path tool call significantly increases the likelihood of failure of the next tool call. In other words, most agent failures are reliability failures, not capability failures. Paper: https://arxiv.org/abs/2602.19008 Learn to build effective AI agents in our academy: https://academy.dair.ai/ [图片: https://pbs.twimg.com/media/HB95MuOXsAAvhAb?format=png&#x26;name=orig]

【10】Claude Code 发布远程控制功能：/remote-control 本地终端启动 Claude Code 任务后，可随时从手机 Claude App 或浏览器接管并继续控制整个会话。可以边散步、开...
Claude Code 发布远程控制功能：/remote-control 本地终端启动 Claude Code 任务后，可随时从手机 Claude App 或浏览器接管并继续控制整个会话。可以边散步、开会或离开电脑，Claude 仍持续在机器上本地运行，而远程界面仅作为"窗口”提供交互 所有计算和文件操作仍在本地机器上完成（无数据迁移到云端），远程端只是实时同步对话和指令，终端、浏览器、手机等多设备实时同步，可交替发送消息 启动与连接流程 · 方式一（推荐新会话）：进入项目目录，运行 claude remote-control（支持 --verbose 查看日志、--sandbox 开启沙箱隔离） · 方式二（接续现有会话）：已在 Claude Code 交互中输入 /remote-control（或简写 /rc） · 终端会立即显示： · 会话 URL（直接在浏览器打开） · QR 码（按空格键切换显示，用手机 App 扫码） · 连接后：远程端显示电脑图标 + 绿色在线点；会话名称可通过 /rename 自定义，便于多会话管理 · 全局配置：输入 /config 可开启"Enable Remote Control for all sessions”，让每次启动自动支持远程 [图片: https://pbs.twimg.com/media/HB9372FbIAAR0EB?format=jpg&#x26;name=orig] Claude: New in Claude Code: Remote Control. Kick off a task in your terminal and pick it up from your phone while you take a walk or join a meeting. Claude keeps running on your machine, and you can control the session from the Claude app or http://claude.ai/code [视频: https://video.twimg.com/amplify_video/2026417722394021888/vid/avc1/1080x1080/JzFH0UlylpC8DVQ9.mp4?tag=21]

【11】Claude Code 这个更新不错，可以把 Claude 当小龙虾🦞用了，简单来说就是你用 claude rc 运行 claude，然后会生成一个链接或者二维码，你扫描二维码或者打开链...
Claude Code 这个更新不错，可以把 Claude 当小龙虾🦞用了，简单来说就是你用 claude rc 运行 claude，然后会生成一个链接或者二维码，你扫描二维码或者打开链接，就可以从手机上或者其他电脑上控制你本机的 claude code。 由于两边都要登录相同的 claude 账号，所以即使别人知道你的 URL 也无法控制你的电脑，倒是不用担心安全问题。 目前只有 Max 订阅用户能用，Pro 还要等等 Claude: New in Claude Code: Remote Control. Kick off a task in your terminal and pick it up from your phone while you take a walk or join a meeting. Claude keeps running on your machine, and you can control the session from the Claude app or http://claude.ai/code [视频: https://video.twimg.com/amplify_video/2026417722394021888/vid/avc1/1080x1080/JzFH0UlylpC8DVQ9.mp4?tag=21]

【12】RT Jason Ginsberg:
RT Jason Ginsberg [视频: https://video.twimg.com/amplify_video/2026425444934012928/vid/avc1/1920x1200/18A-a16uPzYZmgwt.mp4?tag=21] Jason Ginsberg: This tweet was sent with Cursor's new computer use feature. The agent can actually use its own virtual machine to do anything.

【13】🤨 Mercury 2：基于扩散的极速推理模型——性能与可验证性之争
原标题： 《Mercury 2: The fastest reasoning LLM, powered by diffusion》 评分: 28 | 作者: fittingopposite 💭 最快的推理模型，不说参数和成本，能信吗？ 🎯 讨论背景 Mercury 2 是 Inception Labs 推出的一款闭源大模型，宣称自己是"由扩散驱动的最快推理 LLM”。社区讨论集中在两点：扩散方法在语言推理场景是否能在成本/性能（Pareto frontier）上胜出，以及即便模型更快，是否能在实际任务（尤其是编码与验证流程）中带来决定性收益。评论里有人贴出价格/性能对比并批评公告措辞与未公布参数，指出演示存在排队问题，建议使用 server‑side pre‑render 并支持 OpenRouter（将模型请求路由到不同后端的桥接服务）以便第三方验证。总体上社区既看到速度带来的迭代与并行尝试机会，也强调必须通过编译器、静态分析、测试和人工审查等手段来验证结果质量。 📌 讨论焦点 扩散模型与成本/效能质疑 部分评论者对将扩散模型用于语言推理持怀疑态度，指出 Google 等团队的尝试在多数用例上并未占据成本/性能的 Pareto frontier，并贴出价格/性能对比作为参考。官方公告中的措辞（例如强调 p95 latency、稳定吞吐）被一些人视为典型的营销话术，而真实基准、参数量和开放性信息并未充分披露，降低了对"最快”主张的信任。演示和宣传中缺少可复现数据与开放验证路径，使得社区要求更多透明度以验证成本/性能优势是否真实存在。 [来源1] [来源2] [来源3] [来源4] 把速度视为产品力：更快的迭代与并行尝试 多位评论者认为极高的 tokens/s（4 位数/秒）能实质改变交互模式，使 multi‑shot prompting 与微步 nudging 变得"无感”，从而降低部分幻觉与非确定性问题。有人提出用"每秒智能量”（intelligence per second = intelligence per token × tokens per second）来衡量速度与单 token 质量的折衷，并用过去代际间速度/质量的选择偏好做类比说明。速度带来的实际机会包括并行探索多个解空间（例如在本地 Postgres 上同时测试多种 SQL 改进并用 explain plan 与测试套件验证）、多模型仲裁与合成以快速筛选有效方案，从而提高迭代效率。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 演示与可访问性问题：排队、延迟与预渲染 多人指出线上聊天演示受队列影响，导致实际体验并不能体现模型宣称的低延迟，建议在请求脱离队列时给出明显反馈以证明真是出速优势。还有人建议官网采用 server‑side pre‑render，让自动化 agent 和抓取器能读取发布说明；并尽早支持 OpenRouter（将模型请求路由到不同后端的桥接服务），以便第三方更容易试用和评估。这些可用性和可访问性问题被视为阻碍外部验证和采纳的现实障碍。 [来源1] [来源2] 速度不能替代验证：编码与架构场景仍需工具与人工把关 有评论者提醒，变快并不等于更可靠或更"聪明”，在编程与架构决策场景中，瓶颈常常是输出的正确性与验证，而不是生成速度本身。建议把模型当作快速生成候选解的引擎，然后用编译器、静态分析、测试套件和人工审查来验证结果，避免把模型的"意见”当作最终架构决策。即便速度允许大规模并行尝试，最终仍需可靠的验证流程，多模型互审（用小模型评判大模型）被提出为减少错误输出的可行策略之一。 [来源1] [来源2] [来源3] 📚 术语解释 diffusion models（扩散模型）: 扩散模型是一类生成模型，最初常用于图像，通过逐步去噪/反向扩散生成样本。近期有人把这类方法用于语言模型推理以期并行化或加速 token 生成，但评论中有人质疑它在成本/性能（Pareto frontier）上是否真的优于传统自回归解码。 tokens per second (tok/s): tokens per second（tok/s）表示模型每秒生成的标记数，是衡量响应速度和吞吐量的指标。讨论中多位评论者把高 tok/s 与更快的迭代、多次提示（multi‑shot prompting）和并行解空间探索联系起来，并提出把它与单 token 的"智能量”相乘作为衡量‘每秒智能量’的思路。 类别： AI | Systems | Programming | Release | Mercury 2 | Inception Labs | diffusion | reasoning LLM | tokens/sec | latency

【14】Anthropic重磅更新！Claude Code"远程控制”功能上线，手机秒变电脑终端神器
Anthropic近日向Claude Max订阅用户推送了一项重量级更新:Claude Code正式引入"Remote Control”（远程控制）功能。这项功能让开发者能够在电脑终端启动编码任务后，通过手机或平板无缝接管整个会话，实现真正的"随时随地Coding”。 [图片: image.png https://upload.chinaz.com/2026/0225/6390760930308073483219639.png] 核心亮点:本地执行+手机接管，上下文零丢失 用户只需在运行中的Claude Code终端输入/remote-control（或简写/rc），系统即会生成一个专属会话链接和QR码。扫描QR码后，即可通过Claude官方iOS/Android App或浏览器(claude.ai/code)直接连接。 最关键的是:所有计算和文件操作依然在你的本地电脑上进行，手机仅作为远程操控界面。上下文、文件系统访问权限、自定义技能、MCP服务器等全部完整保留，无需将项目上传云端，兼顾隐私与效率。 使用场景直击痛点 - 在沙发上躺平继续debug - 开会间隙监控长任务进度 - 出门散步时通过语音/文字下达新指令 - 甚至搭配服务器实现"24小时不间断AI编程助理” 这项功能目前处于研究预览（Research Preview）阶段，优先向Max计划用户开放，Pro用户即将跟进。官方文档已同步更新，包含详细连接步骤和注意事项。 社区反馈:这可能是2026年最实用的Coding黑科技之一 开发者们普遍表示，这不仅仅是"手机看代码”，而是真正打通了桌面与移动端的开发链路。尤其适合需要频繁上下文切换、或偏好"vibe coding”（氛围式编程）的工程师。相比纯云端方案，本地+远程的混合模式在安全性和灵活性上更胜一筹。 如何立即体验 1. 确保Claude Code已更新至 最新 版本（运行`claude update`） 2. 在终端启动或进入已有Claude Code会话 3. 输入`/remote-control`生成连接 4. 用手机Claude App扫描QR码接入 Anthropic正持续迭代Claude Code系列工具，此次Remote Control的推出，进一步巩固了其在AI编程代理领域的领先地位。更多细节可参考官方文档:code.claude.com/docs/remote-control。

【15】​英国 AI 独角兽 Wayve 获 10.5 亿美元融资，软银领投开启自动驾驶新赛道
英国自动驾驶初创公司 Wayve 近日宣布完成 10.5 亿美元的 C 轮融资。这笔巨额资金由日本软银集团领投，同时吸引了英伟达（NVIDIA）和微软（Microsoft）等科技巨头的深度参与，标志着欧洲 AI 领域迎来了有史以来规模 最大 的单笔融资之一。 与特斯拉或 Waymo 依赖高精地图和昂贵传感器的路径不同，Wayve 走的是一条"端到端”的具体化 AI（Embodied AI）技术路线。AIbase 了解到，Wayve 开发的模型就像人类驾驶员一样，能够通过摄像头数据进行实时学习和推理，从而在未曾见过的复杂城市街道中灵活穿梭。这种"纯视觉+大模型”的方案，被认为更具扩展性，能够更轻松地跨越不同城市甚至不同车型进行部署。 软银愿景基金此次重金押注，展现了其对"物理 AI”概念的坚定信心。软银高层表示，Wayve 的技术不仅限于乘用车，未来还将延伸至机器人等更多物理实体中。与此同时，英伟达的加入也为 Wayve 提供了强大的底层算力支持，而微软则继续通过 Azure 云平台为其提供大规模模型训练的基础设施。 目前，Wayve 已将其研发中心扩展至伦敦以外，并计划利用这笔资金加速其基础模型（AV2.0）的商业化落地。虽然自动驾驶行业曾一度陷入寒冬，但 Wayve 此次融资的成功，无疑为全球自动驾驶市场注入了一剂强心针，预示着基于生成式 AI 的驾驶技术正步入爆发前夜。 概要： 💰 英国史上 最大 募资 ：Wayve 完成 10.5 亿美元 C 轮融资，由软银领投，英伟达与微软跟投，刷新英国 AI 初创公司融资纪录。 🚗 端到端技术革新 ：摒弃传统的高精地图模式，采用纯视觉、端到端的 AI 架构，使车辆具备更强的泛化能力和"大脑”般的推理素质。 🌐 跨巨头生态协作 ：融资不仅带来了资金，还整合了英伟达的硬件优势与微软的云端算力，旨在加速"具体化 AI”在现实物理世界中的应用。

【16】为了开会不被骂，Uber 工程师竟背着老板开发了一个"AI 版 CEO”
面对严厉的老板，打工人总能想出一些出人意料的"生存套路”。近日，Uber 首席执行官达拉·科斯罗萨西（Dara Khosrowshahi）在接受播客采访时爆料，公司内部的工程师们为了确保向他汇报工作时万无一失，竟然专门开发了一个"AI 版达拉”。 这个有趣的工具被员工们亲切地称为"Dara AI”。科斯罗萨西透露，团队成员告诉他，很多小组在正式向他提交演示文稿（PPT）之前，会先对着这个"虚拟老板”进行模拟汇报。通过"Dara AI”的反馈，工程师们可以反复打磨幻灯片的逻辑，精准预判老板可能会提出的尖锐问题，从而在真正的会议室里表现得无懈可击。 科斯罗萨西对此不仅没有生气，反而对这种创新行为大加赞赏。他表示，目前的 Uber 本质上就是一个巨大的代码库，而工程师则是公司的建筑师。据他观察，目前 Uber 约 90% 的软件工程师已经在工作中使用 AI 工具，其中 30% 更是深度用户，甚至在利用 AI 重新构思公司的底层架构。 AIbase注意到，这种"用 AI 对付 AI 老板”的行为，侧面印证了 AI 在提升企业内部沟通效率方面的巨大潜力。科斯罗萨西感叹道，AI 对生产力的改变是他职业生涯中前所未见的。目前，这些工程师不仅在制造系统的"砖块”，更在通过 AI 像建筑大师一样思考公司的未来。 概要： 🤖 虚拟老板分身 ：Uber 工程师开发了名为"Dara AI”的聊天机器人，用于模拟 CEO 的思维方式，帮助员工在正式汇报前进行压力测试。 📈 生产力大爆发 ：CEO 透露公司九成工程师已将 AI 融入日常工作，AI 正在以前所未有的速度重塑公司的开发流程与架构思维。 💡 职场生存新姿态 ：员工利用 AI 精炼演示文稿并预判高层提问，这种"模拟考试”模式有效提升了跨层级沟通的质量与成功率。

【17】体积减半性能不减!西班牙 Multiverse 靠量子压缩术挑战 OpenAI
针对大语言模型（LLM）体积臃肿、部署成本高昂的痛点，西班牙 AI 初创公司 Multiverse Computing 正在通过独特的"压缩术”打破僵局，试图在企业级 AI 市场与 OpenAI 等巨头分庭抗礼。 核心技术:让60B 模型仅占32GB 空间 Multiverse 的核心竞争力源于其受量子计算启发的压缩技术 CompactifAI 。凭借这一技术，该公司成功将其基于 OpenAI 原型（gpt-oss-120b）开发的 HyperNova60B 模型体积缩减了一半。 最新 发布的 HyperNova60B2602 版本现已在 Hugging Face 开放免费获取。该模型大小仅为 32GB ，在显著降低内存占用和延迟的同时，保持了与原版几乎持平的准确度。此外，新版本专门优化了推理成本较高的"工具调用”和"智能体编码”场景。Multiverse 声称，该模型在性能上已超越法国 AI 独角兽 Mistral AI 的旗舰模型 Mistral Large3。 [图片: 芯片 AI绘图 (1) https://pic.chinaz.com/picmap/202304041450446401_5.jpg] 欧洲 AI 的崛起:地缘政治与商业版图 与 Mistral 类似，Multiverse 正在成为欧洲自主 AI 技术的代表。目前，该公司的业务已横跨欧美，并赢得了 博世（Bosch）、西班牙电力(Iberdrola)及加拿大银行 等重量级企业客户。 这种"主权 AI”的定位使其获得了政府的大力支持。西班牙技术转型署（SETT）参与了其去年 2.15亿美元的 B 轮融资 。凭借在整个人工智能技术栈提供自主解决方案的能力，Multiverse 正迅速填补市场对美国技术替代方案的需求。 估值跃升:迈向15亿欧元独角兽 尽管 Multiverse 对市场传闻保持谨慎，但据知情人士透露，该公司正洽谈一轮 5亿欧元 的新融资，估值预计将突破 15亿欧元 。 虽然其年度经常性收入（ARR）据传约为1亿欧元，与 OpenAI 的200亿美元仍有巨大差距，但已逼近 Mistral 的4亿美元水平。随着2026年更多压缩模型计划开源，这家源自巴斯克地区的初创公司极有望成为西班牙首家 AI 独角兽。

【18】通义千问Qwen3.5开源家族新增多款模型，并上线托管服务
近日，通义千问（Qwen）团队宣布其开源大模型家族Qwen3.5实现重要扩容，一次发布多款新模型，并同步上线了对应的生产级API服务。 本次新增的开源模型主要包括三款: Qwen3.5-122B-A10B :该模型在复杂Agent任务（如多步推理、工具调用）中表现亮眼，进一步缩小了中小模型与 顶尖 闭源模型的性能差距。 Qwen3.5-35B-A3B :其性能已全面超越前代更大参数规模的Qwen3-235B-A22B等模型，体现了通过优化架构、数据与强化学习协同，而非单纯增加参数来提升智能的技术路径。 Qwen3.5-27B（Dense） :一款主打"小尺寸、高能效”的模型，旨在降低大模型的使用门槛。 同时，面向企业级生产应用，阿里云百炼平台正式上线了 Qwen3.5-Flash API 。该服务是与Qwen3.5-35B-A3B对齐的托管版本，默认支持长达 100万tokens 的上下文，并内置了官方原生工具链，开箱即用，无需额外集成。 [图片: QQ20260225-092635.png https://upload.chinaz.com/2026/0225/6390760841189338285791363.png] 目前，开发者与研究人员可通过GitHub、Hugging Face或魔搭（ModelScope）社区下载上述开源模型进行研究与微调。企业用户可前往阿里云百炼平台直接体验Qwen3.5-Flash API服务。此举被视为阿里云推动大模型技术普惠与加速产业落地的重要举措。

