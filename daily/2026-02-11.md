## AI洞察日报 2026/2/11

>  `AI 日报` 

### 今日摘要

【1】langextract
一个使用大语言模型从非结构化文本中提取结构化信息的Python库，具备精确的源定位和交互式可视化功能。

【2】AionUi
免费、本地、开源的24/7协同工具和OpenClaw，适用于Gemini CLI、Claude Code、Codex、OpenCode、Qwen Code、Goose CLI、Auggie等 | 🌟 喜欢的话请点星！

【3】shannon
完全自主的AI黑客，用于在您的Web应用程序中发现实际漏洞。Shannon在无提示、源码感知的XBOW基准测试中取得了96.15%的成功率。

【4】gh-aw
GitHub智能体化工作流

【5】compound-engineering-plugin
官方Claude Code复合工程插件

【6】TradingAgents-CN
基于多智能体大语言模型的中文金融交易框架 - TradingAgents中文增强版

【7】从直觉到度量：用 Eval 体系化验证 Agent Skill 的质量，来自 @OpenAIDevs 分享 https://developers.openai.com/blog/eval-skills Skill 本质上是给 LLM 的结构...
从直觉到度量：用 Eval 体系化验证 Agent Skill 的质量，来自 @OpenAIDevs 分享 https://developers.openai.com/blog/eval-skills Skill 本质上是给 LLM 的结构化指令集。开发者在迭代 Skill 时，常常只能凭感觉判断"是否变好了"，直到回归错误出现——Skill 没触发、步骤被跳过、多余文件被遗留。 OpenAI 的核心主张：用 Eval 替代直觉 > Eval = Prompt → 执行记录（trace + artifacts）→ 检查规则 → 可比较的分数。 --- 方法论：八步闭环 --- 一、先定义成功，再写 Skill 从四个维度定义"好"： 结果：任务完成了吗？应用能运行吗？ 过程：调用了正确的 Skill 吗？按预期步骤执行了吗？ 风格：输出符合代码规范吗？ 效率：有没有命令重复或 token 浪费？ 关键原则：保持检查项少而聚焦，只覆盖"必须通过"的行为。 二、创建 Skill 时把约束写明确 SKILL. md 中的 name 和 description 是 Agent 决定是否调用该 Skill 的首要信号，必须精确。Skill 的指令越有主见，越容易被评估——模糊的指令产生模糊的输出，模糊的输出无法客观评估。 三、手动运行，暴露隐含假设 首轮运行的目的不是验证正确性，而是发现三类隐含假设： 触发假设：哪些 prompt 应该/不应该触发此 Skill 环境假设：是否依赖空目录、特定包管理器等前提 执行假设：Agent 是否跳过了它认为"不必要"的步骤 > 每一次手动修复都是未来 Eval 用例的候选项。 四、用小规模 Prompt 集捕获回归 10-20 个 prompt 足矣，关键是覆盖四种场景： · 显式调用：直接点名 Skill，确保基本调用链不断裂 · 隐式调用：只描述场景不提名字，测试语义匹配能力 · 带噪声的上下文调用：加入领域信息，测试真实 prompt 下的鲁棒性 · 负面控制不应触发的场景，防止误触发 原则：既测"该做的做了"，也测"不该做的没做"。随着真实失败的积累，逐步扩充这个列表。 五、确定性检查：锚定行为而非输出 通过 codex exec --json 获取结构化 JSONL 事件流，编写确定性规则： · 是否执行了 npm install？ · package.json 是否被创建？ · 命令执行顺序是否正确？ 优势：失败时可直接打开 trace 文件定位问题，完全可解释、可调试。 六、结构化评分表：覆盖定性需求 确定性检查无法覆盖代码风格、组件结构等定性要求。解决方案是用模型做判断，但用 JSON Schema 约束输出格式（--output-schema），确保评分结果可解析、可比较、可追踪。 这在两个极端之间找到了平衡： · 纯规则检查 → 太僵硬，无法覆盖模糊需求 · 纯模型评判 → 太不稳定，格式不一致 七、按需扩展，控制成本 按"成本从低到高"分层补充检查： · 命令计数与循环检测（从 trace 中统计） · Token 用量追踪（检测 prompt 膨胀） · 构建检查（npm run build） · 运行时冒烟测试（启动 dev server 验证） · 仓库清洁度与权限回归 原则：先用快速检查覆盖基线，只在能实质降低风险时才引入更重的检查。 八、核心原则总结 · 衡量真正重要的东西 · 从可检查的"完成定义"出发 · 评估锚定在行为上，而非仅看最终输出 · 规则不够时让模型辅助，但约束其输出格式 · 让真实失败驱动覆盖率增长 -- 更深层的价值与局限 --- 三个核心贡献： · 将 Skill 视为可测试的工程单元，把 prompt 迭代从"手艺"拉回到有测试、有度量的工程实践 · 基于执行轨迹的测试，不只看最终输出，还审查中间过程，实现对 Agent 行为的可观测性 · 确定性规则 + 模型评判的分层架构，兼顾速度/稳定性与灵活性 三个值得注意的局限： · 用模型评判模型输出时，评判本身的一致性未被充分讨论 · 每次 Eval 需实际运行 Agent，频繁迭代时的 API 成本不容忽视 · Skill 的触发依赖语义匹配，这本身是模型能力的边界问题，无法通过 Eval 根本解决 [图片: https://pbs.twimg.com/media/HA1_GTUaAAMrmrl?format=jpg&#x26;name=orig]

【8】A Language For Agents https://lucumr.pocoo.org/2026/2/9/a-language-for-agents/ 来自 @mitsuhiko 对 Agent 时代编程语言的思考，他认为：编程语言的设计假设...
A Language For Agents https://lucumr.pocoo.org/2026/2/9/a-language-for-agents/ 来自 @mitsuhiko 对 Agent 时代编程语言的思考，他认为：编程语言的设计假设正在过时，Agent 时代需要重新思考语言设计的基本取舍。 先说一句话结论： 显式、可 grep、本地可推理、确定性——从为"写代码的人"优化，转向为"读代码的机器与审查代码的人"共同优化。 根本逻辑 · 旧假设：打字昂贵，所以用简洁换效率（类型推断、动态类型、语法糖）。 · 新现实：写代码近乎免费，但代码总量爆炸式增长，理解代码的成本反而成为瓶颈。 · 结论：语言设计应从"优化书写"转向"优化理解"——同时服务于审查代码的人类和生成/消费代码的 Agent。 新语言为什么可行 · 训练数据中的存在感不是决定因素，工具链的友好程度才是（Swift 数据丰富但 Agent 仍挣扎）。 · 编码成本下降使生态广度不再是硬约束——缺库可以让 Agent 从其他语言移植。 · 新语言若采用 LLM 已熟悉的语法元素，可以快速被 Agent 掌握。 Agent 偏好的六个设计原则 1. 源码自解释：不依赖 LSP 就能读懂类型和语义；Agent 经常跳过 LSP 2. 大括号 > 缩进：缩进对 token 化不友好；但密集括号（Lisp 风格）同样有问题 3. 显式副作用标注：用 needs { time, rng } 声明依赖，格式化工具自动传播，测试时精确 mock 4. Result 类型 > 异常：Agent 对异常过度防御，typed result 提供更清晰的错误路径信息 5. 可 grep 可本地推理：包前缀（如 Go 的 context.Context）让符号来源一目了然；Agent 依赖 grep 而非索引 6. 确定性构建：一个命令，要么通过要么失败；禁止循环依赖；缓存测试结果 Agent 的四大痛点 · 宏：生成的代码对 Agent 不透明，而"减少手写代码"的理由已不成立 · Re-export 与别名：切断了声明位置与导入路径的对应关系，Agent 无法定位来源 · Flaky tests：Agent 擅长制造（过度 mock、非并发安全），却最不擅长诊断 · 模糊的失败状态：TypeScript 类型检查失败仍可运行，会误导 Agent 判断 [图片: https://pbs.twimg.com/media/HA17oqjakAA3Ln6?format=jpg&#x26;name=orig] Armin Ronacher ⇌: This weekend I was thinking about programming languages. Programming languages for agents. Will we see them? I believe people will (and should!) try to build some. https://lucumr.pocoo.org/2026/2/9/a-language-for-agents/

【9】好 很快可能就用不了了
好 很快可能就用不了了 Ben Jammin: My post about free Twitter APIs went viral. X suspended the whole service overnight. Here's another way to do it. Last week we showed how @composio lets you post, search, and pull data from X without paying for API access. The post blew up. Then X suspended Composio's [图片: https://pbs.twimg.com/media/HA0xdJHaAAAptFV?format=png&#x26;name=orig] [图片: https://pbs.twimg.com/media/HA0yY8zX0AAE1Rt?format=png&#x26;name=orig]

【10】很多人问这篇文章是人写的还是AI写的。 其实这个问题不言自明：此文是人指挥 AI 所写。 我和 Opus 一起写了 5 个小时，写到最后上下文爆表，每次发送 CPU 都飙升...
很多人问这篇文章是人写的还是AI写的。 其实这个问题不言自明：此文是人指挥 AI 所写。 我和 Opus 一起写了 5 个小时，写到最后上下文爆表，每次发送 CPU 都飙升到 100%。 文中所有的观点都是我口述的，所有的逻辑和观点我提出的，我还在最后修改了很久，确保每一个字都是我相信的，但大部分字都是 AI 推理出来的。 如果没有 AI 可以写吗？当然，只不过可能要花 10 个小时，也不会写得这么好。 最好的文章，能改变人的认知，进而影响人的行为。 拿到这个结果才是重要的，过程如何并不重要。 我再摘要一下文中的两段话： 新世界里人类的价值不是亲自干活，是决定干什么、为什么干。 前几天君晨说了一句很扎心的话：现在自己动手，反而显得自己没有动手能力。 未来人和人的差距，不取决于你自己能做什么，取决于你能驱动多少 Agent 为你做什么。 人类的需求从来就是结果，而不是软件。 只是过去没有别的选择，只能自己操作软件来获得结果。 而现在有了 Agent，它可以自己看文档学习操作软件，它可以百倍速地操作软件。 Agent 才是软件的新主人。 Orange AI: http://x.com/i/article/2020649239060340736

【11】RT Orange AI: 很多人问这篇文章是人写的还是AI写的。 其实这个问题不言自明：此文是人指挥 AI 所写。 我和 Opus 一起写了 5 个小时，写到最后上下文爆表，每次...
RT Orange AI 很多人问这篇文章是人写的还是AI写的。 其实这个问题不言自明：此文是人指挥 AI 所写。 我和 Opus 一起写了 5 个小时，写到最后上下文爆表，每次发送 CPU 都飙升到 100%。 文中所有的观点都是我口述的，所有的逻辑和观点我提出的，我还在最后修改了很久，确保每一个字都是我相信的，但大部分字都是 AI 推理出来的。 如果没有 AI 可以写吗？当然，只不过可能要花 10 个小时，也不会写得这么好。 最好的文章，能改变人的认知，进而影响人的行为。 拿到这个结果才是重要的，过程如何并不重要。 我再摘要一下文中的两段话： 新世界里人类的价值不是亲自干活，是决定干什么、为什么干。 前几天君晨说了一句很扎心的话：现在自己动手，反而显得自己没有动手能力。 未来人和人的差距，不取决于你自己能做什么，取决于你能驱动多少 Agent 为你做什么。 人类的需求从来就是结果，而不是软件。 只是过去没有别的选择，只能自己操作软件来获得结果。 而现在有了 Agent，它可以自己看文档学习操作软件，它可以百倍速地操作软件。 Agent 才是软件的新主人。 Orange AI: http://x.com/i/article/2020649239060340736

【12】巨大更新，为AI用的产品设计理念啊
巨大更新，为AI用的产品设计理念啊 Obsidian: Anything you can do in Obsidian you can do from the command line. Obsidian CLI is now available in 1.12 (early access). [视频: https://video.twimg.com/amplify_video/2021239296343330816/vid/avc1/1396x1080/pjDqw0ttAzv3qvOu.mp4?tag=21]

【13】🤔 《The Little Learner》：用 Scheme 与"Little”风格入门深度学习合适吗？
原标题： 《The Little Learner: A Straight Line to Deep Learning》 评分: 20 | 作者: AlexeyBrin 💭 先教 Scheme 学深度学习，不学微积分就能懂？ 🎯 讨论背景 《The Little Learner: A Straight Line to Deep Learning》被置入经典的 'Little' 系列脉络，引发读者对教学顺序和入门语言选择的讨论。评论主要围绕两点争议：是否应在掌握微积分和用 Python 建立直觉之后再学深度学习，以及 Scheme/Racket 是否比 Python 更适合作为第一门编程语言。讨论引用了个人经历（大学被动学 Java 导致厌恶编程）、替代读物建议（Fleuret 的 The Little Book of Deep Learning）和工具偏好（推荐 PyTorch、回忆 Matlab），并反复提醒 'Little' 系列通常面向已有基础的读者。评论里还提供了示例视频与其他入门资源链接以佐证不同路径的可行性。 📌 讨论焦点 先修数学与用 Python 入门深度学习 部分评论者认为不应把深度学习放在微积分之前或把 Scheme 放在 Python 之前来教。留言者回忆自己在纯数学课程被迫上以 Java 为主的 CS 课——大量记忆算法与数据结构，导致对编程反感，进而建议新手先学微积分并用 Python 做绘图以建立直觉，再读 Fleuret 的 The Little Book of Deep Learning 并用 PyTorch 实现简单模型以巩固理解。该观点强调项目式学习有益，但警告本书目录看起来可能对年轻或零基础读者不友好。另有评论指出 Fleuret 的小书更偏高层次的概念性总结，对需要实际实现的读者帮助有限，因此应谨慎选书与学习顺序。 [来源1] [来源2] [来源3] Scheme/Racket 作为首门语言的支持 另一派评论支持以 Scheme 或其方言 Racket 作为第一门编程语言，理由在于 Scheme 语法极简、只有一种主要做法，能减少学习时的分心和"多种做法”的困扰，相比之下 Python 的多样性和张冠李戴的特性可能成为干扰。有人贴出孩子使用 Scheme 的视频作为实证，指出历史上有不少用 Scheme 入门的先例，并称 Racket 是优秀的入门语言，但同时提醒这本书对完全零基础读者推进得很快。评论还指出 Java 的样板和风格容易把新手吓跑，并推荐其他入门资源（例如 Alice 相关读物）作为补充路径。 [来源1] [来源2] [来源3] [来源4] [来源5] "Little”书系的风格与目标读者 多条评论把《The Little Learner》放在经典的 'Little' 系列脉络中，列举 Little Schemer、Seasoned Schemer、Reasoned Schemer、The Little Typer、The Little Prover 等后续作品，强调该系列以插图与 Socratic（问答式）教学为特色。评论指出除第一本外，后续书籍普遍难度较高、面向编程语言爱好者，假定读者已有编程基础和基本微积分知识，因此并非为完全初学者设计。有人表示对《The Little Learner》印象良好，认为它延续了该系列的深度与趣味，但也警告它依然是一套严肃且具挑战性的文本；另外有人对"哪本是第一本”表示困惑，反映出系列定位对新读者并不直观。 [来源1] [来源2] [来源3] 📚 术语解释 Scheme: 一种简洁的 Lisp 方言，语法极简、强调函数式编程与表达式求值，常被用于编程语言教学与思想性练习。 Racket: 基于 Scheme 的方言与教学生态，提供更多工具和教育资源，常用于大学课程与作为入门语言的实践平台。 PyTorch: 一个以动态图（eager execution）著称的深度学习框架，适合实验与原型实现，评论中被推荐用于动手实现神经网络模型。 Matlab: 商业数值计算与可视化环境，科研与工程领域常用，用于快速原型、矩阵运算与绘图，部分评论者回忆在研究中使用过。 'Little' series: "Little”书系（如 The Little Schemer）是一组用插图与对话式（Socratic）问答风格讲述概念的书，风格看似轻松但常常深奥，通常面向已有一定基础的读者。 Socratic method: 问答式教学法，通过连续引导性问题让读者逐步推导出概念与证明，是 'Little' 系列常用的表现手法。

【14】🧰 Tambo 1.0：代理渲染注册 React 组件的开源工具包（支持 Zod，拟兼容 A2UI/MCP）
原标题： 《Tambo 1.0: Open-source toolkit for agents that render React components》 评分: 24 | 作者: grouchy 💭 把线上产品的 UI 随机交给模型，稳吗？ 🎯 讨论背景 Tambo 1.0 是一个开源工具包，目标让代理（agent）能渲染开发者事先实现并注册的 React 组件，从而以交互式 UI 回应用户，而非单纯文本。团队与评论里说明实现路径：通过 React SDK 注册组件并用 Zod schemas 定义组件结构，agent 通过工具调用选择组件并传入 props；当前不直接生成源码，但提供 skill 来辅助创建组件。讨论延伸到与 A2UI、MCP 等协议的兼容性与哲学差异——是否优先可预测的预构建界面或让模型即时生成界面，以及如何在互操作性与模型可理解性之间权衡。早期采用者在副项目和内部工具中试用并反馈良好，但社区也强调必须设计好验证与回退机制以应对模型生成错误。 📌 讨论焦点 对"batteries included”式封装的担忧 有评论指出那类试图把所有功能打包的库在 demo 阶段表现很好，但在真实生产应用中往往失去灵活性和可维护性。讨论中特别警示即时生成 UI 的风险，认为模型在运行时生成界面容易出错，降低可预测性。有人把 MCP Apps 提出作为对比，认为可确定性地预构建/打包界面能稳定返回可用结果，更适合需要高可靠性的场景。总体观点强调工程可控性、验证手段和明确的责任边界，而不是把 UI 制作完全交给模型即刻决定。 [来源1] [来源2] Tambo 的实现与开发者体验 Tambo 的工作流是通过 React SDK 把开发者自行编写的 React 组件注册进系统，并用 Zod schemas 描述组件的 props/结构，agent 在运行时选择哪个组件并传入 props，而不是从零生成完整界面。具体使用流程包括安装 React SDK、基于 Zod 注册组件，使 agent 能以 UI 组件而非纯文本回应用户；社区用户表示把 Zod 当作 LLM 结构化输出的单一可信源很方便。目前 Tambo 不直接生成组件源码（团队表示未来可能会扩展），但提供了一个 skill（npx skills add tambo-ai/tambo/components）来让 agent 协助创建新组件。团队还声明支持标准 schema 与多数流行类型库，并提供内置 agent 作为开箱即用方案，开发者无需自带代理，且已在内部迁移到 AG-UI events 以便事件处理。 [来源1] [来源2] [来源3] [来源4] [来源5] 标准与互操作性（A2UI、MCP、AG-UI） 有人询问 Tambo 与 Google 的 A2UI 的关系，团队回应表示可以支持 A2UI 并可能添加 A2UI renderer，从而让模型以结构化方式描述生成式 UI。关于 MCP（Model Context Protocol）和 MCP Apps 的讨论聚焦在设计哲学差异：MCP Apps 倾向于把界面作为可嵌入到其他代理中的应用，而 Tambo 是一个可嵌入的代理，目标是在主应用内直接渲染 UI。团队表明已支持大部分 MCP 规范并计划为 UI 添加支持，同时已迁移到 AG-UI events 并计划扩展跨标准兼容性。评论里也提醒标准只有在模型能直接理解时才高效，否则需要额外上下文或工具调用策略来桥接兼容性问题。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 应用场景与早期采用者 评论显示有实际用例和早期用户关注，例如 type.com 表示会用 Tambo 在聊天工作区内让用户构建轻量内部应用（如招聘跟踪）并与团队对接。社区用户反馈在副业项目中使用 Tambo 并把 Zod schemas 作为 LLM 输出的单一可信来源，体验良好。团队在评论区积极回应并安排进一步沟通，说明已有开发者在真实项目中试用该工具。总体上，早期采用者把 Tambo 看作较为"drop-in”的解决方案，能降低自建 agent 与 UI 协调的成本。 [来源1] [来源2] [来源3] 功能边界与未来路线 目前 Tambo 不会直接自动生成组件源码，团队表示正在构建一个 generative UI 库，短期仍以注册组件和 schema 驱动为主。已有可用扩展包括一个 skill（npx skills add tambo-ai/tambo/components），允许 agent 帮助创建组件，团队也列出了未来跨标准兼容和更多开箱功能的计划。评论多次提醒对自动生成 UI 的谨慎性，强调需要回退机制、验证与可控性，以防模型在运行时生成错误或不可用的界面。因此社区当前共识是短期内采用可验证的组件注册与 schema 驱动模式，长期探索生成能力与标准互操作性。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 Zod schemas: Zod 是一个 TypeScript/JavaScript 的模式验证与类型推断库，Zod schemas 用于声明组件 props 或 LLM 的结构化输出，常被当作单一可信源（source of truth）。 MCP Apps（Model Context Protocol Apps）: MCP Apps 指基于 Model Context Protocol 的应用规范，目标是在代理/模型生态中嵌入可复用界面，强调确定性和可嵌入性，常用于把界面暴露给其他代理平台。 A2UI: A2UI 是 Google 提出的协议概念，允许模型以结构化方式描述生成式用户界面（generative UI），便于前端按协议解析并渲染模型描述的 UI 元素。 类别： AI | Programming | Web | Release | Tambo | React | agents | tambo-ai | Zod | generative UI | A2UI | MCP Apps

【15】AIGC跨界大银幕！中国首部 AI 动画电影《团圆令》定档：以赠台大熊猫为原型，续写两岸同胞情
中国影视产业正在见证一场技术与情感的深度共鸣。 2026 年 2 月 10 日，中国首部 AIGC（生成式人工智能）动画电影《团圆令》 在北京举行定档发布会。该片由民革中央、中央广播电视总台共同指导，正式定档于 2 月 28 日 上映。 技术赋能：AI 笔触下的"团圆”寓言 作为国内首部全面应用人工智能技术生成的动画电影，《团圆令》不仅是技术创新的展示，更是中华文化传播的新探索。 原型故事 ：影片以大陆赠台大熊猫"团团”"圆圆”为原型，讲述了动漫 IP 形象"团仔”与"圆妞”兄妹离散寻亲、终得团圆的故事。 家国情怀 ：民革中央主席郑建邦指出，影片通过前沿科技淬炼出关于大团圆的寓言，旨在促进两岸心灵契合。 情感共鸣 ：海协会副会长马晓光表示，影片传递了两岸民众求和平、求交流的深切民意，展现了血浓于水的同胞亲情。 十年磨一剑：从舞台走向大银幕 "团仔”"圆妞”这一 IP 的背后是长达十余年的沉淀。 发展历程 ：该 IP 自 2014 年启动，此前已成功推出儿童舞台音乐剧、图书及有声读物等多维作品。 跨岸合作 ：其音乐剧曾邀请 台湾 少数民族艺术家参与创作，并在全球多地巡演，具有深厚的两岸合作基础。 行业意义：AI 电影时代的开端 中央广播电视总台副台长邢博强调，《团圆令》通过人工智能技术的创新表达，不仅增进了两岸的情感共鸣，也为弘扬家国文化提供了数字化新路径。 随着 2 月底的上映，这部融合了 顶尖 AI 技术与两岸温情故事的作品，或将开启 AIGC 技术在国产动画电影领域大规模应用的新纪元。

【16】📚 费曼《物理学讲义》（1961–64）：经典教材、练习缺失、相关讲稿与人物争议
原标题： 《The Feynman Lectures on Physics (1961-1964)》 评分: 20 | 作者: rramadass 💭 发明路径积分就能被免除人格争议吗？ 🎯 讨论背景 Feynman Lectures on Physics 是 Richard Feynman 在 1961–1964 年为加州理工学院（Caltech）本科开设的讲义集，后辑成书并广泛公开。讨论中除了称赞其文笔与以第一性原理讲解物理的教育价值外，还提到相关材料如 Lectures on Computation（费曼关于计算的讲稿）和 1959 年的 'There's plenty of room at the bottom'（提出纳米技术愿景的演讲）。社区关注点集中在原书缺乏习题、章节顺序非典型以及在现代课堂中如何补充实验、数值方法与练习。讨论亦延伸到如何在肯定其学术贡献（如 path integral、Feynman diagrams 与 QED 工作）的同时审视费曼的个人争议。 📌 讨论焦点 讲义的可读性与科学方法教育价值 许多评论称赞讲义文笔优美、以第一性原理和直觉式推理示范科学方法，读起来既是物理入门也是科研思维的示范。无考试压力时，读者能更好地体会费曼对现象的连带联想与哲学式阐述（评论中引用了其关于星空的抒情段落作为例证）。教师将整套讲义用作中级力学参考时，发现作者常省略某些推导，这既是短板也是布置填空式作业的良好素材。网络上可找到带讲前后聊天的录音，增加了历史语境和教学附加值。 [来源1] [来源2] [来源3] [来源4] 教材在教学中的局限：缺乏练习与非标准顺序 评论普遍指出原书缺少习题且章节顺序并非为标准大学课程设计，直接拿来做课程会带来组织与评估上的困难。有人提到存在一本配套的《Exercises for the Feynman Lectures on Physics》可作为补充，但教师通常仍需自行重排与挑选章节。费曼常省略细节推导，这一特点被看作双刃剑：对自学者是精炼，对授课则需补题或布置推导练习。总体上讲义更适合做为哲学性导读与直觉训练，而非完整的按部就班教材。 [来源1] [来源2] [来源3] 相关与补充资料：计算讲稿、纳米论断与特定讲座录音 评论推荐了若干费曼的相关作品作为补充：Lectures on Computation（费曼关于计算的讲稿）对 computability、information theory、entropy 与 thermodynamics 的解释被认为仍然有价值且不易过时。另有提到 1959 年的 'There's plenty of room at the bottom' 演讲，被视为现代 nanotechnology（纳米技术）设想的早期论述。还有人标注网站上单讲音频（例如 'The Principle of Least Action'）包含讲前后聊天，这些材料可扩展讲义的教学与历史背景。 [来源1] [来源2] [来源3] 时代性与教学更新问题 有人询问六十年后哪些内容需要更新或加以背景化；评论倾向认为许多基本概念与直觉仍适用，但需为学生补充现代实验背景与数值/方法论的发展。具体而言，Lectures on Computation 被评论者认为大体保持相关性，但课堂上常需加入例题、推导与现代示例以完成教学目标。因此讲义更适合作为参考与思维训练，教师在使用时通常要在内容组织与实践练习上进行现代化补充。 [来源1] [来源2] [来源3] 人物争议：私德批评与学术贡献的辩护 讨论出现针对费曼个人遗产的批评视频，激起是否应将个人行为与学术贡献分开评判的争论。反驳者强调他的核心学术贡献：以 path integral（路径积分）表述量子幅度、引入 Feynman diagrams（费曼图）并在 QED（quantum electrodynamics，量子电动力学）中实现可计算化的方法学突破。另一方则指出路径积分的思想有更早的历史渊源，提醒说学术归属并非没有争议。整体讨论反映出社区在肯定讲义与贡献价值的同时，也在审视如何平衡科学成就与个人品行的问题。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 path integral（路径积分）: 量子力学与量子场论的一种表述方法，将量子幅度表示为系统在所有可能路径上的积分，常用于推导传播子与计算 Feynman diagrams 的贡献，且与 QED 的可计算性推导密切相关。 类别： Science | Release | Feynman Lectures on Physics | Richard Feynman | Caltech | Physics | Path integrals

【17】亚马逊拟推 AI 内容交易平台，开辟版权授权"合规新战场”
面对人工智能行业日益胶着的版权诉讼与数据饥渴，亚马逊计划利用其云服务（AWS）的庞大生态，为出版商与 AI 开发者建立一座"合法贸易桥梁”。 据《The Information》周一报道，亚马逊已开始向出版业高管推介一个全新的 内容交易市场 。在周二举行的 AWS 出版商大会前夕，一份内部幻灯片展示了该平台的构想:出版商可以直接在该市场上架其内容资产（如文章、档案等），并向开发 AI 产品的科技公司进行授权。 [图片: 亚马逊a (4) https://pic.chinaz.com/picmap/201811151728184402_5.jpg] 从"被动抓取”到"透明市场” 长期以来，AI 训练数据的获取一直处于灰色地带。虽然 OpenAI 等公司已通过与美联社、新闻集团等机构签署个别协议来规避法律风险，但这种"一对一”的谈判模式难以规模化。 亚马逊模式 :拟将该市场与其 Bedrock（基础模型服务）等 AI 工具整合，使开发者能直接在云端获取合规、高质量的训练素材。 行业先行者 :微软近期也推出了类似的"出版商内容市场”（PCM），旨在提供透明的经济框架，让出版商自主定义授权条款。 出版商的"救命稻草”还是"饮鸩止渴”? 媒体机构正面临空前的流量危机。近期研究显示，谷歌等搜索引擎提供的"AI 摘要”导致网站点击率（CTR）出现断崖式下跌，部分站点流量损失甚至高达25% 至40%。 新商业模式 :出版商倾向于将这种市场化的系统视为比单纯的授权协议更具"可持续性”的模式。 既往案例 :亚马逊此前已显露野心，据报道其每年支付给《纽约时报》逾2000万美元用于 Alexa 等产品的 AI 训练及摘要显示。 亚马逊发言人虽未正面证实细节，但强调了其与出版业在 AGI 和 Alexa 领域的"长期创新合作”。随着监管压力增加，这个即将浮出水面的平台或将重新定义 AI 时代的版权价值。

【18】智谱 GLM-5 意外"泄露”？复用 DeepSeek 架构性能炸裂，市值狂飙 200% 坐稳国产 AI 顶流
国产大模型赛道在2026年春节期间爆点频出。继 DeepSeek 成为现象级产品后，智谱 AI 的新一代大模型 GLM-5 也揭开了神秘面纱。 这一动作直接引爆资本市场，智谱股价近期大涨 200% ，总市值冲至1500亿港币，达 IPO 时的3倍之多。 [图片: image.png https://upload.chinaz.com/2026/0211/6390639793589957751657905.png] 马甲曝光:神秘模型"Pony Alpha”即为 GLM-5 前几日，全球模型服务平台 OpenRouter 上出现了一款代号为 "Pony Alpha” 的匿名模型，因其代码编写能力直逼 Claude Opus 而引发全球热议。 身份确认 :该模型的系统提示词自曝为 GLM 身份。 "指纹”识别 :网友通过验证 GLM 家族特有的逻辑 Bug（如输入"锅内倒入植物油烧热”得到特定异常答案），几乎可以断定其归属。 [图片: image.png https://upload.chinaz.com/2026/0211/6390639795877963738227475.png] 核心黑科技:复用 DeepSeek 架构，参数翻倍 GLM-5在技术路线上选择了与DeepSeek-V3相同的 稀疏注意力架构 （DSA） ，这被视为一种极具性价比的演进策略。 规模跨越 :总参数量高达 745B ，是前代 GLM-4.7的2倍。 计算效率 :拥有256个专家，每次激活8个（约44B 激活参数），稀疏度仅为5.9%。 长文本与多模态 :支持 最高 202K token 的上下文窗口。 同时，针对2026年的市场需求，GLM-5强化了视频理解等多模态能力，补齐了此前DeepSeek纯文本架构的短板。 行业影响:部署门槛进一步降低 由于采用了 DSA 架构，GLM-5可以直接复用 vLLM、SGLang 等主流推理框架的现有优化方案。 这意味着企业级用户在部署该模型时，技术门槛和算力成本将大幅降低。 在国产 AI "偷家”海外大模型的浪潮中，智谱凭借 GLM-5的强悍表现，再次证明了其在模型性能与工程实现上的 顶尖 实力。

