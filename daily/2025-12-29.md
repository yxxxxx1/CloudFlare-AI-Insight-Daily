## AI洞察日报 2025/12/29

>  `AI 日报` 

### 今日摘要

【1】zapret-discord-youtube


【2】Mole
🐹 深度清理并优化你的Mac。

【3】Python
所有算法均用Python实现

【4】zapret-discord-youtube-linux
（目前仅支持NFTABLES）从Flowseal和bol-van移植zapret-discord-youtube，便于在Linux上使用

【5】vibe-kanban
让Claude Code、Codex或任何编程助手效率提升10倍

【6】RustPython
用Rust编写的Python解释器

【7】AI 初创公司 Scribe 获 7500 万美元融资，估值达到 13 亿美元
近日，AI 初创公司 Scribe 宣布获得7500万美元的融资，公司的估值已达到13亿美元。Scribe 旨在帮助企业更有效地采用人工智能，通过分析公司工作流程，提供改进建议，进而提升效率。Scribe 的工作原理是记录用户在浏览器或桌面应用中的操作，并生成可共享的文档，从而简化团队协作和培训过程。 [图片: 投资，融资，钱 https://pic.chinaz.com/picmap/201901101704279841_1.jpg] 该公司的产品 Scribe Capture 能够捕捉专业员工的工作方式，通过自动化生成文档，帮助企业快速创建标准操作程序（SOP）。这一功能不仅能节省时间，还能降低员工培训的难度，使新员工更快上手。Scribe 表示，其数据库中已经积累了超过1000万个工作流程，这些数据将为新客户提供参考，助力他们改善自身业务。 尽管 Scribe 的服务吸引了众多企业的关注，但也引发了对于数据隐私的担忧。许多评论者质疑，企业是否真的清楚自己的数据会被用来帮助竞争对手，甚至有观点认为这可能涉及到商业道德的问题。然而，Scribe 的团队强调，他们在与客户签署合同时，确保客户的内部数据不会被滥用。 划重点: 🌟 Scribe 获得7500万美元融资，估值达到13亿美元。 📈 公司分析工作流程，帮助企业提高效率和协作。 🔒 数据隐私引发关注，Scribe 承诺保护客户内部数据安全。

【8】几分钟拼出视频AI应用！开源框架VideoPipe让CV落地如搭积木般简单
近日，一款专注于计算机视觉（CV）领域AI算法快速集成落地的开源视频分析框架VideoPipe，在开发者社区引发热议。该框架以其创新的管线设计和极简上手体验，成为视频AI应用开发的"加速器”，帮助开发者从繁琐的底层编码中解放出来，专注于业务逻辑实现。 VideoPipe的核心设计:可组合管线，模块化拆解任务 VideoPipe采用独特的管道（Pipeline）架构，将复杂的视频分析任务分解为一系列独立的"节点”(Node)。每个节点负责单一功能，如拉流、解码、推理或推流等，节点之间相互独立，却可自由组合搭配。这种插件式设计，让开发者像搭积木一样构建应用，无需从零编写完整流程。 [图片: image.png https://upload.chinaz.com/2025/1229/6390259811605428404888937.png] 据框架文档介绍，只需准备好AI模型并解析其输出，即可通过简单配置快速组建管道。相比传统框架依赖重、调试难的问题，VideoPipe依赖极少、跨平台支持出色，更易移植到不同硬件环境。 多源输入与协议支持:无缝接入主流视频流 VideoPipe在数据读取方面表现出色，支持多种主流视频流协议，包括UDP、RTSP、RTMP，以及本地文件和应用程序图像输入。这使得框架适用于实时监控、流量摄像机等场景，能轻松处理网络流媒体或离线视频数据。 此外，它还兼容图片序列输入，扩展了在静态图像搜索或混合媒体分析中的应用潜力。 [图片: image.png https://upload.chinaz.com/2025/1229/6390259813645275101850616.png] 多样化推理引擎:深度学习+传统算法+多模态大模型 框架的 最大 亮点在于算法推理的灵活性。它支持深度学习模型的多级级联推理，同时兼容传统图像处理算法（如OpenCV经典方法）。更值得一提的是，VideoPipe已集成多模态大模型支持，允许开发者将前沿大语言视觉模型无缝嵌入视频处理流程中。 内置多种目标跟踪算法，确保在视频中对特定对象进行持续追踪，适用于动态场景下的精准分析。 全链路一条龙:从拉流到推流，一站式覆盖 VideoPipe几乎覆盖了视频AI应用的完整链路:拉流解码 → 多级推理 → 目标跟踪 → 行为分析 → 画框标注 → 录屏截图 → 编码推流 → 消息通知。开发者只需"缺哪块补哪块”，几分钟内即可拼出一个功能完整的视频AI原型。 典型应用场景包括: - 视频结构化处理 - 图像检索与搜索 - 人脸识别与追踪 - 交通事件检测（如违章识别、逆行监测） - AI换脸等创意应用 - 安防监控与行为分析 社区反馈积极:40+示例助力快速上手 VideoPipe提供超过40个现成示例，涵盖人脸识别、车辆检测、姿态估计等热门场景，配套详细文档和视频教程。近期社区分享显示，许多开发者利用该框架快速实现了智能监控原型和交通分析系统，极大缩短了从概念到落地的周期。 AIbase观点:在AI视频分析领域，VideoPipe的出现降低了工程门槛，让更多中小团队和个人开发者能高效落地CV应用。随着多模态大模型的集成，其潜力还将进一步释放。感兴趣的开发者可访问GitHub仓库（sherlockchou86/VideoPipe）星标体验。 项目地址：https://github.com/sherlockchou86/VideoPipe

【9】NVIDIA 发布 NitroGen：开创游戏代理的视觉行动基础模型
NVIDIA 的人工智能研究团队近日推出了 NitroGen，这是一款针对通用游戏代理的开放视觉行动基础模型。NitroGen 能够从网络视频中直接学习如何通过游戏画面和手柄操作来玩商业游戏，整个模型经过40，000小时的游戏体验训练，覆盖了超过1，000款游戏，同时还提供了开放数据集、通用模拟器和预训练策略。 [图片: image.png https://upload.chinaz.com/2025/1229/6390259785901648171941505.png] NitroGen 的构建流程始于公开的游戏视频，这些视频包含输入叠加层，如游戏手柄的可视化。研究团队收集了71，000小时的原始视频，经过质量过滤后，最终得到40，000小时的精选数据，涵盖了818位创作者的38，739个视频。数据显示，这些视频跨越846款游戏，其中34.9% 的游戏时间来自动作角色扮演类游戏，18.4% 来自平台类游戏，9.2% 来自动作冒险类游戏，剩余则涵盖了体育、 roguelike、赛车等多个类别。 在提取每帧动作的过程中，NitroGen 使用了三阶段的提取流程。首先，系统通过300个控制器模板定位手柄叠加层。接着，使用基于 SegFormer 的分类分割模型解析手柄区域，最后对坐标进行精细化处理。这一流程确保了动作预测的准确性，使得 NitroGen 能够有效进行大规模行为克隆。 此外，NitroGen 还配备了一个通用模拟器，它能够将商业 Windows 游戏包装为兼容 Gymnasium 的接口，支持逐帧互动，且无需修改游戏代码。这使得 NitroGen 可以在多个游戏中直接应用同一策略。 NitroGen 采用了基于 Diffusion Transformer 的策略架构，该模型在256×256分辨率的 RGB 图像上运行。经过预训练后，NitroGen 在多个任务上展现了良好的零 - shot 评估能力，任务完成率在45% 至60% 之间。该模型的预训练使其在迁移到新游戏时，表现出显著的性能提升，相较于从头训练，提升幅度可达52%。 huggingface:https://huggingface.co/nvidia/NitroGen 划重点: 📊 NitroGen 是一款开放视觉行动基础模型，能够从网络视频中直接学习游戏操作。 🎮 数据集涵盖40，000小时游戏视频，覆盖超过1，000款游戏。 🚀 预训练的 NitroGen 在新游戏中的表现显著提升，相较于从头训练有高达52% 的性能改善。

【10】智谱 GLM-4.7 横扫编程大赛，重塑开源 AI 未来！
年底的科技圈再度掀起波澜，智谱科技 最新 推出的 GLM-4.7模型不仅在代码竞技场的 WebDev 榜单上超越了 GPT-5.2，荣登开源大模型 第一 ，还引发了网友们的热烈讨论和实测狂潮。这个被称为 "Claude Code 最佳 平替” 的国产模型，以其卓越的编程表现和灵活的应用能力，让人眼前一亮。 [图片: image.png https://upload.chinaz.com/2025/1229/6390259710184018643719621.png] 智谱团队在一次 AMA（Ask Me Anything）活动中，详细揭示了 GLM-4.7的技术进步之道。团队表示，GLM-4.7的成功得益于后训练阶段的优化，特别是在监督微调(SFT)和强化学习(RL)方面，采用了更为精细的发布配方，使得模型在实际应用中的稳定性大幅提升。此外，团队还强调，训练和部署成本是设计的关键考量，他们希望让模型能够在消费级显卡上运行，并保持出色的性能表现。 GLM-4.7的应用场景更是丰富多彩。与之前版本相比，这款模型在多语言编码方面表现优异，支持包括 Python 和 JavaScript 在内的多种编程语言，并在创意写作方面也显得更加灵动。开发者们在调试和执行复杂任务时，GLM-4.7展现出更高的理解力和逻辑能力，甚至在角色扮演任务中也能保持角色一致性，减少 "出戏” 的现象。 [图片: image.png https://upload.chinaz.com/2025/1229/6390259708218013471152284.png] 此外，智谱在 AMA 中宣布开源其自研的 Slime 框架，旨在提升大模型强化学习的效率和稳定性。团队表示，开源生态是他们成长的动力，将继续保持开源承诺，即便在公司上市之后也不会缩减对开源的投入。 通过这些技术革新，智谱 GLM-4.7正逐步展现出国产 AI 模型在国际舞台上的竞争力，赢得了用户的高度认可。随着 AI 技术的快速发展，智谱团队也透露将在明年为人工智能的广泛应用作出更多贡献，值得期待。

【11】⏳ 纽约 Water Tunnel #3：1954 启动，历经 62 年即将完工
原标题： 《62 years in the making: NYC's newest water tunnel nears the finish line》 评分: 20 | 作者: eatonphil 💭 修了 62 年才接近完工，这是奇迹还是预算黑洞？ 🎯 讨论背景 Water Tunnel #3（纽约市第三供水隧道）是一个分段、多年代施工的大型基础设施项目，最早在 1954 年启动，目的是为城市提供更可靠、冗余的输水路径。讨论基于工程学与城市规划的前提，集中在为何要在深处穿越基岩（以避免软土问题）、如何保证水流（重力坡降 versus 泵站）、以及跨河和绕行现有地下设施的设计权衡。评论还提到该隧道部分段已向曼哈顿和布朗克斯供水，最终段将把服务扩展到布鲁克林与皇后区，官方预计 2032 年完成最后阶段。公众把该长期工程与流行文化（如电影 Die Hard 第三部）和其他高成本项目（如 CA HSR，即加州高铁）作比较，表达既惊叹又质疑的混合情绪。 📌 讨论焦点 长期工程历史与流行文化 评论指出该工程始于 1954 年，标题中的"62 years in the making”与有人称之为"70 year old project”的说法一致，凸显项目跨代的长期性。多条评论以电影引用放大这一点：第三部《Die Hard》曾以该隧道为场景，成为公众记忆中的文化注脚。这种文化联想被用来表达对工程历时、历史沉淀以及大众关注度的惊讶与戏谑。 [来源1] [来源2] [来源3] [来源4] 工程与地质理由（深度、坡度与输水方式） 核心讨论围绕为何隧道深埋（约 800 英尺）与输水方式：回复指出深度主要用于穿越基岩（bedrock），以减少软土引起的沉降、渗漏和施工并发症，从而提高隧道的长期稳定性。评论还强调这是约 60 英里的输水干线，水流要么依靠重力坡降（hydraulic gradient）要么依赖泵站；有人推测因供水水库接近海平面，部分路段必须更深以跨越河道或城市地下结构。具体数值被拿来比较以说明坡度影响：密西西比河梯度约 0.01% ，与讨论中假设的 0.25% 相差 25 倍，这展示了坡度对是否需要泵和设计复杂度的直接影响；原问题关于随深度增加的钻掘能量与成本也被提出但未给定精确比例，讨论以工程可持续性为核心理由。 [来源1] [来源2] [来源3] [来源4] 项目现状与完工进度 评论信息表明工程已分段投入使用：布朗克斯（Bronx）和曼哈顿已从 Water Tunnel #3 取水，但最后一段将服务布鲁克林与皇后区仍在施工中，官方预计该最终阶段将在 2032 年前完成。有人提到施工曾在十年前一度停工并后来重启，因此公众对重启进度、资源调配与时间表保持关注。评论里还有对在最终段注水、隧道封闭前能否开放参观的期待，反映公众对这一工程可见性的兴趣。 [来源1] [来源2] 戏谑与高成本对比 多位评论以讽刺和玩笑回应工程的时间与成本：有人提到若重拍《Die Hard》应加入 CA HSR（加州高铁）式的昂贵基础设施桥段以凸显代价。简短调侃诸如"Die Hard: The most expensive mile”之类的表述把公众对大规模基建长期耗时与高成本的不满和幽默反应结合起来。这类评论既是对工程规模的感慨，也是对预算与效率的隐含质疑。 [来源1] [来源2] [来源3] 📚 术语解释 Water Tunnel #3: 纽约市第三供水隧道（Water Tunnel No. 3），是分阶段建设的大型输水工程，旨在为多个行政区提供更可靠的水源通道，工程始于 20 世纪中期并分段投入使用，最终段计划在 2032 年前完成。 bedrock（基岩）: 位于土层下的坚硬岩体，隧道穿越基岩可减少沉降与渗水风险并提高衬砌稳定性，但钻掘和掘进成本通常更高且技术要求更大。 hydraulic gradient（水力坡降 / 下坡坡度）: 单位距离的水头差决定重力驱动流动的能力；坡降越小需要的落差或泵站越多，评论中以密西西比河约 0.01% 与讨论中的 0.25% 比较来说明坡度对设计和是否需泵的影响。 类别： Policy | Science | Water Tunnel #3 | New York City | NYC Department of Environmental Protection | NY1 | water tunnel | bedrock | Manhattan | Brooklyn | Queens | Bronx

【12】​以简胜繁:Meta AI 推出 Pixio 图像模型，凭借像素重建刷新3D 重建纪录
据 AIbase 报道，Meta AI 的研究团队近日发布了一项名为 Pixio 的图像模型研究，证明了即使采用更简单的训练路径，也能在深度估计和3D 重建等复杂视觉任务中展现出卓越的性能。长期以来，学术界普遍认为掩码自编码器（MAE）技术在场景理解上逊色于 DINOv2或 DINOv3等复杂算法，但 Pixio 的出现打破了这一固有认知。 [图片: QQ20251229-091312.png https://upload.chinaz.com/2025/1229/6390259643186984376940473.png] Pixio 的核心逻辑源于对2021年 MAE 框架的深度改良。研究人员发现，原始设计中较弱的解码器限制了编码器的表现，因此他们显著增强了解码器的功能，并扩大了图像遮罩区域。通过将细小的遮罩方块改为大面积连续区域，Pixio 被迫放弃简单的像素复制，转而必须真正"理解”图像中的物体共现、3D 透视以及反射等空间关系。此外，通过引入多个用于聚合全局属性的类别标记，该模型能更精准地捕捉场景类型、相机角度及光照信息。 [图片: QQ20251229-091319.png https://upload.chinaz.com/2025/1229/6390259644029938178427847.png] 在训练策略上，Pixio 展现出 极高 的纯粹性。不同于 DINOv3针对特定基准测试（如 ImageNet）进行重复优化，Pixio 从网络收集了20亿张图像，并采用动态频率调整:减少简单产品照的权重，增加复杂场景的训练频次。这种不针对测试集"刷分”的做法，反而赋予了模型更强的迁移能力。 [图片: QQ20251229-091337.png https://upload.chinaz.com/2025/1229/6390259645040772726545844.png] 数据对比显示，仅拥有6.31亿参数的 Pixio 在多项指标上超越了8.41亿参数的 DINOv3。在单目深度估计中，其准确率提升了16%;在3D 重建任务中，仅凭单张图像训练的 Pixio 甚至优于使用八视角训练的 DINOv3。同时，在机器人学习领域，Pixio 也以78.4% 的成功率领先于 DINOv2。尽管研究团队承认人工掩蔽存在局限性，并计划向视频预测方向探索，但 Pixio 目前取得的突破已足以证明:回归像素重建的本质，往往能通向更深层的视觉理解。

【13】当我们把思考外包给 AI，我们失去了什么？ 你有没有发现，自己正在变成一个机器人观点的专业验证员？ 微软研究院的 Advait Sarkar 在一场 TED 演讲中抛出了这个...
当我们把思考外包给 AI，我们失去了什么？ 你有没有发现，自己正在变成一个机器人观点的专业验证员？ 微软研究院的 Advait Sarkar 在一场 TED 演讲中抛出了这个扎心的问题。他描绘了一幅我们都很熟悉的场景：早上到办公室，邮件太多，让 AI 总结一下；报告不知道怎么写，丢点资料让 AI 起草；数据要分析、PPT 要做、代码要写——全都交给 AI。 这不是科幻，这是我们的日常。 Sarkar 给这个时代起了个名字：理性外包的时代 (the age of outsourced reason)。我们不再直接接触工作的原材料，而是变成了「智力游客」，在自己的工作中，我们只是参观观点，而非栖居其中。 四重隐性代价 Sarkar 引用了一系列研究，揭示了这种工作方式的认知代价： 1、创造力在萎缩。 研究表明，使用 AI 助手的知识工作者，集体产出的想法范围比手动工作的小组更窄。我们创造了一个蜂巢思维，但这个蜂巢很无聊，总是重复建议那几个想法。 2、批判性思维在偷懒。 当人们对 AI 越信任、对自己越不信任时，他们在批判性思维上投入的精力就越少。我们不再质疑，只是点头。 3、记忆力在退化。 依赖 AI 写作时，人们对自己写的内容记得更少；阅读 AI 摘要时，记住的也比读原文少。 4、元认知在超载。 以前直接处理材料时，「该怎么做」是内置在过程中的。现在我们要不断思考：这个任务适合让 AI 做吗？AI 的输出对不对？我该怎么评估？ Sarkar 用了一个精准的比喻：我们变成了自己思想的「中层管理者」，不再动手做事，只是审批和转发。 他还说了一句让我印象深刻的话：以前的写作障碍是对着空白页发呆；现在是对着 AI 填满的页面发呆，还得琢磨自己同不同意它的观点。 思维工具，而非服从的助手 问题来了：难道我们要放弃 AI 吗？ 当然不是。Sarkar 提出的方案是重新定义 AI 的角色，AI 应该成为「思维工具」，而不是助手。AI 应该挑战我们，而不是服从我们。 他和团队开发了一个原型工具来演示这种范式。在这个工具里，一位叫 Clara 的知识工作者需要写一份提案。但他的工作方式和我们习惯的丢资料给 AI 写完全不同： - 他看到的不是简单的摘要，而是可定制的「透镜」，能强调与当前任务最相关的内容； - 他在阅读时会看到 AI 生成的「激发项」，不是补全他的想法，而是提出替代方案、识别谬误、提供反驳论点； - 他手动构建论点大纲，保持与源文档的深层连接； - 最后生成的文本虽然是 AI 写的，但深深植根于他自己的思考过程 Sarkar 特别指出：在这个界面里找不到聊天框。Clara 不需要和任何东西聊天来完成工作，他是作为计算机的用户被辅助着，而不是面对一个伪人类。 三个设计原则 这套方案背后有三个核心原则，我认为对每一个使用 AI 的人都有启发： 1. 保留材料接触 Clara 仍然亲自阅读了文档的相关部分，亲自构建了决策和论点。AI 帮他更快、更有策略地阅读，但没有替代阅读本身。 这意味着什么？当你用 AI 分析一份报告时，不要只看 AI 给你的摘要。至少挑出 AI 标记为重要的 2-3 个段落，自己读一遍。当你用 AI 写代码时，不要只是复制粘贴，花几分钟理解它的逻辑。 保留材料接触，是为了保留你与工作之间的直接关系。否则，你只是在「参观」自己的工作，而不是「拥有」它。 2. 提供生产性阻力 传统 AI 助手的设计逻辑是「顺从」，你说什么，它就做什么。但 Sarkar 的原型里，AI 会主动提出挑战：这个论点有什么漏洞？有没有考虑过相反的观点？这个假设成立吗？ 这些激发项不是为了让你照单全收。Sarkar 说得很好：如果你对工作理解得足够深，能自信地决定不接受某条反馈，那么反馈机制依然在按预期运作。 被挑战本身就是价值所在。 在日常使用中，你可以主动要求 AI 扮演这个角色：「请指出我这个方案的三个潜在问题」、「如果有人反对这个观点，他们会怎么说？」。 3. 搭建元认知支架 元认知就是「思考自己的思考」。当我们直接处理材料时，这个过程是自然发生的，你写着写着会停下来想「我到底要说什么」。但当 AI 介入后，这个过程被打断了，我们反而要花更多精力在管理 AI 而不是思考问题上。 好的思维工具应该帮你重建这个支架。在 Clara 的工作流里，每一阶段的激发项都让他保持元认知层面的参与，时刻意识到自己在做什么、为什么这么做、还有什么没考虑到。 你可以借鉴这个思路：在使用 AI 完成一个任务后，花 30 秒问自己三个问题：我真的理解这个输出吗？我同意它的逻辑吗？如果要向别人解释，我能说清楚吗？ [图片: https://pbs.twimg.com/media/G9TGpqMaIAAc7VG?format=jpg&#x26;name=orig]

【14】运气 = 深入做事 × 广泛分享 来自 GitHub ReadME Project 的指南，由 Tuple 公司的营销工程师 Aaron Francis 撰写。核心观点是：通过公开分享你的工作（尤其是...
运气 = 深入做事 × 广泛分享 来自 GitHub ReadME Project 的指南，由 Tuple 公司的营销工程师 Aaron Francis 撰写。核心观点是：通过公开分享你的工作（尤其是开源项目、学习心得或创作过程），你可以显著增加"运气”降临的机会。这里的"运气”指那些意外的积极事件，如开源库突然流行、收到演讲邀请、找到新工作或结识行业朋友，我自己也非常认同！ 1. 先要做事 发布的前提是有内容可分享。大多数开发者已经擅长这一步，但有两类人可能卡住： · 觉得自己工作不值得分享：专家常低估自己的知识。建议观察社区，看看别人分享什么就能发现机会——很多人正需要你已经掌握的知识。 · 想开始却无从下手：建议立即从小事开始，今天就行动。动力会带来更多动力。 从哪里找内容？ · 工作之外：跟随好奇心，公开探索感兴趣的话题（好奇心具有传染性）。 · 工作之中：将遇到的难题、模式或心得转化为可分享的内容（如博客、演讲、开源代码）。建议平时记录工作中的"困惑点”，一个月后就会积累大量素材。注意：不是分享公司机密，而是通用概念和经验教训。 2. 敢于发布 很多人卡在这一步，原因是恐惧：怕被嘲笑、怕作品不完美、怕显得自夸，或单纯讨厌"营销”。 作者的建议： · 审视自己的恐惧：分享不是自大，而是帮助他人学习、激发创作。 · 人们更喜欢看到"正在行动的人”，而不是完美成果。 · 发布平台：X（AI 聚集地）、GitHub、Newsletter、Blog、YouTube、播客、论坛等——总之，别让作品只留在自己硬盘上。 · 发布是一项技能：需要练习。不要等完美，先分享过程、成功与失败。刚开始会觉得别扭，坚持下去就自然了。 3. 收获运气 当你持续做事并公开分享时，好事自然发生： · 别人会把你视为某个领域的"代表人物”。 · 收到邮件、DM：工作机会、咨询邀请、演讲请求、结识新朋友。 · 开源项目获得关注和贡献。 这听起来简单，但做起来不容易——公开意味着可能面对批评。但作者强调：负面声音总是少数，更多人是默默欣赏你的勇气。其中一人伸出的机会，就可能改变人生。你会感慨："哇，运气来了！” 博客地址 https://github.com/readme/guides/publishing-your-work [图片: https://pbs.twimg.com/media/G9TIMV5bkAAlnXZ?format=jpg&#x26;name=orig] Garry Tan: If you build it, don’t forget to publish it https://github.com/readme/guides/publishing-your-work

【15】「Context Graphs」关乎未来万亿级 AI 平台，那我们应该如何构建它呢？ 作为「AI’s trillion-dollar opportunity: Context graphs」的实践构建篇，PlayerZero ...
「Context Graphs」关乎未来万亿级 AI 平台，那我们应该如何构建它呢？ 作为「AI’s trillion-dollar opportunity: Context graphs」的实践构建篇，PlayerZero 创始人 Animesh Koratana 这篇长文证明我们需要构建一个新层：捕捉决策过程的"上下文图”，让 AI 能访问从数据到行动的完整推理痕迹，从而形成可积累的组织智能。 如何实际构建这样的上下文图？不是简单添加内存或工具，而是需要从根本上重新思考数据和决策的捕捉方式。上下文图本质上是组织的"世界模型”，它通过积累 AI Agents 的执行轨迹，来学习组织的动态结构和决策规律，先看总结的三个关键点： · 重建事件时钟（捕捉推理而非仅状态） · 让本体从 Agents 轨迹中自然输出（结构嵌入而非语义嵌入） · 转向世界模型而非检索系统（支持模拟和反事实推理） 1. "两个时钟问题” 当前所有企业系统都只优化了"状态时钟”：记录当前事实（如交易关闭、配置值）。但忽略了"事件时钟”：记录事情如何发生、为什么发生、决策背后的推理。 · 比如：代码配置从5秒超时改为30秒，系统只记录当前值，却丢失了"为什么改”的讨论。 · 后果：人类过去通过对话重建上下文，但AI缺乏这些"为什么”，导致决策缺乏先例支持。 · 难点： · 系统不完全可观测（黑箱、第三方服务）。 · 无通用本体（每个组织实体和关系不同）。 · 一切都在变化（动态环境）。 传统知识管理（如文档检索）失败的原因，就是只处理静态状态，而非动态过程。 2. "Agents 作为有指导的漫游者” 构建上下文图的关键不是预定义静态图结构，而是让 AI Agents 在解决问题时自然"遍历”组织状态空间。 · Agents 执行任务时，会访问各种系统、API、数据，形成一条"轨迹”。 · 这些轨迹类似于图嵌入学习中的"随机漫游”：通过大量漫游，统计共现模式，就能自动学习图的结构。 · 不同之处：Agents 的漫游是"有指导的”，偏向真实重要的问题路径，更高效地揭示组织本体。 · 结果：不需要提前定义 schema，本体从使用中浮现。实体共现频繁的即重要；路径相似的即结构等价。 · 经济闭环：Agents 解决有价值的问题产生轨迹 → 轨迹改善上下文 → 上下文让 Agents 更强 → 更多部署。 3. "上下文图是组织的世界模型” 积累足够轨迹后，上下文图不再是简单检索系统，而是成为组织的"世界模型”： · 编码"组织物理学”：决策如何传播、例外如何处理、变更的连锁效应等。 · 支持模拟：预测"如果这样做，会发生什么？”。 · 示例：在 PlayerZero 中，他们用积累的生产问题轨迹构建模型，模拟代码变更对生产的影响，预测故障模式和受影响客户。 · 更深层含义：这避免了"持续学习”的难题。 · 替代方案：保持基础模型固定，通过不断扩展世界模型来"伪学习”，用推理时计算模拟未来、评估行动。 这类似于资深员工的直觉：不是模型变聪明，而是内部世界模型更丰富，能预判结果。 [图片: https://pbs.twimg.com/media/G9TF8PebQAAb9DB?format=jpg&#x26;name=orig] Jaya Gupta: Part 2: How to build a context graph

【16】Nano Banana这波真的是给图文营销带来了很多不一样的机会 比如做到店流量的 店家上传自己的实拍门店照片 ai就能基于这些实体背景 加个美女 小红书上就能跑流量 ...
Nano Banana这波真的是给图文营销带来了很多不一样的机会 比如做到店流量的 店家上传自己的实拍门店照片 ai就能基于这些实体背景 加个美女 小红书上就能跑流量 弄两三个水军问问这是在哪儿 做一个置顶评论就引流了 2年前comfyui想搞这种东西 做几十个节点多重处理都费劲 已经营销素材自由了

【17】Jim Fan 的「机器人领域 2025 年三点经验」 作为 NVIDIA 资深研究科学家、通用具身智能研究团队负责人，Jim Fan 在机器人和具身智能领域具有重要影响力。他以节...
Jim Fan 的「机器人领域 2025 年三点经验」 作为 NVIDIA 资深研究科学家、通用具身智能研究团队负责人，Jim Fan 在机器人和具身智能领域具有重要影响力。他以节日轻松语气分享了对机器人研究"狂野西部”现状的焦虑与反思，总结了 2025 年亲身经历的三点关键教训。 第一点：硬件领先于软件，但硬件可靠性严重制约软件迭代速度 当前，人形机器人硬件已取得显著进步，例如 Tesla Optimus、Boston Dynamics 电动 Atlas、Figure 系列、1X NEO、Unitree G1 等前沿机型在机械设计、关节灵活性和运动能力上表现出色。这些硬件的物理潜力往往超出当前 AI 控制能力的极限——"身体比大脑更强大”。 然而，实际研发中，硬件的脆弱性成为最大痛点：机器人容易过热、电机损坏、固件故障频发，与人类不同，它们无法自我修复。小错误可能导致永久损伤，每次实验都需要专业团队维护。这大大降低了 AI 模型的迭代速度：软件训练需要大量真实数据和反复试错，但硬件问题使实验成本高昂、周期漫长。Jim Fan 感慨，只有自己的"耐心”实现了规模化增长。这反映了 2025 年机器人领域的普遍挑战：硬件工程精湛，但可靠性仍需大幅提升，以支持高效的软件开发循环。 第二点：机器人基准测试仍是一场灾难 在 LLM 领域，MMLU、SWE-Bench 等标准化基准已成为共识，推动了公平比较和进步。但机器人领域远未达到这一水平：硬件平台、任务定义、评分标准、模拟器 vs. 真实环境等均无统一规范。 结果是，每个团队或公司往往自行定义"基准”，并在新闻发布时宣称 "SOTA”。演示视频通常从上百次尝试中挑选最完美的片段，缺乏可重复性和科学严谨性。这导致行业进步难以量化，容易陷入炒作而非实质创新。Jim Fan 呼吁 2026 年机器人社区共同努力，建立更规范、可复现的基准体系，将科学纪律置于首位。 第三点：基于 VLM 的 VLA 模型方向可能有误 VLA（视觉-语言-行动模型）是当前机器人"大脑”的主流范式：取预训练的 VLM（视觉-语言模型），在其上添加行动输出模块，实现从图像+语言指令直接生成机器人动作。 但 Jim Fan 认为这一路径存在根本问题： · VLM主要针对视觉问答等基准优化，大量参数用于语言知识和高层次语义理解，而非物理世界低级细节。 · 视觉编码器在训练中主动丢弃细粒度信息，但机器人灵巧操作高度依赖这些细节。 因此，随着 VLM 参数规模扩大，VLA 性能未必线性提升——预训练目标与机器人控制需求不匹配。 他更看好"视频世界模型”作为预训练目标：通过预测视频序列学习物理动态、因果关系和低级视觉细节，更适合生成机器人策略。这是一种对未来方向的重大押注，暗示需从基础预训练范式上重新思考。 [图片: https://pbs.twimg.com/media/G9TC1ApWUAArhWQ?format=jpg&#x26;name=orig] Jim Fan: Everyone's freaking out about vibe coding. In the holiday spirit, allow me to share my anxiety on the wild west of robotics. 3 lessons I learned in 2025. 1. Hardware is ahead of software, but hardware reliability severely limits software iteration speed. We've seen exquisite [图片: https://pbs.twimg.com/media/G9Rk1T9bMAE_l5V?format=jpg&#x26;name=orig]

【18】最近看了下 Cloudflare 的 2025 年互联网年度回顾，还挺有意思的。 生成式 AI 这块，Claude、Perplexity、Gemini 已经实打实地站到了 ChatGPT 的对面，不再是备...
最近看了下 Cloudflare 的 2025 年互联网年度回顾，还挺有意思的。 生成式 AI 这块，Claude、Perplexity、Gemini 已经实打实地站到了 ChatGPT 的对面，不再是备选方案。 社交平台这边，在 Facebook、Instagram、TikTok 之后，Snapchat 的整体表现已经超过了 X，而所谓的元宇宙里，Roblox 依然是那个最稳的。 整体来看，Google 还是第一，但 Instagram 和 YouTube 在 2025 年都挤进了前十。 Tw93: Cloudflare’s Internet Year in Review 2025 is worth a read. https://radar.cloudflare.com/year-in-review/2025 A few signals really stand out: Generative AI continued its rapid rise — Claude, Perplexity, and Gemini have clearly emerged as the main rivals to ChatGPT. On social platforms, after Facebook, [图片: https://pbs.twimg.com/media/G9Qn83vasAAGNFo?format=jpg&#x26;name=orig]

