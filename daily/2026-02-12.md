## AI洞察日报 2026/2/12

>  `AI 日报` 

### 今日摘要

【1】RT Cursor: We've raised limits for Auto and Composer 1.5 for all individual plans. Individual plans now have 3x usage of Composer 1.5 versus Composer ...
RT Cursor We've raised limits for Auto and Composer 1.5 for all individual plans. Individual plans now have 3x usage of Composer 1.5 versus Composer 1. For a limited time (through February 16), we're increasing that to 6x.

【2】RT Jackywine: Re @Yangyixxxx Vibecoding 了一个推特数据看板 第一时间看到大 V 的百万热贴 分析人设、口头禅 推文创作技巧 有种被扒光的感觉，太狠了
RT Jackywine Re @Yangyixxxx Vibecoding 了一个推特数据看板 第一时间看到大 V 的百万热贴 分析人设、口头禅 推文创作技巧 有种被扒光的感觉，太狠了 [视频: https://video.twimg.com/amplify_video/2021758002139971584/vid/avc1/1106x720/qiv8GMKDzGTt_snB.mp4?tag=21]

【3】Shell + Skills + Compaction OpenAI 对"长时运行 Agent 如何真正工作"给出的官方答案 https://developers.openai.com/blog/skills-shell-tips Agent 需要什么才...
Shell + Skills + Compaction OpenAI 对"长时运行 Agent 如何真正工作"给出的官方答案 https://developers.openai.com/blog/skills-shell-tips Agent 需要什么才能"真正工作"？ 1. 执行能力：Agent 不能只"说"，还得"做"：安装依赖、运行脚本、写出文件 -- Shell 2. 流程一致性：Agent 不能每次都从 system prompt 临时推理怎么做，需要稳定的程序化流程 -- Skills 3. 上下文连续性：长时任务必然超出上下文窗口，Agent 不能"失忆" -- Compaction 三个原语的技术细节 1. Skills：从 Prompt 工程到 Skill 工程 关键设计是渐进式披露 · 启动时：平台只向模型暴露所有 Skill 的 name + description（约 100 token/skill） · 激活时：模型决定调用某 Skill，才加载完整 SKILL. md（建议 &#x3C; 5000 token） · 按需时：references/ 和 scripts/ 中的文件只在需要时才读取 2. Shell：从"能说"到"能做" - 两种模式： · Hosted Shell：OpenAI 托管的容器，通过 Responses API 调用，Agent 在沙盒中运行完整 Linux 环境（含 Python 运行时），产物写入 /mnt/data/ · Local Shell：开发者自己控制的本地执行环境，语义相同但由开发者执行 shell_call 并返回 shell_call_output 3. Compaction：长时运行的生命线 - 两种模式： · 服务端自动压缩：在 Responses API 请求中设置 context_management 的 compact_threshold（如 200,000 token），当上下文超过阈值时，服务端在流式响应中自动触发压缩，输出一个加密的 compaction item。这个 item 是不透明的——对人不可读，但携带了模型继续工作所需的关键状态和推理。 · 独立压缩端点：/responses/compact，完全无状态，开发者显式控制何时压缩。发送完整上下文窗口，返回压缩后的窗口（包含 compaction item + 保留的重要条目） -- OpenAI 的十条实战经验 -- 1. Skill 描述是路由逻辑，不是营销文案 写明"何时用 / 何时不用 / 输出是什么"，让模型能做出清晰的调用决策。 2. 加负例和边界条件，防止路由误触发 Glean 实测：添加 Skills 后触发率反降 20%，补充"Don't call when..."后恢复。相似 Skills 之间必须显式消歧。 3. 模板和示例放进 Skill，别塞 system prompt Skill 内的模板只在激活时消耗 token，未使用时成本为零——这是惰性加载，不是冗余堆叠。 4. 从第一天就为长时运行设计：容器复用 + Compaction 复用同一容器保持依赖和中间文件，用 previous_response_id 维持线程，Compaction 作为默认长运行原语而非应急手段。 5. 需要确定性时，直接指定 Skill 默认让模型自主路由；但生产环境中有明确合约时，一句 "Use the X skill" 是最简单的可靠性杠杆。 6. Skills + 网络 = 高风险组合，必须做隔离 三者叠加（程序化操作 + 执行能力 + 外联能力）打开数据外泄攻击面。默认姿态：Skills 允许、Shell 允许、网络仅最小白名单。 7. /mnt/data 是产物交接边界 工具写磁盘、模型推理磁盘内容、开发者从磁盘取回产物——文件系统是 Agent 与人之间的审阅接口。 8. 网络白名单是两层体系：组织级 + 请求级 组织级白名单设最大可达范围，请求级白名单进一步收缩为"这个任务需要的那几个域名"。请求不能超出组织范围。 9. 用 domain_secrets 注入凭证，杜绝模型看到明文 模型只看到占位符 $API_KEY，sidecar 在运行时仅对白名单域名注入真实值。Agent 调用受保护 API 的标准做法。 10. 本地和云端用同一套 API，同一套 Skills 本地快速迭代 → 托管容器获得隔离性和可复现性。Skill 保持不变，只有执行环境切换——做到 build once, run anywhere。 三种构建模式的递进关系 Pattern A：安装 → 获取 → 写出产物 — 最基础的 Shell 用法。Agent 安装库、调用 API、写出报告。价值在于创造了明确的"审阅边界"——产物是一个文件，而不是一段对话。 Pattern B：Skills + Shell 实现可复现工作流 — 在 Pattern A 基础上解决"prompt 漂移"问题。当同一个工作流跑了几十次后，如果全靠 prompt 即兴推理，可靠性会下降。Skills 将流程固化为可版本化的"剧本"，Shell 负责执行，两者结合实现确定性输出。 Pattern C：Skills 作为企业工作流载体 — 这是最终形态。Glean 的案例：一个面向 Salesforce 的 Skill 将评估准确率从 73% 提升到 85%，首 token 延迟降低 18.1%。Skills 在这里扮演的角色是活的标准操作程序（Living SOPs）——随组织演进更新，由 Agent 一致执行。 这三种模式的递进逻辑是：从执行（Pattern A）到可靠执行（Pattern B）到企业级可靠执行（Pattern C）。 [图片: https://pbs.twimg.com/media/HA62J2-aAAAiv8S?format=jpg&#x26;name=orig] OpenAI Developers: We just announced new primitives for building agents. Here are 10 tips on running multi-hour workflows reliably 👇 https://developers.openai.com/blog/skills-shell-tips

【4】早上开车上班第一次遇到A柱盲区的问题，十字路口时看了左侧没车，结果A柱视角藏了个车🙁最后蔚来隔好远猛踩刹车，直接刹停了。
早上开车上班第一次遇到A柱盲区的问题，十字路口时看了左侧没车，结果A柱视角藏了个车🙁最后蔚来隔好远猛踩刹车，直接刹停了。 [图片: https://pbs.twimg.com/media/HA6ziXiaAAASWUy?format=jpg&#x26;name=orig]

【5】公司即文件系统：文件系统即 Agent 基础设施 从 Openclaw 说起：为什么「文件优先」有效 Openclaw 有一个关键设计选择：整个上下文就是你电脑上的文件系统。对话...
公司即文件系统：文件系统即 Agent 基础设施 从 Openclaw 说起：为什么「文件优先」有效 Openclaw 有一个关键设计选择：整个上下文就是你电脑上的文件系统。对话是文件（http://MEMORY.md），用户画像是文件（http://USER.md），Agent 灵魂是文件（http://SOUL.md），每日记录是文件（memory/YYYY-MM-DD.md），连接 Gmail 后邮件变成文件，连接 Eight Sleep 后睡眠数据变成文件。 这个设计之所以有效，有三个层次的原因： 第一层：LLM 天然理解文件系统。 这一点常被忽略。Claude、GPT 等大模型在数十亿行代码上训练，ls、cat、grep、find 对它们来说是母语级操作，而非后天学习的工具调用。Vercel 工程团队实测发现，基于文件系统的 Agent 方案将每次调用成本从约 $1.00 降至约 $0.25，根本原因就是文件操作比复杂工具链更贴合模型的认知结构。 第二层：文件系统天然是 append-only 日志。 正如 Claude Code 将所有会话存储为 ~/.claude/projects/ 下的 JSONL 文件——每条消息、工具调用、文件编辑、决策推理都逐行追加。不需要索引失效管理，不需要同步机制，不存在冷启动问题，调试只需 cat 一下文件。 第三层：数据越多，Agent 越强。 这是 Mernit 点出的一个关键动态——文件系统是一个正反馈回路。连接的数据源越多、积累的文件越多，Agent 可用的上下文就越丰富，做出的决策就越好，用户就越愿意连接更多数据源。这是经典的网络效应，但作用于个人数据层面。 公司即文件系统：从个人场景跳跃到企业场景 推演一：权限即组织架构。 Unix 文件权限天然映射到企业的层级结构：一年级律师对自己的案件有读写权限，合伙人对所有人的案件都有访问权。治理结构就是 chmod 和 chown。 这个类比虽然简化，但点出了一个真实的技术难题：企业 AI Agent 最头疼的不是"模型不够聪明"，而是"权限管理太复杂"。每个系统有自己的 ACL、RBAC、ABAC 体系，跨系统的统一权限几乎不存在。而文件系统的权限模型是所有工程师从第一天就理解的东西。 推演二：消灭数据孤岛。 > "Invoices are in Quickbooks, emails are in Outlook, proposals live in Sharepoint, contracts live in Netsuite... There is no shared namespace to access all this data." 这句话精准地描述了企业 AI Agent 落地的最大障碍。当数据散落在十几个 SaaS 系统中，没有统一命名空间，Agent 就无法获得足够的上下文来做决策。而"把公司建模为文件系统"本质上就是构建一个统一命名空间——不管数据来自哪个系统，最终都变成 /billing/、/contracts/、/emails/ 下的文件。 [图片: https://pbs.twimg.com/media/HA6yFPHbcAElp3y?format=jpg&#x26;name=orig] Eli Mernit: http://x.com/i/article/2021308996020211712

【6】typeless 新版本很强大 不过交互变得复杂了起来，甚至去掉了之前很好用的交互，fn + space 短长时间无缝切换 another AI 问答在今天还有意义吗？ 这是输入法用户...
typeless 新版本很强大 不过交互变得复杂了起来，甚至去掉了之前很好用的交互，fn + space 短长时间无缝切换 another AI 问答在今天还有意义吗？ 这是输入法用户的真需求吗？

【7】langextract
一个使用LLM从非结构化文本中提取结构化信息的Python库，具备精确的源定位和交互式可视化功能。

【8】gh-aw
GitHub智能体工作流

【9】PowerToys
Microsoft PowerToys是一套实用工具集，可大幅提升Windows系统的生产效率和自定义能力。

【10】chrome-devtools-mcp
用于编码智能体的Chrome DevTools

【11】compound-engineering-plugin
官方Claude Code复合工程插件

【12】ai-engineering-hub
关于LLM、RAG和真实世界AI智能体应用的深度教程。

【13】😏 Telnet 未死：PTT/BBS 仍用，SSH 与密钥管理引发安全争议
原标题： 《Reports of Telnet's Death Have Been Greatly Exaggerated》 评分: 22 | 作者: ericpauley 💭 Telnet 都活着了，你们还在怕明文吗？ 🎯 讨论背景 标题源自围绕一篇或一系列文章的论点：有人宣称 Telnet 应已"死去”，但评论提供反证表明并非如此。评论基于多种观察：特定社区（如美国的 Telnet BBS 群体和台湾的 PTT BBS）仍在使用 Telnet，遗留设备和路由器的管理接口也常是原因。讨论建立在对网络管理实践、密钥管理质量、以及现代操作系统复杂性与信任边界的不同假设之上。相关技术与替代项包括 SSH（加密远程登录）、WireGuard（一个现代 VPN 方案）、以及试图对终端输入实施加密的产品（例如 Keystrokelock），这些都被用来对比是否应弃用 Telnet。 📌 讨论焦点 实际使用：BBS 与社区仍依赖 Telnet 许多评论指出 Telnet 并未彻底消失：美国的 Telnet BBS 社区没有报告连通性中断，说明社区内部依然可用。具体例子包括台湾的 PTT BBS（PTT Bulletin Board System），这是一个仍以 Telnet 为主要接入方式的流行论坛，显示在某些地区和社群中 Telnet 仍被广泛使用。这些实例表明，即便在公共讨论中被视为过时，Telnet 在特定用途和遗留系统中仍具有现实价值。 [来源1] [来源2] 对明文协议的辩护与对现代安全架构的批评 有评论认为对明文协议的普遍嘲讽过于武断，理由是安全性要看具体环境而非协议本身。在一个受信任且安全的局域网（LAN）内，评论者认为 SSH 带来的好处有限，社交信任与网络边界往往比协议加密更重要。批评还延伸到现代操作系统的复杂性，称早期的 SMTP/telnet/http 以明文运行是因为那时用户能理解系统内部，今天的"臃肿且不透明的企业控制 OS”才是真正的问题；同时有人提到像 Keystrokelock 这样的'keystroke encryption'产品作为对策示例。 [来源1] [来源2] 为何仍有人用 Telnet：遗留设备、路由器与密钥管理问题 讨论集中在实践层面为何仍有人用 Telnet：一因是遗留设备与路由器管理接口仍有 Telnet 实现，部分设备手册也没有提到加密支持。评论中有人指出 Telnet 在某些实现上不会改变其明文行为，而 SSH 的 cipher 会更新，且 Telnet 本不应直接暴露到公网；这使得在内网或隔离环境中仍有人选择 Telnet。另有观点认为如果缺乏良好的 SSH 密钥管理，SSH 带来的实际安全提升可能很有限，但除非使用允许'None' cipher 的老旧 SSH 实现，总体上还是建议采用 SSH 而非 Telnet。 [来源1] [来源2] [来源3] [来源4] [来源5] 幽默与怀旧 部分评论以幽默和怀旧口吻回应，调侃类评论包括对歌曲改编的感谢和"退出 Telnet 是否要重启电脑”这样的玩笑。这些轻松语气反映出 Telnet 在部分用户心目中的复古形象和社区文化。笑话也提示出讨论并非全是技术争论，还包含对早期上网经验的集体回忆。 [来源1] [来源2] 历史讨论与先前帖子引用 有人链接了之前的讨论（'The Day the Telnet Died'），把当前话题放回到长期的社区对 Telnet 命运的追踪中。历史贴表明关于 Telnet 是否'死亡'的争论并非新鲜话题，而是多次被提起和反驳的循环议题。不同时间点的观察（例如服务中断或特定社区的持续使用）会被用作支持或反驳'Telnet 已死'的证据，说明结论往往依赖样本和语境。 [来源1] 📚 术语解释 Telnet: Telnet（Telnet）：一种早期的远程终端协议，用户输入与终端输出以明文传输，常用于管理老旧网络设备和通过 BBS 访问的社区接口，因此在遗留系统中仍有存在。 SSH: SSH（Secure Shell）：用于替代 Telnet 的加密远程终端协议，提供认证与加密通道；讨论中涉及密钥管理、cipher（加密套件）变化以及旧版实现可能允许'None' cipher 的安全弱点。 BBS: BBS（Bulletin Board System，电子公告板/论坛）：一种早期在线社区形式，很多早期社区（例如台湾的 PTT）通过 Telnet 被远程访问，体现了 Telnet 在特定用户群体中的持续使用。 类别： Systems | Security | Opinion | Telnet | Routing | SSH | BBS | Terrace Networks

【14】🧹 清空桌面能提升效率吗？空白仪式 vs 窗口式工作地图
原标题： 《"Nothing" is the secret to structuring your work》 评分: 32 | 作者: spmvg 💭 只要把窗口和标签都清空，工作就会变好吗？ 🎯 讨论背景 标题源自主张通过"空白”来组织工作的文章，引发关于物理与数字工作区是否应清空的讨论。评论围绕浏览器标签、窗口布局、虚拟桌面（多个桌面）、每日收尾仪式与短迭代等实践展开，既有每天清空并写下主目标的经验，也有把窗口当作"工作地图”的观点。讨论将现代工具纳入视野，提到 OneTab（浏览器标签管理扩展）、LLMs（大型语言模型）与 agents（自动化代理），并普遍认为这些工具不会自动缩短人的反馈循环。话题还牵涉界面设计趋势与关于整洁作为美德或道德判断的争论。 📌 讨论焦点 空白桌面与日常清理仪式 一派主张每天把物理桌面与数字标签清空，作为开始新一天的仪式以降低认知负担。典型做法包括用小记事本写下每天的主目标与下一个步骤、列出即时任务、将屏幕挂墙并保持浅而不深的半圆桌面以避免把桌面当存储区。很多人每天早上关闭前一天的浏览器标签，认为 99% 的标签不再需要，少数重要的记入待办或用 OneTab 等扩展保存。另有经验显示在"日终留下清晰的下一步动作”可以帮助第二天快速进入流状态，且这种习惯能逐步减少拖延。 [来源1] [来源2] [来源3] [来源4] 把窗口和虚拟桌面当作工作地图 另一派认为有序的窗口布局与多个虚拟桌面本身就是工作的地图和锚点，而非冗余。评论中提到用 3–7 个桌面把不同上下文分隔开，窗格排列像保龄球的护栏那样把注意力保持在车道上；工作空间反映任务进展，维护地图是工作内容的一部分而非可丢弃的杂物。他们强调清理与更新应是持续行为而非一次性"大清理”，并采用周期性任务来逐步清除问题点以防信息丢失（例如每天清理最旧两天的邮件）。 [来源1] 短迭代以避免杂乱和上下文切换 有评论把杂乱归因于迭代过长与频繁改动，导致在多个上下文间切换从而形成未完成项堆积。该观点建议把问题限定在短反馈环内：如果 30 分钟内看不到结果就停止并重塑问题，若 90–120 分钟内仍无进展说明方法有问题，需要调整。评论强调即便有 LLMs（大型语言模型）和 agents（自动化代理）等工具，真正缩短循环與减少上下文切换的仍是使用者的组织与决策，而非工具自动完成。 [来源1] 没有通用金律——因人而异 多人提醒不存在万能的组织秘密，不同方法可能把不同人带到相似的结果。评论把例行化模板与当下 LLM 写作的效果相比较：套路化流程经常能满足很多需求，但并不说明适用于所有人或所有创作阶段。建议是尝试并采纳有用的习惯，但不要过于依赖或神化某一种方式；如果方法失效，可以暂时放下再回头检验。 [来源1] [来源2] 产品与界面设计批评：极简化有时反而增加负担 部分评论从产品设计角度批评极简化界面：为了追求"干净”的界面，厂商会移除或拆分功能，结果让用户更难完成原先的工作流。举例指出某些公司会砍掉功能、把功能移到另一个产品或留到下个版本，从而以版本或订阅为由增加用户成本。这种策略被认为会迫使用户手工重建工作流程或频繁在产品间切换，反而降低效率。 [来源1] [来源2] 价值判断与俗语的争论 讨论中也出现传统格言与讽刺的对立：有人引用"乱桌是懒惰”的论断来支持清理，另一些人则嘲讽这种道德化的建议不适用于工程实践。有人坚持"整洁即清晰思维”的价值，也有人认为把整洁当成品德评判会误导对效率和实际工作的判断。总体上，整洁既被当作实用的生产力工具，也被视为容易被滥用的规范性说法。 [来源1] [来源2] [来源3] 📚 术语解释 LLM（LLM / 大型语言模型）: LLM（Large Language Model）是通过海量文本训练、用于生成或理解自然语言的模型（例如 GPT 系列），评论中指它能模板化写作产生合格输出，但并不能替代人对迭代节奏和上下文切换的管理。 agents（自动化代理 / agents）: agents 指基于 LLM 并能调用工具或串联多步任务的自动化代理；讨论里把它们视为辅助工具，但强调缩短反馈回路仍需人为组织与决策。 OneTab: OneTab 是一个浏览器标签管理扩展，用于把大量标签压缩成单页列表以节省内存并清理视图，评论者把它当作清理标签的实用工具。 类别： Work | Opinion | workspace | productivity | browser tabs | desktop | minimalism | vangemert.dev

【15】xAI 公开45分钟全体会议视频:马斯克重组四大团队，剑指月球 AI 工厂
周三，马斯克旗下人工智能公司 xAI 罕见地在 X 平台上公开了长达45分钟的全体员工会议视频。此举疑似是对《纽约时报》此前泄露会议细节的回击。视频全面揭示了 xAI 与 X 平台的紧密联系、全新的组织架构，以及马斯克极具科幻色彩的"月球 AI 基地”蓝图。 [图片: xAI，马斯克，人工智能，AI https://pic.chinaz.com/picmap/202307180849462170_0.jpg] 组织巨变:创始团队流失与四大核心团队确立 马斯克在会上确认了近期的一系列人员变动，将其定性为"组织结构调整导致的裁员”。尽管马斯克强调这是快速发展公司的必然，但多位创始成员的离职仍引发了外界对团队稳定性的关注。 重组后，xAI 将划分为四大职能团队: Grok 团队 :专注 Grok 聊天机器人及语音交互。 编码系统团队 :专注应用程序自动化开发。 Imagine 团队 :专注视频生成技术。 Macrohard 团队 :负责模拟计算机操作及公司全流程建模。该团队负责人 Toby Pohlen 指出，其 终极 目标是实现"完全由 AI 设计的火箭发动机”。 财务与数据:X 订阅收入破10亿美元，内容争议并存 X 平台产品负责人 Nikita Bier 透露，得益于假日营销，X 的年度订阅经常性收入已 突破10亿美元 。技术指标方面，Imagine 工具表现惊人，日均生成视频 5000万个 ，过去30天生成的图像突破 60亿张 。 然而，繁荣背后暗藏危机。报道指出，这些海量数据中包含大量争议性的深度伪造内容。据估算，仅在9天内平台就生成了约180万张具有性暗示的图像。 [图片: QQ20260212-094328.png https://upload.chinaz.com/2026/0212/6390648657239516701974094.png] 星际雄心:月球弹射器与戴森球雏形 会议结尾，马斯克再次展现其"火星视角”，提议在月球建立 AI 卫星工厂，并配套建设 月球质量驱动器 （电磁弹射器）。他设想: 利用月球低引力环境高效发射 AI 集群。 捕获太阳总能量的大部分，以支持规模空前的智能算力。 最终将算力网络扩展至其他星系。 马斯克总结道:"亲眼目睹这种规模的智能如何思考，将是令人无比兴奋的事情。”

【16】"版权狂魔”迪士尼胜诉？谷歌 Gemini 正式下线迪士尼 IP 生成功能：AI 界的版权红线愈发清晰
大模型时代的"版权野蛮生长”正在被法律红线终结。2026年2月11日，据 IT 之家援引外媒 Deadline 消息，谷歌旗下的 AI 工具 Gemini 以及 Nano Banana 已全面开启"自我审查”模式，正式开始拒绝用户生成任何涉及 迪士尼 角色的请求。 从"虚拟售货机”到"红牌禁区” 这场纠葛始于去年12月，拥有" 最强 法务部”之称的迪士尼向谷歌发出了一份长达32页的停止侵权函。 迪士尼指控 :谷歌的 AI 产品如同"虚拟自动售货机”，通过简单的提示词就能精准输出达斯·维达、钢铁侠等受版权保护的精细图像。 谷歌的回应 :此前谷歌曾辩称其训练数据来自公开网络，并拥有版权控制机制，但显然压力之下最终选择了妥协。 "拦截”实测:AI 不再有求必应 根据 最新 测试，此前在今年1月还能轻松生成的高质量迪士尼角色图像，现在已触发拦截系统。 系统提示 :目前尝试输入相关提示词时，系统会提示:"由于第三方内容提供方的相关顾虑，我暂时无法生成该图像”。 技术漏洞 :值得注意的是，虽然文本提示词被拦截，但若用户主动上传迪士尼角色照片并结合指令，AI 仍可能输出相关 IP 内容，这显示版权防护仍存在"猫鼠游戏”的空间。 版权背后的"商业博弈” 就在谷歌屏蔽迪士尼内容的同时，迪士尼却转身与 OpenAI 达成了一项价值 10亿美元 的巨额协议，官方授权其 IP 角色用于视频应用 Sora 的模型训练。这一鲜明对比揭示了 AI 时代的生存法则:要么付费获得正式授权，要么被踢出版权方的资源库。 谷歌的退让无疑给整个生成式 AI 行业敲响了警钟:随着巨头们版权意识的觉醒，AI 的"免费午餐”时代已经宣告终结。

【17】拒绝"智障”眼镜！Rokid Glasses 支持接入 DeepSeek/Kimi 等私有模型，你的眼镜你定义
AI 眼镜赛道正在卷向更深层的定制化。2026年2月11日，乐奇 （Rokid）正式宣布，为其配备显示屏的AI 眼镜 Rokid Glasses上线**"自定义智能体”**功能。这一举动打破了传统 AI 硬件的闭环生态，允许开发者将最前沿的私有模型直接"装”入眼镜中。 [图片: image.png https://upload.chinaz.com/2026/0212/6390648632156777345956250.png] 深度定制:私有大模型与开源框架的"入场券” 本次功能更新的核心在于"开放”与"连接”: 模型适配广 :开发者可以通过标准化接口，将私有部署的 DeepSeek R1 、 Qwen3 、 Kimi K2.5 等热门模型接入眼镜系统。 原生支持开源框架 :支持直接接入 OpenClaw 开源框架，让眼镜具备更强的逻辑处理能力。 技术底座稳健 :该功能基于 SSE （Server-Sent Events） 通信协议，确保了指令传输的实时性与稳定性。 [图片: image.png https://upload.chinaz.com/2026/0212/6390648633828279325007898.png] 灵珠平台赋能:开发者只需三步走 为了方便开发者操作，Rokid同步优化了配套的开发流程: 注册获取 API :在Rokid 开放平台获取开发权限。 创建与配置 :通过灵珠平台创建专属智能体并配置 URL 鉴权密钥。 私有化调用 :个人开发者创建的智能体支持 免审核私有化调用 ，极大缩短了开发周期。 应用场景:从语音对话到"操控现实” 通过接入 OpenClaw 框架，Rokid Glasses的能力边界得到了极大拓展: 本地化数据闭环 :支持更安全的本地化数据处理。 系统级操控 :用户可通过语音指令让眼镜执行浏览器操作、读取文件系统、甚至运行 Python 脚本。 专家提醒:技术红利伴随安全责任 虽然该功能为 AI 爱好者提供了极大的想象空间，但Rokid官方也强调了技术门槛与安全规范: 性能要求 :建议采用2核4G 及以上的云服务器部署，不推荐安全性较低的内网穿透方案。 主体责任 :用户需对自定义智能体的数据安全及合规性负责，并严格遵守网络安全法规。 作为由前阿里 M 工作室负责人祝铭明创立的公司，乐奇 （Rokid）此次上线"自定义智能体”，不仅提升了硬件的可玩性，更标志着 AI 穿戴设备正从"厂商定义”转向"用户定义”的新阶段。

【18】剑指 AI 主权！法国巨头 Mistral 豪掷 14 亿美元赴瑞典建厂：摆脱美国云依赖，打造欧洲"独立大脑”
欧洲 AI 领军者正在通过大手笔的基础设施布局，筑起科技主权的"护城河”。2026年2月11日，法国人工智能独创企业Mistral AI宣布，将在瑞典投资 12亿欧元（约合14.3亿美元） 建设全新的数据中心。 这不仅是 Mistral 成立以来的 最大 规模基建投入，更是其 首次 在法国本土以外进行基础设施布局。 逃离"美国云”:打造纯血欧洲 AI 生态 在OpenAI等竞争对手高度依赖美国云计算平台之际，Mistral 正在走出一条完全不同的道路: 基础设施自主 :该项目旨在将核心技术、算力设施及云服务器全部扎根欧洲，减少对比邻美国科技巨头的依赖。 全栈服务能力 :资金将用于提升先进算力，通过"Mistral Compute”平台提供包括 GPU、API 及 PaaS 在内的一体化技术栈服务。 支持下一代模型 :新数据中心预计于 2027年 投入运营，将作为 Mistral 下一代 顶级 AI 模型训练与部署的核心阵地。 瑞典选址背后的考量:绿色算力与本地化 此次瑞典数据中心将由本地运营商 EcoDataCenter 负责设计与建设。 瑞典丰富的绿色能源和成熟的基础设施，将为 Mistral 提升本地化 AI 服务能力提供强力支撑。 Mistral 首席执行官Arthur Mensch表示，此举是构建"欧洲自主 AI 云平台”的关键一步，旨在为产业、公职机构和科研人员提供大规模的独立基础设施。 估值百亿欧元，资本版图横跨全球 成立于2023年的 Mistral 发展速度惊人，目前估值已达 117亿欧元 。 其背后站着由荷兰芯片巨头阿斯麦（ASML）领衔的豪华投资团，同时包括英伟达、微软等科技巨头，以及Andreessen Horowitz、DST Global 等知名机构。 尽管与美国动辄千亿美金的融资规模相比仍有差距，但 Mistral 正在通过"硬件+软件”双管齐下的策略，试图在 AI 时代的全球博弈中，为欧洲抢占一个独立的话语权席位。

