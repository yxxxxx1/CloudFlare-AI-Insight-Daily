## AI洞察日报 2025/11/4

>  `AI 日报` 

### 今日摘要

【1】RT howie.serious: google drive 没有官方的MCP，而各家llm厂商实现的版本差异巨大。 chatgpt 实现的版本，非常好用，很强大。 （洞穿我的一万多md笔记，指哪打...
RT howie.serious google drive 没有官方的MCP，而各家llm厂商实现的版本差异巨大。 chatgpt 实现的版本，非常好用，很强大。 （洞穿我的一万多md笔记，指哪打哪。我让chatgpt综述诸葛亮相关内容，连《阳光开朗孔乙己》里面的一句歌词都rag出来了🤣） claude 实现的版本，能运行，但是同样的prompt却基本检索不到多少内容。 都叫google drive connector，但是二者天差地别。 记录一下。避免大家在此掉坑。 [图片: https://pbs.twimg.com/media/G435lApa8AAHcT3?format=jpg&#x26;name=orig]

【2】小公司领导的主要工作只有两个：搭班子，抓增长。 什么组织，什么流程，在没有稳定的增长面前都是第二件事。
小公司领导的主要工作只有两个：搭班子，抓增长。 什么组织，什么流程，在没有稳定的增长面前都是第二件事。

【3】让每个人 0 门槛开发自己的 AI 播客，我们的 API 终于上了。 大聪明和youmind已经用上了。 未来属于多模态，你也试试在产品里加入音频吧。 另外完全免费的 Next ...
让每个人 0 门槛开发自己的 AI 播客，我们的 API 终于上了。 大聪明和youmind已经用上了。 未来属于多模态，你也试试在产品里加入音频吧。 另外完全免费的 Next Music 也欢迎来玩。 Suno v5 级别，但是更好用。 https://mp.weixin.qq.com/s/vvkRfP148Qf4VWst7Cab1w

【4】[开源推荐] OpenSkills: 把 Claude Skills 能力带给任意 AI Agent (如 Claude Code、Cursor、Windsurf 和 Aider 等) 核心目标与关键功能 OpenSkills 的目标是实...
[开源推荐] OpenSkills: 把 Claude Skills 能力带给任意 AI Agent (如 Claude Code、Cursor、Windsurf 和 Aider 等) 核心目标与关键功能 OpenSkills 的目标是实现技能的"即插即用”和跨平台共享。它解决了一个痛点：不同 AI 智能体往往使用专有格式，导致技能难以迁移。通过标准化 Claude Code 的提示格式、文件夹结构和 SKILL. md 文件规范，OpenSkills 确保 100% 兼容性。主要功能包括： · 从任意来源安装技能：支持从 GitHub 仓库直接克隆安装，不限于特定市场。 · 跨智能体共享：通过单一的 AGENTS. md 文件，将技能列表暴露给多个智能体，避免重复配置。 · 版本控制与管理：技能可存储在用户自己的仓库中，支持 Git 跟踪更新。 · 渐进式披露：初始上下文仅加载技能名称和描述，完整指令仅在调用时注入，保持智能体提示窗口的简洁高效。 · 交互式界面：内置终端用户界面 (TUI)，便于安装、同步和批量管理技能。 · 资源捆绑支持：技能可附带脚本、参考资料和资产文件夹，适用于复杂工作流如 PDF 处理或数据提取。 这些功能让开发者能快速扩展 AI 智能体的能力，例如添加 PDF 解析或代码生成工具，而无需编写自定义插件。 技术架构与工作原理 OpenSkills 采用 CLI 架构，而非动态协议（如 MCP），因为技能本质上是静态的 Markdown 指令文件。这种设计简单可靠，避免了服务器依赖。核心组件包括： · 技能加载器：CLI 工具负责克隆仓库到 .claude/skills/（或通用模式下的 .agent/skills/）目录。 · XML 技能目录：运行 openskills sync 时，生成 AGENTS. md 文件中的 XML 块，列出所有技能。该块包含使用指南，如调用 Bash("openskills read ") 来加载具体技能。 · AI 智能体集成：智能体（如 Claude Code）扫描 XML 块，当用户任务匹配技能描述时（如"提取 PDF 数据”），自动调用 CLI。CLI 则读取 SKILL. md（包含 YAML 前置元数据和 Markdown 指令），输出完整内容，包括资源基路径。 · 通用模式：为多智能体环境设计，避免与 Claude Code 原生插件冲突。 工作流程简洁：安装技能 → 同步目录 → 智能体调用 → 加载指令 → 执行任务。这种链式机制确保了低延迟和高兼容性。 开源地址 https://github.com/numman-ali/openskills [图片: https://pbs.twimg.com/media/G43zO__bQAUKUSY?format=jpg&#x26;name=orig] Ian Nuttall: This tool lets you use Claude Skills with any AI agent (Codex, Factory, Cursor etc) - Same format and folders, just CLI instead of tools - Access marketplace skills through GitHub - Uses progressive disclosure (skills on demand) https://github.com/numman-ali/openskills [图片: https://pbs.twimg.com/media/G4XxZEDWYAAk5b6?format=jpg&#x26;name=orig]

【5】并不是你卖东西就要做售后 什么情况下需要售后 有一个必要条件和一个充分条件 首先必要条件是： 不是一次性交易，而是需要靠续费拉高LTV的生意 其次充分条件是：...
并不是你卖东西就要做售后 什么情况下需要售后 有一个必要条件和一个充分条件 首先必要条件是： 不是一次性交易，而是需要靠续费拉高LTV的生意 其次充分条件是： 退款带来的损失远高于售后成本 如果售后成本和退款损失差不多，或者稍微比退款损失少一部分，都不值得做 因为你还要额外设计售后流程，安排售后处理，这些都是机会成本 高效AI: @Yangyixxxx 交付后的售后服务怎么做？一个提示词很难满足大众多样性的需求吧

【6】我们是真的需要 MCP 吗？如果不用 MCP ... 行吗？ 来自 @badlogicgames 很好的一篇文章，探讨了 AI 智能体开发中的一个核心痛点：是否真的需要依赖 MCP 服务器来...
我们是真的需要 MCP 吗？如果不用 MCP ... 行吗？ 来自 @badlogicgames 很好的一篇文章，探讨了 AI 智能体开发中的一个核心痛点：是否真的需要依赖 MCP 服务器来实现复杂任务？作者以浏览器自动化和网页爬取为例，提出一个简洁的替代方案——通过 Bash 脚本和代码执行来取代繁重的 MCP 工具链。这种观点挑战了当前 AI 工具生态的"标准化”趋势，强调简约与高效，值得 AI 开发者深思。 MCP 的痛点：为什么它往往是多余的负担？ MCP 是一种标准化协议，让 AI 智能体通过预定义的工具接口（如浏览器控制或文件操作）调用外部功能。这些工具通常伴随详尽的描述性提示，注入到智能体的上下文中，以帮助模型理解如何使用它们。然而，作者指出，这种设计在实际应用中暴露了三大问题： 1. 上下文膨胀（Context Bloat）：一个典型的 MCP 服务器（如 Playwright MCP 或 Chrome DevTools MCP）可能包含数十个工具，每个工具的描述都需要数千 token。例如，Playwright MCP 的21个浏览器工具就占用了约1.37万至1.8万 token，相当于上下文的 6.8%。这不仅增加计算成本，还容易让智能体在海量信息中迷失方向，尤其当与其他工具结合时。 2. 组合性差：MCP 工具的输出必须先通过智能体的上下文"中转”，才能保存或与其他结果合并。这导致了不必要的摩擦，无法像脚本那样直接将输出写入文件或链式调用。 3. 扩展困难：修改 MCP 服务器需要深入其代码库，而添加新功能往往繁琐。相比之下，作者的方案允许智能体即时生成和调试代码，扩展起来如行云流水。 简而言之，MCP 像一个"全家桶”工具箱：功能齐全，但体积庞大、笨重，适合标准化场景，却不利于个性化、动态的任务。 替代方案：Bash 脚本 + 代码执行，简约而强大 作者的核心主张是：AI 智能体天生擅长编写和执行代码，为什么不直接利用这一能力？他的解决方案基于一组轻量级 Node.js 脚本（使用 Puppeteer Core 库），通过 Bash 命令调用。这些脚本聚焦于最小化工具集，只覆盖浏览器自动化的核心需求： · 启动浏览器（start.js）：以远程调试模式打开 Chrome，支持加载用户配置文件（包括 cookies 和登录状态）。 · 导航页面（nav.js）：跳转到指定 URL，支持新标签页。 · 执行JavaScript（eval.js）：在页面上下文中运行自定义代码。 · 截屏（screenshot.js）：捕获视口截图并返回文件路径。 这些脚本存储在 ~/agent-tools/ 目录下，通过 README. md 文件提供简要文档。智能体只需在提示中引用 @ README. md，即可"即时学习”工具用法，而非每次都加载巨量描述。这种"渐进式披露”（progressive disclosure）大大降低了上下文开销。 更妙的是，扩展性极强：智能体可以根据需求生成新脚本。例如： · 元素选择器（pick.js）：注入一个 window.pick() 函数，让用户通过鼠标点击 DOM 元素，智能体据此快速构建爬虫逻辑。这结合了"人机协作”（human-in-the-loop），加速了调试。 · Cookie 提取器（cookies.js）：智能体仅用"一分钟”就生成了这个工具，用于捕获 HTTP-only cookies，确保爬取的会话状态一致。 作者分享了一个 GitHub 仓库，包含这些脚本： https://github.com/badlogic/browser-tools 实际示例：从协作开发到高效爬虫 文章以 Hacker News 爬虫为例，展示了方案的实战价值。传统 MCP 可能需要智能体在海量工具中"挑选”浏览器命令，而这里的过程更流畅： 1. 启动浏览器，导航到目标页面。 2. 用 pick.js 交互式选中标题、链接等元素，获取 XPath 或 CSS 选择器。 3. 智能体基于这些信息编写 Node.js 爬虫脚本，执行并输出结构化数据（如 JSON）。 这种方法不仅节省 token，还支持模块化组合：脚本输出可直接保存为文件，下一个脚本读取它继续处理。相比 MCP 的"黑箱”调用，它更像一个可编程的"积木系统”。 作者的洞见与启示 Zechnner 的结论直击要害：MCP 服务器对许多任务来说是"杀鸡用牛刀”。在 AI 智能体时代，工具不应是刚性接口，而应是灵活的代码沙盒。这不仅提升了效率（更少 token、更快推理），还放大了智能体的自主性——让它们像程序员一样"即兴创作”。 对 AI 开发的更广含义是：未来可能从"工具中心”转向"代码中心”。这会减少对 MCP 标准的依赖，促进创新，但也要求开发者维护工具目录的整洁（"能力越大，责任越大”）。对于浏览器自动化或爬虫爱好者，这篇文章提供了一个低门槛起点：从 Bash 脚本入手，逐步构建个性化智能体工作流。 [图片: https://pbs.twimg.com/media/G43xZJwbQAQeICU?format=jpg&#x26;name=orig] Mario Zechner: New blog post, wherein I beat a dead horse for the last time. https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/?t=0

【7】BettaFish
微舆：人人可用的多智能体舆情分析助手，打破信息茧房，还原舆情原貌，预测未来走向，辅助决策！从零实现，不依赖任何框架。

【8】nano-vllm
Nano vLLM

【9】DeepCode
"DeepCode：开放式智能编码（论文转代码 & 文本转网页 & 文本转后端）"

【10】glow
在命令行中炫酷渲染Markdown！💅🏻

【11】opencode
专为终端打造的AI编程助手

【12】chef
唯一懂后端的AI应用构建器

【13】掘金AI基建!Lambda与微软达成数十亿美元GPU部署协议
云计算公司 Lambda 周一宣布与科技巨头 微软（Microsoft） 达成一项价值数十亿美元的人工智能基础设施协议，旨在加深双方的合作关系，共同部署大规模 AI 超级 计算机。 部署数万块英伟达GPU，加深八年合作 这项由英伟达投资的交易将涉及部署数万块英伟达 GPU，其中包括今年早些时候发布并已开始出货的 尖端 英伟达 GB300NVL72系统。值得注意的是，微软已于10月份启用了其首个 GB300NVL72集群。 Lambda 首席执行官 Stephen Balaban 在新闻稿中表示，此次合作是双方长达八年合作关系中"意义非凡的一步”。 成立于2012年的 Lambda，早在当前的 AI 热潮前就已奠定基础，并已筹集了17亿美元的风险投资。随着全球企业对 AI 基础设施和计算资源的需求持续飙升，Lambda 的市场需求表现强劲。 [图片: GPU 芯片 (1) https://pic.chinaz.com/picmap/202304071204217442_0.jpg] AI云容量市场硝烟弥漫 Lambda 与微软的合作公告，正值云计算行业 AI 基础设施交易频发之际，凸显了市场对计算能力的巨大渴求: 微软:在宣布与 Lambda 合作的数小时前，刚刚公布与澳大利亚数据中心企业 IREN 达成了一项价值97亿美元 的 AI 云容量交易。 OpenAI:今天早些时候宣布与 亚马逊 达成一项价值380亿美元 的云计算协议，将在未来七年内购买其云服务。此前，该公司据称在9月份还与 甲骨文 签署了一项价值3000亿美元 的云计算协议。 亚马逊AWS营收创三年 最佳 云计算需求的爆发直接推动了行业巨头的业绩增长。亚马逊总裁兼首席执行官 安迪·杰西（Andy Jassy） 在上周的第三季度财报中透露，亚马逊 AWS 的增长速度达到了自2022年以来的 最高 水平，同比增长20.2%，本年度迄今已实现330亿美元 的销售额。 杰西强调:"我们持续看到人工智能和核心基础设施的强劲需求，并且我们一直致力于加速提升产能——过去12个月新增了超过3.8吉瓦 的产能。”

【14】OpenAI 与亚马逊 AWS 达成 380 亿美元合作，拓展 AI 云基础设施
近日，OpenAI 宣布与亚马逊 AWS 达成了一项价值380亿美元的长期合作协议，这标志着 OpenAI 在 AI 云基础设施方面的重大进展。此前，OpenAI 主要依赖微软 Azure 提供的云服务，但随着其对算力需求的不断增长，OpenAI 选择了与 AWS 合作。 [图片: 人机合作 https://pic.chinaz.com/picmap/202306131355473164_2.jpg] 图源备注：图片由AI生成 根据新协议，OpenAI 将在未来七年内使用 AWS 的基础设施，尤其是其 Amazon EC2UltraServers，这将为 OpenAI 提供数千块高性能的 NVIDIA GB200及 GB300GPU。这些强大的计算资源将支持 OpenAI 进行更大规模的 AI 模型训练和推理，预计到2026年底，OpenAI 将消耗完这些计算能力，并在2027年继续扩容。 AWS 首席执行官 Matt Garman 表示，AWS 的基础设施将成为 OpenAI 推动 AI 技术发展的重要支撑。Garman 强调，AWS 提供的广泛且即时可用的算力将为 OpenAI 的大规模 AI 工作负载提供独特的支持。此次合作不仅将助力 ChatGPT 等应用的推理，还将支持下一代模型的训练。 在达成新协议之前，微软对与 OpenAI 的合作条款进行了调整，允许 OpenAI 将非 API 产品（如 ChatGPT 和 Sora）托管在任何云服务平台上。这一变化为 OpenAI 提供了更多的灵活性，使其能够更好地满足自身对算力的需求。 亚马逊也指出，OpenAI 的 gpt-oss 系列模型在其 Amazon Bedrock 平台上已成为 最受欢迎 的公有模型之一，吸引了包括 Comscore、Peloton 和 Thomson Reuters 等多家客户的使用。这一合作关系的建立，预示着 OpenAI 和 AWS 在人工智能领域的进一步深耕与发展。 划重点: 🌟 OpenAI 与亚马逊 AWS 签署380亿美元的长期合作协议，拓展 AI 云基础设施。 💻 AWS 将提供数千块高性能 GPU，支持 OpenAI 进行大规模的模型训练和推理。 🚀 此次合作使 OpenAI 能够灵活使用非 API 产品，并推动下一代 AI 模型的发展。

【15】告别旧Siri!曝苹果2026年两次AI大爆发:iOS26.4将迎来"超级 Siri”
彭博社知名记者 马克・古尔曼（Mark Gurman） 于11月2日发文指出，苹果正计划对 Apple Intelligence 进行重大升级，并有望在 2026年 推出两次重量级更新，分别聚焦于 " 超级 Siri” 和 更广泛的 AI 战略 调整。 [图片: WWDC23，iOS17，苹果，iPhone14 https://pic.chinaz.com/picmap/202306060938564405_0.jpg] 2026年初迎" 超级 Siri”:交互体验彻底革新 据古尔曼透露， 首次 重磅升级预计将随 iOS26.4 系统版本推出。这次更新的核心是推出 " 超级 Siri” ，它不仅将包含最初为 iOS18承诺的多项功能，还将带来更多全新特性，旨在 彻底改变 Siri 的交互体验和能力上限 。 这一升级标志着苹果对 Siri 这一核心功能的一次颠覆性改造，旨在将其提升到一个全新的智能水平。 2026年WWDC:发布Apple Intelligence重大更新 此外，苹果的第二次重大 AI 部署预计将在 2026年6月 举行的 全球开发者大会（WWDC） 上亮相。 届时，除了预告和展示 iOS27、macOS27 等新一代操作系统外，苹果还将发布对 Apple Intelligence 的重大更新 ，以及对**"更广泛人工智能战略”**的调整。 虽然报告未透露具体的细节，但"重大更新”的措辞暗示了这次变革幅度将远超以往的常规迭代，可能涉及更深层次的系统集成与功能创新。

【16】惊天内幕：OpenAI 动荡期密谋与死敌 Anthropic 合并！伊利亚证词揭开硅谷最大胆B计划！
硅谷的棋局远比表面更加惊心动魄。 最新 曝光的法庭文件，如同一道闪电，劈开了 OpenAI 一段鲜为人知的"B计划”:就在两年前，那场震惊全球的"宫斗”导致萨姆·奥特曼短暂下台后，陷入混乱的 OpenAI 竟然将橄榄枝伸向了自己 最强 劲的对手——Anthropic，试图探讨一场震惊行业的合并。 这一爆炸性消息来自 OpenAI 的联合创始人、前首席科学家伊利亚·苏茨克沃的亲口证词。它揭示了在奥特曼卸任后，公司内部是何等的波涛汹涌。面对重大的变革压力和重组需求，在那个 AI 行业竞争日益白热化的十字路口，OpenAI 与 Anthropic 的这场合并谈判，无疑成为了当时最引人注目的"救生索”之一。它不仅反映了 OpenAI 寻求稳定和增长的迫切努力，也凸显了 AI 行业内部动态的极端复杂性。 这场未遂的合并谈判，背后还笼罩着一个巨大的阴影:埃隆·马斯克与 OpenAI 及其 领导者 奥特曼之间持续升级的法律战争。马斯克，这位曾经的早期支持者，因与公司的发展方向彻底决裂而分道扬镳，随后的连串纷争让 OpenAI 的未来航向充满了巨大的不确定性。在如此内忧外患的背景下，OpenAI 试图启动合并这一选项，其当时的焦虑与挣扎可见一斑。 对于当时的 OpenAI 而言，如果能成功"牵手” Anthropic，两家在 AI 领域都拥有深厚技术积累和创新能力的巨头合体，无疑将在技术版图和市场上筑起一道无人能及的护城河。然而，这个宏大的构想最终未能落地。这背后，或许是双方在最核心的战略目标上难以妥"妥协，抑或是根深蒂固的企业文化差异，让这场"世纪联姻”从一开始就注定困难重重。 如今，随着 OpenAI 逐步稳定了其领导层结构和发展战略蓝图，AI 行业的未来赛道依旧充满了无限的变数与可能。尽管那场与对手的合并密谈早已烟消云散，但 OpenAI 依旧在不断加速推进技术创新与市场拓展的步伐，期待在未来给世界带来更多的惊喜。

【17】吉卜力等日企施压OpenAI:要求停止未经许可使用版权内容训练AI模型
日本内容创作者对人工智能巨头 OpenAI 未经许可使用其受版权保护材料训练生成式AI模型的行为，表达了强烈不满并采取了行动。 上周，代表包括知名动画制作公司 吉卜力工作室 在内的多家出版商的日本行业组织—— 日本海外内容分发协会（CODA） ，已致信OpenAI，正式要求其停止在未获授权的情况下，使用其成员的内容进行机器学习。 [图片: OpenAI https://pic.chinaz.com/picmap/202502061723412816_0.jpg] 吉卜力成"重灾区” CEO也曾使用AI生成图 吉卜力工作室（代表作《千与千寻》《龙猫》）受OpenAI产品的影响尤为突出。今年3月，OpenAI的图像生成器发布后，"吉卜力动画风格”的自拍和宠物照片迅速成为流行趋势，甚至连OpenAI首席执行官 Sam Altman 也一度将他在X上的头像更换为"吉卜力风格”的图片。 如今，随着更多用户能够使用OpenAI的视频生成器 Sora ，CODA要求OpenAI不得将其成员的内容用于机器学习。 ⚖️"先斩后奏”模式引公愤，深度伪造易如反掌 CODA的请求并非空穴来风。OpenAI在处理版权内容时，采取的是**"事后请求原谅”而非"事先获得许可”**的模式。这种做法不仅使任天堂等机构提出投诉，也引起了马丁·路德·金博士遗产管理机构的不满，因为用户可以轻易生成受版权保护的角色，甚至对已故名人进行深度伪造。 CODA强调，这种做法在日本可能被视为版权侵权。根据日本的版权制度，使用受版权保护的作品通常需要 事先获得许可 ，并且"没有制度允许通过事后提出异议来规避侵权责任。” CODA进一步指出，在像Sora这样的案例中，"当特定受版权保护的作品被复制或以类似方式生成为输出结果时，CODA认为机器学习过程中的复制行为可能构成版权侵权。” 💥版权法不明晰，宫崎骏曾表达"厌恶” 尽管OpenAI可以自行决定是否配合请求，否则受害方将可能提起诉讼。然而，美国法律对于使用受版权保护材料进行AI训练的规定仍不明确， 1976年以来未更新 的版权法几乎没有先例可循。美国联邦法官近期的一项裁决认定，Anthropic公司使用受版权保护书籍训练AI并 未违反法律 ，尽管该公司因盗版用于训练的书籍而被罚款。 吉卜力工作室的核心人物 宫崎骏 虽然未直接评论AI对其作品的改编，但他对AI技术的态度一直十分负面。在2016年，当他看到AI生成的3D动画时，他表示"极其厌恶”，并强烈地感到这"简直是对生命的侮辱”。

【18】万代南梦宫等日本大厂联合发声，要求 OpenAI 停止使用其作品训练 AI
近日，多家日本知名出版商，包括万代南梦宫、Square Enix 和东映等，联合成立了一个名为内容海外分发协会（CODA）的组织。他们向 OpenAI 提出了明确的要求，希望其立即停止使用协会成员的创意作品进行 AI 视频生成工具 Sora2的训练。 [图片: 专利 版权 (2) https://pic.chinaz.com/picmap/202304111645241217_1.jpg] 图源备注：图片由AI生成 根据 CODA 的声明，OpenAI 在未获得事先许可的情况下，使用这些作品进行机器学习的行为已经违反了日本的《版权法》。他们指出，Sora2的默认政策是，除非作品的版权所有者选择退出，否则这些作品将被用于训练，这种做法显然不合规。CODA 强调，在使用任何作品之前，法律要求必须获得授权。 该组织在声明中还提到，当前并没有有效的机制来处理事后异议，这使得著作权侵权的风险加大。CODA 的成立旨在保护版权，打击盗版行为，同时也促进日本视频游戏、电影、音乐、电视节目和动画的合法全球发行。 参与这一倡议的公司包括万代南梦宫、Cygames 和东映等。通过这一举措，这些企业希望能够更好地维护自身的版权利益，确保创意作品不被不当使用。 划重点: 🌟 CODA 成立，万代南梦宫等日本大厂联合要求 OpenAI 停止使用其作品。 📜 OpenAI 使用创意作品进行训练的行为被指违反日本《版权法》。 🔒 CODA 旨在保护版权，推动日本文化作品的合法全球发行。

