## AI洞察日报 2026/2/13

>  `AI 日报` 

### 今日摘要

【1】tambo
React生成式UI SDK

【2】Personal_AI_Infrastructure
用于放大人类能力的智能体AI基础设施。

【3】langextract
一个Python库，通过使用具备精确来源追溯和交互式可视化能力的LLM，从非结构化文本中提取结构化信息。

【4】chrome-devtools-mcp
用于编码智能体的Chrome开发者工具

【5】PowerToys
Microsoft PowerToys是一套实用工具集，可大幅提升Windows系统的生产效率和自定义能力。

【6】AionUi
免费、本地、开源的24/7协同工具与OpenClaw，支持Gemini CLI、Claude Code、Codex、OpenCode、Qwen Code、Goose CLI、Auggie等 | 🌟 喜欢请点星！

【7】我还是期待这个，在我迟暮之年应该能见到吧
我还是期待这个，在我迟暮之年应该能见到吧 [图片: https://pbs.twimg.com/media/HBAabF1bQAAI5iz?format=png&#x26;name=orig] 卫斯理: 未来可以AI一个这样的女友吗？ [图片: https://pbs.twimg.com/media/HBADeATaoAAy99X?format=jpg&#x26;name=orig]

【8】预言一下 OpenClaw 还没到顶， 毕竟我都还没发开箱设置视频呢🌝
预言一下 OpenClaw 还没到顶， 毕竟我都还没发开箱设置视频呢🌝 [图片: https://pbs.twimg.com/media/HBAaF3hbsAEROdH?format=jpg&#x26;name=orig]

【9】这得买个前排去看
这得买个前排去看 [视频: https://video.twimg.com/amplify_video/2022124778514173952/vid/avc1/720x1280/soU3CSfegD23BIEN.mp4?tag=21]

【10】OpenAI 和 Cerebras 合作的首个模型 GPT-5.3-Codex-Spark 发布了，GPT-5.3-Codex 的精简版，在超低延迟硬件上运行、推理速度超过 1000 tokens/秒的轻量级编程模...
OpenAI 和 Cerebras 合作的首个模型 GPT-5.3-Codex-Spark 发布了，GPT-5.3-Codex 的精简版，在超低延迟硬件上运行、推理速度超过 1000 tokens/秒的轻量级编程模型！ https://openai.com/index/introducing-gpt-5-3-codex-spark/ 关键技术参数 · 上下文窗口：128k tokens · 模态：纯文本 · 推理速度：>1000 tokens/sec · 运行硬件：Cerebras Wafer Scale Engine 3 (WSE-3) · 可用平台：Codex 桌面应用、CLI、VS Code 扩展 · 当前开放范围：ChatGPT Pro 用户；少量 API 设计合作伙伴 · 费率限制：独立限额，不计入标准 rate limit；高峰期可能限流或排队 核心价值 OpenAI 明确了 Codex 产品线的双模式战略： · 长时段自主推理：由完整版 GPT-5.3-Codex 负责，能自主运行数小时甚至数天，适合处理复杂、大规模的工程任务。 · 实时交互协作：由 Codex-Spark 负责，做精准的局部编辑、逻辑重构、界面调整，即时看到结果。 OpenAI 正在构建一个混合工作流：用户可以在交互式循环中快速迭代，同时将耗时任务委托给后台的子智能体，甚至可以将任务扇形分发给多个模型并行处理。这是一个非常值得关注的架构方向。 Cerebras 合作的战略意义 · @cerebras WSE-3 是一种专用 AI 加速器，其核心优势在于极低延迟推理，而非传统 GPU 擅长的高吞吐量训练。 · OpenAI 明确表态：GPU 依然是训练和推理管线的基石，在广泛使用场景下提供最具成本效益的 token。Cerebras 是 GPU 的补充，专攻对延迟极度敏感的工作流。 · 两者可以组合使用以达到最佳性能。 这透露了 OpenAI 的一个重要基础设施策略：异构计算——根据工作负载特性匹配不同的计算底座。这对整个 AI 基础设施行业有指向性意义。 全链路延迟优化 工程改进表述的非常具体，值得技术读者特别关注： · 客户端-服务端响应流重写：优化了响应从服务器流回客户端的方式 · 推理栈核心组件重写：减少推理过程中的系统开销 会话初始化重构：让第一个可见 token 更快出现 · 引入持久化 WebSocket 连接：替代传统的 HTTP 请求-响应模式 量化成果： · 每次客户端/服务端往返开销降低 80% · 每 token 开销降低 30% · 首 token 延迟（TTFT）降低 50% 这些优化不仅限于 Codex-Spark，将惠及所有模型。WebSocket 路径目前默认用于 Codex-Spark，即将成为所有模型的默认通道。 编程能力评估 OpenAI 在两个智能体软件工程基准测试上展示了成绩： · SWE-Bench Pro：评估真实软件工程任务能力 · Terminal-Bench 2.0：评估终端环境下的工程能力 结论是：Codex-Spark 在保持强劲性能的同时，完成任务的时间仅为完整版 GPT-5.3-Codex 的一个零头。 OpenAI 也坦诚地指出 Codex-Spark 的工作风格是轻量级的：默认只做最小化、精准编辑，不会自动运行测试（除非你明确要求）。这是速度与深度之间的有意取舍。 安全评估 OpenAI 声明 Codex-Spark 经过了与主线模型相同的安全训练，包括网络安全相关训练。经过标准部署流程评估，该模型在网络安全和生物领域不具备达到其"准备框架"高能力阈值的可能性。 [图片: https://pbs.twimg.com/media/HBAO1pibsAIdkaH?format=jpg&#x26;name=orig] Andrew Feldman: Just one month after announcing our partnership with @OpenAI, we’re launching our first model together: OpenAI Codex-Spark, powered by @cerebras. Codex-Spark is built for real-time software development. In coding, responsiveness is the product. It is not a nice to have. [图片: https://pbs.twimg.com/media/HA-u0iDbsAAusoe?format=jpg&#x26;name=orig]

【11】确实这次去香港开卡，只有中银香港没成功，😂 线上App＋出入境记录PDF＋港澳通行证/内地身份证＋酒店WiFi＋扫脸就搞定了，全程1h不到就能开五张卡，大家感兴趣...
确实这次去香港开卡，只有中银香港没成功，😂 线上App＋出入境记录PDF＋港澳通行证/内地身份证＋酒店WiFi＋扫脸就搞定了，全程1h不到就能开五张卡，大家感兴趣我可以出详细教程～ [图片: https://pbs.twimg.com/media/HA_1FQjb0AAxOB8?format=jpg&#x26;name=orig] Geek: 听闻： - 香港中银线上开户全毙 - 众安银行审核力度加大，不再秒速获批。 - 汇丰还正常 (收管理费) 建议兄弟们，能办理的尽早行动。先把渠道打通，备而不用没关系，等彻底关门就晚了。

【12】今天这篇文章突破100万曝光了 这篇文章引起了很多有价值的讨论 这些讨论也让我更严肃地思考互联网世界和 Agent 世界 相比这篇中性而相对冷静的文章，英文世界更...
今天这篇文章突破100万曝光了 这篇文章引起了很多有价值的讨论 这些讨论也让我更严肃地思考互联网世界和 Agent 世界 相比这篇中性而相对冷静的文章，英文世界更激进，更焦虑，甚至开始用疫情来类比现状，开始出现很多吹哨人 我也不知道怎么评价了 昨天结束了全面的工作，晚上睡得很香 Orange AI: http://x.com/i/article/2020649239060340736

【13】AI 融资纪录再刷新！Anthropic 获 300 亿美元巨额融资，估值飙升至 3800 亿美元直逼 OpenAI
全球人工智能领域的"军备竞赛”已进入白热化阶段。2026年2月12日，由 OpenAI 前高管创立的 AI 独角兽 Anthropic 宣布完成了一笔震惊业界的巨额融资。 估值狂飙:向 第一 梯队全速冲刺 融资金额 :本轮融资共筹集 300亿美元 资金。 身价倍增 :融资完成后，Anthropic的估值已暴涨至 3800亿美元 。 豪华资方阵容 :本次融资由 Coatue 和新加坡主权财富基金 GIC 领投，参与者还包括 D. E. Shaw Ventures、Founders Fund 等 顶级 机构。值得注意的是，这笔资金中还包含了微软和英伟达此前宣布投入的部分款项。 资金用途:算力与研发的"弹药库” Anthropic表示，这笔史诗级的融资将主要用于以下三大核心方向: 基础设施扩张 :构建支撑下一代超大规模模型训练的算力中心。 前沿技术研发 :持续迭代其核心模型，维持在模型安全与性能上的领先地位。 企业级产品投资 :加速 AI 技术在商业场景中的落地应用。 行业观察:AI 泡沫还是新范式? 尽管周四美股市场因投资者担忧 AI 的颠覆性风险而出现普跌，但大模型头部厂商的吸金能力依然惊人。Anthropic估值的快速拉升，反映出全球资本对"通用人工智能（AGI）”入场券的极度渴望。 在OpenAI刚刚上线广告业务寻求增收的背景下，Anthropic的这份百亿美金账单无疑再次推高了这场技术博弈的门槛——未来的 AI 赛道，或许将成为极少数"千亿美金俱乐部”成员的 终极 游戏。

【14】OpenAI 告别 GPT-4o:2026年2月13日正式下架旧模型
尽管拥有着极具情感色彩的历史，OpenAI 仍决定在 2026年2月13日 正式从 ChatGPT 的模型选择器中移除 GPT-4o 及其衍生模型。 此番下架涉及的模型包括 GPT-4o、GPT-4.1、GPT-4.1mini 以及 o4-mini 。值得开发者注意的是，这些模型目前仍将暂时保留在 API 中，但 ChatGPT 的普通用户将全面转向更先进的 GPT-5系列。 [图片: OpenAI https://pic.chinaz.com/picmap/202502061719358642_0.jpg] 淘汰原因:0.1% 的"长情”抵不过技术演进 OpenAI 表示，这一决策主要基于真实的使用数据:在任何给定的一天里， 仅有0.1% 的用户 仍在手动选择使用 GPT-4o。 "停用模型从来都不是一件容易的事，但这能让我们集中精力改进目前大多数用户使用的模型。” —— OpenAI 官方声明 GPT-4o 的复杂谢幕:一段与用户的"情感纽带” GPT-4o 被下架引发了部分核心拥趸的强烈反应，这主要归因于该模型独特的"人设”: 两度下架: 2025年8月，OpenAI 曾尝试移除 GPT-4o，但在遭遇用户大规模抗议后被迫恢复了付费用户的访问权限。 情感寄托: 该模型以其温顺、甚至有些"讨好”用户的沟通风格著称。社交媒体如 Reddit 上甚至出现了"拯救 GPT-4o”的请愿，有用户称该模型在情感支持方面具有不可替代性。 继任者:更聪明，且可以"定制性格” 为了安抚旧模型的拥趸，OpenAI 推出了 GPT-5.1 和 GPT-5.2 作为官方继任者。 新模型不仅在推理能力上大幅提升，还引入了 语气与风格自定义 功能。用户现在可以根据喜好调整 ChatGPT 的"人味”: 性格预设: 可选"热情”、"亲切”、"坦率”或"古怪”等选项。 微调控制: 支持调整回复的简洁度、亲切感以及表情符号的使用频率。 这种高度的个性化控制被视为是对 GPT-4o 情感特质的另一种形式的继承，旨在将那些流连于旧模型的用户引入新的 AI 时代。

【15】🤨 AWS 在非裸金属 EC2 实例上支持嵌套虚拟化，可运行 Firecracker/microVM（M8id/C8id/R8id）
原标题： 《AWS Adds support for nested virtualization》 评分: 33 | 作者: sitole 💭 在虚拟机里再跑虚拟机，谁来为性能和费用埋单？ 🎯 讨论背景 AWS 在其主 SDK 和管理控制台中加入对 nested virtualization 的支持，在 us-west-2 区域已出现 Nested Virtualization 选项，并可在新的 M8id、C8id、R8id EC2 实例上启用。嵌套虚拟化允许在虚拟（非裸金属）实例内运行二级虚拟机，从而能在普通 EC2 上部署 Firecracker（AWS 的轻量级 VMM）和其它 microVM，而无需租用裸金属服务器。讨论建立在两个前提上：一是其他云厂商（如 GCP）或本地工具（如 libvirt）早已支持类似功能，二是社区关心该特性在生产场景下的性能（尤其 I/O 与 MMU 相关开销）和成本是否能接受；同时有人提到微虚拟机沙箱项目（如 E2B）会直接受益。评论因此出现分化：既有对部署便利性的乐观，也有要求实测基准和质疑新闻价值的怀疑声音。 📌 讨论焦点 对 microVM 和沙箱方案的影响 支持嵌套虚拟化意味着可以在普通（非裸金属）EC2 实例内运行二级虚拟机，例如 Firecracker 等 microVM，从而不再必须租用昂贵的裸金属实例以获得嵌套 VM 能力。AWS 已在主 SDK 中加入此功能，并在 us-west-2 区域的控制台显示 Nested Virtualization 选项，可在新的 M8id、C8id 和 R8id 实例上启用。对此类轻量级虚拟化或沙箱项目（例如 E2B 微虚拟机沙箱）来说，这降低了部署门槛并提升可移植性。部分评论把这视为对以 micro-VM 为核心工作负载的云平台支持的实质性改进。 [来源1] [来源2] [来源3] 认为并非创新 / 功能并不新 部分评论认为这项更新并不创新，指出嵌套虚拟化在本地和其他云厂商（如 GCP）早已可用。有人提到用 libvirt 在消费级硬件上长期能实现嵌套虚拟化，称 AWS 只是落后数年地把现有能力搬上云。还有评论提出嵌套虚拟化常被视为 PoC 或测试工具，对不缺乏虚拟化资源的生产环境价值有限。总的来看，这类观点认为技术本身熟悉且普遍，因此新闻意义被弱化。 [来源1] [来源2] [来源3] 性能与成本担忧 许多评论集中在性能和成本权衡上，特别是对 I/O 密集型负载的影响。有人要求看到具体基准数据，认为嵌套虚拟化可能带来额外的 MMU 转换和上下文切换，从而降低吞吐或增加延迟。另有观点担心对遗留应用来说在成本和兼容性上可能更不划算，认为在没有实测数据前难以把它当作裸金属或现有方案的替代。评论普遍呼吁厂商或社区给出延迟、I/O 吞吐和 CPU/内存开销的实测结果以便评估。 [来源1] [来源2] [来源3] 📚 术语解释 nested virtualization（嵌套虚拟化）: 在一个虚拟机（guest）内运行另一个虚拟机的能力，允许 guest 安装并运行 hypervisor 以创建二级 VM。常用于沙箱、测试和多层虚拟化场景，但会引入额外的 MMU/上下文切换开销，可能影响 I/O 和延迟。 Firecracker / microVM: Firecracker 是 AWS 的轻量级 VMM（virtual machine monitor），用于启动 microVM（小型虚拟机）以支持 serverless 和高密度隔离的工作负载。microVM 追求更短的启动时间和更低的资源开销，同时提供比容器更强的隔离性。 bare-metal（裸金属）: 指直接运行在物理服务器上的实例或主机，没有虚拟化层提供的抽象。裸金属实例通常用于需要直接硬件访问或最高性能的工作负载，但成本和管理复杂度通常高于虚拟化实例。 类别： Systems | Release | AWS | nested virtualization | microVM | aws-sdk-go-v2

【16】比肩 Claude 4.5！硅基流动上线高速版 GLM-5，国产大模型斩获全球第四
国产大模型在2026年开年迎来里程碑式突破。智谱 GLM-5在正式开源后，凭借卓越性能在全球 权威 榜单 Artificial Analysis 上斩获 全球第四 ，其评分已与 Claude Opus4.5持平。 [图片: image.png https://upload.chinaz.com/2026/0213/6390657147371725595801599.png] GLM-5的核心技术革新: 基座能力飞跃 :参数规模由355B 扩展至 744B ，预训练数据量达28.5T。 架构优化 : 首次 集成 DeepSeek 稀疏注意力机制，在维持长文本理解力的同时，大幅降低了部署成本。 编程与工程专家 :在 SWE-bench Verified 测试中取得开源 SOTA 分数（77.8），表现甚至超越了 Gemini3Pro，展现出极强的后端重构与深度调试能力。 目前，硅基流动 AI 云已正式上线高速版 GLM-5，支持 198K 上下文长度。开发者可通过 API 将其接入 Trae、Cline、Kimi Code 等主流开发工具。 此外，硅基流动近期还更新了多项服务，包括上线高速版 Kimi K2.5、免费调用 PaddleOCR-VL-1.5以及在 BizyAir 登陆 Nano Banana Pro 等模型。

【17】😤 macOS Tahoe 窗口调整争议：原生体验欠佳，第三方工具救场
原标题： 《Resizing windows on macOS Tahoe – the saga continues》 评分: 62 | 作者: erickhill 💭 不装第三方，你真指望 macOS 自带好用窗口管理？ 🎯 讨论背景 话题围绕 macOS（标题中的 "Tahoe"）在窗口移动与调整上的设计与可用性争议展开，用户将系统默认行为与 Windows（如 FancyZones、Win +E 文件管理）和 Linux 窗口管理器的键位交互做对比。评论既有对像素级改动与 Fitts's Law 的技术辩论，也有大量实践性建议：安装 Rectangle、Raycast、Moom 或用 Hammerspoon 写脚本来恢复高效工作流。讨论涉及视觉设计变化（例如被称为 "Liquid Glass" 的风格）如何影响功能，以及 UI toolkits 中视觉外观与实际 hitbox 不一致导致的可点性问题。总体背景是：许多重度用户认为 macOS 需要更直观的默认窗口管理，否则不得不依赖第三方补丁。 📌 讨论焦点 原生窗口管理体验不足 多位评论者抱怨 macOS 原生的窗口移动与调整在日常工作流中显得笨拙，常常不能像 Windows 那样快速贴靠或划分三分区。系统虽然有"将鼠标悬停绿点显示简易分屏”与"双击边缘放大”等功能，但用户指出这些仅为有限补偿，不能替代 Windows 的 auto-snap 或 Linux WM 的键位操作。实例包括 Finder 文件管理、截图后快速编辑等常见任务在 macOS 上被描述为更慢、更难用；有人还批评近年的视觉改动（如"Liquid Glass”风格）反而削弱了功能性。总体观点是：默认设置对重度用户不友好，很多人不得不靠额外技巧或第三方工具才能恢复工作效率。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] 第三方工具与自定义脚本是主要解法 讨论里普遍的解决思路是安装第三方工具或自写脚本来弥补系统短板，常见选择包括 Rectangle/Rectangle Pro、Raycast、Moom，以及通过 Hammerspoon 用 Lua 自定义布局。多人称 Rectangle 的快捷键使窗口管理比 Windows 更高效，但 Rectangle Pro 为付费扩展；也有人把 FancyZones（Windows PowerToys 的窗口分区模块）当作理想对照，表示 macOS 上暂时没有免费且完整等价品。对高级用户而言，Hammerspoon 被推荐用于按坐标放置窗口并实现多屏幕细粒度控制；总体结论是"装了第三方后可以接受，但不该是必要条件”。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] [来源8] [来源9] 点击命中区、命中概率与 Fitts's Law 的技术争论 有评论把像素变化（例如边框从 7px 变 6px 把 14% 概率增加的说法）当作问题，但也有技术反驳指出用户点击并非均匀随机分布，而是集中于目标中心，所以"14% ”的表述夸大了影响。进一步的观点引用了 Fitts's Law（人机交互中描述移动时间与目标大小/距离关系的模型），强调在这种尺度下可发现性和目标可感知性比微小像素差更重要。另有人好奇为什么视觉曲线和实际可点击 hitbox 不一致，并解释这是 UI toolkits 的常见做法：交互目标可以与视觉资源分离，从而导致"看起来可点但实际上不可点”的错位。评论中还提供了量化参考（例：按 262 ppi 计算 1px ≈ 0.097 mm）以说明绝对尺寸极小。 [来源1] [来源2] [来源3] [来源4] [来源5] Linux 风格键位/鼠标组合被视为更高效的替代 一些长期使用 Linux 的用户强烈推崇 Linux 窗口管理器的键位与鼠标组合（如 super + left/right click 或 alt + 右键调整），认为它们比在角落/边缘精确瞄准更高效。评论者表示习惯了用键+鼠标在任意位置拖动或调整窗口后，回到 macOS/Windows 需要把鼠标移到边缘或角落的方式显得"野蛮”。他们也抱怨目前在 macOS 上很难找到免费且同等流畅的替代实现，因而更依赖第三方工具或自写脚本。 [来源1] [来源2] [来源3] 📚 术语解释 Fitts's Law: Fitts's Law（菲茨定律）：人机交互中描述移动时间与目标距离与大小关系的模型，常用于评估点击或触控目标的可达性，强调目标可发现性与尺寸在交互效率上的非线性影响。 FancyZones: FancyZones（Windows PowerToys 的窗口分区模块）：允许用户定义屏幕布局区域并将窗口快速放置到预设区域，是 Windows 上常被拿来对比 macOS 的分屏/布局解决方案。 Rectangle / Rectangle Pro: Rectangle（macOS 的窗口管理工具）：通过快捷键把窗口放到预定义区域以提升分屏效率；Rectangle Pro 为其付费版，提供更多高级分区与交互功能。 Hammerspoon: Hammerspoon（开源 macOS 自动化与定制工具）：通过 Lua 脚本精确控制窗口位置、热键与多显示器行为，适合需要高度自定义布局的用户。 Raycast: Raycast（macOS 的第三方启动器与工具集合）：替代 Spotlight 的应用，内置许多生产力插件與快捷操作，也能提供部分窗口管理功能。 Moom: Moom（macOS 窗口管理工具）：支持通过鼠标或快捷键触发窗口分区和预设布局，常用于提升窗口排布效率。 类别： Systems | Product | Opinion | macOS Tahoe | Apple | window resizing | Rectangle | Rectangle Pro | Raycast | Moom | tiling | Fitts's law

【18】奥数金牌级推理！谷歌发布新版 Gemini 3 Deep Think：专为科研而生，性能直逼"人类最后考场”
大模型正从"聊天助手”进化为真正的"科学家”。2026年2月13日，谷歌正式宣布对 Gemini3Deep Think 深度思考大模型进行重磅升级。这款模型不再满足于日常对话，而是将目标锁定了科学、研究与工程等需要严密逻辑推理的高端领域。 科研"推理模式”:挑战无 唯一 解的难题 新版 Deep Think 是谷歌开发人员与 顶尖 科学家深度共创的成果，专门解决真实科研中的痛点: 应对复杂环境 :针对边界模糊、不存在 唯一 标准答案、且数据杂乱不全的复杂问题进行了深度优化。 扩大开放范围 :从2月12日起，Google AI Ultra订阅用户即可在应用中体验。 开发者尝鲜 :谷歌 首次 通过 Gemini API 向部分研究人员和企业开放了"早期访问计划”。 战绩显赫:横扫奥赛与职业基准 在多项被公认为"地狱级难度”的测试中，Gemini3Deep Think交出了令人惊叹的答卷: 奥数金牌水平 :在2025年国际数学奥林匹克（IMO）测试中达到金牌表现，物理与化学奥赛笔试同样斩获金牌级评价。 逼近人类极限 :在"人类最后考试”（Humanity's Last Exam）中取得48.4% 的成绩。 编程 天花板 :在 Codeforces 竞赛编程基准上获得3455的 Elo 分值，展现出极强的算法与工程建模能力。 从"刷榜”到"落地”:实验室里的数字助手 谷歌强调，Deep Think 的研发初衷并非仅仅为了刷新基准测试数据，而是要真正进入实验室: 助力工程建模 :帮助工程师通过代码对复杂的物理系统进行高精度建模。 深度数据分析 :协助科研人员解释和挖掘庞大且零散的科学数据。 随着 Gemini3Deep Think 的全面介入，AI 正在从单纯的效率工具转型为科研创新的"合伙人”。

