## AI洞察日报 2026/1/29

>  `AI 日报` 

### 今日摘要

【1】全球最强AI音乐模型，现在来自中国！高晓松也来围观了
全球最强AI音乐模型，现在来自中国！高晓松也来围观了 [图片: http://www.qbitai.com/wp-content/themes/liangziwei/imagesnew/head.jpg] 一水 2026-01-29 10:29:27 来源： 量子位 "好的AI音乐是一种新的音乐品类” 把AI模型发布会开在Livehouse，昆仑天工你是懂氛围感的（doge）！ 虽然乍一听有点奇怪，但如果告诉你这里正在发布的是一款 音乐模型 ，估计你也就get到它的小巧思了。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/e8d40bb7e848dd1e193e39748ee055d2.jpeg] 先不说别的，咱这就火速品鉴一下这支由 新模型Mureka V8 提供BGM的MV： [图片: https://i.qbitai.com/wp-content/uploads/2026/01/331feee8e5d41f825325d2cca1570d6c.png] 视频链接：https://mp.weixin.qq.com/s/WRyKhNOkfkpZVLiYEGYnKg 是不是很有韩国女团打歌的feeling了~不过从现场来看，这还只是Mureka V8实力的冰山一角—— 在各路音乐人实测中， 它一举打败硅谷顶尖音乐模型Suno V5，登顶垂类世界第一 。 而随着这一标志性节点的出现，此前被反复讨论、却始终缺乏共识的判断，第一次有了现实依据—— 好的AI音乐，正在逼近从辅助工具走向"新品类”的关键门槛 （类似爵士/乡村/说唱这些品类）。 毕竟放在不久之前，很难想象AI写这样一首歌可能就是一眨眼的事情！ [图片: https://i.qbitai.com/wp-content/uploads/2026/01/a03825fc48f520bc4ca7b9d85c7d74ff.png] 音频链接：https://mp.weixin.qq.com/s/WRyKhNOkfkpZVLiYEGYnKg 在发布会现场，昆仑万维董事长兼CEO方汉表示： 为什么要把Mureka当品类来做？这其实和我们的使命有关——我们想让音乐变成每个人都拥有的表达方式，记录当下的心情、记忆、想说的话等等。 而当好的AI音乐成为一种新品类，AI版"Spotify”（指旗下的Mureka）会成为行业的灯塔 ，能让创作者被看见，让作品被放大，让行业形成新的共识。 而他所描绘的这一未来图景，也获得了高晓松及国内顶尖唱片公司负责人的认可。作为离产业一线最近的人，他们对好的AI音乐引发的变革浪潮，感知也最为敏锐。 那么问题来了—— Mureka V8真实能力究竟几何？它真能扛起AI音乐变革的大旗吗？ 老规矩，一手实测见真章。 超越Suno V5，昆仑天工新模型登顶世界第一 事先声明，本人算是日常听歌比较多的人（网易云10级临门一脚选手），之前一直觉得AI对音乐领域的开发还处于比较初级的阶段，一般新东西出来后也只是浅尝辄止、再无后续。 但体验了Mureka V8后，内心只有两个想法： 1）虽然不懂专业音乐知识，但有了这个工具，以前随手写的歌词也能立马变成完整歌曲了，几乎0门槛就实现了自己的音乐梦； 2）有了这个工具，以后人人都能写歌并且发歌了，而且因为平台提供了销售模式，所以普通人也能dream一个靠这个赚钱了（搞钱思路+1）。 而且在随机对比了Mureka V8和它之前的版本后，你能明显发现—— AI音乐领域的叙事逻辑变了，以前模型交出的"作品”还停留在"可生成”（用了AI）阶段，但现在直接迈向了"可发布”（一种新的、完整的作品）阶段。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/7174fe516836367cb55654c8a63124b8.jpeg] 怎么个"可发布”？这主要从 演唱与表达力、音乐性完整度、制作与音质水准、市场适配性等 几个层面展开。 这些都是常规意义上，一首歌写完后能否直接发布的主要参考因素，而Mureka V8这次基本都做到了。 先说唱功。 以前因为歌手念词总有种机械感，所以很多歌一听就是AI唱的。 但这次Mureka V8 会根据用户选择的歌手性别，智能匹配唱法，所以听起来明显更像人类主唱了 。 同样的歌词，保证其他设置一致而只改变性别的情况下，男生/女生版分别如下： 摇滚乐风格，可参考The Kinks乐队（与披头士滚石齐名的一支英国乐队、迷幻摇滚风格）。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/dde707ca31b73311ed91968c392d7ef4.png] 视频链接：https://mp.weixin.qq.com/s/WRyKhNOkfkpZVLiYEGYnKg 是不是开口就能明显听出不同风格和唱法？ 男声在Intro后很快就接上歌词，而女声明显加了一段自己的唱腔，一下子就给整体分别定调：一个浑厚一个慵懒。 而且每一句歌词都有自己的情绪和张力，就拿"咚”这个明显不好处理的歌词来说，Mureka旧版就处理得相对平淡，而这里明显都变成重音，Rock and Roll的感觉一下子就出来了。 再说音乐的完整度。 现在仅需一句话或简单的歌词，Mureka V8就能火速生成一支完整的乐曲了。 为了体现差异，我们还是用同样的歌词测试Mureka V8和旧版本，只不过换一个乐队风格： 摇滚乐风格，可参考平克弗洛伊德乐队（Kimi月之暗面的起名灵感就是这支乐队的一张专辑）。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/1b390935a44c731024b6849c24c57e37.png] 视频链接：https://mp.weixin.qq.com/s/WRyKhNOkfkpZVLiYEGYnKg 别的不说，从时长就能一眼看出差别了。旧版只有两分多钟，而新版是更接近主流歌曲规格的三分多钟。 而且这多出来的，还恰好是能体现这支乐队风格的精华——开头和结尾都是大段大段的纯乐器演奏。 （p.s.这支乐队采用这种独特的器乐编排技巧，有一首专辑时长有40多分钟，并收获全球乐迷的喜爱。） 这样一来，整首歌的旋律和编曲，一下子就变得更加丰富和抓耳了。 不过鉴于旋律和编曲这事儿主观性比较强，所以咱们还是听听专业音乐人的客观评测。 从以下对比图可以看到， 即使以专业的耳朵来听，Mureka V8也在综合实力上打败了硅谷顶尖音乐模型Suno V5、成为世界第一 。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/1aff2b65d8eadfd70c19b143fc078555.webp] 更关键的是，作为一款国产模型， Mureka V8天然"继承了”东方音乐审美，很多歌曲一出来你就能感受到浓浓的中国风、中国味儿 。 这不，春节马上就要到了，就让Mureka V8创作一首马年贺曲吧。 马年新春贺曲、年味儿 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/cf9186b21d0fff548ade4a21f47c544a.png] 视频链接：https://mp.weixin.qq.com/s/WRyKhNOkfkpZVLiYEGYnKg 好好好，一开口就知道离放假不远了~ 尤其是副歌阶段男女生混唱的时候，听起来真的很像过年超市会循环放的其中一首歌。 Anyway，一番实测下来，Mureka V8给人留下的最大印象就一个词： 完整 。 随机丢给它任何一个简单的想法（简易模式）、任何一段歌词（自定义模式），Mureka V8都能立马输出一首足以直接发布的作品—— 它不再只是一段"AI生成的音频片段”，而是一首结构完整、情感连贯、制作精良的"歌” 。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/80b5cbfc8228094ed2e633e37e328bf1.webp] 而之所以能实现这一点，这还要得益于模型背后所采用的 MusiCoT技术 。 由于将思维链技术应用到了音乐制作领域，所以Mureka V8能模仿人类进行创作—— 就像人类音乐人那样，它会主动构思整体结构、设计情绪推进，最终产出的不是音频片段，而是结构完整、情感连贯、可直接发布的成熟作品。 下面这张图就清晰展示了传统模型和Mureka V8之间的区别： 传统自回归音乐生成模型 ：文本/歌词→直接生成→音乐片段； 基于MusiCoT的模型 ：文本/歌词→思维链规划（结构、配器、情绪）→按结构生成→一首完整的歌。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/0767d0ebbe6c702c3de0185c51fbd790.webp] 这种从"能生成”到"能发布”的跨越，正是技术质变的关键。 也正因为如此，Mureka V8的意义已经不再只是一次模型迭代—— 它不再只是创作流程中的"辅助工具”，而是 第一次以完整性、自主性和可发布性，站到了一个全新位置上 。 在这个意义上，好的AI音乐，终于开始以"新品类”的姿态屹立。 但问题是，如果只是模型进步，这一切真的足以支撑"新品类”这个判断吗？ 就在AI音乐领域，行业新范式诞生了 答案，显然不只在模型里。 技术的成熟，最终必须走向行业的融合与价值的重塑。 而这一次，昆仑天工作为AI代表，也终于将触角伸向了产业深处—— 直接联合 高晓松与太合音乐 （秀动运营方、旗下艺人有许嵩、刘惜君等）一起"搞事”，一举打通好的AI音乐从技术到商业、从创作到发行的整个链路。 其中，高晓松作为知名音乐人，代表的是专业音乐人开始主动拥抱AI，通过新工具拓展创作边界。 在围绕"AI时代的音乐创作新范式”展开的圆桌论坛上，高晓松现场表示： AI本质上是在处理"怎么说”，而不是"说什么”。真正的创作源于人心里那个独特的"洞”——那是生活、情感和个体经验赋予的，AI无法替代。 但AI在编曲、演唱、制作效率上的能力已经无与伦比，它让音乐创作的门槛前所未有地降低，正在推动音乐从PGC（专业生成内容）向UGC（用户生成内容）转型。 最终他认为， 当每个人都可能成为创作者，音乐将不再只是版权交易的商品，而可能成为更普遍的社交语言和表达方式 。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/5f128a4737f7e7fe1b4855fd380c7248.webp] 这一判断，也得到了知名音乐人、环球音乐Republic唱片中国首任董事总经理闻震（下图左二）的认同。 而且他在现场补充表示： AI音乐在未来音乐风格品类中一定会占据重要地位，并且份额会越来越大 。 对于专业音乐人而言，AI是一个强大的赋能工具——它能把基础工作做到80分，剩下的20分则需要音乐人用自身的审美、认知和与AI的提示词交互能力去完成。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/21a5fa846bd06c028da0a7b55bcdb591.webp] 总之，作为资深音乐人，他们都感受到了AI音乐给整个行业带来的冲击。 这一感受或许不亚于昆仑天工董事长兼CEO周亚辉（右一）在见证Mureka V8诞生时的激动之情： 最初技术团队认为"五年内做不出完整的AIGC音乐”，但到Mureka V8仅用约两年时间实现了上百倍的进步。 当我们真的把V8训练出来的时候，我意识到，音乐产业100%肯定要变化 。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/1402fca8945b1f5d0ec478135e7af2f4.webp] 至此，变化已经成为一种共识。 而这个新事物若想持续健康发展，则离不开整个产业链的协同发力。在这方面，中国传媒大学教授赵志安（右二）认为： 音乐产业的发展离不开艺术价值、商业价值与社会价值的统一。AI目前作为工具，在激发灵感、提升效率和风格化体验方面优势明显。 但未来的持续发展，核心在于数据版权与收益分配的规范化 。只有解决了训练数据的授权、AI生成内容的版权确权与合理分配机制，无论是UGC还是PGC模式，AI音乐才能真正形成健康、可持续的产业生态。 对此，昆仑天工这一次也拉来了太合音乐这个产业端的关键角色。 在发布会现场，昆仑天工正式官宣与太合音乐达成深度战略合作，并举行了现场签约仪式。 作为打通"产业最后一公里”的关键一环， 太合音乐将为Mureka V8生成的音乐提供发行渠道、商业变现资源，从而解决AI音乐从创作到落地的核心痛点 。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/d0d95120bdea27ec031115a66c53736b.webp] 而到这里，一条围绕好的AI音乐的新型产业链条，已经呈现出清晰的分工结构： 昆仑天工的Mureka V8 ：作为技术底座与创作载体，解决"能不能写出好音乐”的问题； 高晓松 ：代表专业音乐人主动拥抱AI，让AI音乐创作进入主流叙事的视野，主要起到催化剂的作用； 太合音乐 ：通过发行与商业化能力，为好的AI音乐提供变现渠道，从而让整个商业逻辑形成闭环。 而"传统唱片公司+顶流音乐人+AI巨头”联手，所释放出的信号也已经相当明确了—— 作为行业最前沿的一批玩家，他们已不再将AI视为颠覆性的替代威胁，而是开始学会适应 。 其实这也很好理解。 大多数新事物刚出来时，人们总是会下意识抗拒和恐惧，但一旦经历过一定的发展阶段，当它的价值被反复验证、边界被逐渐厘清，合作便成了比对抗更务实、也更有利的选择。 而好的AI音乐就处在这样的阶段。 一旦跳出"AI是否会替代人类创作”的陈旧争议，考虑如何将其作为一种新的、强大的创作变量纳入生产体系，便成了顺理成章的议题。 好的AI音乐正在成为一种新品类 而当人们开始认真讨论"如何才能创作出好的AI音乐”，一个新的创作阶段，事实上已经拉开序幕—— 音乐创作不再只属于少数专业人群，而是开始向更多普通创作者开放。 就是说，人人参与好的AI音乐创作的时代，正在加速到来 。 在这个过程中，好的AI音乐"新品类”的身份也被进一步坐实，因为相较于传统音乐与早期AI音乐工具，它正在呈现出一种全新的形态—— 不只是"创作工具”，更是"新消费载体” 。 这种消费属性可以体现在我们日常生活中的方方面面，例如，用AI给好友写首专属生日歌、给某个私人旅行vlog配首应景的BGM、给自家咖啡店生成一首专属音乐…… 此时，每个人都可以根据自身需求，定制专属的旋律、风格与情绪表达，使音乐从标准化内容，演变为高度个性化的体验。 甚至还能拿来玩梗，承担起社交职责（doge）——去年B站一首AI创作的《美猴亡》就一度爆火，最高播放量上千万并引发广泛社媒讨论。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/aa6982871e10dc9d8992d68ce7760eb9.webp] 显而易见，此时好的AI音乐已经不再仅仅是被"听见”的作品，而是被用户深度"参与”的内容。 而这，正是它作为一种新消费载体的本质所在。 此外，最近摩根士丹利的一份调研显示，在美国18–44岁人群里，一半以上的人每周都会听AI音乐，平均大概2.5–3小时/周。换算一下，这些人每天大概会听20分钟。 如此也侧面证明了，当AI音乐达到"好”的标准时，其作为一种新消费载体的应用潜力。 当然了，除了在结果端彰显其"新品类”地位，好的AI音乐也在创作端拥有自己的独特定位—— "新创作伙伴” 。 回顾整个实测过程，我们对这种 人机协同的创作模式 可谓感受颇深。 一边是创作方式的"极简”，另一边是作品的"极深”。当你发现仅需一句话、一段随机哼唱就能创作一首完整的歌时，那种瞬间掌握某种技能、瞬间拿到成果的成就感，确实直击人心。 而这一切的核心价值在于—— 它同时解放了创意的上限，与创作效率的下限。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/67706a93300bcc916a600e22ff90110c.jpeg] 当这种创作模式被越来越多的人反复使用、持续产出时，接下来的问题则只剩下一个—— 如何变现形成良性循环？ 对此，昆仑天工也算是为我们打了个样。 不同于早期AI音乐工具多停留在"生成即结束”的阶段，他们围绕新一代音乐模型，尝试将创作工具、内容社区、发行渠道与商业化服务，逐步串联起来。 模型 ：负责提供稳定且持续演进的创作能力； 工具 ：负责降低使用门槛，帮助创作者高效完成表达； 社区 ：承载内容的交流、反馈与扩散； 发行与服务体系 ：为好的AI音乐提供进入现实世界的通路。 还是以Mureka V8为例。这边模型一更新，另一边工具端的 Mureka创作平台 就立即上架新模型了。 对所有普通用户来说，这种开箱即用的工具极大降低了使用最前沿模型进行音乐创作的门槛。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/b62ea1534adb900f846d746c6d4ee685.webp] 甚至，如果你段位更高，是熟悉DAW（数字音频工作站）制作流程的专业音乐人或发烧友，堪称进阶版的 Mureka Studio 或许更适合你。 昆仑天工对这款工具的定义为： 我们想用AI的方式改造DAW的核心逻辑，把"操作软件”变成"指挥创作”。 你只要把想法说清楚：我要什么情绪、什么推进、什么副歌钩子、什么人声质感。Mureka Studio负责把它快速做成可编辑、可迭代的作品形态——让新创作者进入门槛变低，让专业创作者上限更高。 悄咪咪透露，目前这款工具也正在 内测中 ，在Mureka官网即可申请。 [图片: https://i.qbitai.com/wp-content/uploads/2026/01/e1a081ba30f5754c551b8bdc8055b176.webp] 而在用户端之外，他们还同步开放了B端的 Mureka API服务 —— 通过完整封装的API功能，终端用户可以像在C端产品中一样，结合歌词、人声和参考歌曲进行深度定制与反复调整。 据昆仑天工透露，凭借每年2-3个版本的极速迭代，以及针对音乐创作和视频创作等全场景的模型微调服务，他们已经为全球8000多家客户提供了性能最稳定的官方支持。 一些典型的合作方式be like： [图片: https://i.qbitai.com/wp-content/uploads/2026/01/4cb5c2075186f316895b0b9a9921b2fd.webp] 总而言之，靠着打通 "模型+工具+社区+服务”这套链路 ，好的AI音乐第一次真正拥有了走出实验场的现实可能—— 它不再只是新奇的技术展示，而是开始成为能驱动产出、创造价值的新型生产工具。 而也正是在具备了"被使用”"被消费”"被变现”的能力之后，好的AI音乐才第一次脱离了概念讨论，开始在现实世界中站稳脚跟。 一旦整个闭环运转良好，好的AI音乐与传统音乐之间，就不会是"二选一”的状态。 最终的结局或许就是今日好的AI音乐被反复提及的一个论断： 它更可能与传统音乐并肩而行，作为一种新的音乐品类，共同拓展音乐的表达边界，丰富人类的精神世界 。 最后，对于昆仑天工此次发布的Mureka V8，国内用户已经可以通过Mureka官网和API体验。 不知道你的第一首AI音乐，又是为谁而作的呢？（林俊杰：？） [图片: https://i.qbitai.com/wp-content/uploads/2026/01/f7ec8ee7e8298249a3971225354c21c6.jpeg] 【传送门】： https://www.mureka.ai/ https://www.mureka.cn/（国内版） 版权所有，未经授权不得以任何形式转载及使用，违者必究。

【2】阿里AI芯片露真容 "通云哥”黄金三角浮出水面
1月29日上午，平头哥官网悄然上线一款名为"真武810E”的高端AI芯片，此前被央视《新闻联播》曝光的阿里自研芯片PPU正式亮相。这是通义实验室、阿里云和平头哥组成的阿里巴巴AI黄金三角"通云哥”首次浮出水面。 阿里巴巴正在将"通云哥”打造成一台AI超级计算机，它同时拥有全栈自研芯片平头哥、亚太第一的阿里云，以及全球最强的开源模型"千问”，可以在芯片架构、云平台架构和模型架构上协同创新，从而实现在阿里云上训练和调用大模型时达到最高效率。目前，阿里和谷歌是全球唯二在大模型、云和芯片三大领域均具备顶级实力的科技公司。 据悉，"真武”PPU已在阿里云实现多个万卡集群部署，服务了国家电网、中科院、小鹏汽车、新浪微博等400多家客户。[图片: https://image.jiqizhixin.com/uploads/editor/6c4bfe02-8335-4a52-98b0-9f36a96010c5/%E5%9B%BE%E7%89%871.png] （图说：平头哥官网上线"真武”PPU。） 据平头哥官网介绍，"真武”PPU采用自研并行计算架构和片间互联技术，配合全栈自研软件栈，实现软硬件全自研。其内存为96G HBM2e，片间互联带宽达到700 GB/s，可应用于AI训练、AI推理和自动驾驶。阿里巴巴已将"真武”PPU大规模用于千问大模型的训练和推理，并结合阿里云完整的AI软件栈进行深度优化，为客户提供一体化产品和服务。 据业内人士透露，对比关键参数，"真武”PPU的整体性能超过了英伟达A800和主流国产GPU，与英伟达H20相当。另据外媒最新报道，升级版"真武”PPU的性能强于英伟达A100。多位行业从业者告诉记者，"真武”PPU性能优异稳定、性价比突出，在业内口碑良好，市场供不应求。 "真武”PPU的正式亮相，显示了平头哥在芯片领域积累多年的实力。阿里巴巴2009年创建阿里云，2018年成立平头哥芯片公司，2019年启动大模型研究，经过长达17年的战略投入和垂直整合，终于实现"通云哥”全栈AI的完整布局。 1月26日，通义实验室发布千问旗舰推理模型Qwen3-Max-Thinking，创下多项权威评测全球新纪录，性能媲美GPT-5.2、Gemini 3 Pro。全球最大AI开源社区Hugging Face的最新数据显示，千问开源模型的衍生模型数量突破20万个，下载量突破10亿次，稳居全球第一。 ]]>

【3】🤨 罗斯·史蒂文斯捐 1 亿：承诺每名美奥/帕运员 20 万美元，但延迟与身故给付遭质疑
原标题： 《Ross Stevens Donates $100M to Pay Every US Olympian and Paralympian $200k》 评分: 21 | 作者: bookofjoe 💭 承诺二十年后给钱，能当下提升成绩吗？ 🎯 讨论背景 罗斯·史蒂文斯（一位金融界富豪）向美国奥运与残奥运动员群体捐赠 1 亿美元，媒体报道每名运动员承诺 20 万美元：一半在首次入选奥运后 20 年或年满 45 时发放，另一半作为身故给付留给家属。该方案与即将到来的 Milan–Cortina Olympics（米兰-科尔蒂纳 2026 年冬奥会）相关，细节由 Wall Street Journal 报道。评论围绕两类核心问题展开：一是这类延迟或遗属给付是否能改善运动员当前训练与生活开支，二是条款如何影响真实价值（通胀、利息、兑付程序）及法律后果（信托、类人寿险、可否作为抵押或影响资格）。讨论同时出现支持将来保障与可货币化操作的观点和对即时可用性、通胀侵蚀及"细则陷阱”的怀疑。 📌 讨论焦点 延迟发放的实效性质疑 按华尔街日报的报道，捐赠方案为每名美国奥运和残奥运动员承诺 200,000 美元，其中一半在其首次入选奥运后 20 年或到达 45 岁时发放，另一半以保证给付的形式在其去世后给到家属。多名评论者质疑这种安排是否能实现声明目标：几十年后的名义款项无法用于当前的教练、器材、场地或住房开销，因此对提升当下训练强度并无直接帮助。有人指出"半数永远不会被运动员看到”，并直言这种延迟给付与"防止经济不安全阻碍运动员发展”的初衷相悖。 [来源1] [来源2] [来源3] 长期保障与可货币化的支持理由 赞同者认为即便是延迟给付也有现实价值：运动员知道将来会拿到 100,000 美元，可以进行收入平滑（income smoothing），借贷或现在相对更大胆地消费以支持训练和生活支出，从而间接提升当下的竞争力。评论中还指出保证给付可替代部分人寿险开支并带来代际保障，且理论上可以被货币化——例如用 LPOA（Limited Power of Attorney）把未来身故给付的权益作为担保换取即时贷款或预支。有人用职业选手晚年收入困难的真实例子说明 45 岁一次性给付对退役后经济安全的意义，并有评论直接称这是"帮助热爱者追梦”的特别方式。 [来源1] [来源2] [来源3] [来源4] [来源5] 价值与兑付风险：通胀、利息与领取程序 不少评论关注名义给付的实际购买力和兑现流程：有人用通胀举例计算如果 20 岁运动员 70 年后其家属才领到 100,000 美元，实际价值会大幅缩水（评论中举例降至约 8,400 美元的当日价值）。另外对"定义给付（defined benefit）”的处理方式、利息或复利假设、以及所谓的"breakage”（长期未被认领或无法兑现的福利）提出疑问。还有人担心多年后的申领程序和受托人角色会增加认领难度，但也有评论反驳对"条款陷阱”或故意设置地雷的指控缺乏证据。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 法律结构、动机与宣传争议 评论讨论了捐赠可能采用的法律结构（信托或类人寿险）会如何设置取款条件并影响可及性，且有人认为这种设计可能被用作合规或宣传手段以避免直接付现。有人怀疑延迟与遗属给付的组合或许能在媒体上放大承诺总额而不一定带来即时帮助，因此劝诫"查看细则”。同时也存在对立观点：有人认为这是慈善赠与，批评者不必过度苛责捐赠者的动机或形式。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 信托 (trust): 一种法律安排，委托人把资产交给受托人管理并按设定条件分配给受益人，常用于分期给付、遗产规划或设定取款限制。 身故给付 / death benefit（guaranteed benefit）: 在受益人去世后支付给家属的保证款项，类似人寿保险的受益金，用于长期或代际保障。 定义给付 (defined benefit): 一种承诺未来按固定金额或规则支付款项的安排（与按账户余额支付的定义贡献相对），其给付额在合同中已明确。 收入平滑 (income smoothing): 利用已知的未来给付或借贷安排平衡不同时期的现金流，使人在职业早期能提高当前消费或投资以支持发展。 LPOA (Limited Power of Attorney): 有限授权书，授权第三方在特定事务上代表本人行事；在讨论中被提到可用于把未来权益作为借款担保的法律工具。 breakage（未领取福利）: 长期给付计划中指名义存在但最终未被认领或兑现的金额，可能因受益人不知情、行政问题或条款限制而遗留。 类别： Business | Work | Release | Ross Stevens | U.S. Olympic &#x26; Paralympic athletes | $100 million | $200,000 per athlete | Wall Street Journal | USOPC

【4】🛠️ 反向工程：Netflix 4K 受多层检测与 Widevine L1 限制（仅 Edge/Windows 可获）
原标题： 《I reverse-engineered Netflix's 4K restrictions》 评分: 20 | 作者: picklepixel 💭 我付钱看 4K 却要自己破解，谁为体验买单？ 🎯 讨论背景 该讨论起因于作者对 Netflix 网页端 4K 限制的逆向工程与实现一个"4K enabler”扩展，发现 Netflix 在发放 Ultra HD 前进行多层客户端能力检测（包括 user agent、屏幕分辨率、Media Capabilities API、编码支持、DRM 协商及 Cadmium 播放器的码率阈值）。作者证明仅靠伪装 JavaScript 层不足以解锁 4K：Chrome 因只支持 Widevine L3 而无法完成向 L1 的协商，只有在 Windows 上的 Edge（具备 L1 或 PlayReady 相应支持）才能拿到 3840x2160、约 15000 + kbps 的流。评论围绕技术细节展开，同时延伸到商业决策、带宽成本与反盗版机制如何影响付费用户体验，以及是否应回归实体媒体或容忍用户绕过限制的伦理与实践争论。 📌 讨论焦点 技术逆向与实现细节 作者通过逆向分析发现 Netflix 在下发 4K 内容前执行多层能力检测：user agent、屏幕分辨率、Media Capabilities API、编码器支持、DRM robustness negotiation，以及 Cadmium 播放器内部的码率上限。扩展需要在每一层拦截并伪装这些信号，漏掉任意一项就会回退到 1080p，说明 Netflix 有逐层指纹检测的策略。即便 JavaScript 层被完全欺骗，Chrome 因只支持 Widevine L3（软件 DRM）无法与服务端协商到 Widevine L1（硬件 DRM），所以无法获得 4K；而 Windows 上的 Edge 因支持 L1 能拿到 3840x2160 且码率约 15000 + kbps。这个过程揭示了为什么单靠伪装用户代理或分辨率不足以解锁 Ultra HD，以及为何需要在浏览器与底层硬件层面同时满足条件。 [来源1] [来源2] [来源3] [来源4] 付费用户体验与盗版对比 多位评论者抱怨付费用户在体验上反而不如盗版用户，举例 Amazon Prime 在 Linux 上出现黑屏或被降为 SD，而同片盗版能顺利播放 4K。有人把原因归结为反盗版的"猫鼠游戏”以及运营方以带宽或防护为由降低实际交付的分辨率，认为这是商业策略导致的副作用。评论强调用户付费是为了方便，但当观看需要花大量时间调试或绕过限制时，盗版反而变得更省事且体验更好。还有人直接建议回归实体媒体以规避这些在线平台施加的限制。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 对扩展实用性的质疑 不少人质疑这类"4K enabler”扩展的实际意义，指出本质上是把浏览器或平台伪装成 Netflix 已认可的环境（例如 Edge/Windows），而 Netflix 本身就明确要求特定浏览器或硬件来解锁 Ultra HD。批评者认为这意味着扩展只会在本来就能拿到 4K 的地方生效，对缺乏硬件 DRM 支持的环境（如 Chrome 的 Widevine L3 或多数 Mac 设置）无能为力。还有人未能独立验证扩展效果，或认为让用户安装/运行特定浏览器的成本高于潜在收益，因此对普通用户价值有限。支持者则认为概念可行，但确实受限于底层 DRM 与硬件条件。 [来源1] [来源2] [来源3] [来源4] [来源5] 社区对逆向工作的认可与批评 尽管对工具的实际价值存在争议，许多评论赞赏作者的逆向与记录工作，认为揭示 Netflix 在客户端如何做能力检测和设备指纹具有技术价值。有人指出识别这些"soft”限制（播放前的能力检测）往往比直接破解 DRM 更具挑战性，并赞赏对各类 API 检查流程的详细说明。也有评论表达对公司业务决策的失望，认为问题更多是商业策略而非纯技术障碍。总体上，技术社区把这类调查视为理解大厂播放链路与策略的重要参考。 [来源1] [来源2] [来源3] 📚 术语解释 DRM: 数字版权管理（DRM），一组用于限制受保护媒体复制与播放的技术与协议；在流媒体中通过 robustness negotiation 决定是否下发高分辨率受保护流。 Widevine L1 / L3: Widevine 是 Google 的 DRM 实现，L1 表示硬件安全级别（需要硬件解码或 TEE 支持），L3 表示仅软件实现的低安全级别；Netflix 通常要求 L1 才允许 4K。 Media Capabilities API: 浏览器提供的 API，用于报告设备对特定视频编码、分辨率与性能组合的解码能力，内容提供方据此判断是否能交付高质量流。 Cadmium player: Cadmium 是 Netflix 的网页播放器框架（HTML5 层面的播放器），内部管理码率上限并参与播放质量决策。 HDCP 2.2: High-bandwidth Digital Content Protection 的 2.2 版本，用于在设备与显示器之间进行链路级别内容保护，某些服务要求显示链路支持 HDCP 2.2 才允许 4K 输出。 PlayReady SL3000: PlayReady 是微软的 DRM 方案，SL3000 指在某些实现或平台上的安全等级或规范，常用于与 Widevine 的硬件级别实现相对应以达成受保护播放。 类别： Web | Security | Programming | Release | Guide | Netflix | netflix-force-4k | 4K | Widevine | DRM | Microsoft Edge | Chrome | browser-extension | Linux | Pickle-Pixel

【5】扎克伯格:Meta 步入"交付年”，超级智能实验室领衔1350亿美元 AI 布局
在周三举行的投资者电话会议上，Meta 首席执行官马克·扎克伯格宣布，Meta 已经完成了人工智能项目基础架构的重建，并正式进入大规模产品交付期。扎克伯格明确表示，未来几个月内，用户将开始体验到该公司推出的全新 AI 模型与产品。 [图片: Meta，元宇宙，Facebook https://pic.chinaz.com/picmap/202207271436142427_0.jpg] 战略重组与"个人背景”优势 扎克伯格透露，Meta 内部已完成人工智能实验室的重组，并确立了2026年作为"交付个人 超级 智能”的关键一年。Meta 认为，相比竞争对手，其核心优势在于对用户 个人背景数据 （经历、兴趣、人际关系等）的深度访问权限。这种独特性将使 Meta 能够提供" 独一无二 的个性化体验”，让 AI 助手不仅仅是工具，更是理解用户生活上下文的智能伙伴。 押注 AI 商业:重塑购物体验 人工智能驱动的商业模式被列为 Meta 的重点领域。扎克伯格指出，新一代智能购物工具将通过分析商家目录，为用户精准匹配最合适的产品组合。这一愿景也得到了技术层面的支撑:去年12月，Meta 收购了通用代理开发商 Manus ，并计划将其代理交易技术整合至 Meta 的生态中，直接与谷歌、OpenAI 及 Stripe 等巨头在 AI 交易领域展开竞争。 基础设施支出翻倍:剑指 超级 智能 伴随宏伟愿景而来的是庞大的财务支出。根据 Meta 最新 季度财报，公司显著提高了基础设施投资: 2026年资本支出: 预计在 1150亿至1350亿美元 之间。 增长幅度: 较2025年的720亿美元大幅攀升。 核心用途: 资金将重点拨付给 "Meta 超级 智能实验室” ，以支持核心业务及未来长期增长。 尽管投资数额惊人，但 Meta 此前设定的2028年基础设施支出目标更高达6000亿美元。面对投资者对盈利路径的关切，扎克伯格此番表态旨在明确:长期的巨额投入即将转化为触手可及的公众产品，并以此重塑公司的未来。

【6】Google Chrome 迎来 Gemini "自动浏览”时代：多步骤在线任务一键代办
2026年1月29日，Google 宣布为桌面版Google Chrome浏览器引入重磅更新，正式上线基于 Gemini AI 的**"自动浏览 （Auto Browse）”**功能。这一升级标志着 Chrome 从一个信息检索工具进化为能够代用户执行复杂操作的"AI 代理”。 从"问答助理”到"行动代理” 此前，集成在Google Chrome中的 Gemini 主要负责网页摘要、回答问题或跨标签页比价。而全新的"自动浏览”功能更进一步，能够自主处理一系列繁琐的在线任务: 商旅安排:自动查询机票与酒店价格，并协助完成预约。 表单与订阅:智能填写在线表单，管理各类服务订阅。 购物决策:识别图片中的商品并在 全网 寻找同款，自动将其加入购物车，甚至在结账时寻找并套用折扣码。 账号管理:在执行需要权限的任务时，可调用内置密码管理器自动登录账号。 深度集成的协同体验 为了提升交互效率，Gemini 在Google Chrome中的界面已调整为右侧固定面板。该面板实现了与 Google 生态系统的深度打通: 跨服务联动:Gemini 可以检索 Gmail 邮件中的会议通知，提取日期地点后在Google Flights中推荐航班，并在预订完成后起草邮件通知同事。 图像技术加持:该功能利用名为 Nano Banana 的技术对屏幕图像进行识别与编辑，增强了视觉任务的处理能力。 订阅方案与权限 目前，"自动浏览”功能已率先向美国地区的 Google AI Pro 和 Ultra 订阅用户开放。 随着这一功能的落地，Google展示了其在浏览器领域深化 AI 一体化的雄心:让 AI 代理真正接管耗时的数字化流程，为用户节省宝贵的时间。

【7】moltbot
你的个人AI助手。任何操作系统。任何平台。龙虾之道。🦞

【8】pi-mono
AI智能体工具包：编码智能体CLI、统一LLM API、TUI与Web UI库、Slack机器人、vLLM容器

【9】vault
用于秘密管理、加密即服务和特权访问管理的工具

【10】system_prompts_leaks
从ChatGPT、Claude和Gemini等流行聊天机器人中提取的系统提示词集合

【11】memU
为moltbot（clawdbot）等7x24小时主动式智能体设计的记忆模块

【12】ext-apps
MCP Apps协议规范与SDK官方仓库——用于UI嵌入式AI聊天机器人的标准，由MCP服务器提供支持

【13】Gemini 的风终于吹到 Chrome 了 👏🏻 Addy Osmani 宣布 Gemini 在 Chrome 浏览器中迎来重大功能升级：智能体式自动浏览、Nano Banana 集成、Google Workspac...
Gemini 的风终于吹到 Chrome 了 👏🏻 Addy Osmani 宣布 Gemini 在 Chrome 浏览器中迎来重大功能升级：智能体式自动浏览、Nano Banana 集成、Google Workspace 深度整合、全新侧边栏交互体验等 智能体式自动浏览 本次更新的最大亮点，也是目前最前沿的浏览器 AI 形态。 · Gemini 不再只是回答问题或总结页面，而是能主动在浏览器里替你完成多步操作 · 支持复杂任务（例如：研究竞品 → 对比价格 → 找优惠码 → 加入购物车） · 也适合重复性/繁琐任务（取消订阅、批量处理邮件、填写表格、抓取特定信息后整理等） · 这代表浏览器从"工具”向"能思考和行动的协作者”迈出了实质性一步 Nano Banana 集成（图像编辑/生成能力） · 用户可以在 Gemini 侧边栏直接对网页上的图片进行编辑、变换、生成变体，无需离开浏览器或跳转到其他工具 · 这把图像 AI 从独立应用拉到了浏览即创作 的体验层面，对设计师、内容创作者、电商用户尤其实用 Google Workspace 深度整合 · 与 Gmail、Docs、Sheets 等实现更紧密的连接 · 支持行内编辑（直接在侧边栏修改邮件正文、表格内容等） · 可以跨应用拉取上下文（例如在看一份邮件时让 Gemini 直接去 Docs 找相关文档） 全新侧边栏交互体验 · 更流线型的界面设计 · 支持跨标签页上下文（聊天时可以引用/拉取其他标签页的内容） · 整体让 AI 感觉更像浏览器"原住民”，而不是一个独立的插件 [图片: https://pbs.twimg.com/media/G_y0nGIbkAAoZht?format=jpg&#x26;name=orig] Addy Osmani: Announcing big changes to Gemini in Chrome - agentic browsing with Auto-browse, Nano Banana &#x26; more! 🚀 [视频: https://video.twimg.com/amplify_video/2016576082196189184/vid/avc1/1920x1080/yGX-RyqKpGAiY-ec.mp4?tag=21]

【14】Google 正式发布 LiteRT：面向全行业、跨框架的端侧 AI 通用框架，原来是 TensorFlow 子项目的 TFLite LiteRT 的核心目标是解决当前端侧 AI 开发的三个痛点：硬...
Google 正式发布 LiteRT：面向全行业、跨框架的端侧 AI 通用框架，原来是 TensorFlow 子项目的 TFLite LiteRT 的核心目标是解决当前端侧 AI 开发的三个痛点：硬件碎片化、性能瓶颈以及模型转换复杂性。它不再仅仅绑定 TensorFlow，而是进化为一个跨平台的、高性能的模型推理加速方案。 四大核心性能提升 1. 更高速的 GPU 性能： · 引入了新一代 GPU 引擎 ML Drift。 · 相比原 TFLite 性能提升约 1.4 倍。 · 支持 Android、iOS、macOS、Windows、Linux 和 Web。在 Android 上能自动在 OpenCL 和 OpenGL 间智能切换以平衡性能与覆盖率。 2. 极致的 NPU 深度集成： · 这是 LiteRT 的重大突破。它提供了一套统一的工作流，抽象化了底层 SoC 厂商（如联发科、高通）复杂的 SDK。 · 实测显示，其 NPU 性能比 CPU 快 100 倍，比 GPU 快 10 倍。 · 支持提前编译（AOT）和运行时编译（JIT），前者可实现"即开即用”的极速启动体验。 3. 更强的生成式 AI 支持： · 针对 Gemma 3 等大模型进行了深度优化。 · 在三星 Galaxy S25 Ultra 上的基准测试中，LiteRT 的性能优于 Llama.cpp（CPU 快 3 倍，GPU 推理快 7-19 倍）。 · 提供了 LiteRT Torch Generative API，方便开发者直接将 PyTorch 训练的 Transformer 模型转换为 LiteRT 格式。 4. 更灵活的框架兼容性： · PyTorch 优先：提供一键转换功能，消除复杂的中间环节。 · JAX 支持：通过 jax2tf 桥接，支持最前沿的研究模型快速部署。 技术底座的优化：CompiledModel API LiteRT 引入了全新的 CompiledModel API，这是其性能飞跃的关键： · 异步执行与零拷贝：支持直接从 OpenGL/Metal 缓冲区读取数据，大幅减少 CPU 开销和内存拷贝延迟。 · 双轨并行：保留了原有的 Interpreter API，同时推行 CompiledModel API。 行业协作与生态 LiteRT 的发布并非闭门造车，其生产就绪版本已获得业界巨头的深度支持： · 硅谷巨头：与 MediaTek（天玑 9500 系列）和 Qualcomm（骁龙 8 Elite）深度联调。 · 终端厂商：在 vivo、小米、三星的新款旗舰机型上已展现出极高的实时多模态助手能力。 Google for Developers LiteRT: The Universal Framework for On-Device AI https://developers.googleblog.com/litert-the-universal-framework-for-on-device-ai/ [图片: https://pbs.twimg.com/media/G_yyvUdaoAAmqmU?format=jpg&#x26;name=orig] Google for Developers: LiteRT is here. The universal framework for on-device AI. 📱💻 ✨ 1.4x faster GPU performance ✨ Unified NPU acceleration ✨ Seamless PyTorch and JAX support ✨ Ready for Gemma and gen AI Build faster, simpler, and everywhere. Read the blog: https://goo.gle/4bTwIPa [视频: https://video.twimg.com/amplify_video/2016620298435481600/vid/avc1/720x720/ASc2LQE7AtLS7NJr.mp4?tag=14]

【15】ClawdBot/MoltBot 最大的意义在于把大众对通用 Agent 的想象进一步打开了。 即便已经有了 Manus 这样能自己上网调研的"通用 Agent” 即便有了 Claude Code 这样...
ClawdBot/MoltBot 最大的意义在于把大众对通用 Agent 的想象进一步打开了。 即便已经有了 Manus 这样能自己上网调研的"通用 Agent” 即便有了 Claude Code 这样能用 Coding 解决一切开放问题的"通用Agent” 在这个赛道依然有巨大的想象空间和可能性 垂直和通用，其实是个观测视角的问题 在通用 Agent 赛道里，大厂的创新不如个人开发者 也是值得深思的

【16】Remotion Skill 能做出来这种视频吗？
Remotion Skill 能做出来这种视频吗？ [视频: https://video.twimg.com/ext_tw_video/2016563495114883072/pu/vid/avc1/360x640/4RRJYi1M_rRvubZj.mp4?tag=19]

【17】I recently found a great project on GitHub: Gatus. It’s a developer-friendly health dashboard for monitoring services via HTTP, ICMP, TCP, and DNS ch...
I recently found a great project on GitHub: Gatus. It’s a developer-friendly health dashboard for monitoring services via HTTP, ICMP, TCP, and DNS checks, with a clean status page. You can validate results with conditions like status code, latency. https://github.com/TwiN/gatus

【18】[D] Evaluating AI Agents for enterprise use: Are standardized benchmarks (Terminal, Harbor, etc.) actually useful for non-tech stakeholders?
I've been assigned to vet potential AI agents for our ops team. I'm trying to move away from "vibes-based" evaluation (chatting with the bot manually) to something data-driven. I’m looking at frameworks like Terminal Bench or Harbor. My issue: They seem great for measuring performance (speed, code execution), but my stakeholders care about business logic and safety (e.g., "Will it promise a refund it shouldn't?"). Has anyone here: Actually used these benchmarks to decide on a purchase? Found that these technical scores correlate with real-world quality? Or do you end up hiring a specialized agency to do a "Red Team" audit for specific business cases? I need something that produces a report I can show to a non-technical VP. Right now, raw benchmark scores just confuse them. submitted by /u/External_Spite_699 [link] [comments]

