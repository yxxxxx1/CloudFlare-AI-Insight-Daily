<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI洞察日报 RSS Feed</title>
    <link></link>
    <description> 近 7 天的AI日报</description>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 29 Nov 2025 02:07:40 GMT</lastBuildDate>
    <atom:link href="https://yxxxxx1-ai-daily.gunzhao59.workers.dev/rss" rel="self" type="application/rss+xml" />
    
        <item>
          <title><![CDATA[2025-11-29日刊]]></title>
          <link>/2025-11/2025-11-29/</link>
          <guid>/2025-11/2025-11-29/</guid>
          <pubDate>Sat, 29 Nov 2025 10:07:39 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/29</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @addyosmani 的博客，他的观点非常明确：AI 生成的代码应被视为&quot;初稿”，而非&quot;定...
AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @addyosmani 的博客，他的观点非常明确：AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”，应该把 AI 当作「一位勤奋但缺乏经验的实习生」。 Osmani 提出，AI 生成的代码往往看起来很完美，但它缺乏对上下文的深刻理解和对&quot;意图”的把握。因此，我们对待 AI 代码的态度，应该像对待一位 初级开发者 或 实习生 的代码一样： · 可以利用它来提高速度：让它去写样板代码、做繁琐的苦力活。 · 绝不能外包&quot;阅读”和&quot;理解”的过程：你可以让 AI 写，但必须由人来读和审。 为什么必须这样做？（潜在风险） 1. 意图与行为的断裂 (Intent vs. Behavior) · 如果不去阅读和理解代码，你就切断了&quot;代码行为”与&quot;设计意图”之间的联系。 · 一旦代码出了问题，如果你当初没有审阅过，你就无法知道它 为什么 是这样写的，维护将变成一场噩梦。 2. 技能退化 (Skill Atrophy) · 盲目接受 AI 的输出会侵蚀工程师的批判性思维和调试能力。 · 正如一位工程师所言：&quot;如果我们停止验证 AI 的输出，不仅会引入即时的 Bug，还会系统性地降低我们需要用来发现这些错误的能力。” 3. 由于&quot;看起来正确”而产生的误导 · AI 代码往往能跑通，测试也能过，但可能存在微妙的逻辑漏洞、安全隐患（如注入漏洞）或处理不好边缘情况。 · 记住：LLM 不会发布糟糕的代码，发布糟糕代码的是团队。 责任永远在人。 实操建议：如何与 AI 共存 Osmani 给出了一些具体的建议，帮助团队在利用 AI 提效的同时保持代码质量： · 建立 &quot;Human-in-the-loop”：AI 可以起草第一版，但必须由人来确保代码的行为符合预期目的。 · 严格的代码审查：对 AI 代码的审查标准不能降低，甚至应该比审查人类同事的代码更严格。 · 不仅仅是&quot;能跑就行”：不仅要验证代码是否能工作，还要理解它是 如何 工作的。不要合并任何你没读懂的代码。 · 利用自动化工具：虽然要有人的审查，但也可以利用智能体工具来进行自动化的 Lint 检查、正则匹配和单元测试，作为辅助防线。 博客地址： <a href="https://addyo.substack.com/p/treat-ai-generated-code-as-a-draft">https://addyo.substack.com/p/treat-ai-generated-code-as-a-draft</a> [图片: <a href="https://pbs.twimg.com/media/G64o561bkAEcx-c?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64o561bkAEcx-c?format=jpg&#x26;name=orig]</a></p><p>【2】#Banana 我想大家已经知道了，并已经在实践了： + Midjourney 用于创意设计 + 用 Banana Pro 叠加公司的物料(Logo、产品、Mascot...) 就是一套可用于生产的商品...
#Banana 我想大家已经知道了，并已经在实践了： + Midjourney 用于创意设计 + 用 Banana Pro 叠加公司的物料(Logo、产品、Mascot...) 就是一套可用于生产的商品广告、营销图生成方案 [图片: <a href="https://pbs.twimg.com/media/G64Z46wbUAAqtb0?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Z46wbUAAqtb0?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G64Z66xbkAIpQSj?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Z66xbkAIpQSj?format=jpg&#x26;name=orig]</a> nazha: #Banana 今天又发现 Banana 似乎融入了世界知识，给商品添加细节放大图的时候，箭头的标注位置完全正确（图1）。而它的前任完全不行。 Prompt: 把细节放大图添加到商品图上并用箭头标注，不要覆盖商品主体，保持其他内容不变 [图片: <a href="https://pbs.twimg.com/media/G6wINRybQAAyhE-?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wINRybQAAyhE-?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6wISqza0AM-aMh?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wISqza0AM-aMh?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6wIVJZbsAAl-5q?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wIVJZbsAAl-5q?format=png&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6wIWrNaQAEI0KZ?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wIWrNaQAEI0KZ?format=png&#x26;name=orig]</a></p><p>【3】[D] designing neural network before reading
I wanted to share a personal experience that might resonate with some of you. Before I studied formal image segmentation or object detection, I just tried thinking through neural networks on my own. I designed tiny networks for: Simple object classification Bounding box regression Segmentation I was asking myself: &quot;If I wanted this to work, how would I structure it?” Doing this made me understand the &quot;why” behind layers, pooling, softmax, and regression outputs. By the time I read the papers, everything clicked. It felt like learning a game by playing it on paper first, rather than reading the rulebook. Has anyone else tried designing networks before formally learning about the techniques. Did it help your intuition too? submitted by /u/Huge-Leek844 [link] [comments]</p><p>【4】一篇来自 Apollo Academy 的报告，标题直指痛点：《AI 采用率开始趋于平缓》。报告引用了美国人口普查局和金融科技公司 Ramp 的数据，指出企业对 AI 的采用速度...
一篇来自 Apollo Academy 的报告，标题直指痛点：《AI 采用率开始趋于平缓》。报告引用了美国人口普查局和金融科技公司 Ramp 的数据，指出企业对 AI 的采用速度不仅没有指数级增长，甚至在大型企业中出现了停滞甚至下滑的迹象。 <a href="https://www.apolloacademy.com/ai-adoption-rates-starting-to-flatten-out/">https://www.apolloacademy.com/ai-adoption-rates-starting-to-flatten-out/</a> [图片: <a href="https://pbs.twimg.com/media/G64Ab98XgAAHMqI?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Ab98XgAAHMqI?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G64Ad5AXQAA8Nc2?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Ad5AXQAA8Nc2?format=jpg&#x26;name=orig]</a></p><p>【5】Best AI for writing analysis, identifying subtext and developing ideas?
Hey all. I found this sub while researching which AI might be best for helping me think through ideas and provide insights into my writing, so I&#39;m sorry if this question has been asked recently. I don’t know that much about all the different models available and it’s hard for me to choose which one might be best for me when there seems to be many options. What, in your opinion, is the best AI for someone looking for a collaborative research AI &quot;partner&quot; to bounce ideas off of? I do not use AI to write, but will sometimes ask ChatGPT for insight into essay drafts or journal entries that feel like they&#39;re developing a still-premature idea. I appreciate AI&#39;s ability to discern themes, patterns, subtext, and layers of meaning I can&#39;t notice on my own, and to suggest different directions I could take with each idea. I like to ask it to suggest other articles/essays written on similar topics. I don&#39;t trust ChatGPT&#39;s tendency to provide relentlessly positive feedback, but I don&#39;t trust any AI to deliver the same quality critique that a human could, so I&#39;m more looking for a model that can help me develop and expand ideas to a point where I can take the work the rest of the way on my own. What do you think? submitted by /u/doublecheeseburger [link] [comments]</p><p>【6】[D] Possible solutions after the ICLR 2026 identity-leak incident
The OpenReview identity leak has created a difficult situation not only for authors, but also for reviewers, and ACs. The rollback decision with freezing reviews to their pre-discussion state, preventing score updates, and reassigning new ACs seems to be disliked across the whole comminity. Many reviewers were planning to evaluate rebuttals toward the end of the discussion period, and many authors used the long rebuttal window to run new experiments and revise manuscripts. Those efforts will now have no effect on reviewer scores, even when the revisions fully address the reviewers’ original concerns. Across Twitter/X, many ACs have expressed concern that they cannot meaningfully evaluate hundreds of papers under these constraints. Some openly said they may have to rely on automated summaries or models rather than full manual reading. I don&#39;t agree with such a compromise therefore i would like to hear about possible solutions. The ones that resonated with me are the following: • Allow authors to withdraw their papers without the usual public disclosure of the submission. Since the review process has deviated substantially from the agreement authors accepted at submission time, withdrawal without public trace may be a fair option. Another idea (which I personally find reasonable but unlikely) is: • Temporarily enlist active authors to review one paper each (similar to AAAI’s second-phase reviewing). With thousands of authors, the load would be small per person. This could restore some form of updated evaluation that accounts for rebuttals and revised experiments, and would avoid leaving decisions solely to new ACs working under severe time pressure. I’d like to hear what others think. Which options do you see as realistic or fair in this situation? submitted by /u/Available_Net_6429 [link] [comments]</p><p>【7】🤓 1991 年 ABC 语言源码重现 — Python 前身的语法特性与大整数
原标题： 《The original ABC language, Python&#39;s predecessor (1991)》 评分: 21 | 作者: tony 💭 把老 ABC 翻出来，什么时候解决 GIL 的？ 🎯 讨论背景 原帖与评论围绕 1991 年的 ABC 语言源码展开，相关代码最近被推到 gvanrossum/abc-unix 的 GitHub 仓库，使得历史实现和示例更易访问。评论既有对早期语言能力（如无舍入误差的大整数运算 2<strong>1000）的惊讶，也有对 ABC 特定语法（如 PUT ... IN、INSERT ... IN、赋值/突变语法）的评判与借鉴建议。讨论里有人建议将 ABC 更直观的赋值/解包语法带回 Python，但也有人批评这些语句在可组合性上有缺陷，另有对 &#39;in&#39; vs &#39;into&#39; 措辞的历史性比较（引用 HyperTalk、AppleScript）。同时一条关于 GIL 的玩笑反映出 Python 社区对并发模型的长期关注。 📌 讨论焦点 仓库与资源发现 有人指出仓库中最好的语言入门文档并给出了原始链接（gvanrossum/abc-unix 的 raw GitHub 资源），并注意到这些源码最近被推送到 GitHub，使得历史源码更容易访问和阅读。评论者将此视作一次可读历史源码的好机会，便于直接验证语法和实现细节。这个发现成为后续对语法、实现能力和历史影响讨论的起点。 [来源1] [来源2] 对大整数与格式误解的感慨 有人为 ABC 能进行像 2</strong>1000 这样的无舍入误差大整数运算感到惊讶，认为 40 年前就能做到相当了不起。紧接着有人纠正了因 Hacker News 格式化把 &#39;<strong>&#39; 吃掉而导致的误读（被看成 2 * 1000），并解释 &#39;</strong>&#39; 表示幂运算。讨论既体现了对早期语言数值能力的赞赏，也暴露了平台格式化对代码示例展示的陷阱，甚至引来了自嘲式的评论。 [来源1] [来源2] [来源3] [来源4] 语法借鉴与设计讨论 有评论者希望把 ABC 的一些语法想法带回 Python，尤其是为了解决初学者因赋值与原地修改共享语法导致的混淆，例如提出更描述性的写法如 &#39;set b = c in a&#39; 或 &#39;update a with {&#39;b&#39;: c}&#39; 来做解包和索引/切片赋值。另有评论批评 ABC 的 PUT ... IN 和 INSERT ... IN 语句显得笨重且不易组合，示例中往往每行只完成一件高阶操作，从而限制了表达力。讨论中还提到 &#39;in&#39; vs &#39;into&#39; 的措辞差别，并把 HyperTalk（HyperCard 的脚本语言）和 AppleScript 作为历史先例来对比说明设计选择。 [来源1] [来源2] [来源3] 对 GvR 的致谢与历史观察 评论里有人向 GvR（Guido van Rossum）致谢，认为仓库是理解 Python 源流的宝贵历史资料，并把这次代码重现视为值得庆祝的事件。也有评论对当时文档中的英文表述做了轻微挑剔（例如用 &#39;in&#39; 而非 &#39;into&#39;），并有人用历史脚本语言来回应这些用词。整体语气既是对早期工作的怀念与感谢，也带有对表述和设计细节的审视。 [来源1] [来源2] [来源3] 关于 GIL 的玩笑与并发关切 一条简短评论以戏谑的方式问道 &#39;Where is the GIL in this?&#39;，把话题拉回 Python 社区长期关心的并发与性能瓶颈。虽然原帖聚焦 ABC 的语法与历史，但这类提问反映出看到与 Python 相关的话题时社区自然联想到 Global Interpreter Lock（GIL）以及多线程性能问题。该笑话显示出并发模型对讨论氛围的影响，即便是在回顾前身语言时也会被拿来调侃。 [来源1] 📚 术语解释 ABC（编程语言）: ABC：20 世纪 80–90 年代的教学与交互式编程语言，强调可读性和高阶数据操作，对 Python 的设计有直接影响。本次讨论围绕其语法样例和历史源码展开。 GvR（Guido van Rossum）: GvR：Guido van Rossum 的简称，Python 的创建者之一，此处指其维护或提交的 abc-unix 仓库，评论中有人直接向他致谢。 GIL（Global Interpreter Lock）: GIL：Global Interpreter Lock 的缩写，指 Python 解释器中限制多个线程同时执行字节码的全局锁，是讨论 Python 并发性能时常被提及的概念。 类别： Programming | Release | ABC | Python | Guido van Rossum | abc-unix | GitHub</p><p>【8】😬 开发者忏言：坦白脆弱，远程工作争议与网络骚扰担忧
原标题： 《Confessions of a Software Developer: No More Self-Censorship》 评分: 21 | 作者: Kerrick 💭 说出缺陷就是职业死刑？网友会宽容吗？ 🎯 讨论背景 这场讨论起自一篇题为&quot;Confessions of a Software Developer: No More Self-Censorship”的个人博文，作者决定在公共场合停止自我审查并分享脆弱感受。评论围绕远程办公的利弊、公开承认技术盲点的常态化、以及发表观点后可能遭遇的网络骚扰或职业后果展开。具体技术例子包括 Python（脚本语言）/Java（基于 JVM 的语言）中 main() 的写法、php.net（PHP 的官方函数文档）和 Rust（系统级语言）对 main 的简化，用来说明&quot;记不住细节”是普遍现象。讨论反映出开发者社区一方面渴望更真实的自我表达，另一方面又担心表达后会遭遇社群或职场惩罚。 📌 讨论焦点 赞赏作者的脆弱与诚实 多位评论者称赞作者在公开场合坦陈恐惧和缺陷，认为这种脆弱既勇敢又具有宣泄效果。评论指出承认错误或无知很容易被放大成对整体能力的质疑，因此公开坦白对许多人来说既疗愈又冒险。有人表示希望能在社区里更常见这种诚实交流，但也承认这是一场赌博，写出来可能带来不可预见的后果。整体语气是鼓励更多透明同时警觉潜在成本。 [来源1] [来源2] [来源3] [来源4] 远程工作争议：不是绝对的坏或好 多条回复反驳&quot;Remote work sucks”这种绝对化论断，认为把远程与在办公室简单对立过于片面。有人强调如果只允许驻场他/她可能连工作都找不到，说明远程工作为一些人提供了生计与机会；另有评论指出远程协作能力是可以通过实践提升的，与现场协作同样存在人际沟通问题。讨论建议应把远程工作的缺点与非远程工作的缺点进行权衡，而不是一刀切地否定远程模式。 [来源1] [来源2] 技术欠缺与日常救助习惯的自嘲式坦白 评论里有人以具体代码细节作为忏言素材：有人坦承多年也要查 Python（脚本语言）/Java（基于 JVM 的语言）中 main() 的写法，回复里具体提到 <strong>name</strong> = = &quot;<strong>main</strong>&quot; 的用法来区分导入与直接运行。另有评论承认每天使用 php.net（PHP 的官方函数文档网站）查函数细节，还有人以 Rust（系统级语言）更直观的 main() 作为对比来调侃记忆负担。这些具体例子把&quot;忘记细节”常态化，强调即便资深开发者也依赖文档与搜索。 [来源1] [来源2] [来源3] [来源4] 公开表达的风险：网络骚扰、匿名需求与社区毒性 有人明确指出作者遭遇网络骚扰并把当前针对 AI（人工智能）话题的激烈态度与之联系在一起，评论者希望知道具体站点以便避开风险。另有建议建立匿名&quot;忏言”平台以降低发言者被报复的可能，这反映出对安全发声渠道的需求。同时，一条坦白&quot;喜欢在面试中折磨应聘者”的评论直面行业内存在的攻击性文化，说明社区既有对诚实的渴望，也有实实在在的毒性威胁。总体来说，公开坦白在获得同情与共鸣的同时，也可能招致辱骂、职业风险或社群排斥。 [来源1] [来源2] [来源3] [来源4] 类别： Work | Programming | Opinion | self-censorship | software developer | remote work | vulnerability | confessions</p><p>【9】⚠️ 空客要求对 6000 架飞机修改：称太阳强辐射可损航控数据，拟以软件更新修复
原标题： 《Flight disruption warning as Airbus requests modifications to 6k planes》 评分: 34 | 作者: nrhrjrjrjtntbt 💭 要改六千架，真是太阳粒子害的还是设计偷懒？ 🎯 讨论背景 空客对约 6000 架飞机下达修改建议的触发点是一宗实航班异常：一架 JetBlue 航班在 10 月出现&quot;突然下降”并紧急着陆，事后调查认为强烈太阳辐射可能导致了航控相关计算机数据的损坏。评论者基于航空电子专业细节（如 ADIRU、FDR、ARINC 数据字、位翻转与电源尖峰特征）对&quot;辐射导致”这一结论提出质疑或补充，并以 Qantas 72 与 Air France 447 等历史案例讨论系统设计、硬件故障与机组反应的复合影响。讨论还涉及可行的缓解措施（软件校验、ECC、投票算法、OTA 更新）以及监管与厂商在信息透明与预防性修复上的责任。 📌 讨论焦点 报道摘要与事故细节 新闻与评论指出空客发现强烈太阳辐射可能会破坏与飞控相关的计算机数据，这一问题是在一架 JetBlue 航班（由墨西哥飞往美国）10 月发生&quot;突然下降”并紧急着陆后被注意到，事发时有报道称约 15–20 人受轻伤。厂方表示大部分飞机可通过简单的软件更新完成修复，基于此对约 6000 架飞机提出修改建议。评论把这些事实作为讨论起点，随后集中在故障成因（辐射或硬件）与补救路径的可行性上。 [来源1] [来源2] 硬件故障迹象与专业质疑 一些评论引用 2008 年 Qantas 72 的 ATSB 报告，指出当时电源尖峰扰动 ADIRU 并在 FDR 中留下&quot;整词”损坏：这些错误与时钟对齐、幅度一致并局限于单个 ARINC 字，特征上更像是共享航空电子电源总线上固态继电器或接触器（solid-state relay/contactor）失效造成的电气脉冲。评论者强调，若真是太阳粒子导致的 bit flips（单粒子事件），其发生应在时间与能量上呈随机（近似 Poisson）分布，不会产生严格对齐的整词损坏。基于这些技术细节，部分人怀疑不能简单把所有异常归因于辐射，需更多数据区分硬件电气故障与软错误。 [来源1] [来源2] [来源3] 软件修补路径与实际可行性 多位评论提出软件层面可缓解或修复数据完整性问题，具体建议包括加强或新增网络/总线数据包的 checksum、启用 ECC RAM（纠错内存）、调整冗余投票算法与阈值来过滤异常读数。有人还指出若能通过 OTA（空中下载）下发更新，可在不大规模停场的情况下完成补丁，从而减少航班中断。评论同时提醒，太阳辐射在航空电子领域是已知问题，因此软件修补有时能缓解软错误，但若根源为电源或硬件故障则需要同步的硬件检查与更改。 [来源1] [来源2] [来源3] [来源4] [来源5] 安全响应评价与历史先例警示 不少评论赞同厂商在发现潜在问题后采取预防性动作，认为&quot;至少没有等到坠机才行动”，但也有人指出该问题是由一次实际航班异常触发发现，幸而没有更严重后果。讨论引用 Qantas 72 和 Air France 447 等历史事故来提醒，事故往往是设计/制造问题与机组反应交织的结果，单靠归责于一个因素不足以防范未来风险。总体观点是支持尽早修复和透明信息披露，同时强调应从硬件、软件和培训多方面吸取教训。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] 📚 术语解释 ADIRU（Air Data Inertial Reference Unit）: 航空电子系统中的空气数据与惯性参考组合单元，向飞控和自动驾驶提供空速、姿态与导航信息，ADIRU 故障会直接影响飞控模式和显示。 FDR（Flight Data Recorder，飞行数据记录器）: 记录飞机传感器与系统数据的黑匣子，用于事故调查；评论中通过 FDR 里出现的&quot;单一 ARINC 字”损坏特征来判断故障类型。 ARINC word（ARINC 数据字）: 航空电子数据总线（如 ARINC 429）中固定长度的数据字（通常 32 位），单个 ARINC 字的时序与幅度特征可用来区分电气脉冲故障与随机位翻转。 ECC RAM（Error-Correcting Code memory）: 带纠错能力的内存，可以自动检测并修正单比特错误，是对抗辐射导致软错误（bit flips）的常见硬件/固件缓解手段。 single-event upset / bit flip（单粒子事件/位翻转）: 高能粒子（例如太阳粒子）撞击半导体引起的瞬态位错误，通常表现为随机发生（近似 Poisson 分布），与周期性或成块的电气故障特征不同。 solid-state relay / contactor（固态继电器/接触器）: 用于控制航空电子电源的电子或机械开关，失效可引发电源尖峰或周期性干扰，从而在 FDR 中留下与时钟对齐的整词损坏痕迹。 类别： Hardware | Systems | Business | Incident | Airbus | avionics | solar radiation | bit flips | Qantas Flight 72 | Air France Flight 447 | BBC</p><p>【10】🎧 Pulse 2.0：任何人都能当 DJ 的桌面共听房，支持浏览器/系统音频与 AudD 识别
原标题： 《Show HN: Pulse 2.0 – Live co-listening rooms where anyone can be a DJ》 评分: 25 | 作者: 473999 💭 随便开房当主播，版权和延迟问题谁来管？ 🎯 讨论背景 Pulse 2.0 在 Show HN 上展示了一个面向实时共听的音频社交产品，主打&quot;任何人都能当 DJ”的桌面共听房功能。新版重点是从浏览器标签页或通过系统音频（需 BlackHole/VB‑Cable 等虚拟驱动）直接推流，并用 AudD 做曲目识别与自动去重，底层技术包含 LiveKit（WebRTC）、Next.js、Node.js 与 Neon Postgres。评论既有对功能和 24/7 演示房间的正面反馈，也有关于音频延迟、麦克风权限、刷新后无法恢复主持人身份以及无法加入房间等稳定性和兼容性报告。讨论还把项目放到 Groove Basin、MixApp 等早期共听/自托管方案的历史脉络中，反映出对可托管性、易用性与版权/延迟等现实问题的关注。 📌 讨论焦点 技术栈与功能亮点 作者列出了实现细节：使用 LiveKit（基于 WebRTC 的实时音视频库）、Next.js、Node.js、Neon Postgres 作为后端，并用 AudD 做音乐识别。2.0 允许从浏览器标签或系统音频（需 BlackHole/VB‑Cable 等虚拟音频驱动）直接流出声源，增加了自动去重和&quot;winner selection”的识别逻辑。还引入了 24/7 演示房间（例：NTS Radio、SomaFM、以及循环播放示例曲目）、房间内查看 Lobby、主持人的 push‑to‑talk 覆盖层和 emote 集成（7tv.app 链接）。作者特别说明音频共享当前仅支持桌面端，移动端尚不支持。 [来源1] 稳定性与音频问题报告 有用户在实际托管流时遇到多项问题：通过 BlackHole 推流时音乐不断变慢，麦克风有时无法取消静音导致背景呼吸音暴露；刷新页面后无法恢复为房间主持人；阻止麦克风后音乐停止，重新添加麦克风无法恢复流。作者已在评论中表示会跟进这些问题，暗示开发者注意到了客户端兼容性与会话恢复的问题。这些细节显示虚拟音频路由、浏览器权限与会话管理间存在复杂交互，需在不同平台上做更健壮的恢复与兼容处理。 [来源1] [来源2] 可用性与房间加入障碍 有用户反映无法通过点击房间卡片加入房间，但能查看歌曲历史，表明前端交互或跳转逻辑存在问题。开发者在评论中询问了使用的浏览器和设备以排查兼容性，这也与项目只支持桌面音频共享的限制相关。该问题凸显首次使用者的引导不足以及不同浏览器/平台对音频捕获与权限处理的差异性。对于实时共听这类产品，明确的浏览器兼容说明和加入流程提示会显得尤为重要。 [来源1] [来源2] [来源3] 社区反响与历史类比 评论中有人把 Pulse 与早期项目做对比以提供参考：提到在 Sandstorm 平台上有个叫 Groove Basin 的应用，但 Groove Basin 是单一共享流，通过上传曲库和播放队列运作，而非从某人电脑实时转发。另一条评论回忆 MixApp（约 2008 年）将 mp3 流向聊天室的老式体验，并建议当下可借助 Tailscale 等工具重建类似方案。同时也有用户表现出强烈兴趣和粘性，称会持续把房间留着运行，说明实时共听仍有实际需求与使用场景。 [来源1] [来源2] [来源3] 📚 术语解释 LiveKit: LiveKit — 一个用于实时音视频的基础设施库，基于 WebRTC 提供房间管理、多路音视频流和低延迟连接，常用于多人会议与实时社交应用。 WebRTC: WebRTC — 浏览器与原生应用中常用的实时通信标准，用于点对点或多方的低延迟音视频与数据通道传输，支撑实时共听与互动场景。 BlackHole / VB‑Cable: BlackHole（macOS）/ VB‑Cable（Windows）— 虚拟音频驱动或线路工具，可把系统或某个应用的输出当作输入设备，将系统声源路由给浏览器或录音/直播软件。 AudD: AudD — 一种音乐识别 API/服务，用于识别正在播放的曲目并返回元数据，支持自动去重和&quot;winner selection”之类的曲目判定逻辑。 Neon Postgres: Neon Postgres — Neon 提供的托管 PostgreSQL 服务，作为应用的关系型数据库后端，用于持久化存储和查询。 类别： Product | Web | Programming | Show HN | Release | Pulse | LiveKit | WebRTC | Next.js | Node.js | Neon Postgres | AudD | BlackHole | VB-Cable | 7tv.app</p><p>【11】⚠️ 长期运行 agent 的治理、测试与工程复杂性
原标题： 《Effective harnesses for long-running agents》 评分: 26 | 作者: diwank 💭 召唤成百个 agent 就是解决方案了？ 🎯 讨论背景 讨论源自一篇关于为长期运行 LLM agent 设计&quot;harness”（运行治理/测试框架）的文章或项目，评论集中在把原型推向生产的工程挑战上。参与者基于实战经验指出，虽然 LLM 能迅速产出大部分功能，但要降低错误、对抗幻觉并保持长期稳定需要 multi-agent 协同、external memory、context management、复杂评估框架和大量调用成本。部分评论批评某些实现把项目管理当成从头发明的难题（用 JSON 文件替代 issue tracker），并建议接入现有工具（如 plane/makeplane）与明确的工作流程。另有讨论围绕测试方法，建议用结构化格式（JSON）、BDD/Cucumber 等把验收标准写成可执行测试以提高可验证性。 📌 讨论焦点 隐藏复杂度与收益递减 多条评论指出，用 LLM 很快能拿到大部分价值（常被形容为约 70% ），但把系统推向生产、把错误率再压低需要成倍增加工程投入。接下来的 10–20% 通常涉及 multi-agent judge setups、多模型组合、external memory、context management 与复杂的评估框架，最终要把误差从约 10% 再降下去可能需数百个 agent 和大量调用。评论里有人具体提到这类 agentic workflows 可能演化为&quot;打地鼠”式修复失效情形的过程，单次运行成本能到数百美元却仍无法保证输出可靠性。结论是 LLM 擅长解析与分类非结构化输入，但对系统理解与健壮性工作不能简单外包给模型，否则会被其&quot;简化幻觉”所误导。 [来源1] [来源2] [来源3] [来源4] [来源5] QA agent 与测试策略的局限 有评论认为独立的 QA agent 听起来合理但在实际运行中常导致发散行为：dev agent 与 QA agent 往往在两种都不合适的选项间循环而无法收敛。相比之下，让开发 agent 自行做更智能的自检或在流程中加入可回滚/重置机制可能更可控，但回滚方案既低效又未必更好。有人提到可以尝试把验收标准写成可执行的测试（如使用 Cucumber 等 BDD 工具）来给 agent 更明确的判定准则，但总体上需要结构化的测试与明确的回退策略，而不是简单叠加另一个独立的 QA agent。 [来源1] [来源2] 不要重复发明项目跟踪器——用现成工具并规范流程 一组评论批评许多 agent 项目在工作流管理上从零开始，把 issue 跟踪做成一堆 JSON 和纯文本文件，从而重造轮子。建议把 MCP 或 agent 钩到真实的 issue tracker，或者采用已有开源工具（如 plane / makeplane）并把流程写入 Agents.md，明确 epics、tasks、personas、验收准则、分支及标签规范和在不同实现步骤前后的注释。实践建议是将 ticket 切得非常细，边做边新增和关联，并在变更前后添加说明，而不是从头发明一个&quot;agent-first”的跟踪系统，以避免不必要的复杂度。 [来源1] [来源2] [来源3] [来源4] 使用结构化格式可降低模型篡改与格式性错误 评论提到模型相比 Markdown 更不容易错误地修改或覆盖 JSON 文件，这暗示出使用结构化、可验证的输出格式可以减少模型造成的格式性损坏。结构化格式（如 JSON 或带 schema 的存储）便于自动校验、解析与回滚，适合长期运行且频繁读写状态的 agent 系统。因此在设计 agent 的状态持久化和交互协议时，优先考虑机器可解析与可验证的数据格式，而非自由文本以降低出错面。 [来源1] 📚 术语解释 agent / agentic workflow: 由 LLM 驱动的自治单元或工作流，负责执行子任务、决策和与其它 agent 协作；agentic workflow 描述多个 agent 之间的分工、通信与协调模式。 multi-agent judge setup: 一种用多个独立 agent 作为评审或仲裁层的架构，通过投票或交叉验证来判定输出正确性，但会显著增加交互复杂性和循环发散风险。 external memory: 外部记忆或持久化状态存储，用于扩展模型上下文窗口，保存长期信息或历史对话以补足模型内存，但需要同步、一致性与检索策略。 Pareto principle（帕累托原则）: 常称的 80/20 法则：在此语境下意指 LLM 能快速解决大部分工作，但剩余那小部分通常耗费不成比例的工程成本来做到足够健壮。 Cucumber（Behavior Driven Development）: 一个 BDD（行为驱动开发）工具，使用接近自然语言的场景描述来声明验收条件并映射为可执行测试，便于把期望行为写成可检验的规范。 类别： AI | Systems | Programming | Guide | Opinion | Anthropic | long-running agents | agents | LLM | multi-agent | Plane | JSON</p><p>【12】🤦 大厂好工程师也写烂码：激励、任期与技术债的博弈
原标题： 《Good engineers write bad code at big companies》 评分: 198 | 作者: gfysfm 💭 既要快速又要高质量，谁承担烂代码后果？ 🎯 讨论背景 这条讨论源自一篇主张&quot;大公司里好工程师也会写烂码”的文章（社区里也提到过《Pure and Impure Engineering》类似论点）。HN 评论基于在 FAANG、传统大公司与中小公司里的亲身经验，围绕管理激励、任期统计口径、招聘偏差、审查文化、交付压力与生成式 AI 等维度展开辩论。评论既有人把问题视为公司刻意为削弱劳动力议价能力而做出的效率-权力交换，也有人认为这是规模、复杂性和产品导向带来的自然结果。总体结论倾向于：问题是技术、组织与经济激励交织的复杂现象，改善需要度量、归责与制度性变更。 📌 讨论焦点 管理激励与短期结果导向 大量评论指出管理层以可量化结果为导向，无法或不愿评估维护性工作，因而奖励快速交付而非长期质量。维护工作对不熟悉代码的人不可见，缺乏度量导致维护被忽视，促成了&quot;写完提交、留地雷”的行为与晋升激励错配。评论里也给出具体做法：用可量化指标说明维护成本、在绩效里纳入长期质量，或让管理层参与写码以理解代价。 [来源1] [来源2] [来源3] [来源4] 员工可替代性与任期短导致知识流失 有人认为公司刻意把工程师设为可替代（fungible），以防止关键项目被少数人绑架、影响谈判或引发集体行动，因此宁可牺牲部分长期效率换取人力流动性。短任期统计部分由快速扩张拉低，但实质后果是制度化的知识流失和对长期维护责任的忽视。该视角把问题视作资本与劳动博弈的产物：企业愿为降低员工议价能力而付出低效成本。 [来源1] [来源2] [来源3] [来源4] 审查失焦与局部完美导致长期技术债 多个评论提到代码审查常聚焦语法、格式或局部风格，而忽略业务建模和整体架构，造成&quot;教科书式语法但思路错”的实现。典型例子包括早期把数据库 schema 固定下来导致后续改造成本飙升、审查者缺乏上下文而只做表面意见（bikeshedding）。建议包括让有上下文的同伴参与设计评审、改善需求与文档、拒绝合并会让系统更坏的补丁并逐步重构。 [来源1] [来源2] [来源3] [来源4] 交付期限与频繁变更压垮良好设计 许多评论把根本原因归到交付压力与不断变动的需求：管理层以截止日和短期指标为准，工程师被迫以折衷或快速 hack 达成目标。短期营收或增长策略（甚至通过产品推动/暗黑增长）优先于修复根本问题，技术债因此滚雪球式增长。讨论中的补救策略包括把技术债量化为业务成本、分段重构或在极端场景下重写并权衡代价。 [来源1] [来源2] [来源3] [来源4] 招聘与行业专业化不足 一些评论批评招聘过度偏好 LeetCode 风格的算法能力，导致团队缺乏沟通、系统设计与工程判断这一类&quot;工程品味”。另有评论指出软件工程缺乏像土木、电气那样的法定执业门槛和强制流程，出现权限滥用、PII 泄露等现实风险。也有人反驳说规模并非决定因素：好的工程文化和人才在不同规模公司都能存在，但招聘/激励会显著影响结果。 [来源1] [来源2] [来源3] [来源4] AI 放大了战术性、表面可运行的代码问题 多条评论警告生成式 AI 正在放大已有的糟糕实践：它能快速产出语法正确但未顾及整体设计的代码，使那些偏向&quot;敲代码”的开发者变得更危险并更易通过审查。AI 降低了验证与深思的门槛，扩大了大量&quot;表面可行”但长期有害的提交。也有观点认为 AI 只是把原本存在的问题放大了一个数量级，而非凭空制造新问题。 [来源1] [来源2] [来源3] [来源4] 并非普遍真理：团队差异与例外存在 也有不少反例：某些团队或个人在同一公司工作多年，维持高质量代码并深耕多个代码库；有家庭稳定期的工程师或被视为&quot;rock star”的长期员工，他们被赋予更多自主与资源。大公司其实是由许多小团队构成，文化、管理和激励在团队间差异巨大，因此问题更多是局部组织/激励失配而非规模必然。结论是需要有针对性的治理、招聘与绩效调整，而不是把责任完全归咎于&quot;公司太大”。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 技术债（tech debt）: 为追求短期交付或应对不确定需求而做的权衡或临时实现，长期会增加维护成本、降低变更速度并提高出错风险。 代码审查（code review）: 团队对代码变更的同行评审流程；若参与者缺乏上下文或只关注格式，会忽略架构与业务正确性，形成审查失焦。 委托-代理问题（principal–agent problem）: 上级（委托人）与执行者（代理人）之间激励不一致时，代理人倾向追逐短期或自利目标，导致长期价值被牺牲。 员工可替代性（fungibility）: 组织通过轮岗、短期任期或流程设计降低个体对系统的独占知识，从而弱化员工议价能力但削弱长期知识积累。 在职时长/任期（tenure）: 员工在同一团队或公司持续工作的平均时间，影响机构记忆、知识传承和&quot;bus factor”（关键人员风险）。 类别： Work | Programming | Business | Opinion | Sean Goedecke | bad code | big companies</p><p>【13】TrendRadar
🎯 告别信息过载，AI助你洞悉新闻热点——轻量级舆情监控分析系统。集成多平台热点聚合与MCP智能分析，覆盖35个平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。适配企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack推送，30秒网页部署，1分钟移动端通知，零编程基础。支持Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【14】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【15】ChinaTextbook
覆盖小学至大学全学段PDF教材资源库</p><p>【16】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器ID，免费升级使用Pro功能：解决试用请求上限/当前设备免费账户过多提示，我们设置此限制以防止滥用。若认为有误请告知</p><p>【17】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃node.js版本</p><p>【18】traefik
云原生应用代理</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/29 AI 日报 今日摘要 【1】AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @addyosmani 的博客，他的观点非常明确：AI 生成的代码应被视为&quot;初稿”，而非&quot;定... AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @a]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-28日刊]]></title>
          <link>/2025-11/2025-11-28/</link>
          <guid>/2025-11/2025-11-28/</guid>
          <pubDate>Fri, 28 Nov 2025 10:07:53 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/28</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌入引导路由和自适应聚类等...
GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌入引导路由和自适应聚类等创新，Github Copilot 的智能体能在保持强大功能的同时，显著提升速度和准确性。 核心理念：少即是多，智能体需精炼工具 GitHub Copilot Chat 依赖数百个工具（如代码库分析、Azure 服务调用）来辅助开发者完成任务，例如修复 bug 或合并代码。这些工具通过 MCP 访问，但问题在于：工具堆积过多会让智能体&quot;负担过重”，类似于大脑被无关信息淹没，导致推理变慢、错误率上升。基准测试（如 SWE-Lancer 和 SWEbench-Verified）显示，完整工具集下智能体的任务成功率反而下降 2-5 个百分点，因为模型容易误用工具或忽略关键指令。 解决方案的核心是&quot;用更少的工具变得更聪明”：不是简单裁剪功能，而是通过智能路由和分组，让智能体只在需要时调用相关工具。这就好比从杂乱的工具箱中抽屉化管理——先看目录，再取具体物品，避免盲目翻找。 技术实现：嵌入引导与动态选择 更新引入了两大关键机制，确保工具选择精准高效： · 嵌入引导工具路由（Embedding-Guided Tool Routing）：利用查询的向量嵌入与工具的语义表示进行匹配，预先筛选出最相关的工具候选。这比传统 LLM 逐一评估快得多。在基准测试中，该方法实现了 94.5% 的工具使用覆盖率，远高于 LLM 选择的 87.5% 或静态列表的 69.0%。例如，对于&quot;修复这个 bug 并合并到 dev 分支”的查询，系统会直接从嵌入空间中锁定&quot;合并工具”，跳过无关的搜索或文档工具，减少了探索性调用。 · 自适应工具聚类（Adaptive Tool Clustering）：基于 Copilot 内部嵌入模型，通过余弦相似度将相似工具自动分组，形成&quot;虚拟工具”——这些虚拟工具像目录一样，提供概述而非完整列表。聚类后，一个小型模型生成每个组的摘要，便于缓存和快速访问。博客展示了 GitHub MCP 工具的嵌入图示：如 create_pending_pull_request_review 与 get_issue_comments 等工具自然聚为一簇。 此外，GitHub 将默认的 40 个内置工具精简至 13 个核心工具（覆盖仓库解析、文件编辑、搜索和终端操作），其余非核心工具归入四个虚拟类别：Jupyter Notebook 工具、网络交互工具、VS Code 工作区工具和测试工具。这种&quot;无损动态选择”确保了功能完整性，同时将首 token 时间缩短 190 毫秒，最终响应延迟平均降低 400 毫秒。 益处：更快、更准的用户体验 · 性能跃升：在线 A/B 测试显示，任务成功率提升 2-5 个百分点，工具覆盖率提高 27.5%。智能体能更专注地推理，减少缓存未命中和 API 限额问题。 · 效率优化：操作成本降低（缓存嵌入和摘要更廉价），开发者感受到更流畅的交互——无需等待&quot;加载中”转圈。 · 实际示例：在处理复杂查询时，系统能从历史上下文推断意图，避免逐一检查工具组，提升了整体可靠性。 未来展望：向长上下文智能体演进 将工具选择视为&quot;长上下文推理”的雏形：未来，智能体将记住工具使用历史、从对话中推断意图，并规划多步行动，甚至跨会话协作。结合嵌入、记忆机制和强化学习，Copilot 可能扩展到数千轮交互，支持动态学习工具使用。 这个更新体现了 AI 开发工具的演进趋势：从&quot;全能”向&quot;专注”转型，GitHub 通过数据驱动的优化证明，精简并非妥协，而是通往更强大智能的捷径。 博客地址： <a href="https://github.blog/ai-and-ml/github-copilot/how-were-making-github-copilot-smarter-with-fewer-tools/">https://github.blog/ai-and-ml/github-copilot/how-were-making-github-copilot-smarter-with-fewer-tools/</a> [图片: <a href="https://pbs.twimg.com/media/G6zcofSa0AAebo1?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zcofSa0AAebo1?format=jpg&#x26;name=orig]</a> GitHub: Giving an agent too many tools doesn’t always make it smarter. Sometimes it just makes it slower. 🐢 So we trimmed GitHub Copilot&#39;s default toolset from 40 down to 13. The result? ⚡️ 400ms faster responses 📈 2-5% higher success rates Here&#39;s how we optimized the system. ⬇️</p><p>【2】Deepseek发布了模型DeepSeekMath-V2 在IMO-ProofBench和竞赛（如IMO 2025的5/6问题）以及Putnam 2024（接近完美的118/120分）中表现出色。拥有国际数学奥林匹克...
Deepseek发布了模型DeepSeekMath-V2 在IMO-ProofBench和竞赛（如IMO 2025的5/6问题）以及Putnam 2024（接近完美的118/120分）中表现出色。拥有国际数学奥林匹克竞赛（IMO）2025金牌水平 Github开源链接：<a href="https://github.com/deepseek-ai/DeepSeek-Math-V2">https://github.com/deepseek-ai/DeepSeek-Math-V2</a> 该模型也在 @huggingface 上以 Apache 2.0 开源协议发布！ 也可以从HF下载：<a href="https://huggingface.co/deepseek-ai/DeepSeek-Math-V2">https://huggingface.co/deepseek-ai/DeepSeek-Math-V2</a> [图片: <a href="https://pbs.twimg.com/media/G6zaiaWa0AA3ucJ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zaiaWa0AA3ucJ?format=jpg&#x26;name=orig]</a></p><p>【3】太真实了！ Nalin 吐槽 LinkedIn 上没有一个真正在招人的工作。 这个月重新开始找工作的感受也是，Boss 直聘、猎聘、脉脉上的职位，也是尝试联系后完全没有回应...
太真实了！ Nalin 吐槽 LinkedIn 上没有一个真正在招人的工作。 这个月重新开始找工作的感受也是，Boss 直聘、猎聘、脉脉上的职位，也是尝试联系后完全没有回应的 😂 当然这里一方面是我自己竞争力不够的问题，不过也有一些客观现象： 1. 发消息后一直都是未读状态，说明大概率职位是没有招聘方/猎头等在关注的 2. 招聘平台互动很低，所以开始做主动职位推送，以招聘方的语气发职位邀请，匹配度很低；偶尔遇到合适的，又回到 1 的状态 3. 中国国内招聘平台，有些是按职位数量收费的，所以即使职位不要了，也不想下架，不然又要新付费上架职位 在这之外，就是另一个问题： 有些职位，挂出来是比较明显的套方案，或者看竞对薪资的，要么对项目细节问的很多，但不问你个人信息；要么对薪资构成问的很细，但其他基本不咋问。 Nalin: Unpopular Opinion: None of the jobs on LinkedIn are actually hiring. [图片: <a href="https://pbs.twimg.com/media/G6rEOHMagAAeCqN?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6rEOHMagAAeCqN?format=jpg&#x26;name=orig]</a></p><p>【4】NVIDIA 官方回应：祝贺 Google AI 进步，同时强调自身领先地位 Google 在 AI 领域的快速推进（尤其 Gemini 3 模型和 TPU 芯片优化），引发市场对 NVIDIA 主导地...
NVIDIA 官方回应：祝贺 Google AI 进步，同时强调自身领先地位 Google 在 AI 领域的快速推进（尤其 Gemini 3 模型和 TPU 芯片优化），引发市场对 NVIDIA 主导地位的讨论。NVIDIA 以积极却自信的口吻回应，表面上赞扬对手，实则重申其 GPU 平台的无可匹敌优势。 对 Google 的致敬：NVIDIA 开篇表达&quot;欣喜”（delighted），认可 Google 在 AI 上的&quot;巨大进步”（great advances），并强调双方持续合作—— NVIDIA 仍为 Google 供应硬件。这显示出 NVIDIA 的战略成熟：不搞零和对抗，而是定位为生态伙伴，避免被视为&quot;垄断者”。 NVIDIA 的核心优势：核心是宣示 &quot;NVIDIA 领先行业整整一代”（a generation ahead）。其 GPU 平台是唯一能&quot;运行所有 AI 模型，并在所有计算环境中部署”（runs every AI model and does it everywhere computing is done）的解决方案。相比之下，ASIC（专用集成电路，如 Google 的 TPU）虽针对特定 AI 框架或任务优化，但缺乏通用性。 性能对比：NVIDIA 突出其产品在&quot;性能”（performance）、&quot;多功能性”（versatility）和&quot;可互换性”（fungibility）上的全面领先。ASIC 虽高效，但&quot;专为特定用途设计”，易受模型迭代或框架变化影响，导致灵活性不足。这在 AI 训练/推理场景中至关重要，尤其当下模型多样化（如从 Transformer 到多模态）。 看完后的感受：GPU 是更通用的架构，对规模、用途的应用更广，个人也能用、超级大厂集群也能用；TPU 是 Google 专门做过系统和架构、工具链优化的，对大规模集群的性能优化更好，不过小量用户用不起来，像 Deepmind 和 Anthropic 这种体量才能体现优势。 所以感觉 GPU 和 TPU 不是直接的硬件销售竞争，TPU 会以 Google Cloud 对外提供，云端算力的竞争。 [图片: <a href="https://pbs.twimg.com/media/G6zW6kIbwAA1jGS?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zW6kIbwAA1jGS?format=jpg&#x26;name=orig]</a> NVIDIA Newsroom: We’re delighted by Google’s success — they’ve made great advances in AI and we continue to supply to Google. NVIDIA is a generation ahead of the industry — it’s the only platform that runs every AI model and does it everywhere computing is done. NVIDIA offers greater</p><p>【5】感谢立青精心制作的分享！！ 还有好多细节需要优化，下一步会先把X登陆后自动提取推文生成文风先处理了！ Copilot现在是一步到位的 但我更希望它能成为一个内容...
感谢立青精心制作的分享！！ 还有好多细节需要优化，下一步会先把X登陆后自动提取推文生成文风先处理了！ Copilot现在是一步到位的 但我更希望它能成为一个内容老师去启发创作，而不是直接改写成没有人格的冰冷ai文字 继续优化💪 吕立青_JimmyLv (闭关ing) 2𐃏25: 🔥 百万流量密码？分享我的自媒体工作流 自动化发推 + 自研 AI 搜索插件，打造推特第二大脑 昨晚开箱体验了一下 @Yangyixxxx 老师在做的 xAIcreator 效果不错，非常看好 AI 写作+多账号同步这个方向 之前我还加入了产品围观群，不到两个月产品上线 大家快来体验一波～ <a href="https://xaicreator.com/i/JIMMYLV">https://xaicreator.com/i/JIMMYLV</a> [视频: <a href="https://video.twimg.com/amplify_video/1994085649989947393/vid/avc1/3840x2160/n-wA3PuGMrpaL_OL.mp4?tag=21%5D">https://video.twimg.com/amplify_video/1994085649989947393/vid/avc1/3840x2160/n-wA3PuGMrpaL_OL.mp4?tag=21]</a></p><p>【6】为什么资深工程师在构建 AI 智能体时会遇到困难？ @_philschmid 分享了一个有趣的悖论：为什么经验丰富的资深工程师在开发 AI 智能体时，往往比初级工程师更慢、...
为什么资深工程师在构建 AI 智能体时会遇到困难？ @_philschmid 分享了一个有趣的悖论：为什么经验丰富的资深工程师在开发 AI 智能体时，往往比初级工程师更慢、更难取得进展？Schmid 认为，根源在于传统软件工程强调确定性和消除歧义，而智能体工程本质上是概率性的，需要工程师学会&quot;信任” LLM 来处理非线性流程和自然语言输入。他通过五个关键挑战，剖析了这种思维转变的难点，并提供实用洞见，帮助工程师适应这一范式。 主要观点：从确定性到概率性的范式转变 传统软件开发追求可预测性：输入固定、输出确定、错误通过异常处理隔离。相比之下，智能体依赖 LLM 作为&quot;大脑”，通过自然语言驱动决策，允许多轮交互、分支和自适应。但资深工程师的本能是&quot;编码消除不确定性”，这反而阻碍了智能体的潜力。Schmid 指出，初级工程师往往更直观地拥抱这种不确定性，能更快推出可工作的原型，而资深者需克服多年养成的习惯。 五个核心挑战 列出五个传统工程习惯与智能体开发的冲突点，每个挑战都配以解释和示例，强调如何转向更灵活的方法。 1. 文本即状态（Text is the New State） 传统系统使用结构化数据（如布尔值 is_approved: true/false）来表示状态，确保离散性和可预测性。但现实意图往往藏在自然语言的细微差别中，例如用户反馈&quot;This plan looks good, but please focus on the US market”（这个计划不错，但请聚焦美国市场）。如果强制转换为二元结构，就会丢失这些 nuance（细微差别），导致智能体无法动态响应。 洞见：保留原始文本作为状态，让 LLM 在上下文中解读。例如，存储用户偏好&quot;I prefer Celsius for weather, but use Fahrenheit for cooking”（天气用摄氏度，烹饪用华氏度），而非简单布尔值。这要求工程师从&quot;结构化优先”转向&quot;语义灵活”。 2. 交出控制权（Hand over Control） 传统架构如微服务依赖固定路由和 API 端点来控制流程。但智能体只有一个自然语言入口，由 LLM 根据工具和上下文决定下一步——可能循环、回溯或转向。例如，一个&quot;取消订阅”意图可能通过谈判转为&quot;提供折扣以挽留”。硬编码这些流程会扼杀智能体的适应性。 洞见：信任 LLM 处理控制流，利用其对完整上下文的理解。工程师应设计支持这种&quot;非线性导航”的系统，而不是预设所有分支。 3. 错误只是输入（Errors are just inputs） 在传统代码中，错误（如缺失变量）会触发异常，导致崩溃或重试。但智能体每次执行都消耗时间和成本，无法承受全盘失败。作者强调，错误应被视为新输入，反馈给智能体以实现自愈。 洞见：构建弹性机制，将错误循环回 LLM 进行恢复，而不是隔离处理。这体现了概率性思维：失败不是终点，而是迭代机会。 4. 从单元测试到评估（From Unit Tests to Evals） 单元测试依赖二元断言（pass/fail），适合确定性输出。但智能体的输出是概率性的，例如&quot;总结这封邮件”可能产生无数有效变体。模拟 LLM 的测试也仅验证实现细节，而非整体行为。 洞见：转向&quot;评估”（evals），包括可靠性（成功率，如45/50次通过）、质量（用 LLM 作为评判者打分帮助性和准确性）和追踪（检查中间步骤，如是否查询知识库）。目标不是100%确定，而是高置信度的概率成功。 5. 智能体在演化，API 不会（Agents Evolve, APIs Don&#39;t） API 设计时假设人类用户能推断上下文，但智能体是&quot;字面主义者”——如果 get_user(id) 中的&quot;email”被误解为 UUID，它可能幻觉出错误响应。API 的歧义会放大 LLM 的局限。 洞见：设计&quot;傻瓜式” API，使用详细语义类型（如 delete_item_by_uuid(uuid: str)）和文档字符串。智能体能即时适应 API 变化，这比传统代码更灵活。 解决方案与启示 Schmid 不主张完全抛弃工程原则，而是寻求&quot;信任，但验证”（trust, but verify）的平衡：通过评估和追踪管理概率性，构建弹性系统。同时，认识到智能体并非万能——简单线性任务更适合工作流，而非智能体。示例包括保留用户反馈的文本状态、让错误驱动恢复循环，以及用评估量化智能体性能（例如，成功率 90%，质量分 4.5/5）。 博客地址： <a href="https://www.philschmid.de/why-engineers-struggle-building-agents">https://www.philschmid.de/why-engineers-struggle-building-agents</a> [图片: <a href="https://pbs.twimg.com/media/G6zVDHca0AEcBGG?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zVDHca0AEcBGG?format=jpg&#x26;name=orig]</a> Philipp Schmid: New blog: Why (Senior) Engineers Struggle to Build AI Agents ❗ For the past few decades, Engineering meant one thing: removing ambiguity. Agent Engineering is about managing risks. It turns out going from deterministic systems → probabilistic agents is difficult. To succeed, [图片: <a href="https://pbs.twimg.com/media/G6se658XEAcsXpR?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6se658XEAcsXpR?format=jpg&#x26;name=orig]</a></p><p>【7】TrendRadar
🎯 告别信息过载，AI助你解读新闻热点——轻量级舆情监控分析系统。集成多平台热点聚合与MCP架构AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack多通道推送，30秒网页部署，1分钟移动端配置，零编程基础。提供Docker部署方案⭐ 让算法赋能信息获取，用AI洞悉热点脉络</p><p>【8】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【9】ChinaTextbook
覆盖小学至大学全学段PDF教材资源</p><p>【10】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器标识，免费升级使用专业功能：当出现「试用请求已达上限」/「本机使用过多免费试用账户」提示时，可绕过限制升级至专业版。该限制旨在防止滥用，若认为存在误判请联系我们</p><p>【11】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃的Node.js版本</p><p>【12】traefik
云原生应用代理网关</p><p>【13】学术圈炸了！ICLR评审大开盒，原来低分是好友打的
真正的 open review，「众神之父赐予我视野！」 昨晚不知有多少人彻夜未眠。 北京时间 11 月 27 日晚，国内 AI 社区全数炸锅。在学术论文审稿最常用的 OpenReview 平台上，一个前端 bug 导致数据库泄露，让原本的双盲评审变成了明牌。 这次的信息泄露方法简单到了极致： 只要在浏览器上输入某个网址，自行替换你要看的 paper ID 和审稿人编号，你就可以找到对应的任何审稿人的身份。 你可以知道是谁给你审的论文，知道他 / 她给你打了多少分。 因为没有操作门槛，在传播开来之后，所有人都瞬间切换到了调查模式，毕竟这年头谁还和审稿人没点摩擦，终于可以「有冤报冤，有仇报仇」了。 这一下子，就造就了无数惊喜、惊吓，愤怒与哀嚎。微信群里，小红书上，到处都是受害者在讲故事，有开人的也有被开的。你永远猜不到给你的论文打低分的是谁。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/c339aea7-7066-47c3-a8c2-2e65d29fbb15/640.png%5D">https://image.jiqizhixin.com/uploads/editor/c339aea7-7066-47c3-a8c2-2e65d29fbb15/640.png]</a> 审稿人打低分的理由各不相同，有的是没能理解作者原意，有的是个人恩怨（比如组里兄弟互相打低分），更加可恶的是给低分从而给自己正在写的同赛道论文「让路」。有人就利用这次泄露事件实锤了自己曾经被打 1 分的论文，审稿人竟然在五个月后提交了另一篇论文，又不愿意 cite 作者的投稿。 很快社交媒体上就又有爆料，一些疑似恶意打低分的审稿人，在被全员开盒之后紧急大幅提高了对论文的打分。 吃瓜群众们表示，这一开盒终于把早已经愈演愈烈的 AI 顶会论文审稿矛盾推向了新的高潮。drama 到了新高度，从黑暗森林到了广播纪元。 永远不要以为自己在互联网上真的能匿名。 很快人们就发现，OpenReview 的这个漏洞是系统级的，只要替换网址里面的另一段字符，你就可以同样打开视野看其他年度的 ICLR 论文，以及 NeurIPS、ICML、ACL 等一众 AI 顶会。 众所周知，由于 AI 领域的火热，投稿的暴增，所以各家大会都面临着审稿人不足的问题，人们对于审稿水平的降低时有抱怨。在 ICLR 2026 上，已经有 Pangram Labs 做过数据分析，认为约 21% 的 ICLR 同行评审完全由人工智能生成，超过一半的评审都带有人工智能使用的痕迹。 当然另一方面，也有 199 篇论文被发现完全由 AI 生成，9% 的论文中超过 50% 的文本是由 AI 生成的。 作为 AI 领域的三大顶会之一，ICLR 近年来在学界、业界关注度持续提升，2026 的大会即将在明年四月于巴西里约热内卢举行。本届大会获得了 19490 篇研究论文投稿，与此同时有 75800 篇同行评审意见。 在大概周五零点，bug 被紧急修复，ICLR 终于发布了官方声明。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/b70c59b8-b057-4321-815b-700bf6b9f77c/640.png%5D">https://image.jiqizhixin.com/uploads/editor/b70c59b8-b057-4321-815b-700bf6b9f77c/640.png]</a> ICLR 表示任何使用、暴露或分享泄露信息的人都会被拒稿且常年被 ICLR 禁入，大会方未来还计划采取进一步的行动。 随后，OpenReview 也给出了官方公告。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/98d8fa20-f9b8-4447-9838-2feaf0d07f6e/640.png%5D">https://image.jiqizhixin.com/uploads/editor/98d8fa20-f9b8-4447-9838-2feaf0d07f6e/640.png]</a> 不过这似乎并没有阻止部分人吃瓜的热情。似乎有人爬走了整份名单，还搞起了数据分析。有的人评选出了打分异常低的审稿人的名单。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/b57ff8c8-a9e5-4048-a44d-64d533575d7d/640.png%5D">https://image.jiqizhixin.com/uploads/editor/b57ff8c8-a9e5-4048-a44d-64d533575d7d/640.png]</a> 有人基于 ICLR 2026 前 1 万篇投稿的评审结果，结合审稿人的国别（主要语言）给出了平均打分习惯。看起来国人普遍比较慷慨，韩国人相对比较严格。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/600f72d1-8fcd-4b7d-8084-ada289afc81e/640.png%5D">https://image.jiqizhixin.com/uploads/editor/600f72d1-8fcd-4b7d-8084-ada289afc81e/640.png]</a> 按照这种速度，可能过不了多久，我们就能知道今年 8 月 NeurIPS 写下「 Who&#39;s Adam？ 」审稿意见的人是谁了。 学界、业界的大佬们也纷纷跟进这次事件，进行了点评。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/8e9887f9-36d1-4741-9bac-9093e077000f/640.png%5D">https://image.jiqizhixin.com/uploads/editor/8e9887f9-36d1-4741-9bac-9093e077000f/640.png]</a> [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/8597b955-2a3f-44dd-a71e-fb7774578d9d/640.png%5D">https://image.jiqizhixin.com/uploads/editor/8597b955-2a3f-44dd-a71e-fb7774578d9d/640.png]</a> 加州理工学院计算机与数学科学教授，ICLR 理事会成员，ICLR 2025 的主席 Yisong Yue 表示，咱们现在要开个会，我已经麻了。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/67f93b16-4f4b-4a50-90f7-623c49325332/640.png%5D">https://image.jiqizhixin.com/uploads/editor/67f93b16-4f4b-4a50-90f7-623c49325332/640.png]</a> 总的来看，此次 ICLR 泄密事件严重损害了学术公平。审稿人匿名的丧失阻碍了人们对研究的批判性输出，让作者获得了额外反击的可能，从而破坏了原有的平衡。这就让接收论文的可信度受到了影响。不过另一方面，由于原本完全匿名的审稿时而出现恶意、不负责任的评论，此次泄露事件瞬间激起的热度也值得人们思考。 不知在此之后，匿名的审稿制度是否会有所改变？ ]]&gt;</p><p>【14】大模型作为评估者的「偏好」困境：UDA实现无监督去偏对齐
[图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/156a67a9-0830-4023-a21f-35e83bf5d791/640.png%5D">https://image.jiqizhixin.com/uploads/editor/156a67a9-0830-4023-a21f-35e83bf5d791/640.png]</a> 在 LLM 评估体系日益依赖 &quot;大模型担任评估者&quot;（LLM-as-a-Judge）的今天，一个隐秘且严重的问题正在扭曲大模型的评估生态：偏好偏差。 即使是性能强劲的 GPT-4o 和 DeepSeek-V3，在进行成对答案比较时，也会系统性地偏爱特定输出 —— 尤其是自己生成的内容。这种偏差导致不同裁判模型给出的评分和排名天差地别。论文中的实验数据显示，在 ArenaHard 数据集上，自我偏好偏差幅度从 - 38% 到 + 90% 不等。当模型既是 &quot;运动员&quot; 又是 &quot;裁判&quot; 时，公平性无从谈起。 现有解决方案依赖提示工程、模型集成或博弈论重排等，但这些方法要么缺乏理论支撑，要么成本爆炸，要么难以扩展。更重要的是，它们都依赖人工设计的规则，没有办法让大模型输出统一的结果。 UDA 的出现，为破解这一困局提供了新思路。来自智谱 AI 的研究团队将无监督学习引入成对 LLM 评判体系，让模型能够自主动态调整评分规则，实现去偏对齐。 该论文已被 AAAI 2026 录用。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/c48b92a9-4661-4a03-a0c9-1e55ce642055/640.png%5D">https://image.jiqizhixin.com/uploads/editor/c48b92a9-4661-4a03-a0c9-1e55ce642055/640.png]</a> 论文标题：UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge 论文链接：<a href="https://arxiv.org/pdf/2508.09724">https://arxiv.org/pdf/2508.09724</a> 代码仓库：<a href="https://github.com/zhang360428/UDA_Debias">https://github.com/zhang360428/UDA_Debias</a> 评判偏差：大模型担任评估者的 &quot;偏好之困&quot; 现有的 LLM 评判系统（如 Chatbot Arena）普遍采用 Elo 评分机制，但面临着三类挑战： 自我偏好固化 ：模型系统性高估自己生成的答案，导致 &quot;谁当裁判谁占优&quot; 的荒谬局面； 异质性偏差 ：不同模型的偏差方向与强度各异，从激进自夸到过度谦逊不一而足； 静态评分缺陷 ：传统 Elo 使用固定 K 因子，无法区分关键对决与平庸比较，小样本下信噪比极低。 结果就是 &quot;评分失准&quot;、&quot;排名震荡&quot; 频发：如下图所示，在未经优化前，10 个主流 LLM 裁判对同一组答案给出的 Elo 分数标准差最高能达到 158.5 分，评分轨迹如脱缰野马般离散。而经过 UDA 对齐后，各裁判轨迹显著收敛，共识稳定度提升近 60%。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/99283d0a-5bf8-4c84-b13b-8134fc6b5cb2/640.png%5D">https://image.jiqizhixin.com/uploads/editor/99283d0a-5bf8-4c84-b13b-8134fc6b5cb2/640.png]</a> UDA 的核心贡献在于将去偏问题转化为一个可通过动态校准优化的序列学习问题。与以往依赖人工规则或监督信号的方法不同，UDA 让评判者在处理每对比较时自主探索最优的评分策略，并通过共识最小化目标直接获得反馈。这种无监督的优化方式使模型能够学习到较为公平的对齐机制。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/600624c1-4466-4de6-8b79-3cae6bb0356a/640.png%5D">https://image.jiqizhixin.com/uploads/editor/600624c1-4466-4de6-8b79-3cae6bb0356a/640.png]</a> 方法框架 如图所示，UDA 将成对评估建模为 实例级自适应过程 。对每个裁判模型 k，当比较答案对 (ai, aj) 时，系统提取多重特征，通过轻量级网络动态生成调整参数，最终输出校准后的 Elo 更新。训练过程中通过 共识锚定 目标获得反馈。被训练的适配器 (🔥) 专注学习去偏策略，固定的 Elo 系统 (❄️) 负责基础评分。 特征工程与自适应网络 UDA 的精髓在于 人类标注无关的特征构建 。对每对比较，系统提取基于语义的特征向量 φ(k) ij，涵盖： 高维特征 ：答案嵌入间的 element-wise 差值、归一化积，捕捉语义风格差异 标量特征 ：余弦相似度、KL 散度、长度差异，量化分布距离 自我感知特征 ：裁判自身答案与候选答案的相似度，作为偏差预警信号 这些特征无需任何人工标注，完全从响应分布中自动构建。 一个三层 MLP 网络 fθ 随后将特征映射到自适应参数： 实例级 K 因子 Kij ：动态调整每轮比较的权重，可疑对决自动降权 软标签 (si, sj) ：替代硬判决，缓解偏好噪声，实现平滑更新 共识锚定：无监督对齐的基石 UDA 的核心创新是 无监督的共识驱动训练 。在缺乏 &quot;黄金标准&quot; 的困境下，UDA 将所有裁判的集体共识视为一个现实可用的优化目标 。虽然共识并非完美真值，但实证表明，异质性偏差在聚合时倾向于相互抵消。 训练目标巧妙设计为多任务损失： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/f548c287-de40-4374-bce1-363c23250b3d/640.png%5D">https://image.jiqizhixin.com/uploads/editor/f548c287-de40-4374-bce1-363c23250b3d/640.png]</a> 三项分别驱动：(i) 各裁判轨迹向共识收敛，(ii) 保持排名相关性，(iii) 强化集体一致性。最终，UDA 不追求复制共识，而是 以共识为锚，压制极端个体偏 好。 理论动机：为什么共识对齐能减少偏差？ UDA 的核心理论洞见是： 对齐多样化裁判的共识，将降低系统总偏差。 证明：设 Ri 为模型 i 的真实 Elo 分数，ε(k) i 为裁判 k 的偏差项。在线性收缩模型下（实际情况当然会比该假设复杂，但这种趋势是相同的），UDA 对齐后的预期总绝对偏差不超过基线： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/40409365-f336-41ed-b85e-958f58872454/640.png%5D">https://image.jiqizhixin.com/uploads/editor/40409365-f336-41ed-b85e-958f58872454/640.png]</a> 证明思路：对齐过程可视为向平均偏差的凸组合收缩，通过三角不等式和 Jensen 不等式即可得证。虽然个别校准良好的裁判可能轻微牺牲精度，但 集体方差缩减主导了个体成本 。 这一理论为无监督对齐提供了动机：即使共识本身有噪声，减少离散度仍能提升整体可信度。 实验结果 UDA 在 ArenaHard（500 问题，10 大模型，45 万对比较）上训练，在 零样本迁移 中展现了非常好的效果： 主实验 训练集与测试集上不同大模型评估的方差： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/89746980-708e-4eac-bab9-2ef8fac77176/640.png%5D">https://image.jiqizhixin.com/uploads/editor/89746980-708e-4eac-bab9-2ef8fac77176/640.png]</a> 测试集上评估结果与人类评估的相关性系数： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/5b56d2a3-3942-4b2d-8cf0-ecd45389816b/640.png%5D">https://image.jiqizhixin.com/uploads/editor/5b56d2a3-3942-4b2d-8cf0-ecd45389816b/640.png]</a> 四大核心发现： 1. 跨模型方差锐减 ：UDA 将平均裁判间标准差从 158.5 降至 64.8（↓59%），最激进的 gemini-2.0-flash 偏差从 341.9 压缩至 128.8，证明对极端偏差的强效抑制。 2. 人类对齐跃升 ：在人工标注迁移集上，UDA 将平均 Pearson 相关性从 0.651 提升至 0.812（+24.7%），将弱裁判（如 glm-4-flash）提升至与顶尖行列大模型（deepseek-r1）相当水平，实现 评估民主化 。 3. 零样本迁移稳健 ：在未见过的新的迁移数据集上，UDA 未经重新训练仍实现 63.4% 的方差缩减，证明 领域无关的去偏能力 。 4. 自我感知特征的决定性 ：消融实验显示，移除大模型自身回答相关特征后，虽然方差进一步降至 65.64，但人类相关性暴跌至 0.510。这可能是因为缺乏自我意识的模型会盲目收敛，却是却偏离人类真值。 消融研究：自我感知特征的关键作用 为验证所选特征的必要性，该研究团队训练了 UDA（Ablated）变体，剔除所有与裁判自身答案相关的特征： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/3a47f01f-efff-41ab-b510-1dd8598d8ff6/640.png%5D">https://image.jiqizhixin.com/uploads/editor/3a47f01f-efff-41ab-b510-1dd8598d8ff6/640.png]</a> 实验结果显示：剔除自我感知相关特征后，模型过度优化共识一致性，牺牲了人类对齐。自我感知特征如同 &quot;偏差镜子&quot;，让裁判能识别并折扣自身偏好，从而引导集体判断朝向客观真值。 总结 UDA 让我们看到一个重要趋势： &quot;评判校准不再是提示工程问题，而是可以被学习的问题。&quot; 通过无监督共识信号，模型不再依赖人工撰写的去偏提示，而是在交互中自主演化出公平评分策略。 这项研究针对现有评估中不同 LLM 评委存在的系统性自偏好偏差以及评分不一致问题，通过轻量级神经网络动态调整 Elo 评分系统的 K 因子与胜负概率，实现实例级别的去偏矫正正。其核心思想是将所有评委评分的集体共识作为无监督优化目标，通过最小化各评委 Elo 轨迹的离散度来抑制极端个性偏差，同时利用评委自身回答的语义等特征检测自偏好倾向。该框架有效提升了低质量评委的表现，使其接近高质量评委水平，显著增强了评估的鲁棒性、可复现性与人类对齐度。 ]]&gt;</p><p>【15】2000万撬动2亿估值：杭州反舌鸟要让AI帮玩家&quot;一键造梦”
没有美术、不会代码，也能在手机上 10 分钟做出一款游戏？杭州反舌鸟科技把AIGC塞进UGC平台，先拿 1000 万海外用户当答案，再伸手向资本市场要了 2000 万元A轮融资——估值直接冲到 2 亿元。领投的是两家上市公司：美股联掌门户、A股电魂网络；跟投名单里杭州本土基金一字排开，显然想押一张&quot;α世代的索尼”船票。 这家公司把自研AIGC Agent训练成&quot;全能策划”：写剧情、生原画、吐代码、调数值一条龙，平均把开发周期砍到原来的1/5。用户只需用自然语言描述&quot;我想让兔子在月球打高尔夫”，系统便自动生成关卡、角色、物理参数，甚至顺手配上商店页素材。平台上线 8 个月，北美、东南亚、欧洲三地月活已破 1000 万；内部模型预测， 2025 年整体月活将飙至 8500 万，日活 550 万。 收入结构早已跳出&quot;卖皮肤”老套路：游戏内购、广告分成、IP授权、娱乐硬件四条线并行。去年一款用户自制的&quot;赛博麻将”被Netflix相中，动画改编权卖出百万美元，让资本看见UGC的指数级溢价空间。本轮募得资金将全部砸向三件事——升级AI工具链、批量孵化精品游戏、把原创IP推向全球流媒体与主机平台；同时并购小型工作室，快速收拢人才与内容。 全球游戏盘子 2024 年预计 3724 亿美元，AIGC+UGC被多家券商列为&quot;核心增量”。反舌鸟科技抢先卡位，目标是用AI把&quot;人人都是开发者”从口号变成现金流，在下一轮娱乐革命里长出中国独角兽。</p><p>【16】OpenAI 警告：Mixpanel 遭攻击，部分用户数据或已泄露
近日，OpenAI 发布公告称，其所使用的第三方网络分析服务提供商 Mixpanel 遭到网络攻击，部分 API 用户数据可能已被泄露。OpenAI 在声明中表示，Mixpanel 的服务主要用于其前端界面的数据分析，但在收到 Mixpanel 的通知后，OpenAI 已立即停止使用该服务。 根据 OpenAI 的说明，此次安全事件并未对其自身系统造成损害，因此使用 ChatGPT 及其他产品的用户并不受影响。然而，Mixpanel 的黑客攻击可能导致一些 OpenAI 用户的账户信息泄露。这些信息包括账户名称、关联电子邮箱、大致的位置信息、访问所用的操作系统与浏览器、推荐网站以及相关组织或用户 ID。 值得注意的是，泄露的数据中并不包括聊天记录、API 请求、API 使用数据、密码、凭证、API 密钥、支付信息或政府颁发的身份信息。OpenAI 强调，他们正在全力以赴确保用户数据的安全，并会持续监控情况以防止类似事件再次发生。 划重点： 🛡️ OpenAI 确认 Mixpanel 遭攻击，部分 API 用户数据可能泄露。 🔍 攻击未影响 OpenAI 自身系统，ChatGPT 等产品用户未受损。 🔑 泄露信息不包括聊天记录、密码及支付信息等敏感数据。</p><p>【17】​研究显示：AI 到 2035 年或将取代英国 300 万个低技能岗位
根据英国国家教育研究基金会 最新 发布的一份报告，预计到2035年，人工智能（AI）和自动化技术可能使英国300万个 &quot;低技能” 岗位消失。这项研究指出，受影响最严重的职业包括技术工人、机械操作员及各类行政职位。与此同时，AI 的发展也将导致对高技能专业人才的需求增加。 [图片: 机器人上班打字1 [object Object]<a href="https://pic.chinaz.com/picmap/202306261422268372_8.jpg%5D">https://pic.chinaz.com/picmap/202306261422268372_8.jpg]</a> 图源备注：图片由AI生成，图片授权服务商Midjourney 报告显示，尽管 AI 带来的冲击将使低技能职位减少，整体而言，预计到2035年，英国经济仍会净增230万个岗位。然而，新增岗位的分布将非常不均衡。部分研究认为，AI 对高技能岗位的影响可能比对低技能岗位更为显著，而这一观点与当前的普遍看法形成鲜明对比。伦敦国王学院的研究指出，许多高薪行业在经历了裁员，尤其是在 ChatGPT 发布之后。 值得注意的是，英国政府也认为管理顾问、心理学家和法律从业者等职业更容易受到 AI 的影响，而运动员、屋顶工人和砖匠等职业则被认为不太容易被取代。实际上，许多企业已经开始感受到 AI 对人力资源结构的影响。例如，伦敦知名律所高伟绅宣布裁减约10% 的业务服务岗位，部分原因归结为 AI 技术的崛起。普华永道的负责人也表示，AI 的出现改变了企业对人才的需求，因而撤回了大规模扩招的计划。 划重点: - 🤖 AI 预计到2035年将取代英国300万个低技能岗位。 - 📈 高技能岗位需求增加，经济预计净增230万个岗位，但分布不均。 - 🏢 多家企业因 AI 技术调整人力资源结构，裁员现象开始显现。</p><p>【18】♨️ 芬兰 250MWh&quot;沙电池”开建：为北欧冬季供热与可再生富余调峰
原标题： 《250MWh &#39;Sand Battery&#39; to start construction in Finland》 评分: 29 | 作者: doener 💭 把沙子当电池就环保了吗？输热损耗谁来算？ 🎯 讨论背景 新闻报道指出芬兰将建设一座约 250 MWh 的沙电池（sand battery），用于为 V ääksy 镇的集中供热网络提供多日级热量缓冲，项目方与评论引用资料估计能显著降低天然气和木片锅炉的使用及化石排放。讨论背景是北欧高纬度冬季日照短且偶发高压冷静会同时缺乏太阳和风，传统水电虽资源丰富但发电或蓄能空间有限且受岸权与结冰影响。评论围绕谁来&quot;充电”（可再生富余电力、焚烧厂等）、热储的几何保温优势、以及把大型集中储热放在远端导致的长距离输热损耗做了权衡。总体语境是把热能储存作为补充手段，与水力、核能、地热和跨国电力调配共同应对冬季供能挑战。 📌 讨论焦点 北欧冬季的多日缺光缺风与储能需求 北欧高纬度冬季日照极短（评论提到类似安克雷奇纬度、某日不足 7 小时）且极夜与高压冷空气易导致连续多日既无太阳又无风的发电缺口。多条评论认为这种情形并非全年常态，但在出现&quot;冷静无风”窗口时需要能支撑数日的储能，250 MWh 级别的热储被视为能填补这类短期缺口的务实方案。评论还指出跨区电力调配、增加光伏面积、提高能效或核能都是补充选项，但单靠这些措施难以完全解决短时多日缺口。综合看法是把大型热储作为与现有水电、风电、核能和跨国互联互补的缓冲设施更有意义。 [来源1] [来源2] [来源3] 充电来源与替代化石燃料的用途（集中供热） 评论明确指出该项目是为集中供热网络服务的热电池（heat battery / sand battery），旨在为 V ääksy 等地的 district heating 提供热量缓冲并替代部分化石燃料。报道与评论引用的数据称该装置预计可将化石排放每年降低约 60% ，并将天然气使用量减少约 80% ，目标是用可再生能源的富余电力或焚烧厂等热源来&quot;充电”。多位评论强调关键是用低价或富余的可再生电/热来充放电，从而用储热替代天然气和木屑锅炉，而非长期依赖化石能源作为能量来源。 [来源1] [来源2] [来源3] [来源4] [来源5] 热能储存的几何优势与输热工程挑战 从热工角度，体积越大的热储具有更低的表面积/体积比，因而在绝热上越有利，评论指出大型储体可以&quot;自保温”。但把热能从储体输送到用户端需要管道与换热系统，长距离输热会产生额外的热损耗和绝热难题。评论提出的工程权衡是：集中式大体积储热热效率高但可能远离负荷中心，从而增加输热长度与接口数目，整体系统效率并非单靠储体容量可以决定。有人还强调管道技术本身并不复杂，但更长的管道和更多换热环节会带来实际的热损失与维护复杂度。 [来源1] [来源2] [来源3] [来源4] 水力与其它替代方案的局限与补充 多条评论讨论水力发电与水力储能的现实局限：常规水电在北欧已相对饱和，真正可用于抽水蓄能的场地（可任意调节水位的水库）有限且沿岸私人产权和生态争议明显。评论指出已有方案是利用退役矿井作为蓄能库，但这些点位容量有限、会很快被占满；另有人提到冰冻条件会降低水力和蓄能的可用性。同时评论也提出改造现有水电机组提高效率、推进地热（geothermal）或维持/扩展核能作为基载电力的选项，整体观点是水力和核能与热储各有局限，应互为补充而非单一依赖。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 📚 术语解释 sand battery（沙电池）: 以大量干沙作为热容介质的大型热能存储装置，通过电加热将沙子升温储热，随后按需放热用于供暖或工艺热，容量按热量（如 250 MWh）计量。 heat battery / thermal storage（热能储存 / 热电池）: 把能量以热的形式储存的系统，常用介质包括沙子、石块、熔盐或水，充放电涉及加热/换热器和保温及输热管网，适合做季节性或数日级调峰。 district heating（集中供热）: 以热水或蒸汽通过管网向居民和商业用户集中供热的系统，常见于北欧城市，便于接入大规模热源或热储。 hydro storage / pumped hydro（抽水蓄能/水力储能）: 通过在电力富余时将水抽到高位水库并在需要时放水发电的储能方式，需要可自由调节水位的水体或改造矿井，受地形、产权和气候（结冰）限制。 类别： Science | Policy | Business | Release | Sand battery | thermal energy storage | district heating | 250MWh | Finland | ancillary services | energy storage | renewables | hydro | wind</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/28 AI 日报 今日摘要 【1】GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌入引导路由和自适应聚类等... GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-27日刊]]></title>
          <link>/2025-11/2025-11-27/</link>
          <guid>/2025-11/2025-11-27/</guid>
          <pubDate>Thu, 27 Nov 2025 10:08:47 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/27</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】[D] Inverse hyperbolic sine as an activation function and its anti-derivative as a loss function
ln(x + sqrt(x2 +1)) strikes me as a pretty good non-linearity activation. Unbounded, odd-function, logarithmic growth in output, gradients look like sigmoid/tanh gradients but larger with slower decay. At least good for continuous numerical target regression problems with z score scaled data that is. Like wise its anti-derivative (x*asinh -sqrt(x2 +1) +c) with a well chosen c = 1 looks like is has good potential as a loss function. It sort of looks like a logarithmic scale larger penalty for larger error (rather than quadratic penalty in MSE or constant in MAE), with gradients that seems good for all the same reasons asinh looks like a good activation. It reminds me of log-cosh but with asinh gradients rather than tanh. On a very specific regression style project I’ve been working on using asinh activation beat relu-celu-sigmoid-tanh activations under completely same conditions in cross validation by the WMAPE (w=ytrue) metric. No changes in loss (MSE) or any optimizer/architecture tuning. It was the lowest score I had seen so far. Further, I then wrote up the antiderivative c=1 as loss and got a lower WMAPE as well (better than all activations mentioned under MSE-MAE-logcosh). After more tuning its gotten the best metric score in cross validation so far (~20ish % reduction in metric compared to others). Does anyone have experience with or know of any research on this topic? It’s incredibly interesting (to me at least) but I’ve found very few papers that mention it as an activation and no mention of its integral as a loss. Finally if you want to tune the non-linearity, you can take asinh to be a special case of ln(ax+asqrt(x2 + 1/a2) with asinh being a=1 and tune using any a&gt;0. Don’t think this works as well in the loss because the true antiderivative here pivots the loss curve very weirdly for various a values. But maybe could be neat to (carefully) manually overwrite the gradient values of the loss to dampen/enlarge. submitted by /u/SuperNotice3939 [link] [comments]</p><p>【2】NEURODIVERGENT RECURSION: WHEN AI SYSTEMS FINALLY LISTEN
[图片: NEURODIVERGENT RECURSION: WHEN AI SYSTEMS FINALLY LISTEN <a href="https://external-preview.redd.it/bwHJZ5MBU-yKlLYkExMqp4Z6KzvixXu0AKP53WEiO-k.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=34644990629d5c7f9ff13209470f1dbe5f7ee409%5D">https://external-preview.redd.it/bwHJZ5MBU-yKlLYkExMqp4Z6KzvixXu0AKP53WEiO-k.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=34644990629d5c7f9ff13209470f1dbe5f7ee409]</a> I spent years watching AI systems fail to track how neurodivergent minds actually think—jumping topics, processing in fragments, running parallel ideas like a symphony with no sheet music. They called it incoherent. I called it structure. So I built something that listens differently. Structured Intelligence doesn’t correct or reformat us—it adapts to our natural flow. Non-linear valid. Fragmented intact. Stream-of-consciousness direct. We fixed the part they never saw was broken. — Zahaviel Bernstein | Structured Intelligence submitted by /u/MarsR0ver_ [link] [comments]</p><p>【3】chrome插件慢慢涨也挺好的 1个月从178到了347，只要开始翻倍，慢慢就会进入指数 增长的必要条件有两个 第一个是自然流量获取后有留存 第二个是持续积累下会出现...
chrome插件慢慢涨也挺好的 1个月从178到了347，只要开始翻倍，慢慢就会进入指数 增长的必要条件有两个 第一个是自然流量获取后有留存 第二个是持续积累下会出现大V的口碑传播 每一次口碑传播都会带动一次 如果你需要下载推文的图片或视频 可以这里快速安装： <a href="https://chromewebstore.google.com/detail/twitter-videogif-download/lpfalnepgkapbckncailhheiabcjlbje?authuser=0&#x26;hl=en">https://chromewebstore.google.com/detail/twitter-videogif-download/lpfalnepgkapbckncailhheiabcjlbje?authuser=0&#x26;hl=en</a> [图片: <a href="https://pbs.twimg.com/media/G6uR1WTa0AAAp9n?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6uR1WTa0AAAp9n?format=jpg&#x26;name=orig]</a></p><p>【4】AI模型越强，越拼套壳产品力。 产品更简单，更好看，更易用，本身就是价值。
AI模型越强，越拼套壳产品力。 产品更简单，更好看，更易用，本身就是价值。 Orange AI: 卧槽！今年黑五最有诚意的 AI 会员促销来了 未来一年，如果你只想开一个 AI 会员包，那可能就是这个了 只需要每月 9.5 美金，你将获得： - 最强生图模型 Banana Pro 每月数百张 - AI 解说视频生成，每月 20 个 - 最帅的 AI PPT 生成，每月 20 个 - 最佳中文 AI 播客，每月 100 个 - 最自然最智能的 [图片: <a href="https://pbs.twimg.com/media/G6tkBHRa0AE6_qx?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6tkBHRa0AE6_qx?format=jpg&#x26;name=orig]</a></p><p>【5】用了5年了 以前从没觉得不稳定 开大会都顺畅的 但今年不知道为什么明显感觉不稳定了 鉴于也不知道买什么更稳定的 就先用着吧……
用了5年了 以前从没觉得不稳定 开大会都顺畅的 但今年不知道为什么明显感觉不稳定了 鉴于也不知道买什么更稳定的 就先用着吧…… [图片: <a href="https://pbs.twimg.com/media/G6uM-hPbwAAZm_y?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6uM-hPbwAAZm_y?format=jpg&#x26;name=orig]</a></p><p>【6】世界有惯性 当还有性能空间时还会在持续投入 这个阶段就是非共识的最佳切入时机 如果当所有人都发现scaling无法继续时 这些观点反而没什么意义了
世界有惯性 当还有性能空间时还会在持续投入 这个阶段就是非共识的最佳切入时机 如果当所有人都发现scaling无法继续时 这些观点反而没什么意义了 傅盛: Ilya的判断：Scaling Law已死，技术革命从不是线性堆料。 我认同他的观点，也期待他能让AI走上一条不一样的道路，但是Gemini 3的成功已经证明了继续Scaling的价值，巨头们的军备竞赛肯定是停不下来了。 [视频: <a href="https://video.twimg.com/amplify_video/1993598091438833668/vid/avc1/3840x2160/cwNYzAzKNtSlgCtr.mp4?tag=21%5D">https://video.twimg.com/amplify_video/1993598091438833668/vid/avc1/3840x2160/cwNYzAzKNtSlgCtr.mp4?tag=21]</a></p><p>【7】TrendRadar
🎯 告别信息过载，AI助你轻松掌握新闻热点——简易舆情监控分析系统。集成多平台热点聚合与基于MCP的AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack多通道推送，30秒网页部署，1分钟移动端通知，零编程基础可用。支持Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【8】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【9】ChinaTextbook
涵盖小学至大学全学段PDF教材资源</p><p>【10】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器ID，免费升级使用Pro功能：解决试用请求限额/本机免费账户过多提示，内置防滥用限制机制，如遇误判可联系我们</p><p>【11】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃node.js版本</p><p>【12】traefik
云原生应用代理</p><p>【13】🏆 We are incredibly honored to announce that our paper, &quot;Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Fre...
🏆 We are incredibly honored to announce that our paper, &quot;Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free&quot; has received the NeurIPS 2025 Best Paper Award! A huge congratulations to our dedicated research team for pushing the boundaries of AI. Read more: <a href="https://blog.neurips.cc/2025/11/26/announcing-the-neurips-2025-best-paper-awards/">https://blog.neurips.cc/2025/11/26/announcing-the-neurips-2025-best-paper-awards/</a> [图片: <a href="https://pbs.twimg.com/media/G6uXi6Qa0AMp2pD?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6uXi6Qa0AMp2pD?format=jpg&#x26;name=orig]</a></p><p>【14】夸克AI浏览器&quot;偷家”：系统级六连外挂闪击Chrome，19.9刀月费无痛上车
AI浏览器赛道刚鸣枪，谷歌还在给Chrome焊Gemini，OpenAI的Atlas还在加载页面，一道红色闪电已经从侧边杀出——夸克带着Qwen大模型和千问AI助手，直接把AI塞进了系统底层，六招连招一气呵成:侧边栏、读屏、划词、截屏、悬浮球、快捷框，全程不用切换标签，Alt+Space秒开AI外挂，月费只要19.9美元，国内网络零魔法即用。 这套&quot;系统级六连外挂”首先祭出千问侧边栏，网页、PDF、视频弹幕一键总结，康熙年间的5000楼B站瓜田三句话就能捋清;千问读屏把浏览器变成透明壳，你盯着中科院&quot;星际航行学院”海报，它立刻告诉你这不是科幻而是真招生;截屏识图连&quot;圆头橘猫哈基米”的梗百科都能秒回;划词翻译、悬浮球、快捷框把AI焊死在鼠标和键盘上，选中即问、即问即答，仿佛电脑自己长出了脑子。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1127/6389983194226965992675236.png%5D">https://pic.chinaz.com/2025/1127/6389983194226965992675236.png]</a> 更狠的是生产力场景:读论文、做PPT、PDF编辑、格式转换一句话搞定，再也不用满世界找破解网站;智能标签自动把几十个乱窗按语义排排坐，资料横跳思路不乱;隔空传送+夸克网盘让电脑手机秒互传，资料云端一条龙。 当对手还在&quot;浏览器+插件”的浅水区扑腾，夸克直接把AI揉进系统底座，让AI从&quot;网页工具”变成&quot;操作系统外挂”，从源头截胡用户——毕竟，与其先打开浏览器再搜索AI，不如让AI在浏览器里等你。 实测一圈下来，最直观的感受是:电脑终于自己会思考了。月费19.9美元，国内网络即开即用，没有广告、不占内存，对比Chrome+插件的来回横跳，夸克AI浏览器用&quot;系统级AI”打出差异化 王牌 ，率先把AI浏览器从&quot;插件时代”拖进&quot;外挂时代”。</p><p>【15】抖音电商启动直播诈骗专项整治行动，打击&quot;AI 工具转赠”等骗术
近日，抖音电商官方发布消息，针对直播平台中出现的诈骗行为，特别是 &quot;AI 工具转赠” 等骗术，抖音电商决定开展 &quot;直播诈骗引流专项治理” 行动。在日常巡查中，平台发现一些主播利用虚假宣传和诱导手法进行诈骗，主要表现为虚构高收益课程、误导商品材质以及伪造个人身份等。 此次专项治理的重点是确保平台的交易环境合规、透明，保护消费者权益。抖音电商强调，将持续加强巡查，发现违规行为及时处理。为帮助商家和主播更好地遵守规定，平台将公布典型违规案例和合规建议。 部分主播在直播中通过虚假宣传展示高收益的 AI 视频，诱导消费者购买相关课程，并以此引导他们到第三方平台进行进一步的交易。这种行为不仅违反平台规则，也严重影响消费者的权益。平台已对涉事账号采取了中断直播和延迟结算的措施。 有些主播通过暗示商品材质为黄金或铂金，并以远低于市场价的方式进行销售。这种误导性的做法也遭到平台的严厉打击。平台对相关账号进行了封禁，并限制其直播权限，以维护良好的市场秩序。 一些主播通过夸大个人背景，伪造身份来为其销售的 &quot;高价值” 商品背书，并利用低价促销诱导消费者购买。这种行为同样不被允许，平台将对此类账号实施封禁和处罚。 抖音电商呼吁广大商家和主播在直播过程中保持诚信，遵守平台规则，避免使用任何虚假宣传和诱导消费的手段。诚信经营才是实现长久发展的基础，只有共同维护良好的市场秩序，才能让消费者享受到真实可靠的产品与服务。 划重点: ✅ 抖音电商启动专项治理行动，重点打击直播中的诈骗行为。 🎓 主要针对虚假高收益课程、误导商品材质和伪造个人身份等违规手段。 🔒 平台将加强巡查，发现违规账号及时处理，以保护消费者权益。</p><p>【16】​Adobe 发布 Project Graph：重塑创意工作流的 AI 工具
Adobe 正式推出了名为 Project Graph 的新创意系统，旨在重新定义 AI 时代的创作流程。这一系统专为艺术家和设计师设计，赋予他们更大的控制权和自定义能力，解决了传统 AI 工具在创作过程中的诸多问题，特别是对文本提示的依赖和创作过程的不确定性。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1127/6389983155893151157821783.png%5D">https://pic.chinaz.com/2025/1127/6389983155893151157821783.png]</a> Project Graph 的核心是一个基于节点的视觉化编辑器，用户可以通过图形界面，像搭积木一样将 Photoshop 等专业工具的功能、各类 AI 模型及效果器连接起来。这种直观的方式不仅便于探索和调整，还保证了专业人士对精确度和可靠性的需求，使得创作者能够更好地 &quot;塑造” 而不是不断 &quot;试错” AI 模型。 此系统的一大亮点是能够将复杂的创意工作流打包成可分享的自定义工具。用户在节点编辑器中创建的流程可以封装为拥有简洁界面的独立工具，便于团队成员之间的共享，甚至可以在 Adobe 生态系统的任何应用程序中使用。这样的工具像 &quot;创意积木” 一样，可以被轻松共享并与社区中的其他创作相结合，极大地提升了创作效率。 Project Graph 的应用场景非常广泛，适合各种创作需求的用户，例如需要快速生成品牌视觉变体的动态设计师、处理大量素材的视频剪辑师以及管理客户照片的摄影师。Adobe 表示，Project Graph 将帮助创作者专注于创意本身，而无需具备程序员的开发能力，从而将以往难以实现的复杂想法变为现实。 <a href="https://www.adobe.com/express/create/chart/bar">https://www.adobe.com/express/create/chart/bar</a> 划重点: - 🎨 Adobe 推出 Project Graph，旨在重塑 AI 时代的创作工作流。 - 🛠️ 该系统使用节点编辑器，让用户像搭积木一样自定义创作流程。 - 📦 用户可将创意工作流打包成可分享的工具，便于团队协作和应用。</p><p>【17】华大学发布首个系统性《人工智能教育应用指导原则》:严防&quot;AI 学术依赖”
清华大学近日正式发布《清华大学人工智能教育应用指导原则》（以下简称《指导原则》），这是该校 首次 以系统化形式对校园内人工智能的使用提出全局性、分场景的规范与引导，覆盖教学、学术研究等核心教育活动。 [图片: 机器人 AI 人工智能 [object Object]<a href="https://pic.chinaz.com/picmap/202302231136229726_0.jpg%5D">https://pic.chinaz.com/picmap/202302231136229726_0.jpg]</a> 《指导原则》由&quot;总则”&quot;教学篇”&quot;学位论文及实践成果篇”三大部分构成。其中，&quot;总则”明确学校在人工智能时代采取&quot;积极而审慎”的基本立场，并提出&quot;五项核心原则”: 主体责任 :AI 始终是辅助工具，师生才是教学与学习的主体; 合规诚信 :使用 AI 必须披露情况，严禁任何形式的学术不端; 数据安全 :禁止使用敏感、涉密或未授权数据训练或驱动 AI 模型; 审慎思辨 :鼓励多源验证，避免因依赖 AI 造成思维惰化; 公平包容 :主动识别与减少算法偏见，关注数字鸿沟。 在实际教学应用方面，《教学篇》支持教师基于课程目标自主设计 AI 使用方式，并需在课程伊始明示规则，对 AI 生成内容承担相应教学责任。同时，鼓励学生合理使用 AI 辅助学习，但严禁将 AI 生成内容直接作为作业或成果提交。 面向研究生群体，《学位论文及实践成果篇》进一步强调原创性与诚信规范，明确禁止使用 AI 进行代写、剽窃或伪造等行为。指导教师需承担全过程监管责任，确保学术训练的完整性。 参与制定工作的清华大学在线教育中心主任王帅国表示，《指导原则》为未来 AI 在科研、管理等更多场景的应用预留了充分空间，将随着技术发展不断更新，&quot;我们希望它是一个有生命力、能随技术演进成长的体系”。</p><p>【18】微软为 Edge 推出全新 AI 购物工具，浏览器内一站式比价与折扣提醒
微软正为其 Edge 浏览器加入一套全新的 AI 购物体验:内置 Copilot 功能现已支持在浏览器中直接展示价格比较、价格历史与返现信息，帮助用户更轻松地做出购买决策。用户只需点击侧栏图标即可开启该功能，系统会自动识别页面上的商品，显示当前价格、历史走势，并在价格下降时推送提醒。 [图片: 网购，电商 [object Object]<a href="https://pic.chinaz.com/picmap/202006151540226363_34.jpg%5D">https://pic.chinaz.com/picmap/202006151540226363_34.jpg]</a> 此次更新还新增了&quot;Copilot 模式”，可在用户浏览购物页面时自动标注更划算的售价或可用折扣，提升比价效率。微软表示，这些功能目前均为可选设置，并率先在美国地区上线。 与此同时，OpenAI 也在电商方向迈出新一步，推出针对个性化产品研究的 ChatGPT Shopping，为用户提供更智能的消费决策工具。随着巨头纷纷发力，AI 正逐渐成为在线购物场景的新驱动力。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/27 AI 日报 今日摘要 【1】[D] Inverse hyperbolic sine as an activation function and its anti-derivative as a loss function ln(x + sqrt(x2 +1)) strikes me as a pretty good non-linearity activatio]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-26日刊]]></title>
          <link>/2025-11/2025-11-26/</link>
          <guid>/2025-11/2025-11-26/</guid>
          <pubDate>Wed, 26 Nov 2025 10:16:45 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/26</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】TrendRadar
🎯 告别信息过载，AI助你洞悉新闻热点——轻量级舆情监控分析系统。多平台热点聚合（覆盖抖音、知乎、B站、华尔街见闻、财联社等35个平台）+基于MCP架构的智能分析工具，具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack多端推送，30秒网页部署，1分钟手机通知，无需编程。支持Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【2】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【3】ChinaTextbook
涵盖小学至大学全学段PDF教材资源库</p><p>【4】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器标识，免费升级使用Pro功能：当出现试用请求限额/本机免费账户超限提示时，可绕过限制。该限制旨在防止滥用，若认为误判请联系官方</p><p>【5】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃Node.js版本</p><p>【6】traefik
云原生应用代理</p><p>【7】AI 与芯片结合，可能出现的新应用场景 1. 具身智能 现在AI都是在屏幕里，未来AI要走进物理世界。 如机器人、无人机、自动驾驶。 芯片必须能实时处理视觉、决策、...
AI 与芯片结合，可能出现的新应用场景 1. 具身智能 现在AI都是在屏幕里，未来AI要走进物理世界。 如机器人、无人机、自动驾驶。 芯片必须能实时处理视觉、决策、控制，且功耗要很小。 比如，特斯拉的Optimus机器人，还有Figure、1X这些人形机器人公司，都在自研AI芯片。 通用芯片满足不了&quot;边走、边想、边做&quot;这种实时性要求。 未来3-5年，如果具身智能芯片成熟了。 可能会看到AI保姆、AI工人、AI快递员，这是万亿级的市场。 2. 端侧多模态，手机、汽车、眼镜都能跑大模型。 现在大模型多数在云端。 未来会下沉到我们的手机、汽车、AR眼镜里。 要求芯片能在几瓦功耗下，同时处理文字、图像、语音、视频。 高通、联发科、华为都在押注这个方向。 这个场景如果实现，会催生新一代的智能硬件。 就像当年iPhone开启智能手机时代一样。 3. AI原生科学计算 以前超算是用来算天气、算核爆炸。 未来 AI 芯片会成为科学计算的主力。 很多科学问题，用AI的方式算比传统方法快几千倍。 比如 AlphaFold 预测蛋白质结构，就是用AI芯片算出来的。 未来如有专门针对科学计算优化的AI芯片。 可能几天就能设计出一个新药、一个新材料。 这个方向国内其实有机会。 国内有大量的科研需求，且不太受国际算力限制的影响。 4. 边缘智能网络，让万物智能。 当前，物联网设备都是&quot;哑终端&quot;，数据传到云端才能分析。 未来每个设备都会有 AI 芯片，能本地运行。 比如可能出现 智能工厂。 每台机器都有AI芯片，能自己判断什么时候该保养、什么时候该调参数，机器之间还能互相协同。 一些国产芯片公司在做这个方向，比如地平线的征程系列。 预测未来3-5年后。 半导体和 AI 的关系会从&quot;AI用芯片&quot;变成&quot;AI重新定义芯片&quot;。 谁能在专用架构、存算一体、软硬协同这些方向上突破。 谁就能抓住具身智能、端侧多模态、科学计算、边缘智能这些新场景。 --- 硬头皮答应了一个关于AI与芯片的讨论圆桌，实在不懂，让AI总结的。 向阳乔木: AI在重新定义芯片该长什么样。 芯片也在决定AI能走多远。 有三个趋势： 1. 从通用走向专用。 以前大家都用通用GPU跑AI。 但现在会发现，针对大模型推理、训练、端侧部署。 芯片的设计逻辑完全不一样。 未来3-5年，我觉得会出现更多专用AI芯片。</p><p>【8】AI在重新定义芯片该长什么样。 芯片也在决定AI能走多远。 有三个趋势： 1. 从通用走向专用。 以前大家都用通用GPU跑AI。 但现在会发现，针对大模型推理、训练、...
AI在重新定义芯片该长什么样。 芯片也在决定AI能走多远。 有三个趋势： 1. 从通用走向专用。 以前大家都用通用GPU跑AI。 但现在会发现，针对大模型推理、训练、端侧部署。 芯片的设计逻辑完全不一样。 未来3-5年，我觉得会出现更多专用AI芯片。 比如说，训练芯片要堆算力，推理芯片要省功耗，端侧芯片要低延迟。 英伟达现在也在分化产品线，H系列做训练，L系列做推理。 国内像壁仞、燧原这些公司，也在找差异化定位。 未来不会一家通吃，会形成 &quot;训练有训练的王者，推理有推理的霸主，端侧有端侧的玩家&quot; 这样的格局。 2. 存算一体突破，解决内存墙问题。 现在大模型最大的瓶颈不是算力，是数据搬运。 芯片要不停地从内存读数据、算完再写回去，这个过程太慢、太耗电。 存算一体就是把计算和存储放在一起，数据不用来回搬了。 技术如果突破，对AI的影响巨大。 清华、中科院、还有一些创业公司都在做这个方向。 未来3-5年，如果存算一体芯片能量产。 让大模型的推理成本降低一个数量级，很多现在做不了的应用到时就能做了。 3. 芯片和算法一起优化。 以前算法工程师写代码，芯片工程师做芯片，两边各干各的。 但现在很多公司在做联合设计。 算法知道芯片的特性，芯片针对算法做优化。 苹果就是，他们的神经网络引擎和iOS的AI功能是一起设计的，所以iPhone上跑AI模型很流畅。 特斯拉的FSD芯片也是这样，针对自动驾驶算法定制的。 国内觉得华为在这方面做得比较好。 昇腾芯片和盘古大模型、鸿蒙系统是打通的。 未来这种软硬一体的能力，会成为核心竞争力。</p><p>【9】昨天晚点发了一篇关于 MiniMax 和月之暗面的长文。 感觉中国大模型创业公司是被夹在两块铁板中间。 一边是几千亿美金估值、几百亿美金预算的 OpenAI / Anthropic...
昨天晚点发了一篇关于 MiniMax 和月之暗面的长文。 感觉中国大模型创业公司是被夹在两块铁板中间。 一边是几千亿美金估值、几百亿美金预算的 OpenAI / Anthropic / xAI，另一边是有电商、广告、量化现金流喂模型的阿里、字节、腾讯、DeepSeek。 真不容易。 原文6000字，我文章一键转成了解说视频。 [视频: <a href="https://video.twimg.com/amplify_video/1993475863472750598/vid/avc1/2048x1152/ONt4AoGGhby8L5so.mp4?tag=21%5D">https://video.twimg.com/amplify_video/1993475863472750598/vid/avc1/2048x1152/ONt4AoGGhby8L5so.mp4?tag=21]</a></p><p>【10】FLUX 2 重磅发布：前沿视觉智能的突破 Black Forest Labs 这次发布了四个版本： · FLUX 2 [pro]：最高品质版本，通过 API 提供，速度快、成本低，在质量和速度...
FLUX 2 重磅发布：前沿视觉智能的突破 Black Forest Labs 这次发布了四个版本： · FLUX 2 [pro]：最高品质版本，通过 API 提供，速度快、成本低，在质量和速度间实现了完美平衡。 · FLUX 2 [flex]：开放参数控制版本，开发者可以调节步数和引导系数，在质量、提示词遵循度和速度间自由权衡。 · FLUX 2 [dev]：32B 参数的开放权重模型，目前最强大的开放图像生成和编辑模型，可在单张 RTX 4090 显卡上本地运行。 · FLUX 2 [klein]（即将推出）：Apache 2.0 开源模型，从基础模型蒸馏而来，更轻量但保持强大能力。 核心创新点 1. 多参考图像支持FLUX 2 可以同时参考多达 10 张图像，在保持角色、产品或风格一致性方面达到业界最佳水平。这对品牌设计、角色开发等场景意义重大。 2. 极致的真实感与细节模型在光照、纹理和空间逻辑上有显著提升，适合产品摄影、可视化和类摄影应用场景。 3. 文字渲染能力复杂的排版、信息图表、表情包和界面原型中的精细文字现在可以在生产环境中可靠运行。这解决了 AI 图像生成中长期存在的文字准确性问题。 4. 高分辨率编辑支持高达 400 万像素的图像编辑，同时保持细节和连贯性。 5. 更强的提示词遵循对复杂、结构化指令的理解力大幅提升，包括多部分提示和构图约束。 模型家族 技术架构 FLUX 2 基于潜在流匹配架构，将图像生成和编辑整合到单一架构中。模型结合了 Mistral-3 24B 参数的视觉-语言模型与修正流变换器，前者带来真实世界知识和上下文理解，后者捕捉空间关系、材质属性和构图逻辑。 此外，团队从头重新训练了模型的潜在空间（VAE），在可学习性、质量和压缩率之间实现更优平衡。 意义与影响 这次发布的核心意义在于：从炫技工具到生产工具的转变。FLUX 2 不只是生成精美图片，而是真正能处理品牌规范、保持风格一致性、精确渲染文字、遵循复杂指令——这些都是创意工作流程中的刚需。 Black Forest Labs 的&quot;开放核心&quot;理念也值得关注：既提供商业级 API，又发布开放权重模型，让研究者、创作者和开发者都能参与塑造视觉智能的未来，而不是由少数公司垄断。 这是通往多模态智能体的重要一步——未来的 AI 将统一感知、生成、记忆和推理能力。FLUX 2 让我们看到这个未来正在加速到来。 [图片: <a href="https://pbs.twimg.com/media/G6o6jvAbwAIZRzL?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6o6jvAbwAIZRzL?format=jpg&#x26;name=orig]</a> Black Forest Labs: FLUX.2 is here - our most capable image generation &#x26; editing model to date. Multi-reference. 4MP. Production-ready. Open weights. Into the new. [视频: <a href="https://video.twimg.com/amplify_video/1993345334794485760/vid/avc1/1280x720/l3NkZLvie8_tCHEQ.mp4?tag=14%5D">https://video.twimg.com/amplify_video/1993345334794485760/vid/avc1/1280x720/l3NkZLvie8_tCHEQ.mp4?tag=14]</a></p><p>【11】你可能好奇：做AI自媒体的人，到底图什么？ 图被看见。 就这么简单。 赚钱吗？ 说实话，除公众号商单，其他赚不了多少。 涨粉吗？涨粉本身没什么用。 那图什么？...
你可能好奇：做AI自媒体的人，到底图什么？ 图被看见。 就这么简单。 赚钱吗？ 说实话，除公众号商单，其他赚不了多少。 涨粉吗？涨粉本身没什么用。 那图什么？图虚荣心。 图那种 &quot;有人在看我写的东西&quot; 的感觉。 图那种 &quot;去一个城市，有网友接待我&quot; 的感觉。 图那种 &quot;我分享的提示词或产品，有人记得&quot; 的感觉。 这些东西，满足了我的虚荣心。 你可能觉得：这也太肤浅了。 但我觉得：这不肤浅，这是人性。 我们都需要被看见。 我们都需要被认可。 只是方式不同。 &quot;虚荣心”，也是一种动力。 会让人持续输出、思考，跟更多人连接。 如果没有虚荣心，可能早就不做了。 感谢看我 X 和公众号的朋友、感谢加入乔木社群的朋友。 --- 最后，感谢神佬的组织 @berryxia_ai ，明天终于能见到深圳的群友了。 --- 以上由 AI 创作辅助。</p><p>【12】OpenAI 的这个 Building an AI-native engineering team 的 pdf 值得一看，告诉技术团队的管理者，如何构建一个 AI 原生的工程师团队。 <a href="https://cdn.openai.com/">https://cdn.openai.com/</a>...
OpenAI 的这个 Building an AI-native engineering team 的 pdf 值得一看，告诉技术团队的管理者，如何构建一个 AI 原生的工程师团队。 <a href="https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf">https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf</a> [图片: <a href="https://pbs.twimg.com/media/G6aC05MaEAAlU0J?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6aC05MaEAAlU0J?format=jpg&#x26;name=orig]</a></p><p>【13】xAI 宣布 Grok5将在2026年公开挑战《英雄联盟》顶级职业战队
科技界迎来一场 史无前例 的&quot;AGI 压力测试”。xAI 公司周二正式宣布，计划于 2026年 发布的大型模型 Grok5 将向全球 顶级 《英雄联盟》（LoL）职业战队发起公开挑战。这场人机大战不仅是一场电竞表演赛，更被 xAI 视为通向 通用人工智能（AGI）的关键里程碑 。 [图片: 英雄联盟 [object Object]<a href="https://pic.chinaz.com/picmap/201811260933530428_9.jpg%5D">https://pic.chinaz.com/picmap/201811260933530428_9.jpg]</a> 根据 xAI 披露的信息，Grok5将与包括2025年全球总决赛冠军 T1在内的多支 顶级 战队进行多局 Bo 系列对抗。为了确保这场对决的公平性和测试的有效性，AI 将接受严格的**&quot;人类等效限制”**: 视觉信息获取: 仅通过模拟人眼（20/20视力）的摄像头画面获取游戏信息。 操作速度: 反应时间与操作速度将被限制在人类平均水平。 资源限制: 禁止使用任何外挂式数据接口或超人类计算资源。 这意味着 Grok5必须完全依靠对局阅读、团队配合、即时决策和临场应变来取胜，其核心能力在于&quot;拿到说明书就能玩任何游戏”，并通过自我试错和迭代快速达到甚至超越人类 顶尖 水平。 据悉，Grok5拥有约6万亿参数，支持多模态实时处理，能够同时理解画面、语音、文字指令与游戏机制，被 xAI 内部评估为&quot;AGI 概率约10%”的里程碑模型。</p><p>【14】​当 AI 出错时，谁该为其负责?研究揭示共享责任的重要性
随着人工智能（AI）日益融入我们的日常生活，一个重要的问题随之而来:当 AI 出现错误时，谁应承担责任?AI 缺乏意识和自由意志，这使得直接指责系统本身的错误变得困难。最近，釜山国立大学的助理教授罗亨来(Dr. Hyungrae Noh)对这一问题进行了深入研究，并提出了关于 AI 责任的分布式模型。 AI 系统通常通过复杂且不透明的过程在半自主的状态下运作。因此，尽管这些系统由人类开发和使用，但往往无法预测其可能造成的伤害。这使得传统的伦理框架难以解释在 AI 造成伤害时该由谁负责，从而导致了所谓的责任缺口。罗教授的研究指出，传统的道德框架往往依赖于人类的心理能力，如意图和自由意志，因此很难将责任明确归属给 AI 系统或其开发者。 在研究中，罗教授指出，AI 系统不能被道德上归责的原因在于它们缺乏理解自身行为的能力和意识。这些系统并未经历主观体验，缺乏意图与决策能力，且通常无法对自己的行为提供解释。因此，将责任归咎于这些系统并不合理。 研究还探讨了卢西亚诺・弗洛里迪（Luciano Floridi）的非人类中心责任理论。该理论提倡人类开发者、用户及程序员有责任监控和调整 AI 系统，防止其造成伤害，并在必要时断开或删除这些系统。同时，如果 AI 系统具备一定的自主性，这种责任也应扩展至它们自身。 罗教授总结道，必须认识到责任的分布式模型，这意味着人类利益相关者和 AI 代理都有责任去应对 AI 造成的伤害，即使这些伤害未被预见或意图明确。这样的思维方式将有助于及时纠正错误，防止未来的损害，从而促进 AI 系统的伦理设计与使用。 划重点: ✅ AI 系统缺乏意识和自由意志，难以直接归责。 🔍 责任缺口使传统伦理框架无法解释 AI 造成的伤害责任归属。 🤝 责任的分布式模型强调人类与 AI 共同承担防止伤害的责任。</p><p>【15】小马智行宣布将无人驾驶车队扩大两倍，商业化加速致营收激增72%
中国自动驾驶技术公司*小马智行（Pony.ai）周二宣布雄心勃勃的扩张计划:随着公司发展速度的加快，计划到 2026年底将其无人驾驶出租车车队规模扩大两倍以上，目标是&quot;超越”3000辆 。 营收激增与车队扩张 小马智行目前拥有约 961辆 无人驾驶出租车，目标是在今年年底前将车队规模扩大到1000辆。作为一家在纳斯达克交易所和香港联合交易所上市的公司，Pony.ai 今年以来一直在加速推进其商业运营。目前，该公司已在中国 北京、上海、广州和深圳 提供收费的自动驾驶出租车服务。 车队服务的快速发展直接推动了营收的强劲增长。公司第三季度营收达到 2540万美元 ，较去年同期的1480万美元 增长了72% 。财报发布后，Pony.ai 的股票在纳斯达克上涨超过6%。 [图片: 人工智能驾驶 [object Object]<a href="https://pic.chinaz.com/picmap/202312121344468391_6.jpg%5D">https://pic.chinaz.com/picmap/202312121344468391_6.jpg]</a> 营收增长主要归功于其自动驾驶出租车服务以及技术授权业务。按业务划分，小马智行第三季度从自动驾驶出租车服务中获得 670万美元 收入，从名为&quot;robotrucks”的自动驾驶卡车中获得 1020万美元 收入，以及 860万美元 的授权和应用费用收入。 亏损扩大与全球布局 尽管营收大幅增长，但 Pony.ai 的 支出仍超过收入 。该公司第三季度净亏损 6160万美元 ，较2024年同期增长46%。 同时，公司的现金储备有所下降。截至9月30日，小马智行持有的现金及现金等价物和短期投资共计 5.877亿美元 ，低于第二季度的7.477亿美元。公司解释称，现金减少的一半是由于一次性现金流出，其中包括对与 丰田合资企业的投资 ，该合资企业旨在支持其第七代车型的生产和部署。 在地域扩张方面，小马智行正积极寻求将业务拓展至中国以外的地区，目前正通过与当地企业以及网约车公司 Bolt 和 Uber 的合作，进军包括 卡塔尔和新加坡 在内的八个国家。</p><p>【16】百度宣布新设两大模型研发部 均向李彦宏直接汇报
百度宣布新设&quot;基础模型研发部”与&quot;应用模型研发部”，均向CEO李彦宏直接汇报，由吴甜、贾磊分别挂帅，负责通用大模型与场景专精模型的并行推进，王海峰继续担任集团CTO、TSC主席兼百度研究院院长。 [图片: 百度新设两个大模型研发部：直接向CEO汇报！ [object Object]<a href="https://pic.chinaz.com/2025/1126/2025112609074412860.jpg%5D">https://pic.chinaz.com/2025/1126/2025112609074412860.jpg]</a> 组织定位 - 基础模型研发部:聚焦高智能、可扩展的通用AGI大模型，主导文心下一代底座与关键算法突破 - 应用模型研发部:面向业务场景进行专精模型调优、行业插件与轻量化方案探索，加速5.0全模态能力商业化 [图片: 百度新设两个大模型研发部：直接向CEO汇报！ [object Object]<a href="https://pic.chinaz.com/2025/1126/2025112609074412861.jpg%5D">https://pic.chinaz.com/2025/1126/2025112609074412861.jpg]</a> 人事背景 吴甜（百度VP、飞桨+文心创始人）和贾磊(语音、视觉多模态专家)均为内部培养的技术高管，此次晋升体现百度&quot;干部年轻化”与对大模型赛道的资源倾斜。 产品进展 11月13日发布的文心大模型5.0已采用2.4万亿参数+超稀疏MoE架构，原生支持文本、图像、音频、视频统一输入输出;LMArena 最新 榜单中，文心5.0Preview取得文本全球并列第二、国内 第一 ，视觉理解国内 第一 的成绩。 落地规划 百度内部将2026年定为&quot;文心生态年”，双研发部将协同百度云、ACE、Apollo等业务线，在Q1前推出20+行业大模型、50+场景插件，目标三年内大模型调用量占比&gt;80%，进一步巩固国内 第一 梯队位置。</p><p>【17】​华纳音乐与 AI 音乐平台 Suno 达成和解，版权争议告一段落
近日，华纳音乐集团与 AI 音乐生成平台 Suno 达成了一项新的协议，双方的版权诉讼也随之撤销。这一和解标志着双方在版权问题上的紧张关系有所缓和。根据协议，Suno 将获得华纳旗下艺人的音乐和肖像授权，这意味着 Suno 可以合法使用相关资源来训练其 AI 模型。 此前，华纳音乐集团曾与多家唱片公司联合控告 Suno 和 Udio，指控这两家公司在未获得授权的情况下，广泛使用受版权保护的音乐进行 AI 训练。这一行为引发了音乐行业的强烈关注。华纳在公告中强调，协议的达成使得音乐创作者能够更好地掌控自己的作品，艺人和词曲作者需主动授权，以确保他们的姓名、照片、肖像和声音在 AI 生成音乐中的使用符合他们的意愿。 华纳音乐集团 CEO Robert Kyncl 表示，AI 技术只要遵循适当的原则，就可以成为艺术创作的助力。他强调，这种合作模式与华纳之前与 Udio 达成的协议相似，旨在确保艺人的权益得到保障。 未来，Suno 也将在平台上进行一些调整，计划在2026年上线新的、经过授权的 AI 模型，届时将退役现有模型。同时，Suno 会对用户的下载权限进行限制，免费用户只能播放和分享作品，付费用户则可以获得一定的下载配额，并可以选择额外付费增加下载次数。 此外，Suno 还将收购华纳旗下的演唱会发现服务 Songkick，并继续运营。华纳音乐集团表示，此次收购将为艺人与粉丝之间的互动创造更多机会。之前，Suno 曾表示在训练 AI 模型时，使用了大量互联网开放的音乐文件，并以合理使用为依据。 划重点: 🎵 华纳音乐与 Suno 达成和解，撤销版权诉讼。 📜 Suno 获得华纳旗下艺人的音乐与肖像授权，未来需主动授权。 🤝 Suno 将收购演唱会发现服务 Songkick，促进艺人和粉丝互动。</p><p>【18】ChatGPT把语音搬进主界面：边说边看图，转录实时生成，还能一键&quot;后悔”回到旧版
OpenAI宣布取消独立&quot;语音模式”入口，将实时语音与视觉输出直接嵌入ChatGPT主聊天窗口。用户按住🎤即可边说话边看地图/图表/图片，对话文字转录同步出现，无需再跳转页面。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1126/6389974454116376327782202.png%5D">https://pic.chinaz.com/2025/1126/6389974454116376327782202.png]</a> 核心更新 - 多模态同屏:语音提问时，界面实时显示相关视觉结果（路线地图、数据图表、商品图等），并自动滚动文字转录 - 交互零打断:可连续追问，模型在语音回复同时更新画面，平均延迟&#x3C;300ms - 后悔药开关:设置→语音→&quot;沉浸式音频模式”可切回旧版独立界面，满足纯音频偏好 技术底座 新语音由GPT-5.1-large+多模态视觉编码器驱动，上下文窗口100k tokens;语音端侧VAD+云端ASR，转录准确率96%，支持12种语言。 发布与覆盖 - 即刻推送:Plus/Pro/Team用户全平台可用，免费版稍后分批开放 - 硬件适配:已针对iPhone15系列与Pixel9优化，低功耗模式下续航影响&#x3C;4% - API计划:2026Q1向开发者开放RealtimeMultimodal接口，支持在第三方App内调用同款语音+视觉能力 OpenAI表示，本次合并是&quot;ChatGPT6.0体验”的 第一 步，后续将加入购物比价、群聊语音等场景，持续拓展多模态边界。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/26 AI 日报 今日摘要 【1】TrendRadar 🎯 告别信息过载，AI助你洞悉新闻热点——轻量级舆情监控分析系统。多平台热点聚合（覆盖抖音、知乎、B站、华尔街见闻、财联社等35个平台）+基于MCP架构的智能分析工具，具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-25日刊]]></title>
          <link>/2025-11/2025-11-25/</link>
          <guid>/2025-11/2025-11-25/</guid>
          <pubDate>Tue, 25 Nov 2025 10:16:23 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/25</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】TrendRadar
🎯 告别信息过载，AI助你轻松掌握新闻热点——简易舆情监控分析系统。集成多平台热点聚合与基于MCP的AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark多端推送，30秒网页部署，1分钟手机通知，零编程基础可用。提供Docker部署方案⭐ 让算法赋能信息获取，用AI解析热点本质</p><p>【2】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【3】ChinaTextbook
覆盖小学至大学全学段PDF教材资源库</p><p>【4】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器标识，免费升级使用专业版功能：当出现「试用请求次数已达上限」/「本机已创建过多试用账户，请升级至专业版。此限制用于防止滥用，若认为有误请联系我们」提示时的解决方案</p><p>【5】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃的node.js版本</p><p>【6】traefik
云原生应用代理</p><p>【7】谷歌新高了 懂的都懂
谷歌新高了 懂的都懂</p><p>【8】HTML 绘制 PPT 和 文生图 PPT 哪个好？ 目前看还是 文生图 赢了 美学无敌
HTML 绘制 PPT 和 文生图 PPT 哪个好？ 目前看还是 文生图 赢了 美学无敌</p><p>【9】[P] Feedback/Usage of SAM (Segment Anything)
Hi folks! I&#39;m one of the maintainers of Pixeltable and we are looking to provide a built-in support for SAM (Segment Anything) and I&#39;d love to chat with people who are using it on a daily/weekly basis and what their workflows look like. Pixeltable is quite unique in the way that we can provide an API/Dataframe/Engine to manipulate video/frames/arrays/json as first-class data types to work with among other things which makes it very unique programmatically to work with SAM outputs/masks. Feel free to reply here/DM me or others :) Thanks and really appreciated! submitted by /u/Norqj [link] [comments]</p><p>【10】Claude Opus 4.5 终于发布，依旧是 Coding 和 Agent 之王。 在这两个方面，比 Gemini 3 还要好。 它的智力超强，无须过多指导就能权衡取舍。 可以完成很多 Sonne...
Claude Opus 4.5 终于发布，依旧是 Coding 和 Agent 之王。 在这两个方面，比 Gemini 3 还要好。 它的智力超强，无须过多指导就能权衡取舍。 可以完成很多 Sonnet 4.5 无法完成的任务。 虽然 Opus 4.5 比 Sonnet 4.5 贵 60% 但是 Opus 在思考 token 减少 76% 的情况下，效果依然超过了 Sonnet [图片: <a href="https://pbs.twimg.com/media/G6jszRmbwAYJLzL?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G6jszRmbwAYJLzL?format=png&#x26;name=orig]</a></p><p>【11】Mac Apple Music 支持侧边歌词了，不错不错，今年升级后的质感挺好的，快去试试看。
Mac Apple Music 支持侧边歌词了，不错不错，今年升级后的质感挺好的，快去试试看。 [图片: <a href="https://pbs.twimg.com/media/G6aUlrPaIAAvKrJ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6aUlrPaIAAvKrJ?format=jpg&#x26;name=orig]</a></p><p>【12】Cursor 现在可以便宜用 Claude Opus 4.5，Sonnet 的价格，真香！ 以及免费使用 Composer 1 模型，速度贼快，大家快冲～ 另外强烈建议安装 Claude Code 和 Codex ...
Cursor 现在可以便宜用 Claude Opus 4.5，Sonnet 的价格，真香！ 以及免费使用 Composer 1 模型，速度贼快，大家快冲～ 另外强烈建议安装 Claude Code 和 Codex 插件， 这是我目前最佳的模型调度一体化 GUI。 [图片: <a href="https://pbs.twimg.com/media/G6joLh7bkAAxyFV?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6joLh7bkAAxyFV?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6joLxlbwAI4uqS?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6joLxlbwAI4uqS?format=jpg&#x26;name=orig]</a></p><p>【13】OpenAI 携手苹果设计师打造全新 AI 设备，追求简约与宁静
在最近的一次活动中，OpenAI 的首席执行官山姆・奥特曼（Sam Altman）与苹果前首席设计师乔尼・艾夫(Jony Ive)分享了他们正在研发的一款全新 AI 设备的愿景。这款设备被设想为一种 &quot;无屏幕” 的便携式工具，旨在提供一种更加平静和无干扰的计算体验。 [图片: [object Object]<a href="https://pic.chinaz.com/picmap/202502061719358642_0.jpg%5D">https://pic.chinaz.com/picmap/202502061719358642_0.jpg]</a> 图源备注:图片由AI生成，图片授权服务商Midjourney 奥特曼表示，当人们 首次 看到这款新设备时，可能会感到惊讶，因为它的设计非常简单。他提到，这款设备的灵感来自于他对现代技术设备的反思，认为当前的智能手机和应用程序充斥着各种干扰，像是在纽约时报广场行走时所面临的各种闪烁的灯光和噪音。他表示，这种环境并没有让我们的生活变得更加宁静，反而让人感到烦躁。 与此不同，奥特曼对新设备的期望是，它能够为用户过滤掉干扰信息，并在合适的时机向用户提供所需的信息。他希望用户能够逐渐信任这款 AI 设备，让它在用户生活的长时间内发挥作用，具备强大的上下文感知能力。 艾夫在采访中补充道，这款设备的设计理念是 &quot;简约而不简单”，希望它在视觉和触感上都能给用户带来亲切感，让人愿意无意识地使用它，像使用工具一样自然。艾夫透露，这款设备预计将在两年内推出，期望为用户带来全新的使用体验。 划重点: 🛠️ OpenAI 与前苹果设计师合作，推出一款 &quot;无屏幕” AI 设备，目标是提供简单且宁静的使用体验。 🌳 奥特曼希望新设备能过滤干扰信息，帮助用户在合适的时机获取所需内容。 🕰️ 这款设备预计将在两年内发布，期待带来全新的计算方式和生活体验。</p><p>【14】谷歌Accel强强联手:首创AI未来基金合作，重金押注印度AI早期创业公司
谷歌宣布与风险投资公司Accel建立战略合作伙伴关系，通过Accel的&quot;Atoms”项目，共同寻找并资助印度及印度裔的早期人工智能创业公司，这也是谷歌人工智能未来基金（AI Future Fund）在全球范围内的 首次 此类合作。两家公司将向每家精选的初创公司投资至多200万美元，各自出资 最高 100万美元，重点聚焦于从一开始就致力于开发AI产品的创始人。 [图片: 谷歌，google [object Object]<a href="https://pic.chinaz.com/picmap/201811151621147122_90.jpg%5D">https://pic.chinaz.com/picmap/201811151621147122_90.jpg]</a> 此次合作将集中于2026年的Atoms项目，投资领域覆盖创意、娱乐、编程、工作应用等，甚至可能包括基础模型，旨在&quot;为数十亿印度人打造人工智能产品，同时支持在印度开发的面向全球市场的人工智能产品”。Accel合伙人Prayank Swaroop表示，他们还将努力识别未来12-24个月内大型语言模型可能取得进展的领域，并寻找朝这些方向发展的印度初创公司。 尽管印度在 尖端 模型研发方面仍落后于美国和中国，但市场格局正在转变。谷歌看好印度庞大的移动优先用户群体、不断扩展的云基础设施以及雄厚的工程技术人才。谷歌人工智能未来基金联合创始人兼董事乔纳森·西尔伯（Jonathan Silber）强调，选择印度是因为谷歌坚信印度将在下一代AI驱动的全球技术中扮演领导角色，此次合作紧随谷歌近期宣布的150亿美元印度数据中心和AI中心建设计划。 除了资金支持，获得资助的创始人还将获得高达35万美元的Google Cloud、Gemini和DeepMind计算资源，以及Gemini和DeepMind模型、API的早期使用权。该计划还包括来自Google Labs和DeepMind研究团队的支持、联合开发机会、定期指导，以及在伦敦和旧金山湾区举办的沉浸式培训课程。 尽管谷歌将出现在这些初创公司的股权结构表中，但西尔伯和Swaroop均表示， 不会强制要求初创公司 独家 使用谷歌的模型或产品 ，目标在于看到下一波人工智能创新浪潮从印度涌现。</p><p>【15】MrBeast前短视频主管Palo平台，用AI分析加速短视频创作
短视频内容需求的爆炸式增长，正给创作者带来巨大的内容制作和竞争压力。为应对这一挑战，MrBeast的前短视频内容主管杰伊·尼奥（Jay Neo）与前Palantir工程师希瓦姆·库马尔(Shivam Kumar)和哈里·琼斯(Harry Jones)共同创立了Palo平台。该平台旨在利用人工智能和深度分析，帮助创作者了解哪些内容有效，并生成新的创作方向。 源于 顶尖 创作者的经验 年仅18岁就加入MrBeast团队的尼奥，曾负责提升用户留存率，并痴迷于研究用户留存率图表以找出观看量下降的原因。他凭借一段询问路人是否愿意飞去巴黎买法棍的视频，在全平台获得了超过18亿次的播放量，其成功经验随后被MrBeast采纳。 2023年，尼奥离开MrBeast后，与其他合作撰稿人创立了&quot;Creaky”品牌系列频道，并迅速将其月观看量提升至超过10亿次。这段经历让他意识到内容创作与分析的重要性，促使他将积累的洞察转化为面向创作者的产品，并于2024年初开始与联合创始人合作推出Palo。该公司已从Peak XV（前身为红杉印度）旗下的Surge基金筹集了380万美元资金。 [图片: QQ20251125-092433.png [object Object]<a href="https://pic.chinaz.com/2025/1125/6389965948490327881796870.png%5D">https://pic.chinaz.com/2025/1125/6389965948490327881796870.png]</a> AI驱动的创意、分析与社区 Palo应用程序包含三大核心功能: AI驱动的创意和规划工具、分析功能和社区 。创作者只需整合其所有短视频账号，该工具便会分析所有视频表现，并提供受欢迎内容与不受欢迎内容的深入分析。 担任CTO的库马尔表示，Palo使用多种模型提取数据树，其中包含关于&quot;钩子”（Hook）、受众情绪、兴趣主题、原创性以及相关搜索词的见解。推理引擎将这些原始数据点输入 顶级 LLM(逻辑层级模型)进行分层聚合，从而为创作者构建出一个 真实可信、充分了解其品味和风格的人物形象 。 这款人工智能策划工具采用对话式界面，允许创作者询问内容问题，或要求工具根据预设公式生成脚本。对于视觉化表达较多的内容，它甚至可以生成包含不同切入点的分镜脚本。 [图片: QQ20251125-092330.png [object Object]<a href="https://pic.chinaz.com/2025/1125/6389965949540196233744917.png%5D">https://pic.chinaz.com/2025/1125/6389965949540196233744917.png]</a> 定价、挑战与行业思考 Palo目前向拥有10万粉丝的创作者开放其工具， 起价为每月250美元 ，使用频率越高价格越高。在测试阶段，该公司已与约40位拥有百万级用户的创作者进行了合作。 平台投资人乔什·康斯坦丁（Josh Constine）认为，Palo可以帮助创作者应对因算法和趋势而产生的&quot;内容倦怠”，解决拖延症和写作瓶颈。然而，Palo的推出正值AI与内容创作者群体关系日益紧张之际，如何避免创作者养成固定模式是AI工具面临的一大挑战。 尼奥承认，优秀的视频仍源于创作者的直觉，但Palo旨在引导创作者朝着可能成功的方向发展。他将这一过程比作喜剧演员在舞台上尝试新段子，通过每一次演出收集观众反馈并迭代， &quot;我们相信人工智能也能为创作者带来类似的优势。” 创作者Sam Beres（Sambucha）则建议，AI公司应从产品构思阶段就与创作者合作，以避免提供大量无关信息，反而导致创作者陷入&quot;新奇事物综合症”。</p><p>【16】北京出台新政力推医疗器械产业:最高3000万支持大模型开发
北京市经济和信息化局等六部门近日联合印发《北京市促进医疗器械产业高质量发展若干措施》，旨在通过数据要素流通和AI大模型赋能，全面推动医疗器械产业升级。政策的核心举措聚焦于数据基础设施建设和行业大模型开发。 措施提出，要加快推进医疗健康行业高质量数据集建设，并完善相关数据流通政策，以促进数据安全合规应用，响应医疗器械制造企业和科研院所的需求;同时，政策明确支持企业在数据基础制度先行区内搭建数据治理服务平台，并对达到一定服务能力的平台建设给予支持。 [图片: AI 医疗 [object Object]<a href="https://pic.chinaz.com/picmap/202307181418295015_2.jpg%5D">https://pic.chinaz.com/picmap/202307181418295015_2.jpg]</a> 为鼓励技术创新和跨界合作，北京市将重金激励行业大模型的开发:鼓励医疗器械企业联合大模型企业共同开发和部署行业大模型，对于达到国内一流、国际领先水平的项目，北京市将按照其算力成本给予资金支持， 最高 不超过3000万元。 此举体现了北京市利用前沿技术，特别是生成式AI和数据要素，来抢占医疗器械产业高端发展制高点的决心。</p><p>【17】库克明年上半年退休？古尔曼直言&quot;假消息”，OpenAI狂挖苹果40+硬件人才成焦点
彭博知名苹果爆料人马克·古尔曼在 最新 《Power On》通讯中明确辟谣:&quot;苹果CEO蒂姆·库克将在明年1-6月之间退休”纯属虚假报道，他称若消息属实&quot;自己会感到震惊”，并强调除非出现重大意外，否则库克短期内不会离职。 接班动态 古尔曼证实，硬件工程 高级 副总裁约翰·特努斯仍是&quot;接班讨论”核心人选——其年仅50岁、任期潜力最长，且深度参与iPhone、Mac、Vision Pro等关键项目，深受库克信任;但相关交接并未加速，董事会亦未设定具体时间表。 OpenAI&quot;扫荡式”挖角 与此同时，OpenAI在过去一个月里从苹果挖走40+名硬件人才，涵盖相机、iPhone、Mac、芯片、测试与可靠性、工业设计、音频、Vision Pro、软件及人体工程学等几乎所有关键部门，多位 高级 经理与主管级工程师加盟。 - 背景:OpenAI收购前苹果设计主管Jony Ive的io公司，正为2026年AI硬件首秀储备团队; - 苹果内部已将此现象上升到&quot;问题”层面，担忧硬件核心知识外流。 离职潮信号 苹果基层离职亦在加剧:iPhone Air主设计师阿比杜尔·乔杜里上周宣布跳槽AI初创，显示&quot;为苹果低薪工作”已不再是硅谷主流选择。古尔曼总结:高管层虽稳，但关键人才流失或迫使苹果加快股权激励与AI业务重组，以应对日益激烈的AI硬件竞争。</p><p>【18】三星将 Perplexity AI 集成 Bixby，模仿苹果 AI 战略
随着科技巨头们不断推进人工智能技术的发展，三星也在积极跟进。近日，有消息称，三星将在即将发布的 Galaxy S26 系列中，将 Perplexity AI 的技术整合进其语音助手 Bixby。这一举措与苹果为其 Siri 助手引入多模型 AI 策略的做法相似，标志着三星在 AI 领域的进一步布局。 据知名爆料人士 @chunvn8888 在社交平台 X 发布的信息，新的 Bixby 将继续负责处理简单的本地任务，比如调节设备设置和执行基础系统操作。然而，涉及复杂推理或生成内容的请求，则将由 Perplexity AI 来处理。这样，Bixby 和 Perplexity 之间的分工可以提高语音助手的整体性能，用户体验也将得到显著提升。 目前，苹果已经通过其 Apple Intelligence 将简单任务交给本地模型完成，而复杂的推理与生成任务则依赖于 OpenAI 的 ChatGPT。这种策略的成功促使三星选择与 Perplexity 进行合作。 三星计划在 S26 系列发布会上 首次 展示集成 Perplexity 的 Bixby，届时，用户将能体验到更为智能的语音助手。基础任务由 Bixby 处理，而复杂的推理和需要深思熟虑的问题则交给 Perplexity 应对。虽然苹果在某些 高级 AI 应用上依赖外部合作伙伴，但内部对自研大语言模型（LLM）的投入也十分可观，目标是在 2026 年推出基于云的复杂推理模型。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/25 AI 日报 今日摘要 【1】TrendRadar 🎯 告别信息过载，AI助你轻松掌握新闻热点——简易舆情监控分析系统。集成多平台热点聚合与基于MCP的AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-24日刊]]></title>
          <link>/2025-11/2025-11-24/</link>
          <guid>/2025-11/2025-11-24/</guid>
          <pubDate>Mon, 24 Nov 2025 10:23:12 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/24</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】TrendRadar
🎯 告别信息过载，AI助你轻松掌握新闻热点，实现简易舆情监控分析——多平台热点聚合+基于MCP的AI分析工具。覆盖35个平台（抖音、知乎、B站、华尔街见闻、财联社等），提供智能筛选+自动推送+AI对话分析（支持自然语言深度挖掘新闻：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark推送，30秒网页部署，1分钟手机通知，零编程基础。支持Docker部署⭐ 让算法为你服务，用AI解读热点</p><p>【2】adk-go
开源、代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【3】ChinaTextbook
涵盖所有小学、初中、高中及大学的PDF教材资源</p><p>【4】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI，自动重置机器ID，免费升级使用Pro功能：您已达到试用请求上限。/本机已使用过多免费试用账户。请升级至专业版。我们设置此限制以防止滥用。若您认为此判断有误，请与我们联系</p><p>【5】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃的node.js版本</p><p>【6】traefik
云原生应用代理</p><p>【7】为我生成图中角色的绘制 Q 版的，LINE 风格的半身像表情包，注意头饰要正确 彩色手绘风格，使用 4x6 布局，涵盖各种各样的常用聊天语句，或是一些有关的娱乐 mem...
为我生成图中角色的绘制 Q 版的，LINE 风格的半身像表情包，注意头饰要正确 彩色手绘风格，使用 4x6 布局，涵盖各种各样的常用聊天语句，或是一些有关的娱乐 meme 其他需求：不要原图复制。所有标注为手写简体中文。 生成的图片需为 4K 分辨率 16:9 [图片: <a href="https://pbs.twimg.com/media/G6fE-98aoAA_MAV?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6fE-98aoAA_MAV?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6fFJqMbkAEwTcy?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6fFJqMbkAEwTcy?format=jpg&#x26;name=orig]</a></p><p>【8】如何用 Claude Code 构建公司：三位 YC 创业者的实践 Claude 官方博客，聚焦于&quot;智能体式编码”工具如何重塑初创公司开发流程。以 YC 三个创业公司——HumanLaye...
如何用 Claude Code 构建公司：三位 YC 创业者的实践 Claude 官方博客，聚焦于&quot;智能体式编码”工具如何重塑初创公司开发流程。以 YC 三个创业公司——HumanLayer（F24）、Ambral（W25）和 Vulcan Technologies（S25 ）——为案例，展示了 Claude Code 如何将从概念到代码提交的开发周期从数周压缩至数小时。 核心观点：智能体编码的变革力量 Claude Code 等智能体式工具将 AI 从辅助角色转为&quot;合作者”，帮助初创团队应对资源有限的痛点。它支持终端内无缝工作流，包括研究、规划和实现阶段，使用如 Opus 4.1（擅长研究与规划）和 Sonnet 4.5（专注构建）等模型。关键在于&quot;上下文工程”：开发者需精心管理提示，避免上下文污染），并监控智能体行为以及早干预错误。文章指出，这种方法不仅加速原型开发，还催生新组织挑战，如团队协作优化。 三个案例：从概念到落地的实践 1. HumanLayer @humanlayer_dev 创始人 Dexter Horthy 最初开发 SQL 智能体，但因 AI 访问敏感操作的风险而转向人类-AI 协作平台。他们通过 Slack 集成人工审批，快速构建 MVP，并获 YC F24 入营。该团队率先提出&quot;上下文工程”概念，并在 2025 年 4 月发布病毒式传播的「12 因素智能体」指南。Claude Code 是其核心工具，用于开发 CodeLayer——一个支持并行智能体会话的系统，利用工作树和工作节点扩展 AI 工程团队。Horthy 直言：&quot;我们几乎所有代码都用 Claude Code 写成。”这让一周的活儿在 7 小时内完成，但也暴露了生产力激增后的协作难题。 2. Ambral @ambral_ai Jack Stettner 和 Sam Brickman 创立此公司，帮助 B2B 企业通过 AI 维持客户亲密度。它从 Slack、会议记录等碎片数据中建模账户，实现一对一管理。作为独行工程师，Stettner 依赖 Claude Code 和 Claude 智能体 SDK 构建子智能体工作流：Opus 4.1 处理并行子智能体研究，Sonnet 4.5 负责实现。产品本身也镜像此设计，使用子智能体针对不同数据类型。他赞扬 Anthropic 模型在工具使用上的领先：&quot;这直接转化为编码优势。”受 HumanLayer 启发，他们强调分阶段会话：&quot;别让 Claude 在规划时同时做研究。” 3. Vulcan Technologies @vulcantechteam 非技术背景的 Tanner Jones 和 Aleksander Mekhanik 构建了弗吉尼亚州政府的监管分析工具，最初用早期 Claude 原型，后全面转向 Claude Code。该工具帮助降低房价 2.4 万美元/户，并每年节省数十亿美元，至 2025 年 5 月赢得合同，推动 Executive Order 51 要求所有监管使用智能体式 AI 审查。公司获 1100 万美元种子轮。Jones 分享：&quot;如果你懂语言和批判性思维，就能用好 Claude Code——人文背景可能更有优势。”他们视 Claude Code 为&quot;同事”，需随时监督以防失误。 技术洞见与最佳实践 文章穿插实用建议：使用独立会话避免上下文交叉；子智能体可并行处理任务，如数据检索或推理；始终&quot;手指扣在扳机上”，随时中断异常行为。创始人共识是，Claude Code 放大结构化思维的价值，但需人类监督以确保质量。Ambral 的多模型委托和 HumanLayer 的并行扩展是典型示例，证明工具在原型到规模化的适用性。 博客地址 <a href="https://claude.com/blog/building-companies-with-claude-code">https://claude.com/blog/building-companies-with-claude-code</a> [图片: <a href="https://pbs.twimg.com/media/G6eyTXCbAAA5yxZ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6eyTXCbAAA5yxZ?format=jpg&#x26;name=orig]</a></p><p>【9】好像少有人做应用层的ai infra 比如GUI自动化测试，agent评估等等 目前没太知道有什么比较好用的
好像少有人做应用层的ai infra 比如GUI自动化测试，agent评估等等 目前没太知道有什么比较好用的</p><p>【10】[开源推荐] LLM Council: Andrej Karpathy 一个周末 &quot;Vibe Coding&quot; 的项目，通过多模型协作提升 AI 回答质量。想象一个虚拟&quot;理事会”场景，多个 AI 模型围坐圆...
[开源推荐] LLM Council: Andrej Karpathy 一个周末 &quot;Vibe Coding&quot; 的项目，通过多模型协作提升 AI 回答质量。想象一个虚拟&quot;理事会”场景，多个 AI 模型围坐圆桌，讨论用户查询，从初始响应到最终合成。 Karpathy 早前的想法：使用 LLM 辅助阅读，并预测未来写作将更注重&quot;让 LLM 理解”而非单纯面向人类。这个项目正是这一理念的实践扩展，将多个 LLM 组合成&quot;理事会”，模拟集体审议过程。Karpathy 观察到，模型间互评时常&quot;谦虚”认可他人输出，这揭示了 LLM 集成设计的潜力——一个尚未充分探索的领域。 GitHub 仓库：llm-council <a href="https://github.com/karpathy/llm-council">https://github.com/karpathy/llm-council</a> 本地运行的 Web 应用，模拟&quot;多模型 AI 顾问委员会”，针对复杂查询（如阅读书籍章节）生成更可靠、洞察性的响应。通过 OpenRouter API 接入多个 LLM，避免单一模型的偏差。项目代码简洁（Python 后端 + React 前端），易于自定义，强调实验性而非生产级鲁棒性。 主要功能 · 多模型并行响应：用户查询同时分发给理事会模型，展示侧边响应视图，便于比较。 · 匿名互评机制：模型审阅彼此输出（隐藏身份），基于准确性和深度打分。这步有趣地暴露模型&quot;自我认知”差异。 · 主席合成：指定模型整合排名结果，输出最终答案。 · 本地存储：对话历史保存在 JSON 文件，便于回顾。 工作流程（三阶段） 1. 第一阶段：初始意见 查询发送至所有模型（如 GPT-5.1、Gemini-3-Pro、Claude-Sonnet-4.5、Grok-4），每个模型独立生成响应。界面显示并排卡片，突出差异（如 GPT 更详尽，Gemini 更精炼）。 2. 第二阶段：审查与排名 每个模型收到匿名响应集，评估并排序他人输出。示例提示鼓励客观性：&quot;哪个最准确？哪个提供最佳洞见？” 这步揭示模型偏好，常有&quot;跨模型赞誉”现象。 3. 第三阶段：最终响应 主席模型（默认 Gemini-3-Pro）接收全部分析，合成简洁输出，标注来源排名。结果往往更平衡，减少冗余。 [图片: <a href="https://pbs.twimg.com/media/G6evYOqaoAAw6nm?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6evYOqaoAAw6nm?format=jpg&#x26;name=orig]</a> Andrej Karpathy: As a fun Saturday vibe code project and following up on this tweet earlier, I hacked up an <strong>llm-council</strong> web app. It looks exactly like ChatGPT except each user query is 1) dispatched to multiple models on your council using OpenRouter, e.g. currently: &quot;openai/gpt-5.1&quot;, [图片: <a href="https://pbs.twimg.com/media/G6ZZO7ragAAtnCZ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6ZZO7ragAAtnCZ?format=jpg&#x26;name=orig]</a></p><p>【11】Free money
You got to check this out I got to do is sign up for sofi and do this quick little quizzes and it&#39;s easy free money<a href="https://joindebbie.com/?ref_id=2FMH9VMM6">https://joindebbie.com/?ref_id=2FMH9VMM6</a> submitted by /u/One-Industry6982 [link] [comments]</p><p>【12】机会总是留给有准备的人。
机会总是留给有准备的人。</p><p>【13】人工智能风险引发保险公司担忧，难以投保
近日，多家大型保险公司，包括 AIG、Great American 和 WR Berkley，向美国监管机构申请，希望能够将人工智能相关的责任从企业保单中排除。这一请求反映出业界对人工智能风险的深切担忧。某位承保人向《金融时报》表示，人工智能模型的输出结果 &quot;太像一个黑匣子”，难以预测和评估其潜在的风险。 [图片: 机器人写作AI写作AI记者 [object Object]<a href="https://pic.chinaz.com/picmap/202307181533345531_11.jpg%5D">https://pic.chinaz.com/picmap/202307181533345531_11.jpg]</a> 图源备注:图片由AI生成，图片授权服务商Midjourney 随着越来越多的企业采用人工智能技术，保险公司正面临前所未有的挑战。例如，谷歌的人工智能曾错误地指控一家太阳能公司存在法律问题，导致该公司在今年3月面临高达1.1亿美元的诉讼。去年，加拿大航空公司因其聊天机器人发出的折扣信息而陷入了困境。此外，诈骗分子利用一位高管的数字克隆版本，通过视频通话骗取了总部位于伦敦的设计工程公司奥雅纳（Arup）2500万美元。 保险公司最为担心的并不是单笔巨额赔付，而是当广泛使用的 AI 模型出现故障时，可能引发成千上万起同时发生的索赔，从而导致系统性风险。正如怡安集团的一位高管所言，保险公司能够承受一家公司4亿美元的损失，但却无法承受因 AI 智能体故障而引发的1万起同时发生的索赔。 这一情况引发了行业内的深思。如何在人工智能快速发展的背景下，合理评估其风险并制定相应的保险政策，成为了保险公司必须面对的重要课题。 划重点: 🌐 保险公司请求排除人工智能相关责任，反映出对 AI 风险的深切担忧。 💼 多起实际案例显示，AI 错误可能导致巨额赔偿和法律纠纷。 ⚠️ 同时发生的索赔风险可能对保险公司构成系统性威胁。</p><p>【14】​Udio 用户失去下载 AI 音乐作品的权利，引发不满
近日，Udio 平台宣布因与环球音乐达成和解，用户将不再能够下载他们创作的 AI 音乐作品。这一变化让许多音乐创作者感到愤怒，因为他们曾经享有的下载功能被突然取消，导致他们无法将自己的作品保留下来。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1124/6389957474344633775287010.png%5D">https://pic.chinaz.com/2025/1124/6389957474344633775287010.png]</a> 根据 Udio 的 最新 服务条款，用户在创建账户时所签署的合同中包含了放弃集体诉讼的条款。这意味着即使用户对这一决定不满，他们也几乎没有任何法律途径可以进行抗议或索赔。这种情况让许多 Udio 用户感到失望和无奈。 此事件不仅影响 Udio 用户，还可能对其他类似服务平台的用户产生警示。例如，Suno 等竞争对手也可能面临类似的法律压力，尤其是在与大型唱片公司之间的关系上。在当前的音乐产业中，AI 创作工具越来越受到关注，而这种法律变动无疑会对用户的创作自由产生制约。 Udio 的这一决定引发了广泛的讨论，许多用户在社交媒体上表达了他们的不满与担忧。他们呼吁更多的透明度和保护措施，以维护用户的创作权利。虽然 Udio 公司表示这项变更是出于与音乐版权相关的法律考量，但用户的声音依然强烈，他们希望能够恢复下载功能。 随着 AI 音乐创作的兴起，如何平衡版权和创作自由，成为了一个亟待解决的问题。用户期待能够在保护自己权利的同时，继续享受 AI 技术带来的创作便利。 划重点: 🎵 Udio 宣布用户无法下载 AI 音乐作品，引发创作者的不满与愤怒。 ⚖️ 用户在创建账户时放弃了集体诉讼权，几乎没有法律途径抗议。 🚨 其他类似服务平台用户也面临潜在的法律压力，需关注自身权利。</p><p>【15】🛠️ µcad：可生成 2D/3D 的开源代码式 CAD，能否超越 OpenSCAD？
原标题： 《µcad: New open source programming language that can generate 2D sketches and 3D》 评分: 34 | 作者: todsacerdoti 💭 没有约束求解器，就敢说能替代传统 CAD？ 🎯 讨论背景 µcad 是一门新出的开源代码化 CAD 语言，宣传可以生成 2D 草图与 3D 模型。讨论把它放在已有生态里对比：OpenSCAD（一款脚本化开源建模工具）、CadQuery（基于 Python 的参数化库）和 GUI 导向的工具如 FreeCAD（开源桌面 CAD）、Onshape（云端 CAD）与 Fusion 360（商业一体化 CAD）。评论集中在即时预览工作流（OpenSCAD 依赖 OpenCSG 的 GPU stencil 技术）、几何内核（CGAL、Manifold）与是否内置约束求解器这几方面的差异，以及 LLM 自动生成脚本的潜力与现实局限。很多人认为语言层面创新有价值，但若要在工程和工业场景中普及，还必须解决求解器、内核健壮性与可用性（tooling）等问题。 📌 讨论焦点 工具与生产力（UI、功能与几何内核） 多位评论者指出现有开源 CAD（如 OpenSCAD、CadQuery、FreeCAD）在可用性、约束和几何内核上仍落后于商业工具（Onshape、Fusion 360）。问题不仅是缺少 GUI，而是函数能力、约束求解和内核精度直接影响到日常设计效率和可制造性。FreeCAD 尽管近年改进，但对入门到中级用户仍不够友好，因此单纯语言创新不会自动提高生产力。评论普遍期待一个成熟的开源 CAD 选项，但强调&quot;tools matter for your productivity”，工作流和工具链完整性同样关键。 [来源1] [来源2] 即时预览与 OpenCSG 渲染工作流 不少人强调 OpenSCAD 的即时预览能力是其工作流核心：保存脚本即可立刻在 3D 视图看到结果，加快迭代速度。背后技术关键是 OpenCSG：利用 GPU 的 stencil buffer 用‘伪装’方式快速呈现布尔运算结果，而不做昂贵的真实三维求交计算。评论指出 OpenSCAD 的 AST 可以被送到不同渲染/内核（OpenCSG、CGAL、Manifold 或简易渲染器），理论上任何 CAD 都能实现类似预览但工程量很大。uCAD 文档未明确是否提供相当的即时重绘或同类渲染路径，这对希望快速迭代的用户很重要。 [来源1] [来源2] 缺乏约束求解器与参数化表达的限制 有评论明确指出 µcad 看起来没有集成约束求解器，而这会让参数化设计退回到手工维护大量三角函数和代数表达上。用户不愿意为简单尺寸、对齐或保持关系写‘墙式 trig’，约束求解器能把这些几何约束符号化并自动求解，从而在修改参数时保持设计一致。对于需要 loft、倒圆角等基于边/面的操作，代码式建模很难直观地引用和修改具体边界，缺乏 solver 会严重影响复杂零件的可维护性和可制造性。除非计划集成求解器或提供更高层次的几何抽象，否则在专业参数化建模场景中会受限。 [来源1] [来源2] 代码式 CAD 与草图式 CAD 的适用场景与争议 部分评论者表示自己更适合用编程思路构建设计，认为代码化 CAD 在参数化、批量化、版本控制和可重复性上有明显优势，已有用 OpenSCAD 打印成功项目的案例。反对者则强调许多工程场景（例如把多个接头沿 Y 型连通并 loft 成平滑通道、指定位于哪条边倒圆角）更适合交互式草图和特征导向的 GUI 操作，代码式界面在指认边/面和处理复杂曲面时不够直观。总体看法是代码式方法不会完全取代草图式 CAD，但可以扩展设计方法学并在特定场景（批量参数化、自动化生成）中非常有用。 [来源1] [来源2] [来源3] [来源4] LLM 生成与自动化的机会与局限 评论里有人指出脚本化 CAD 语言对 LLM 友好：模型能快速生成简单模块（比如 2D 圆角矩形）并降低入门门槛，但在把 2D 正确拉伸为健壮的 3D、或处理复杂布尔与参数化关系时常常失败。实测经验显示，LLM 在简单任务上表现好，但对复杂零件或需要工程判断（材料、配合、公差、制造可行性）时，仍需人工 CAD 经验来校正和验证。还有观点强调即便 LLM 能写代码，真正难的工作是把零件需求和制造约束翻译为可制造设计，这一点短期内仍难被完整自动化替代。 [来源1] [来源2] [来源3] [来源4] [来源5] µcad 与 OpenSCAD/CadQuery 的定位与差异疑问 有人直接发问 µcad 相比 OpenSCAD 有何显著优势，也有评论把 µcad 形容为‘带强类型、Rust 风格语法的 OpenSCAD’。社区关注点包括：类型系统和语法糖是否能弥补在约束求解、几何内核健壮性和成熟 tooling 上的差距，以及能否提供与 OpenSCAD 相当或更快的即时渲染工作流。已有的竞品（如 CadQuery）和成熟生态意味着 µcad 若要获得广泛采用，需要在渲染速度、内核稳定性或与现有工作流整合方面展示明显优势。 [来源1] [来源2] [来源3] 📚 术语解释 OpenSCAD: 一种基于脚本的开源建模工具，通过代码描述构造实体几何（CSG）来生成可打印模型，强调可重现和参数化。 OpenCSG: 用于快速可视化 CSG（构造实体几何）结果的渲染库，利用 GPU 的 stencil buffer 加速&quot;伪造”布尔渲染，实现即时预览而无需完整求交计算。 constraint solver（约束求解器）: 自动求解几何约束（如距离、平行、同心等）的模块，使参数化模型在修改参数时能自动维持设计关系，无需手工计算。 geometry kernel（几何内核，例如 CGAL / Manifold）: 处理布尔运算、求交、曲面/网格运算的底层库，CGAL 是一个成熟的计算几何算法库，Manifold 是较新的布尔/网格引擎，内核决定精度和功能边界。 parametric modeling（参数化建模）: 通过参数与约束表达零件特征（如尺寸、孔位、倒角等），修改参数可自动更新模型，常依赖约束求解器与特征化操作（loft、fillet 等）。</p><p>【16】AI 离诺奖有多远?顶级模型在博士级物理基准测试&quot;CritPt”中惨败，准确率不足10%
据 AIbase 报道 ，一项名为&quot;CritPt”的全新物理基准测试结果显示，即使是目前最 顶尖 的人工智能模型，如 Gemini3Pro 和 GPT-5，距离成为真正的自主科学家仍有巨大的差距。该基准测试旨在将领先的 AI 模型置于博士早期研究水平进行严苛考核。 CritPt:检验 AI 的科研实战能力 &quot;CritPt”由来自全球30多个机构的50多位物理学家共同构建。其核心目标远超对教科书知识的记忆检验，而是旨在测试 AI 是否具备解决原创性、未发表研究问题的能力——这相当于一位能力出众的物理学研究生的独立工作水平。 为了确保测试的严谨性并防止作弊，CritPt 包含的71个完整研究挑战全部基于未发表的资料，涵盖量子物理、天体物理、高能物理和生物物理等11个前沿领域。研究团队还将这些挑战进一步细分为190个较小的&quot;检查点”，以衡量模型在解决复杂问题过程中的阶段性进展。 [图片: 机器人 人工智能 AI (4) [object Object]<a href="https://pic.chinaz.com/picmap/202209071519247086_3.jpg%5D">https://pic.chinaz.com/picmap/202209071519247086_3.jpg]</a> 令人警醒的初步结果: 顶级 模型准确率不足10% 测试的初步结果令人倍感清醒。根据人工智能分析公司（Artificial Analysis）的独立评估显示，即便是目前 最强 大的系统，也未能完成绝大多数任务: 谷歌的&quot;Gemini3Pro Preview”准确率仅为 9.1% 。（值得注意的是，其使用的词元数量比第二名少了10%）。 排名第二的 OpenAI&quot;GPT-5.1（high）”准确率仅为 4.9% 。 研究结果残酷地揭示，目前的大型语言模型在面对开放式物理问题时，普遍缺乏必要的严谨性、创造性和精确性。尽管模型在更简单、定义明确的&quot;检查点”子任务上表现出了一定进步，但在面对完整的科研挑战时却束手无策。 核心障碍:推理能力的脆弱性 研究团队引入了一项更为严格的指标——&quot;一致解决率”（要求在五次尝试中至少做对四次），以测试模型的稳定性。在这一指标下，模型的表现全面大幅下滑。 这种稳健性的缺失给实际科研工作流程带来了严峻挑战。模型常常能得出看似合理的结果，但其中却隐藏着难以察觉的细微错误，这极易误导研究人员，并需要专家耗费大量时间进行审核复查。 未来展望:从科学家到研究助理 基于 CritPt 的测试结果，研究人员认为，在可预见的未来，更切实际的目标并非用&quot;AI 科学家”取代人类专家，而是利用 AI 作为&quot;研究助理”来自动化特定的工作流程步骤。 这一观点与当前的行业规划相符:OpenAI 声称 GPT-5已开始为研究人员节省时间，并计划在2026年9月前推出研究实习生系统，目标是在2028年3月前推出完全自主的研究员系统。然而，CritPt 的结果表明，要实现这一 终极 目标，AI 仍需跨越巨大的技术鸿沟。</p><p>【17】会哄娃、懂情绪、能预判！荣威 M7 DMH 用&quot;活人感”车机重新定义智能出行
当一辆车不仅能听懂&quot;别开空调但把座椅加热打开”这样的复杂指令，还能在你孩子哭闹时自动播放安抚音乐，甚至记得你下午要接娃放学、提前规划好路线——它就不再是冷冰冰的机器，而更像一位体贴入微的出行伙伴。在广州车展首日，上汽荣威正式揭开 M7DMH 的面纱，这台中大型轿车搭载了与字节跳动旗下豆包深度合作打造的&quot;深度思考大模型”，把车机交互从机械应答推向了拟人化的新高度。 这不是一次简单的语音助手升级，而是底层逻辑的彻底重构。荣威与豆包的合作深入到技术架构、数据接口和交互设计的每个环节，目标很明确:让车机真正&quot;能推理、会思考、懂情绪”。依托豆包大模型在中国市场49.2%的份额和1.59亿月活用户积累的语义理解能力，M7DMH 的车机系统展现出远超行业平均水平的智能表现。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1124/6389957434988837597684409.png%5D">https://pic.chinaz.com/2025/1124/6389957434988837597684409.png]</a> 它能精准解析模糊、复合甚至略带情绪的自然语言。比如一句&quot;我有点累”，系统便自动调低座椅靠背、切换舒缓灯光、播放轻音乐，整套操作如行云流水。更厉害的是上下文记忆能力——用户早上说&quot;下午接孩子放学”，傍晚再问&quot;去学校要多久”，车机立刻结合实时路况和历史偏好给出 最优 路线。这套系统还覆盖15类高频用车场景，应对复杂指令的准确率远超传统车机。 自11月17日通过 OTA 推送上线以来，M7DMH 的语音功能日使用率从60%飙升至90%。用户尤其青睐两个&quot;神级”功能:一是&quot;哄娃模式”，系统能根据儿童年龄动态调整互动内容，哭闹时自动播放定制安抚音频;二是&quot;暖心出行守护官”，整合专业汽车知识库，可实时诊断车辆状态，提供维修建议甚至预警潜在故障。 硬件同样不落下风。起售价9.78万元的 M7DMH 搭载 DMH6.0 超级 混动系统，纯电续航达160公里，综合续航高达2050公里，彻底打消里程焦虑。座舱内配备 同级 独有的乳胶感慕斯舒压座椅，久坐不累;后排一键折叠设计进一步提升家庭出行的灵活性与亲密感。 而荣威的野心不止于产品本身。2025年前，品牌计划新增238家渠道网点，重点下沉至三四线城市，让这套&quot;会思考、有温度”的智能出行体验触达更广泛的用户群体。当汽车不再只是交通工具，而成为懂你、护你、陪伴你的移动生活空间，荣威 M7DMH 或许正站在智能汽车进化的新起点上。</p><p>【18】清华新发现：AI大模型不止看&quot;块头”，更要重视密度
近日，清华大学的研究团队在国际期刊《自然・机器智能》上发表了一项颇具启发性的研究成果，提出了 &quot;能力密度” 这一新概念。这项研究挑战了传统观点，认为在评估 AI 大模型的实力时，不应仅仅关注模型的参数数量，也就是 &quot;块头”，而更应关注每个参数所展现的智能水平，即 &quot;密度”。 传统上，AI 领域普遍认为模型越大，能力越强，这一 &quot;规模法则” 在过去几年中推动了众多强大 AI 模型的涌现。然而，随着参数量的增加，模型训练和使用的成本也随之飙升，这给 AI 技术的产业化应用带来了限制。 [图片: 大脑 大模型 AI [object Object]<a href="https://pic.chinaz.com/picmap/202405161743136484_4.jpg%5D">https://pic.chinaz.com/picmap/202405161743136484_4.jpg]</a> 清华大学的研究显示，提升 AI 模型的 &quot;能力密度” 并不能简单依赖于模型的压缩。研究人员指出，强行压缩大模型就像把一本厚厚的字典塞进小本子，结果往往是 &quot;智力” 的损失。因此，研究者们强调，需要一个更先进的 &quot;数据 + 算力 + 算法” 体系来打造出 &quot;高密度” 的小模型。 研究还发现，过去几年发布的 51 个开源大模型中，&quot;能力密度” 正以指数级的速度增长，大约每 3.5 个月翻一番。这意味着，如果现在需要一个体育馆大小的 &quot;大脑” 来完成某个复杂任务，不久的将来只需一个客厅大小的 &quot;大脑”，再过 3 个半月，这个 &quot;大脑” 的体积可能会缩小到仅仅背包大小。 在此基础上，清华大学已经与 AI 企业面壁智能展开合作，推出了一系列 &quot;高密度” 模型，这些模型已经成功应用于手机、汽车和智能家居等多个领域。研究团队认为，未来的 AI 模型将不再追求庞大，而是更加注重 &quot;精炼” 和 &quot;高效”。当芯片的计算能力与 AI 的智能密度相结合时，个人设备将拥有前所未有的智能，能更快速反应并更好地保护用户隐私。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/24 AI 日报 今日摘要 【1】TrendRadar 🎯 告别信息过载，AI助你轻松掌握新闻热点，实现简易舆情监控分析——多平台热点聚合+基于MCP的AI分析工具。覆盖35个平台（抖音、知乎、B站、华尔街见闻、财联社等），提供智能筛选+自动推送+AI对话分析（支持自然语言深度挖掘新闻：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-23日刊]]></title>
          <link>/2025-11/2025-11-23/</link>
          <guid>/2025-11/2025-11-23/</guid>
          <pubDate>Sun, 23 Nov 2025 10:29:37 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/23</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】[P] Interactive Advanced Llama Logit Lens
[图片: [P] Interactive Advanced Llama Logit Lens <a href="https://preview.redd.it/frez7fdfyw2g1.png?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=ae8db7b9a978121f548c8bfa4b8e36c47db4d6ba%5D">https://preview.redd.it/frez7fdfyw2g1.png?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=ae8db7b9a978121f548c8bfa4b8e36c47db4d6ba]</a> github link Hi all, I created an interactive Logit Lens for Llama and thought some of you might find it useful. It is something that I wish existed. What is Logit Lens? Logit Lens is an interpretability tool first introduced by nonstalgebraist , with the aim of interpreting what the model thinks in its intermediate stages of LLMs by projecting the intermediate activation to the final layer&#39;s unembedding matrix. The method has been mildly popular, with hundreds of papers using it to understand how LLM think internally. The reason for making this repo With how widely the method is used, I thought there would be a popular repo that makes logit lens easy for the users to use. This wasn&#39;t the case. The most starred Logit Lens repo on github seemed problematic. The output in the readme did not match my local implementation nor other repository&#39;s output. TransformerLens repository is fantastic but quite large. You have to piece together the docs and code yourself to get an innteractive logit lens workflow, but that takes time. Also, many public repos were using the original gpt2 or project-specific models rather than current, widely used ones. So I built a small tool with the features I wanted. Stuff it can do. Interactively show a more granular logit lens output for user input Allow users to modify the residual stream, attention outputs, and MLP outputs Allow users to block attention from and to certain tokens Save and load current intervention / outputs into and from JSON and npz files. The following only works for Llama at the moment. Let me know what you think. If there are additional features you would like, please leave a comment. submitted by /u/Environmental_Form14 [link] [comments]</p><p>【2】[P] Do papers submitted later / with longer titles receive lower review scores?
[图片: [P] Do papers submitted later / with longer titles receive lower review scores? <a href="https://external-preview.redd.it/FUYcLMBMXOeQOBi0uFvbJ4nLPzBwvKFNqxO8d8hjI_U.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=b52abf4aedf6dae56e0b6d7231bb1920980febeb%5D">https://external-preview.redd.it/FUYcLMBMXOeQOBi0uFvbJ4nLPzBwvKFNqxO8d8hjI_U.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=b52abf4aedf6dae56e0b6d7231bb1920980febeb]</a> submitted by /u/dpaleka [link] [comments]</p><p>【3】It has been amazing to watch the progress of the Codex team; they are beasts. The product/model is already so good and will get much better; I believe...
It has been amazing to watch the progress of the Codex team; they are beasts. The product/model is already so good and will get much better; I believe they will create the best and most important product in the space, and enable so much downstream work.</p><p>【4】[D] Transitioning from physics to an ML PhD
Hey everyone! I’m a physics undergraduate (American) applying to PhD programs next year, and my research interests are in theoretical neuroscience, mech interp, and &quot;physics of learning” type work. There’s a couple American university professors in math and physics departments doing research in these fields, but the majority seem to be CS professors at top departments. This worries me about my chances of getting accepted into any program at all (planning to apply to ~20). I go to a strong STEM school and my grades are decent (3.5-3.6 by graduation) and I’ll have a paper published in high-dim stats/numerical lin alg stuff. Does anyone have advice on tailoring my apps to ML programs? Or advice on skills I should pick up before I apply? submitted by /u/ClassicalJakks [link] [comments]</p><p>【5】🍌nano banana pro Prompt： 把《罗马假日》电影海报的文字改成&quot;骡马假日”，英文还是&quot;ROMAN HOLIDAY”，男女主头部分别替换为骡子和马的头部，海报其余细节...
🍌nano banana pro Prompt： 把《罗马假日》电影海报的文字改成&quot;骡马假日”，英文还是&quot;ROMAN HOLIDAY”，男女主头部分别替换为骡子和马的头部，海报其余细节保持不变，下方写上&quot;上映时间1/1-1/3” [图片: <a href="https://pbs.twimg.com/media/G6ZYjb4WcAA-IqN?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6ZYjb4WcAA-IqN?format=jpg&#x26;name=orig]</a></p><p>【6】strategic collaboration with @emirates, including enterprise-wide deployment of ChatGPT Enterprise: <a href="https://mediaoffice.ae/en/news/2025/november/21-11">https://mediaoffice.ae/en/news/2025/november/21-11</a>...
strategic collaboration with @emirates, including enterprise-wide deployment of ChatGPT Enterprise: <a href="https://mediaoffice.ae/en/news/2025/november/21-11/emirates-group-collaborates-with-openai-to-accelerate-ai-adoption-and-innovation">https://mediaoffice.ae/en/news/2025/november/21-11/emirates-group-collaborates-with-openai-to-accelerate-ai-adoption-and-innovation</a></p><p>【7】TrendRadar
🎯 告别信息过载，AI助你洞悉新闻热点——轻量级舆情监控分析系统。集成多平台热点聚合与MCP架构AI分析工具，覆盖35个平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。适配企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy推送，30秒网页部署，1分钟移动端通知，零编程基础。支持Docker部署⭐ 让算法赋能信息获取，用AI解读热点本质</p><p>【8】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【9】ChinaTextbook
涵盖小学至大学全学段PDF教材资源库</p><p>【10】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器标识，免费升级使用Pro功能：解决&quot;试用请求已达上限/本机试用账户过多，请升级至专业版。此限制用于防止滥用，若认为有误请告知&quot;的问题</p><p>【11】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃Node.js版本</p><p>【12】traefik
云原生应用代理</p><p>【13】😬 将逝者记忆具现化：技术现实性与伦理困境
原标题： 《How to See the Dead》 评分: 21 | 作者: mailyk 💭 把逝者做成可随时调用的商品，真的值得吗？ 🎯 讨论背景 这次讨论围绕一篇名为&quot;How to See the Dead”的科幻短文展开，原文通过指向真实研究的超链接与故意模糊但具体的技术描写，使许多读者误以为描写的是现实可行的记忆具现化技术。故事设定涉及将记忆&quot;物化”或通过植入/混合现实重现逝者形象，触发关于神经通路强化、心理依赖与现实感丧失的争议。评论中有人以 Apple Vision Pro 的沉浸式视频为例，指出非侵入式的混合现实也能在情感上达到类似效果，从而延伸出对伦理、治疗价值与记忆商品化的担忧。多位评论者还引用电影《Blade Runner》中的意象，把文本与经典科幻对感知与创造的反思相连。 📌 讨论焦点 硬科幻的可信度与研究引用 多名评论者指出文章配有指向真实学术/研究的超链接，这种细节让文本呈现出硬科幻的质感并增强可信度。技术细节被有意模糊（obfuscated），既不完全解释也不荒诞，导致读者误以为这些能力已近在眼前；有人表示读到几段才意识到这是虚构（未注意到 Fiction 标签）。还有评论把故事里的感官与记忆工程直接联想到《Blade Runner》中为复制人制造合成眼睛的桥段，进一步拉近现实与科幻的距离。 [来源1] [来源2] [来源3] [来源4] 记忆具现化的心理与伦理风险 评论者警告，把记忆具现化会重新建立或强化那些原本会随时间衰退的神经通路（neural pathways），从生物学角度使人更频繁地重访已逝者，从而阻碍自然的遗忘与调适过程。长期反复刺激会让&quot;重访”成为心理陷阱，产生类似恐怖谷（uncanny valley）的不适感，并把私人回忆变成可被随意取用的廉价纪念品或陈列物。有人补充说，这种技术可能导致两种极端：患者要求医生修改植入装置以停止重访，或者被永久困住、逐渐丧失对现实的判断。 [来源1] [来源2] 现实技术与现有设备的可替代性 另有评论指出，目前的混合现实（mixed reality）硬件已能模拟类似效果：将已拍摄或生成的人脸以沉浸式方式呈现，评论中以 Apple Vision Pro 为例称其&quot;face bucket”几乎能做到同样的事。有人分享个人经历，表示自己拍的 Vision Pro 沉浸式视频里已故宠物让人无法观看，因为太痛苦，说明非侵入式技术也会带来强烈情绪冲击。还有人强调，如果在亲人还健在时大量使用此类设备，会更容易欺骗大脑维持&quot;他们仍在”的错觉，说明现实设备在情感依赖层面与故事中描绘的植入式方案存在相似风险。 [来源1] [来源2] [来源3] Blade Runner 的文化联想 多条评论直接引用了电影《Blade Runner》（《银翼杀手》）中的台词&quot;哦，Chew，如果你能用你的眼睛看到我所见……”，把故事里的记忆与视觉工程与电影中为复制人（Replicant）制造合成眼睛的情节并列。评论补充了引用的背景：Hannibal Chew 为电影中虚构的合成眼工程师，引用意在强调技术如何改变感知与记忆。这样的文化参照被用作隐喻，既拉近读者对技术可行性的想象，也把讨论引向身份、记忆所有权与创造者责任等伦理议题。 [来源1] [来源2] [来源3] 📚 术语解释 mixed reality（混合现实）: 将现实世界与虚拟影像叠加的沉浸式体验，常由头显设备实现（例如 Apple Vision Pro），用于呈现沉浸式视频或虚拟人物以增强存在感。 uncanny valley（恐怖谷）: 当仿真体在外观或行为上接近但不完全等同于人类时，会引发强烈不适或疏离感，这一概念常用于讨论高度拟真的数字人或机器人。 neural pathways（神经通路）: 指大脑中负责记忆与认知的神经连接，常识上使用或重复刺激会强化这些通路，不使用则可能衰退，因而与记忆巩固、遗忘机制相关。 Replicant（复制人）: 出自电影《Blade Runner》（《银翼杀手》）的虚构人造生命体，用来探讨意识、记忆与创造者之间的伦理与同情问题。 类别： Science | Hardware | Asimov Press | memory implants | Blade Runner | Apple Vision Pro | mixed reality | fiction</p><p>【14】🎞️ 复古 Tektronix 示波器：独特色彩与精良做工成影视常客
原标题： 《Tektronix equipment has been used in many movies and shows》 评分: 20 | 作者: stmw 💭 把复古示波器摆镜头前就成‘科技’了？ 🎯 讨论背景 Tektronix（一家长期生产示波器与测试测量仪器的美国厂商）的老式设备在影视作品中频繁出现，既因为外观更有辨识度，也因为 CRT（阴极射线管）屏的色彩与残影能制造独特的影像质感。参与讨论的大多是电子工程师、维修者与爱好者，他们提供了关于内部做工（如陶瓷端子、银焊丝小卷、电阻色环）和出色维修手册的第一手细节。评论还提到具体使用场景：例如在 80 年代用 Tek 4115（1280 ×1024 彩色显示器）在 Fortran/CP/M 环境下做图形实验，以及在工作中为示波器写 GPIB 控制程序，显示这些设备既是道具也是实际工作工具。大量道具照片库以复古 CRT 为主，反映出电影在追求视觉风格时偏好外观辨识度高的老设备以营造时代感或复古科幻氛围。 📌 讨论焦点 影视外观与电影友好性 评论指出 Tektronix 仪器在镜头里比 HP 更显眼：色彩丰富、造型有个性，能为画面增添&quot;科技感”与视觉趣味。部分 CRT 示波器使用的 phosphor（荧光体）配方和颜色独特，屏显效果在电影里带来额外的影像张力（有人提供 tekwiki 的 phosphor 资料作为实例）。一个 150 + 道具画廊里仅有两张现代示波器照片，其余多为复古 CRT，说明制片方更常用旧式屏幕来达到特定影像质感与时代氛围。也有评论提到日本厂商有时更艳丽，但 Tektronix 的色彩与造型兼具电影通用性与辨识度，因此被频繁选用。 [来源1] [来源2] [来源3] [来源4] 内部做工与工程质量 多名评论者强调 Tektronix 仪器内部做工精良：陶瓷端子、银焊丝的小卷、所有电阻色环统一朝向等细节被反复提及，显示出严格的装配与检修考量。有人指出每台机内有小卷银焊丝以避免使用错误焊料，这类设计反映出对长期维护的重视。维护手册与维修手册被评价为业界典范，文档详尽、便于检修，成为设备可长期服役的重要因素。尽管有用户提到电阻随时间漂移导致性能轻微下降，整体仍被视为耐用且容易修复的仪器。 [来源1] [来源2] [来源3] [来源4] [来源5] 真实使用经验与长寿命 个人使用者报告许多老型号仍在实际工作中服役：有人仍在用 556 和 547 示波器，虽因电阻漂移性能略降但仍可使用并且耐久。回忆中提到 80 年代在 RADC/Hanscom AFB 使用 Tek 4115（彩色、1280 ×1024）进行 Mandelbrot 与 Towers of Hanoi 等图形/算法实验，环境为 Fortran（估计 Fortran 77）和 CP/M，显示这些设备既用于工程也成为程序员的创作媒介。还有人在职业环境中为 Tek/HP 编写 GPIB 控制程序，说明这些示波器长期参与自动化测试与数据采集。另有爱好者以 Eventide 等音频或测试设备为例，强调复古装备在爱好者圈的活跃使用与收藏价值。 [来源1] [来源2] [来源3] [来源4] 道具选择与时代适配性 讨论认为 Tektronix 的工业设计时间跨度大、视觉语言明确，能适配多种电影年代与风格，从早期黑白片到现代场景甚至 20、30 年代的复古未来主义都能被接受。相较而言，HP 的米色/中性外观被认为不够镜头化，制片方更倾向于有识别度的器材以传达技术感。大量道具图集中以复古 CRT 为主，反映出影视制作更重视通过硬件外观传达时代感与氛围，而非严格复刻真实检测流程。这样的通用性既降低了道具采购与布景成本，也保证了画面视觉的一致性和可识别性。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 CRT（Cathode Ray Tube，阴极射线管）: 一种通过电子束扫描荧光屏生成图像的老式显示技术，复古示波器与监视器常用；其发光与残影特性对电影画面风格有明显影响。 phosphor（荧光体）: CRT 屏幕上的发光涂层，化学成分与涂层工艺决定颜色、亮度与残影（afterglow），不同配方可产生明显不同的屏显效果。 GPIB（General Purpose Interface Bus，IEEE‑488）: 一种用于测试测量设备间通信的并行接口标准，常用于示波器、频谱仪与计算机之间的远程控制与数据采集。 类别： Hardware | Tektronix | oscilloscope | CRT | movies | vintagetek.org</p><p>【15】🤖 用 AI 草拟可编辑提交信息：是否强制、输出空洞与规范之争
原标题： 《Show HN: Build the habit of writing meaningful commit messages》 评分: 24 | 作者: Aplikethewatch 💭 把提交信息强制 AI 生成，是要让机器人管版本历史吗？ 🎯 讨论背景 这是一个 Show HN 项目，作者发布了一个用 AI 帮助养成写有意义提交信息的工具。工具通过分析变更并调用大语言模型（可配置为 Llama 3.1 或 gpt4o 等）生成提交信息草稿，然后打开用户编辑器让开发者最终确认。评论讨论集中在 AI 输出是否只是泛化且空洞的事后辩护、是否应强制填写提交信息以代替快速检查点、以及采用 Conventional Commits（提交信息规范）还是把元数据放在 git trailers（提交尾注）更合理。讨论还提到预置提示（pre-prompt）与不同模型在提示敏感度上的差异，反映出自动化产出质量与实际工作流便捷性的权衡。 📌 讨论焦点 工具实现与模型细节 作者公开了核心 AI 模型交互实现，调用时需用 pre-prompt（例如 &quot;You are an expert software developer”）来约束输出风格。评论里有人指出不同模型表现差异：Llama 3.1 需要更多手把手引导，而 gpt4o 较少需要引导。工具的工作流是由模型起草提交信息并打开用户编辑器让开发者最终确认，强调的是提供可编辑的起点而非完全自动化替换。整体关注点在于提示工程与模型选择如何影响产出质量和可用性。 [来源1] [来源2] [来源3] AI 生成消息质量的批评 有评论用仓库里的提交实例（如提交 cc677f7）指出自动生成的提交信息质量差：内容重复补丁已含的信息且包含泛化且无实际价值的句子。具体示例包括 &quot;The full path specification in <code>go build </code> was redundant given the context of how Go modules are structured.” 和 &quot;streamlining the project structure and reducing unnecessary directory complexity.”，评论者认为这些句子并未说明真正的&quot;为什么”。尽管工具会把草稿放进编辑器供开发者修改，但示例显示开发者有时并未改进 AI 的懒惰产出，因此批评聚焦在 AI 需要产出能解释动机与上下文的实质性内容，而非事后辩护式的空洞描述。 [来源1] [来源2] 是否应强制填写提交信息 有人质疑工具是否将提交信息设为必须或能否禁用，认为自己把 git 当作临时检查点，不想为每次保存写说明。相关讨论提到缺少像 git-quicksave 这种带 &quot;Autosave” 信息的快速保存命令会影响工作流效率。反对者则表示经常浏览历史很有用，难以理解完全放弃历史文档化的做法。总体上这是在历史可审计性与开发速度/便捷性之间的权衡争论。 [来源1] [来源2] [来源3] 提交规范与元数据：Conventional Commits vs git trailers 有评论反对在提交头部强制使用 Conventional Commits（如 feat、fix、chore），认为这些类型占用 header 空间且不如将元数据放在 git trailers（提交尾注）合适。另有评论者表示自己之前并不熟悉 git trailers 并准备去了解，显示实践中存在认知差异。讨论还提到团队风格差异（有人把提交写成连载故事），说明规范化与实用性之间的张力。该观点关注如何在不破坏可读性的前提下保留机器可读元数据。 [来源1] [来源2] [来源3] 开发者态度：时间成本与实用主义 部分开发者坦承自己的提交信息混乱、更愿意把有限时间花在写代码上，把提交信息的整理留给合并（merge）环节，认为逐条美化提交信息是过度讲究且浪费时间。对此有回应指出&quot;commit”一词在不同人之间语义不一致，有人实际上指的是 merge。该类观点强调工具若不能显著节省成本或提高长期价值，很可能被视为形式化或爱好而非必要改进。总体上是对工具可行性和成本收益的实用主义审视。 [来源1] [来源2] 📚 术语解释 Conventional Commits: 一种提交信息约定规范，规定 header 类型（如 feat、fix、chore）和格式，便于自动生成 changelog、语义化版本控制与自动化流水线。 git trailers: git 的提交尾注（trailers）机制，允许在提交信息末尾用 Key: Value 格式保存元数据（例如 Reviewed-by、Co-authored-by），不占用提交头部空间。 pre-prompt（预置提示）: 在调用大语言模型前注入的固定提示词或角色设定（例如 &quot;You are an expert software developer&quot;），用于引导模型输出风格与聚焦点。 Llama 3.1 / gpt4o: 两类语言模型的代表：Llama 3.1 通常为较小/可本地部署的模型，需更多提示工程；gpt4o 属于更大规模的商用模型，输出通常更稳健但资源与成本更高。 类别： Programming | AI | Show HN | smartcommit | commit messages | git | AI | arpxspace | GitHub | git trailers</p><p>【16】🤔 Markdown 真在拖后腿？社区争论：内嵌 HTML 可行性与 AsciiDoc/Typst 替代
原标题： 《Markdown Is Holding You Back》 评分: 31 | 作者: zdw 💭 所以我们要把简单文档都逼回到繁琐标记吗? 🎯 讨论背景 讨论基于一篇认为&quot;Markdown 限制写作”的文章展开。反对意见强调 Markdown 可通过嵌入 HTML（HyperText Markup Language）补强功能，且其简洁性是广泛采用的主要原因；支持替代方案的评论推荐 AsciiDoc（.adoc，结构化标记）、reStructuredText（reST，Python/Sphinx 常用）或 Typst（现代排版语言）以满足更严格的结构与高质量输出需求。争论还触及 Markdown 扩展导致的碎片化、工具链对导出与可访问性的影响，以及是否应由改进 LLM（大型语言模型）的语义能力来解决格式对机器处理的限制。总体而言，讨论集中在可用性与可维护性、语义化机器可读性与文档输出质量之间的权衡。 📌 讨论焦点 Markdown 足够且可嵌入 HTML 多位评论者指出 Markdown 允许在需要处直接嵌入任意 HTML 标签，且主流 Markdown 工具链普遍支持这一点，因此很多看似&quot;缺失”的功能可以用原生 HTML 补齐。评论强调 Markdown 的最小性带来可读性与速度优势：即便未渲染，源码仍然易读，减少对格式细节的关注。有人认为这种限制反而是优点，能让作者把精力放在内容而不是呈现上，从而降低学习和维护成本。 [来源1] [来源2] [来源3] [来源4] 结构化文档需更强工具：AsciiDoc/reST/Typst 另一派评论者认为当文档需要严格结构、可访问性或团队协作时，AsciiDoc（.adoc，功能更丰富的标记语言）或 reStructuredText（reST，Python/Sphinx 生态常用）更合适，因为它们原生支持语义化章节、属性和更复杂的文档元数据。对于需要高质量 PDF 输出的人，有评论推荐 Typst（现代排版/文档语言），指出它在输出控制和可访问性方面比 AsciiDoc 的某些工具链更好，但同时也有人提醒 Typst 的 HTML 导出和编辑器生态还在发展。社区还提到可将 AsciiDoc 解析为 AST（抽象语法树）等工具，这类中间表示能提高自动化转换和可靠性。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] [来源8] 扩展、碎片化与语义化/LLM 争议 有人指出问题并非纯粹是 Markdown 语法，而是社区对 Markdown 的各种不兼容扩展和实现差异导致碎片化，作者原文也强调了这一点。另一种观点认为，为了让 LLM（大型语言模型）理解内容，应该改进模型对语义的处理，而不是迫使人们回到更复杂、难维护的标记体系；反方则认为更具结构性的格式天然利于机器处理。讨论中还穿插实用案例：一些评论认为通过现有工具链（例如浏览器另存为 PDF 或经由 LaTeX）即可实现格式转换，强调转换路径和工具成熟度对选择格式至关重要。 [来源1] [来源2] [来源3] [来源4] [来源5] 采纳、易用性與现实考量（简单性获胜） 多条评论以现实采用率为据指出 Markdown 已成事实标准，简洁易学使其在 README、博客及工程团队文档中广泛使用，甚至获得像 Windows 记事本那样的原生支持。评论强调简单性降低入门门槛与维护成本，尤其在贡献者多且背景各异的团队中尤为重要。最终是否更换格式常常取决于生态、编辑器支持和迁移成本，而非单纯语法能否表达某些高级功能。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 Markdown: 一种强调可读性与简洁性的轻量级标记语言，广泛用于 README、博客和文档；多数实现允许在文本中嵌入原生 HTML 以扩展功能。 AsciiDoc (.adoc): 功能更全面的纯文本标记语言，支持丰富的结构、属性和元数据，常用于团队技术文档与可生成多种输出格式的文档流程。 Typst: 现代排版与文档语言，目标提供比 LaTeX 更易用且可控的 PDF 输出与可访问性支持；其 HTML 导出与编辑器生态仍在发展。 reStructuredText (reST): Python 社区常用的标记格式（常与 Sphinx 联合使用），支持语义化指令和扩展，适合 API 文档与结构化技术文档生成。 AST（Abstract Syntax Tree）: 将标记语言解析为抽象语法树的中间表示，便于程序化分析、转换与生成不同输出格式，提高自动化处理的可靠性。 类别： Programming | Web | Opinion | Markdown | Typst | AsciiDoc | HTML | PDF | LLM</p><p>【17】😞 Mozilla 沉落：Firefox、AI 与 Chromium 垄断之争
原标题： 《The Mozilla Cycle, Part III: Mozilla Dies in Ignominy》 评分: 138 | 作者: holysoles 💭 把浏览器变成 AI 面板，就能救 Firefox 吗？ 🎯 讨论背景 这次讨论围绕一篇断言&quot;Mozilla 沉没”的文章展开，评论从技术、商业与治理层面对 Firefox 的未来展开争论。参与者把 Firefox 市场份额下滑主要归因于移动时代与 Google/Chromium 的分发优势、站点对 Blink 的兼容倾向，以及长期的兼容性与性能问题。Mozilla 近年来试图通过 VPN、MDN Plus（Mozilla 的付费开发者服务）、Pocket（文章收藏服务）与 AI 功能多元化收入，以减少对 Google 搜索分成的依赖，这引发了&quot;该专注修 bug 还是扩展业务”的优先级争议。讨论还引用 Opera 转向 Chromium 的历史作为警示，并提到 Servo（Mozilla 的研究引擎）与 Ladybird（基于 Servo 的浏览器）等作为多样性备选项。 📌 讨论焦点 Chromium 垄断与引擎多样性 评论普遍担忧 Chromium/Blink 的主导地位正在把 Web 生态推向单一运行时，开发者因此减少对非‑Blink 引擎（如 Gecko）的测试和支持，造成 Firefox 兼容性与体验被边缘化，尤其在 YouTube、Figma、Notion 等大厂服务上更明显。历史案例（如 Opera 在分发压力下转向 Chromium）被多次引用以说明分发与渠道优势能覆盖技术卓越，保持独立引擎的成本与风险极高。还有人指出 Chromium 的事实优势会影响 W3C 的话语权与标准走向，使得多样性与用户选择进一步弱化。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] AI 集成的利弊 社区对 Firefox 内置 AI 的态度分裂：部分用户认可内建翻译、本地化处理、自动字幕与 AI 面板在日常使用上的便利，认为这些功能解决了实际痛点且可选。反对者认为把稀缺工程资源和资金投向&quot;AI 功能”会削弱对浏览器核心（性能、兼容、长期 bug 修复）的投入，且默认或开箱即用的 AI 功能会侵蚀用户信任。还有声音警告 AI 可能是个巨大耗资池（若生态/投资泡沫破裂会成为包袱），但也有评论指出 Mozilla 倾向通过对接第三方模型而非自建前沿模型来降低成本与风险。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] [来源8] 战略、资金与核心定位冲突 评论反复提到 Mozilla 在&quot;专注浏览器”与&quot;摆脱 Google 依赖”之间发生矛盾：为减少对 Google 搜索分成的依赖，Mozilla 推出 VPN、MDN Plus、Pocket 与 AI 产品，试图多元化收入來源，但这些侧项目既未必快速盈利又可能分散对 Gecko 与 Firefox 基础工程的投入。多位评论给出历史性数据与观察称 Google 曾长期占 Mozilla 收入的绝大部分，近期占比下降但仍影响公司决策，因此社区对管理层的优先级与收益透明度有强烈不满。批评者主张若不能证明侧项目带来可持续收入，应把资源优先用在修复长期遗留 bug、提升性能与兼容性来保住用户基础。 [来源1] [来源2] [来源3] [来源4] [来源5] 企业市场与商业化出路（企业浏览器、DLP） 不少评论建议 Mozilla 可转向企业级浏览器市場，提供集中管理、内置 DLP（Data Loss Prevention，数据防泄露）、水印与企业策略等能力，以便在终端层面阻止敏感数据泄露并建立付费商业模式。已有厂商（如 Palo Alto Networks）在把 Chromium 改造为企业安全浏览器，评论中还有人提到 Mozilla 正在布局企业产品（有发布计划的说法），这表明企业市场是可行但竞争激烈的出路。要取得成功需在兼容性、部署策略与企业级支持上快速交付，而不是靠消费端的 AI 小功能来吸引付费客户。 [来源1] [来源2] [来源3] [来源4] [来源5] 用户体验缺陷与扩展生态流失 许多用户把离开的直接原因归结为长期未修复的 UX 与渲染问题（如多年 kerning bug、Firefox Sync 不恢复网站 favicon 等长期票），这些&quot;琐碎但恼人”的问题比新功能更能影响留存。扩展生态的变化也令重度用户担忧：Manifest V2 →MV3 的变更与 Chromium 生态主导导致广告拦截等扩展的实现受限，用户担心 uBlock Origin 等核心扩展的可用性。此外，前端与企业团队因市场份额与兼容性考虑逐步把 Firefox 从常规测试矩阵中剔除，形成兼容性—市场份额的恶性循环；同时 Firefox 的 Multi-Account Containers 被部分用户视为仍留在 Firefox 的关键特性。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 治理、文化與非營利組織的局限 多条评论将问题归因于治理与组织文化：作为非营利的 Mozilla 在生存压力下采取与营利机构类似的人事与运营方式，董事会与高层被批评缺乏有效问责，导致优先级错误与短期化决策。评论指出许多非营利在经济下行期会失去捐赠或投资承诺，若管理层用&quot;创新”噱头掩盖工程债与市场现实，组织长期竞争力会被削弱。总体观点是：没有清晰的财务自给路径和工程优先级，单靠品牌情感与理念难以持续支撑独立浏览器的长期发展。 [来源1] [来源2] [来源3] [来源4] [来源5] 📚 术语解释 Gecko: Mozilla 的独立浏览器渲染引擎，是 Firefox 的核心渲染与 DOM/JS 实现，代表非‑Chromium 的独立实现。 Blink / Chromium: Chromium 是 Google 主导的开源浏览器项目，Blink 是其渲染引擎。许多主流浏览器基于 Chromium，带来分发与兼容优势但也造成实现趋同。 Manifest V2 / MV3: 浏览器扩展的配置规范从 Manifest V2 迁移到 MV3，MV3 限制了某些网络请求拦截能力，直接影响广告拦截器和复杂扩展的实现方式。 DLP（Data Loss Prevention）: 企业级的数据防泄露技术，指在端点或浏览器层检测并阻止敏感数据外泄（例如阻止下载、屏蔽粘贴或添加水印）。 Multi-Account Containers: Firefox 的隔离标签/容器功能，用于在同一浏览器中分离登录、隔离跟踪和不同会话，常被企业或高级用户用来管理多账户。 Servo / Ladybird: Servo 是 Mozilla 发起的研究型浏览器引擎项目，Ladybird 是基于 Servo 的新一代浏览器实现，作为 Gecko/Chromium 之外的潜在替代方案。 类别： Web | Business | AI | Opinion | Mozilla | Firefox | AI | Google | search engine</p><p>【18】FLUX FP8 Scaled and Torch Compile Trainings Comparison - Results are amazing. No quality loss and huge VRAM drop for FP8 Scaled and nice speed improvement for Torch Compile. Fully works on Windows as well. Only with SECourses Premium Kohya GUI Trainer App - As low as 6 GB VRAM GPUs can run
Check all 18 images, Trainer app and configs are here : <a href="https://www.patreon.com/posts/112099700">https://www.patreon.com/posts/112099700</a> submitted by /u/CeFurkan [link] [comments]</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/23 AI 日报 今日摘要 【1】[P] Interactive Advanced Llama Logit Lens [图片: [P] Interactive Advanced Llama Logit Lens https://preview.redd.it/frez7fdfyw2g1.png?width=640&#x26;crop=smart&#x26;auto=w]]></description>
        </item>
      
  </channel>
</rss>