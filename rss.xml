<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI洞察日报 RSS Feed</title>
    <link></link>
    <description> 近 7 天的AI日报</description>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 01 Dec 2025 02:37:58 GMT</lastBuildDate>
    <atom:link href="https://yxxxxx1-ai-daily.gunzhao59.workers.dev/rss" rel="self" type="application/rss+xml" />
    
        <item>
          <title><![CDATA[2025-12-01日刊]]></title>
          <link>/2025-12/2025-12-01/</link>
          <guid>/2025-12/2025-12-01/</guid>
          <pubDate>Mon, 01 Dec 2025 10:37:57 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/1</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】TrendRadar
🎯 告别信息过载，AI助你轻松掌握新闻热点——多平台舆情监控分析系统。聚合35个平台（抖音/知乎/B站/华尔街见闻/财联社等），配备智能筛选+自动推送+AI对话分析（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack推送，30秒网页部署，1分钟手机通知，零编程基础。提供Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【2】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【3】ChinaTextbook
涵盖小学至大学全学段PDF教材资源</p><p>【4】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器ID，免费升级使用Pro功能：解决试用请求限额/本机免费账户过多提示，我们设立此限制防止滥用。若认为有误请告知</p><p>【5】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃node.js版本</p><p>【6】traefik
云原生应用代理</p><p>【7】三年前第一次提 ChatGPT 的推文 当时还没意识到 ChatGPT 比 GPT3 是多么质变 ChatGPT 的免费一下就坚持了三年 那时候还是太年轻了啊
三年前第一次提 ChatGPT 的推文 当时还没意识到 ChatGPT 比 GPT3 是多么质变 ChatGPT 的免费一下就坚持了三年 那时候还是太年轻了啊 Orange AI: 其实 ChatGPT 也不是说比 GPT-3 有多好，但它就好在是免费的，要知道它提供的这些功能加起来，在商业化产品里每个月要上百美刀。 当然免费就会被滥用的。所以看能坚持多久。</p><p>【8】不认怂，是 AI 创业者最贵的营销方式 比如：产品不行，就花钱找人写软文，硬是把 10% 成功率的东西吹上天 产品数据不行，就靠砸钱维持活跃度。
不认怂，是 AI 创业者最贵的营销方式 比如：产品不行，就花钱找人写软文，硬是把 10% 成功率的东西吹上天 产品数据不行，就靠砸钱维持活跃度。 Frank Wang 玉伯: 认怂，会是 AI 创业者最高贵的品质。 比如：发现 Vibe Coding 问题一堆，还是得求教于 Classic Coding 的大牛。低头跪求就好。 比如：发现 AI GTM Agent 大多还是幼儿园水平。这时大胆弃聊，低头求助于传统人肉服务，才是正道。 比如：某 VC 说不投超过 5 个人的创始团队，觉得每个人都可以驾驭 10</p><p>【9】ChatGPT 在三年前的今天发布 把这个世界带入了生成的范式 彻底改变了世界 也改变了我们的人生 如果这三年你在拥抱 AI 你会很兴奋，很幸福 如果你刚开始拥抱 AI ...
ChatGPT 在三年前的今天发布 把这个世界带入了生成的范式 彻底改变了世界 也改变了我们的人生 如果这三年你在拥抱 AI 你会很兴奋，很幸福 如果你刚开始拥抱 AI 也为时不晚 正是八方来财大展鸿图的时候</p><p>【10】Epic boss Tim Sweeney thinks stores like Steam should stop labelling games as being made with AI: &#39;It makes no sense,&#39; he says, because &#39;AI will be involved in nearly all future production&#39;
[图片: Epic boss Tim Sweeney thinks stores like Steam should stop labelling games as being made with AI: &#39;It makes no sense,&#39; he says, because &#39;AI will be involved in nearly all future production&#39; <a href="https://external-preview.redd.it/A2SZ69Ks9iyM_AxJpDKOjoR57HEajLQTgawYBX5ZkyE.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=d62f58ea334dd99195b9db8b051f74f5dc802312%5D">https://external-preview.redd.it/A2SZ69Ks9iyM_AxJpDKOjoR57HEajLQTgawYBX5ZkyE.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=d62f58ea334dd99195b9db8b051f74f5dc802312]</a> submitted by /u/esporx [link] [comments]</p><p>【11】这个 AI 世界时钟有意思，由各种大模型生成的纯前端的代码的模拟时钟，每分钟生成一遍，并限制 2000 个词元，看看有多少是瞎搞的，挺有趣，不少一本正经瞎搞系统...
这个 AI 世界时钟有意思，由各种大模型生成的纯前端的代码的模拟时钟，每分钟生成一遍，并限制 2000 个词元，看看有多少是瞎搞的，挺有趣，不少一本正经瞎搞系统，严肃编码很重要了。 <a href="https://clocks.brianmoore.com/">https://clocks.brianmoore.com/</a> [图片: <a href="https://pbs.twimg.com/media/G6aUwrAbsAAiDgA?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6aUwrAbsAAiDgA?format=jpg&#x26;name=orig]</a></p><p>【12】Perplexity permabanned me in their official sub for citing their own documentation to expose &quot;Deep Research&quot; false advertising and massive downgrade.
I am writing this as a warning to anyone paying for Perplexity Pro expecting the advertised &quot;Deep Research&quot; capabilities. TL;DR: I proved , using Perplexity&#39;s own active documentation and official launch blog, that their &quot;Deep Research&quot; agent is severely throttled and not meeting its contractual specifications. The community validated my findings (my post reached 280+ upvotes , 65 comments , 100+ shares , and reached the top of the sub&#39;s front page ). Instead of addressing the issue, the moderators permanently banned me and removed the thread to silence the discussion. The Full Story: I have been a Pro subscriber specifically for the &quot;Deep Research&quot; feature, which is sold as an &quot;Autonomous Agent&quot; that &quot;reads hundreds of sources&quot; and takes &quot;4-5 minutes&quot; to reason through complex tasks and deliver a comprehensive report. To prove that these are the official specs, I am providing both the current live links and archived snapshots from the Wayback Machine (to prove these have been the consistent standard for months and to prevent potential stealth edits). Official Help Center Documentation: [ Current Live Link ] | [ Wayback Machine Snapshot (Sept 8, 2025) ] Official Launch Blog: [ Current Live Link ] | [ Wayback Machine Snapshot (Aug 2, 2025) ] (Note: I attempted to capture fresh snapshots of the pages today to confirm their current state, but the Wayback Machine is returning errors/incomplete rendering for the new captures. The provided snapshots from Aug/Sept are the most recent stable versions and confirm these specs have been the published standard for months.) Recently (some months), the service degraded massively. My &quot;Deep Research&quot; queries were finishing in 30 seconds with only 10-15 sources, essentially behaving like a standard search wrapper but sold at a premium. I posted (here) a detailed analysis on their official subreddit. I didn&#39;t attack anyone; I simply compared their Official Help Center Documentation and Launch Blog against the actual Product Output : Advertised Spec: &quot;Reads hundreds of sources&quot; / &quot;Takes 4-5 minutes&quot;. Actual Reality: Reads ~10 sources / Takes ~30 seconds. The community rallied behind my post. 280+ upvotes , 65 comments , 100+ shares , and reached the top of the sub&#39;s front page. It became a hub for other users confirming the same throttling. It was a legitimate customer complaint backed by data. Today, I received a Permanent Ban and the thread got deleted. No warning. No explanation of which rule I broke. Just a permanent ban for the &#39;offense&#39; of holding them accountable to their own written promises. The Takeaway: This confirms that Perplexity is likely throttling compute on their premium features to save costs and is using censorship to hide it. If you rely on Perplexity for your workflow, be careful. They will degrade the product you rely on without warning, and the moment you provide evidence of the decline, they will silence you rather than fix it. submitted by /u/somnolentjam90 [link] [comments]</p><p>【13】🤦 Grokipedia：集中式 AI 百科的事实错误、冗长与所有者偏见
原标题： 《Grokipedia Is the Antithesis of Wikipedia》 评分: 38 | 作者: surprisetalk 💭 把全球知识交给会粉饰自己的人，靠谱吗？ 🎯 讨论背景 讨论源自一篇将 Grokipeida 称为&quot;Wikipedia 的对立面”的文章与 Hacker News 上的跟贴。Grokipeida 是基于 xAI（Elon Musk 相关的 AI 公司）和其聊天模型 Grok 的集中式 AI 百科尝试，评论集中在事实准确性（如将 Don DeLillo 角色错误归属）、所有者或微调导致的政治偏见，以及中心化内容生成与 Wikipedia 志愿编辑模式之间的冲突。参与者还提到 RLHF（Reinforcement Learning from Human Feedback）与微调等技术，呼吁披露训练/微调过程以提高可信度，同时关注条目冗长、缺乏内链等产品可用性问题。 📌 讨论焦点 事实错误与 AI 幻觉 评论指出 Grokipeida 存在明显的事实性错误与信息抽取失败。举例将 Don DeLillo 的设定错误归属到《Mao II》而非《The Body Artist》，且被引用的 Metro Times 只是二次来源并未列出原始出处，显示模型在从来源合成事实时发生 hallucination。还有人发现某些条目篇幅极长（有条目达 5500 +字）却缺乏实质性内容与证据，表明长文并不等于准确或可靠。总体观点是需要更严格的来源链核查与事实验证，而不是仅靠 LLM 生成的自洽叙述。 [来源1] [来源2] 所有者操控与政治偏见 多条评论怀疑 Grokipeida 的倾向来自其所有者或运营团队的意图而非中立算法。观察到 Twitter 上的 Grok 与网站版在评价 Elon 时行为不一致，暗示不同的 system prompt 或 fine-tuning 被用来改变输出；有实例称 Grok 被调成持续赞美 Elon，甚至出现荒诞且带有侮辱性的自夸性表述。有人引用媒体调查认为该平台可能被用来&quot;洗白”极右观点，因此在单一所有权和不透明微调下生成的知识难以获得信任。评论因此把关注点放在谁控制训练/微调以及如何防止权力滥用上。 [来源1] [来源2] [来源3] [来源4] [来源5] 集中式 AI 百科 vs 去中心化 Wikipedia 的根本分歧 讨论被框定为去中心化志愿编辑的 Wikipedia 与由单一实体用 LLM 生成并集中管理的 Grokipeida 之间的政治与技术冲突。评论强调 Wikipedia 的多语言志愿贡献、透明编辑历史与对政府捕获的相对抗性是其核心优势，而 Grokipeida 通过集中化审校能快速部署、在某些话题上表现出更一致的视角但也更易被单一偏见支配。也有人持谨慎乐观态度：多个独立的 AI 百科并存可能形成更丰富的&quot;知识市场”，例如按不同技能层级生成适合初学者到研究生的条目。过去在 Hacker News 的相关讨论和页面长度对比被用来说明两类百科在风格与信息组织上的显著差异。 [来源1] [来源2] [来源3] [来源4] [来源5] 产品质量、可用性与风格批评 评论在产品层面上批评 Grokipeida 条目常常冗长但缺乏可用性與可导航性。具体抱怨包括某些条目被生成到数千字却写法呆板，平台缺少 Wikipedia 那类&quot;蓝色内链”，用户无法顺着知识网络深入探索。有人对条目的编辑历史和页面可读性表示好奇，表明用户既想看到来源可追溯，也希望改进交互（例如自动生成内链或分层难度的条目）。这些反馈把改进重点放在信息架构与阅读体验上，而非仅仅扩充文本长度。 [来源1] [来源2] [来源3] [来源4] 监管、透明度與责任追究 评论多次呼吁对训练数据、RLHF（Reinforcement Learning from Human Feedback）与微调等影响输出偏好的机制进行披露和审查。有人主张法律上应要求公开这些干预，并对虚假或误导性披露承担刑事或民事责任，但也有人质疑对资源充足主体实施伪证类追责在现实中的可行性。讨论还提到开源或可验证模型作为替代路径，认为技术可审计性和可验证性在长期可能比仅靠监管更有效。总体上，透明度、可追溯的训练/微调记录与可审计的技术实现被视为提升信任的关键。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 Grokipedia: Grokipeida（Grokipedia）是由 xAI 生态与 Grok 技术驱动的 AI 生成百科尝试，特点是由集中式 LLM 生成条目并由单一实体控制，近期因事实错误、风格与政治偏向问题被广泛讨论。 Grok: Grok：xAI 推出的聊天模型，存在 Twitter 版与网页版，系统提示（system prompt）或 fine-tuning 差异会导致两者在敏感话题和对特定人物的表态上显著不同。 LLM（Large Language Model）: LLM（大型语言模型）：用于自动生成百科条目的深度学习模型，依赖训练语料、微调与 RLHF，常见风险包括 hallucination（幻觉）与训练数据偏见。 RLHF: RLHF（Reinforcement Learning from Human Feedback）：通过人类评价对模型输出进行强化学习以调整偏好与语调，是影响生成结果但通常不透明的干预手段。 fine-tuning / system prompt: fine-tuning 与 system prompt：通过额外训练或设定初始提示词来改变模型行为与偏好，评论中被用来解释不同部署（如 Twitter vs Web）的行为差异和所有者操控的可能性。</p><p>【14】🤨 美国就业市场将崩塌？股市与 AI 繁荣下的消费分化与债务隐忧
原标题： 《Is America&#39;s jobs market nearing a cliff?》 评分: 20 | 作者: harambae 💭 股市与 AI 热潮，普通人靠刷卡撑得住吗？ 🎯 讨论背景 标题源自对美国就业前景的疑问性报道，文章把增长归因于股市与人工智能（AI）投资的繁荣，同时指出&quot;普通人困顿”。评论用黑色星期五/网购星期一的消费数据与行为（如延迟购买、线上增长、通胀影响）来反驳或质疑这一说法，且有人引用 Bloomberg 的报道指出 4.1% 的增幅未做通胀调整。讨论围绕数据是否被少数高消费群体拉高（K-shaped economy / K 型经济）、信用卡与信贷如何短期撑起消费，以及文章是否缺乏对其 investment thesis（投资论点）的说明与批判展开。 📌 讨论焦点 黑色星期五记录并不能证明大众景气（数据与行为细节） 评论中大量争论指出&quot;黑色星期五破纪录”是有限的观测点，不能直接反驳&quot;普通人困顿”的论断。具体细节包括：Bloomberg 报道的 4.1% 增幅为未通胀调整数，通胀调整后接近持平；很多购买只是把原本会进行的耐用品采购延后到折扣期，从而产生时间转移而非新增需求。另有讨论指出线上增长与线下客流分化会同时推高名义销售（线上面向更广市场），同时信用卡与信贷扩张可以短期抬升消费但并不等于家庭真实收入改善。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] [来源8] [来源9] [来源10] 不平等与 K-shaped economy：少数高消费群体拉高总体数据 多条评论把当前现象归结为 K-shaped economy（K 型经济），即经济与消费数据被较富群体的回升或高支出拉动，而大多数人并未同步受益。评论提出质性差异：富人可能在节庆季购买更多更高端商品，推动总量指标，而低收入家庭靠信用卡或短期借贷买单（例如买游戏机等），但仍难以承担抚养与长期生活成本。因此单看节日销售或总消费容易掩盖分配恶化与债务累积带来的真实民众困境。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] 标题修辞与文章论证缺失（缺少 investment thesis 的讨论） 有评论直接质疑问句式标题的修辞性，援引 Betteridge&#39;s law of headlines（标题贝特里奇法则）暗示这类问题式标题往往倾向否定。另有评论对原文批评在论证上缺乏对其背后 investment thesis（投资论点）的交代与批判，读者因此无法判断股市与 AI 投资的繁荣是否会真正传导到劳动市场或只是资产端的膨胀。总体上，部分评论把文章视为论证不充分或标题党，要求更多实证与投资逻辑分析以支撑如此重大的结论。 [来源1] [来源2] 📚 术语解释 K-shaped economy（K 型经济）: 指经济复苏或增长中出现阶层分化：部分行业或高收入群体快速回升或获益，而低收入群体长期受损，导致宏观指标与多数人实际状况不一致。 Black Friday / Cyber Monday（黑色星期五／网购星期一）: 美国感恩节后的大规模促销时段，常被用作短期消费指标，但受折扣时序、线上线下渠道迁移、通胀和延期购买行为影响，不能简单视为总体消费健康的证明。 Betteridge&#39;s law of headlines（标题贝特里奇法则）: 一种新闻观察法则，认为以问题形式的标题其答案往往是否定，常被用来提示读者该标题可能是修辞或炒作而非严谨结论。 类别： Work | Business | Opinion | U.S. jobs market | The Economist | inequality | consumer spending | inflation | K-shaped economy | Black Friday | consumer debt</p><p>【15】🤨 BrickLink 在 35 国暂停交易：合规、支付疑虑与削弱二手市场的猜测
原标题： 《Bricklink suspends Marketplace operations in 35 countries (developing story)》 评分: 32 | 作者: makeitdouble 💭 把二手市场封了是为了逼人买全新套装吗？ 🎯 讨论背景 BrickLink 是一个以零件和二手/转售乐高套装为主的在线市场（早期曾叫 Brickbay），近期官方宣布将在 35 个国家暂停市场运营，引发用户疑问。评论围绕公告可能的真实原因展开：官方提到的&quot;合规挑战”（如进口限制、物流和当地法律）与支付通道问题（有人联想到此前影响 Steam 用户的 PayPal 事件）被反复提及。另一方面，社区中存在强烈怀疑，认为 LEGO 收购后可能出于商业策略（保护新品销量）而有意削弱二手市场；同时对名单中像巴西或格陵兰这样的条目感到困惑，并批评公司在短期内统一停运且缺乏透明沟通。 📌 讨论焦点 合规与支付/物流限制可能是官方理由 多名评论者认为公告中提到的&quot;合规挑战”可能是真的：有人指出巴西进口手续和关税复杂（导出/进口限制、物流和当地法律可能阻碍平台运作），并把官方公告列入的国家清单当作证据。另一条评论把注意力放在支付通道上，提出是否与此前影响 Steam 用户的 PayPal/支付处理器问题类似，暗示支付商限制也会让平台无法在某些国家完成交易。也有评论提醒这类问题可能存在于个别卖家层面（例如违规发货或报关）而非平台本身，显示社区对&quot;是平台合规问题还是卖家问题”的分歧。 [来源1] [来源2] [来源3] [来源4] [来源5] 对 LEGO 动机的怀疑——收购后或有意削弱二手市场 多位评论者怀疑 LEGO 收购 BrickLink 后并非为长期经营，而是出于遏制二手/转售市场以保护新品销量的商业考量。有人回顾了平台的历史（从早期的 Brickbay 到后被转卖再被 LEGO 收购），并声称收购链条和收购方行为表明&quot;买来关掉”可能性；另有评论援引 LEGO 过去与原始发明权利相关的争议和对继承人的低额赔付，作为其商业策略不太透明的佐证。这种观点把官方给出的&quot;合规”理由与企业保护自身新品销售利益的长期动机联系起来，认为两者可能并存或官方理由只是掩饰。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 名单选择与影响规模引发疑问 有人指出被封锁的 35 国合计人口超过 25 亿这一数字看起来惊人，但也有评论质疑这些国家能为平台贡献多少收入，认为不太可能从中获得占比很大的营收。其他人反驳说 BrickLink 的买家分布非常广泛——活跃卖家曾从世界各地接到订单，说明即便是看似偏远或人口稀少的地区也能带来实际交易量。名单中的某些条目（例如格陵兰）被评论者认为和 LEGO 的传统市场/物流模式不太匹配，这加剧了对名单甄选逻辑的困惑。 [来源1] [来源2] [来源3] [来源4] 沟通方式与社区反弹：两周通知与缺乏解释 不少评论对 BrickLink/LEGO 的沟通方式表示不满：批评集中在短时间（两周）内对所有受影响国家采取统一停运，而没有逐国说明具体障碍或征求社区反馈。评论里有人直指官方措辞和结尾署名（例如&quot;感谢您的理解”）显得回避实质说明，认为可以有更透明的处理与阶段性解决方案。这种不透明的突然性既让长期会员感到被迫，也引发了对公司长期策略与社区关系的质疑。 [来源1] [来源2] [来源3] 📚 术语解释 payment processor（支付处理商）: 负责处理在线付款的第三方服务（例如 PayPal、Stripe 等），当支付通道在某些国家受限或被中断时，会直接导致电商平台无法完成交易结算。 secondary market（二手/转售市场）: 指品牌商品的二手或转售渠道（在本讨论中指 BrickLink 上零件和停产套装的交易），制造商往往担心二手市场对新品销量和定价产生负面影响。 compliance challenges（合规挑战）: 涉及当地法律、海关/进口限制、制裁、税务与金融监管等合规要求，跨境电商在不同国家运营时常因这些差异产生复杂的合规负担。 类别： Business | Policy | Incident | BrickLink | LEGO | JaysBrickBlog | Brazil</p><p>【16】Meta AI 推出 Matrix 框架，革新多智能体合成数据生成
在现代 AI 模型中，如何保持合成数据的新鲜性和多样性而不让单一的调度管道成为瓶颈?Meta AI 的研究人员近日推出了 Matrix，一个去中心化的框架，通过将控制和数据流序列化为消息，分布在不同的队列中进行处理。 随着大型语言模型（LLM）训练日益依赖合成对话、工具轨迹和推理链，现有系统通常依赖中心控制器或特定领域的设置，这会浪费 GPU 资源，增加协调开销并限制数据多样性。而 Matrix 采用了基于 Ray 集群的点对点智能体调度，相比之下，能够在真实工作负载中提供2到15倍的更高令牌吞吐量，同时保持相似的质量。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1201/6390017743767666821855584.png%5D">https://pic.chinaz.com/2025/1201/6390017743767666821855584.png]</a> 传统的智能体框架通常将工作流状态和控制逻辑保留在中心调度器中，所有的智能体调用和工具调用都必须经过这个控制器。这种模式虽然易于理解，但在需要成千上万并发合成对话时却难以扩展。而 Matrix 的设计则将控制流和数据流序列化成一个名为 &quot;调度器” 的消息对象。每个无状态的智能体作为 Ray 的 actor，从分布式队列中获取调度器，应用其特定逻辑后将状态更新并直接发送给下一个智能体。这种设计减少了不同轨迹长度差异带来的空闲时间，故障处理也变得更加局部化。 Matrix 运行在 Ray 集群上，通常通过 SLURM 启动。Ray 提供了分布式智能体和队列，而 Hydra 管理智能体角色、调度器类型和资源配置。该框架还引入了消息卸载，当对话历史超过阈值时，大量负载被存储在 Ray 的对象存储中，仅保留对象标识符在调度器中，从而减少集群带宽。 通过三个案例研究，Matrix 展示了其强大的性能:在 Collaborative Reasoner 的对话生成中，Matrix 的令牌吞吐量达到2亿，相比之下，传统方法仅为0.62亿;在 NaturalReasoning 数据集构建中，Matrix 的吞吐量提升了2.1倍;在 Tau2-Bench 工具使用轨迹评估中，Matrix 提供了15.4倍的吞吐量。Matrix 的设计不仅提升了吞吐量，还保持了输出质量，展示了高效的合成数据生成能力。 论文:<a href="https://arxiv.org/pdf/2511.21686">https://arxiv.org/pdf/2511.21686</a> 划重点: 🌟 Matrix 框架采用去中心化设计，避免了传统中心调度器的瓶颈。 🚀 在多项案例研究中，Matrix 展现出2到15倍的令牌吞吐量提升。 🔧 该框架充分利用 Ray 集群的分布式特性，实现高效的合成数据生成与处理。</p><p>【17】Win11 Copilot 直接送&quot;满血”GPT-5.1，深度思考功能免费解锁！
微软 11 月 29 日向所有Windows 11 Copilot用户推送服务端更新：OpenAI GPT-5. 1 模型已正式上线，免费账号也能一键调用此前月费 20 美元的&quot;Think Deeper”深度推理能力，无需重装、无需注销，打开开关即可体验。 伴随模型升级，Copilot新增&quot;Labs”实验功能区。首批上线的WinUI 3&quot;Vision”组件支持实时画面解析；后续3D生成、音频表达、人像模拟等模块将分批植入。正在内测的&quot;Actions”特性更重磅：借助隔离式&quot;Agent Workspace”，Copilot可像本地沙盒一样直接读写用户文件、批量重命名、生成摘要或执行Python脚本——从&quot;云端聊天”升级为&quot;系统级AI助手”。 微软表示，本轮更新采用灰度发布，预计48 h内覆盖全部Win11 23H2/24H2 设备。对于不想订阅ChatGPT Plus的用户，免费获得GPT-5. 1 深度思考，被视为微软在AI入口大战中甩出的又一张 王牌 。</p><p>【18】​ChatGPT 上线三周年：改变商业与科技的游戏规则
在2022年11月30日，OpenAI 推出了一个名为 ChatGPT 的新产品，宣称它可以以对话的方式与用户互动。这个看似平常的产品却在商业和科技领域引发了巨大的变革，迅速吸引了大量用户，目前仍稳居苹果免费应用榜首。ChatGPT 的推出不仅带来了无数生成式 AI 产品的涌现，还让人们对人工智能的潜力充满期待与担忧。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1201/6390017717776129403012297.png%5D">https://pic.chinaz.com/2025/1201/6390017717776129403012297.png]</a> 在最近的采访中，《AI 帝国》作者 Karen Hao 表示，OpenAI 的影响力已经超过了许多国家，正在重塑全球的地缘政治和我们的生活方式。与此同时，评论员 Charlie Warzel 在《大西洋月刊》中提到，我们正在生活在 &quot;ChatGPT 所构建的世界” 中，这个世界充满了不确定性，尤其是年轻一代在面临就业市场的变化时感受到的压力。 尽管对 AI 未来的看法不一，但许多人仍希望从中获利。Warzel 指出，尽管 AI 的支持者和投资者在等待成果，但他们也意识到生成式 AI 的本质是不断变化和发展的。 Bloomberg 的报道则将目光集中在 ChatGPT 对股市的影响。自 ChatGPT 推出以来，Nvidia 的股票上涨了979%，而与 AI 相关的大型科技公司也因市场热情而获益。现在，标普500指数中七家最有价值的公司（包括 Nvidia、微软、苹果、谷歌、亚马逊、Meta 和博通）占据了近一半的增长，这些公司的市值在市场加权中占到了35%，而三年前这一比例仅为20%。 然而，关于这一增长能持续多久的讨论也在加剧。OpenAI 首席执行官 Sam Altman 在一次与记者的晚餐中提到，AI 行业可能正处于泡沫之中，Sierra 首席执行官 Bret Taylor 则将这种情况比作90年代末的互联网泡沫。尽管个别公司可能面临失败，Taylor 仍然坚信 AI 会转变经济，未来将创造巨大的经济价值。 未来三年，或许我们能得知这些乐观预期是否成真。 划重点: 💡 ChatGPT 自推出以来，迅速改变了商业和科技的面貌，成为苹果应用榜首。 📈 与 AI 相关的公司市值大幅上升，Nvidia 的股票在推出后涨幅接近1000%。 🤔 尽管 AI 热潮兴起，业界仍对未来的市场稳定性表示担忧，可能处于泡沫阶段。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/1 AI 日报 今日摘要 【1】TrendRadar 🎯 告别信息过载，AI助你轻松掌握新闻热点——多平台舆情监控分析系统。聚合35个平台（抖音/知乎/B站/华尔街见闻/财联社等），配备智能筛选+自动推送+AI对话分析（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/s]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-30日刊]]></title>
          <link>/2025-11/2025-11-30/</link>
          <guid>/2025-11/2025-11-30/</guid>
          <pubDate>Sun, 30 Nov 2025 10:28:31 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/30</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】昨天见到了极简汇率的联创... 我用了几年了，还以为是个人开发者作品... 谁能想到一款汇率小工具的背后是一家有支付牌照的金融创业公司呢...
昨天见到了极简汇率的联创... 我用了几年了，还以为是个人开发者作品... 谁能想到一款汇率小工具的背后是一家有支付牌照的金融创业公司呢...</p><p>【2】一次可以清理几十个 G 的 Mac 工具 Mole 小鼹鼠继续更新，<a href="https://github.com/tw93/Mole">https://github.com/tw93/Mole</a> 发布 V1.11 版本，更多是安全和功能体验的完善，发布记录如下： 1. 清理...
一次可以清理几十个 G 的 Mac 工具 Mole 小鼹鼠继续更新，<a href="https://github.com/tw93/Mole">https://github.com/tw93/Mole</a> 发布 V1.11 版本，更多是安全和功能体验的完善，发布记录如下： 1. 清理速度快了不少，扫描算法优化过了。保护规则也更全，renv、JetBrains 全家桶、OpenVPN 配置这些不会被误删。 2. Vim 党福音，所有菜单都能用 h/j/k/l 导航了。 3. analyze 支持刷新，所有列表高度自动适配终端窗口，optimize 命令不再删 Finder 缓存，你的窗口位置、侧边栏设置这些会继续保留。 4. 密码输入更靠谱了，修了合盖唤醒输不了密码、Intel CPU 报错、iTerm2 卡退出这些问题。 5. 代码层面：1000+ 行的清理脚本拆成了 7 个模块，加了健康检查和安全扫描，新写了 400+ 条测试用例提升稳定性。 [图片: <a href="https://pbs.twimg.com/media/G69p2wYaUAAHftL?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G69p2wYaUAAHftL?format=jpg&#x26;name=orig]</a></p><p>【3】[开源推荐] 🌍 Awesome World Models 世界模型精选资源集合，系统地整理了关于世界模型的： · 经典与最新论文（Papers） · 开源代码实现（Code） · 综述与...
[开源推荐] 🌍 Awesome World Models 世界模型精选资源集合，系统地整理了关于世界模型的： · 经典与最新论文（Papers） · 开源代码实现（Code） · 综述与教程（Surveys &#x26; Tutorials） · 数据集与基准测试（Datasets &#x26; Benchmarks） 什么是&quot;世界模型”？ 让 AI 像人类一样拥有一个&quot;大脑中的模拟器”。 · 想象与推演：就像你在开车时，不需真的撞上去就知道&quot;如果我不刹车，就会追尾”。世界模型让 AI 能在脑海中推演&quot;如果我做动作 A，世界会变成状态 B”。 · 本质：它是对物理世界运行规律的抽象和建模。图灵奖得主 Yann LeCun 曾多次强调，世界模型是 AI 具备常识、实现推理和规划能力的必经之路。涉及计算机视觉、强化学习、生成式 AI 等多个领域。 项目里都有什么？ 项目将庞杂的资源分门别类，主要覆盖了以下几个核心方向，这反映了当前 AI 的技术热点： · 具身智能 &#x26; 机器人：机器人如何在不把家里拆了的情况下，通过&quot;脑补”学会走路和拿东西？这里收集了让机器人通过模拟环境学习决策的资源。 · 自动驾驶：比如特斯拉 FSD 或 Wayve 的 GAIA-1 模型。自动驾驶不仅要&quot;看”路，还要预测周围车辆和行人的未来几秒的动作，这正是世界模型的强项。 · 视频生成与物理模拟：类似于 OpenAI Sora 或 Google Genie。这些模型之所以能生成逼真的视频，是因为它们隐式地学会了&quot;物体如何运动”、&quot;光影如何变化”的物理规律。 · 理论基础：收录了如 Dreamer 系列、JEPA 等奠基性的算法架构。 项目地址 <a href="https://github.com/knightnemo/Awesome-World-Models">https://github.com/knightnemo/Awesome-World-Models</a> [图片: <a href="https://pbs.twimg.com/media/G69mT7hawAA6ddn?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G69mT7hawAA6ddn?format=jpg&#x26;name=orig]</a> Rohan Paul: 🌍 Cool useful resource for World-Models. A curated list of works in World Modeling, spanning applications in Embodied AI, Autonomous Driving, Natural Language Processing and Agents. Provides a minimalist map of how world models are utilized in different fields (Embodied AI, [图片: <a href="https://pbs.twimg.com/media/G68ii7vaMAAffWs?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G68ii7vaMAAffWs?format=png&#x26;name=orig]</a></p><p>【4】ChatGPT for Teachers: <a href="https://openai.com/index/chatgpt-for-teachers/">https://openai.com/index/chatgpt-for-teachers/</a>
ChatGPT for Teachers: <a href="https://openai.com/index/chatgpt-for-teachers/">https://openai.com/index/chatgpt-for-teachers/</a></p><p>【5】Reddit 分享向量数据库选型深度分析，为何最终选择 Milvus？ Reddit 开发者基于严格的标准，包括开源、经过验证的十亿级规模和高性能，从众多选项（Vertex AI、E...
Reddit 分享向量数据库选型深度分析，为何最终选择 Milvus？ Reddit 开发者基于严格的标准，包括开源、经过验证的十亿级规模和高性能，从众多选项（Vertex AI、Elasticsearch 等）缩小到最终对决：Qdrant vs. Milvus。 🙌 Reddit 对两个系统进行了压力测试，重点关注以下两个关键运营领域： - 可靠性：虽然 Qdrant 需要手动分片才能进行复制更改，但 Milvus 在自动数据再平衡方面表现出色，从而大大减少了运营维护的工作量。 - 可观测性：Reddit 发现 Milvus 的分布式架构提供了卓越的可观测性和控制力，从而可以更轻松地隔离和解决压力下的问题。 这正是 Reddit 选择 Milvus 的原因。 Milvus 总结道选择没有标准答案，但这里有一些经验教训： - 假设 ≠ 现实：挑战既有需求并避免先入为主，不要陷入现有解决方案的陷阱。 - 基准 ≠ 现实：使用矩阵来阐明需求，但不要被华而不实的文档所迷惑。 - 运营第一：不要痴迷于原始速度。优先考虑维护、调试和可用性，而不是利基性能指标。 博客地址：<a href="https://milvus.io/blog/choosing-a-vector-database-for-ann-search-at-reddit.md">https://milvus.io/blog/choosing-a-vector-database-for-ann-search-at-reddit.md</a> [图片: <a href="https://pbs.twimg.com/media/G69VRzHbkAEwpvs?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G69VRzHbkAEwpvs?format=jpg&#x26;name=orig]</a> Milvus: 𝐑𝐞𝐝𝐝𝐢𝐭 𝐄𝐧𝐠𝐢𝐧𝐞𝐞𝐫𝐢𝐧𝐠 just shared a deep dive on their Vector Database selection journey. Thrilled and honored to see 𝐌𝐢𝐥𝐯𝐮𝐬 stand out for reliability and scale. 🚀 They narrowed the field from many options (Vertex AI, Elasticsearch, etc.) to a final [图片: <a href="https://pbs.twimg.com/media/G60qomGbQAAFxgt?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G60qomGbQAAFxgt?format=jpg&#x26;name=orig]</a></p><p>【6】RT 宝玉: Re Gemini knows your location and current date, so you can ask gemini to get the location and date by itself, e.g. ---- City name: {get my lo...
RT 宝玉 Re Gemini knows your location and current date, so you can ask gemini to get the location and date by itself, e.g. ---- City name: {get my location from my profile} Date: {get current date} ---- ------ full prompt ------- Present a clear, 45° top-down view of a vertical (9:16) isometric miniature 3D cartoon scene, highlighting iconic landmarks centered in the composition to showcase precise and delicate modeling. The scene features soft, refined textures with realistic PBR materials and gentle, lifelike lighting and shadow effects. Weather elements are creatively integrated into the urban architecture, establishing a dynamic interaction between the city&#39;s landscape and atmospheric conditions, creating an immersive weather ambiance. Use a clean, unified composition with minimalistic aesthetics and a soft, solid-colored background that highlights the main content. The overall visual style is fresh and soothing. Display a prominent weather icon at the top-center, with the date (x-small text) and temperature range (medium text) beneath it. The city name (large text) is positioned directly above the weather icon. The weather information has no background and can subtly overlap with the buildings. The text should match the input city&#39;s native language. Please retrieve current weather conditions for the specified city before rendering. City name: {get my location from my profile} Date: {get current date} [图片: <a href="https://pbs.twimg.com/media/G6845edXUAAmXMI?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6845edXUAAmXMI?format=jpg&#x26;name=orig]</a></p><p>【7】TrendRadar
🎯 告别信息过载，AI助你轻松掌握新闻热点——智能舆情监控分析系统。聚合多平台热点（覆盖抖音、知乎、B站、华尔街见闻、财联社等35个平台），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack推送，30秒网页部署，1分钟手机通知，无需编程。支持Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【8】adk-go
开源、代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【9】ChinaTextbook
涵盖小学至大学全学段PDF教材资源</p><p>【10】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器ID，免费升级使用Pro功能：解决试用请求上限/当前设备试用账户过多提示，内置防滥用限制机制，若存在误判可提交反馈</p><p>【11】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃的node.js版本</p><p>【12】traefik
云原生应用代理</p><p>【13】😬 对应计征税（未实现收益）与创始人：稀释、流动性与融资扭曲
原标题： 《Dilution vs. Risk taking: Capital gains taxes and entrepreneurs》 评分: 23 | 作者: hhs 💭 先对未实现利得征税，你准备怎么付日常开销？ 🎯 讨论背景 讨论基于一篇研究提出的替代税制：将资本利得税从实现制改为应计制（对未实现资本利得征税），并分析这种改动对创始人股权稀释、融资选择与风险承担的影响。评论围绕公平性与可操作性展开：反对者指出创始人持股通常高度不流动，提前征税会迫使变现或接受外部资金；支持者或研究模型则强调通过可退税的税收抵免与 VC（风险投资）预付税款，可以将更多创始人纳入正向回报并抑制&quot;僵尸公司”。讨论还涉及将股权抵押借款是否应被视为课税事件、融资时税负的放大效应，以及不同司法辖区的比较意义，例如瑞士（一个在多数情形对个人实现资本利得不征税的国家）带来的反思。 📌 讨论焦点 公平性与流动性担忧；杠杆是否应触发课税 许多评论认为在未出售或未借款的情况下对账面增值征税不公平，因为创始人持有的是高度不流动的股权，无法用这些未变现资产直接支付税款，提前征税可能迫使他们被动变现或放弃长期投入。反对者的回应指出，如果通过股权抵押贷款获得现金，杠杆产生的流动性与分红类似，应被视为税务触发（&quot;leverage = = taxable event”），即借款实质上释放了可课税的价值。讨论还具体提出应计税款需要可退税或税收抵免的安排，并质疑退税是否应计利息、如何处理失败情形等可操作问题。评论多次强调在资产极度不流动时按账面价值征税会带来明显不公与实际困难。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 创始人对融资与稀释的具体担忧与替代税制建议 长期投入的创始人担心应计征税会在他们未变现前剥夺大量价值：一旦小规模融资或出售股份被用作估值触发，创始人可能需要出售远超原计划的股份来缴税。长贴给出具体计算思路，建议税负应只基于实际售出股份的增值或按新估值与出售比例成比例计算，避免把 1% 出售放大为对 99% 估值的课税，从而出现数十倍的税负乘数效应。评论提出混合方案或仅对已售股份征税作为中间路径，以减少对小额融资和引入外部资本的惩罚性后果。相关担忧还包括这种制度会强制创始人接受 VC（风险投资）或放弃控制权以支付税款。 [来源1] [来源2] [来源3] 论文论断：应计征税扩大受益者但降低退出持股 论文模型估算把实现制改为应计制会使创始人在退出时的平均持股下降约 25% ，但如果引入可退税的税收抵免，获得正向回报的创始人比例会从 16% 上升到 47% 。论文指出，大多数创始人会用风险投资资金预付应计税款，并在公司失败时拿回退税，因此&quot;预付”税款对多数创始人可提高最终回报率，这一效果不同于普通的财富税。研究还认为应计征税会抑制&quot;僵尸创业公司”，因为快速失败能触发退税并改善回报分配。 [来源1] 法域差异与作者背景的讽刺性观察 有评论指出研究团队中不少作者来自瑞士，而瑞士在多数情形下对个人实现资本利得并不征税，这与推动对应计征税的提议形成一种讽刺性对比。该观察被用来提醒读者注意作者背景和所在法域的税制经验可能对研究视角产生影响。讨论由此强调在推行新税制时必须考虑不同司法辖区现行税法的差异及其对创始人行为的不同激励效应。 [来源1] 📚 术语解释 Accrual-based taxation（应计制征税）: 对资产账面增值在未出售时按期征税，通常以估值上升或融资事件为触发点，需设计可退税或抵免以应对失败或下跌情形。 Realization-based taxation（实现制征税）: 仅在资产被出售或收益实际实现时征税，这是多数国家资本利得税的典型形式，避免对非流动性资产提前征税。 Unrealized capital gains（未实现资本利得）: 资产升值但尚未通过出售或分红兑现的纸面收益，私有股权常属此类，流动性差且难以用来缴税。 Liquidity event（流动性事件）: 使股权变现的事件，如 IPO、并购或二级市场出售，是创始人实现资本利得并获得现金支付税款的主要途径。 Refundable tax credit（可退税的税收抵免）: 对应计征税中用于在公司失败或净损时退还已预缴税款的机制，研究认为这是减轻风险并提高获得正收益创始人比例的关键工具。 Dilution（股权稀释）: 通过发行新股或引入投资导致创始人持股比例下降，稀释程度会与税制设计和融资决策共同决定创始人的最终回报。 类别： Policy | Business | Paper | PDF | Capital gains taxes | Unrealized capital gains | Accrual-based taxation | Dilution | Entrepreneurs | Founders | Venture capital | NBER | Realization-based taxation | Wealth tax</p><p>【14】🙄 Blender 面部动画：现靠 iPhone ARKit，用户希望 Webcam/本地检测与内录
原标题： 《Blender facial animation tool. What else should it do?》 评分: 21 | 作者: happy-game-dev 💭 这插件只靠 iPhone，是要把大家都赶去买手机吗？ 🎯 讨论背景 原帖在询问 Blender 面部动画插件还能做哪些功能扩展，评论揭示当前实现实际上通过 iPhone 的 ARKit 接收 TrueDepth 摄像头输出的 FACS/blend shape 数据并在 Blender 中映射。讨论围绕两类诉求：一是没有 iPhone 的用户希望支持普通 webcam + 本地模型或基于 displacement map 的捕捉方案；二是改进工作流，比如在 Blender 内直接录制和管理 takes。另有评论推荐现成工具（如 FaceIt 插件）并提醒很多方案自 iPhone X（2017）以来就存在，强调兼容性与工作流整合的重要性。 📌 讨论焦点 依赖 iPhone / ARKit 的实现与限制 多条评论指出该仓库并不实现计算机视觉算法，而是直接使用 iPhone 提供的面部追踪数据。插件通过 Apple 的 ARKit 面部追踪 API 调用前置 TrueDepth 摄像头（用于 FaceID），由系统输出 FACS/blend shape 值后在 Blender 里映射到形状键或驱动器上。评论强调这是常见做法，几乎所有类似替代方案也都依赖 ARKit，而不是自行实现面部检测算法，因此仓库本身无法直接支持普通 webcam 输入。有人补充这类功能自 iPhone X（2017）以来就存在，说明并非新的 CV 算法突破，而是整合现成平台能力。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 用户希望用 Webcam 或本地模型替代 iPhone 没有 iPhone 的用户希望插件能支持普通 webcam 加本地推理模型作为输入，直接在本地做面部关键点/表情检测并驱动 Blender。有人提出更进阶的 DIY 思路：生成黑白 displacement map（位移贴图）来捕捉皱纹细节，再配合 Blender 的 trackers 做映射，以保留面部微表情而不依赖专用硬件。评论也提到可以用 homelab 方案生成 3D 顶点网格，且如果能利用 LiDAR（深度传感）会显著提高深度准确性，但这些方案需要不同的实现、模型或额外硬件支持。 [来源1] [来源2] [来源3] [来源4] 在 Blender 内录制与管理 takes 的需求 多人认为最实用的改进是能在 Blender 内直接录制并管理 takes，把捕捉到的表情数据当作素材版本化、回放和编辑，而无需导入导出多次。评论中有人提到已有作者提供的 add-on，采用免费与付费分层，付费版能直接把录制存入 Blender 场景以简化工作流。由于无论数据来源如何，内置录制与管理都能明显提升效率，评论建议这是优先级较高的功能改进。这样的功能还能降低对外部工具的依赖，方便把捕捉到的数据直接用于后续动画与修正。 [来源1] [来源2] 已有工具与自动化工作流（如 FaceIt） 有评论推荐 FaceIt 这个 Blender Add-on，说明已经有成熟工具支持半自动化面部形状键创建并能与 ARKit 兼容。FaceIt 被描述为一个直观、半自动且非破坏性的工作流，能根据模型拓扑与形态自动生成适配的 facial shape keys，既适用于写实人脸也适用于卡通角色，从而在保留艺术控制的同时节省大量时间。讨论由此提醒：新插件在设计功能时应考虑与现有生态（例如 FaceIt 与 ARKit 的工作流）互补或兼容，而不是重复已有实现。 [来源1] [来源2] 📚 术语解释 ARKit: ARKit（Apple 的增强现实开发框架）提供面部追踪 API，能输出用于驱动动画的表情参数和 blend shape 值。 TrueDepth camera: TrueDepth camera（iPhone 的前置深度传感器）用于 FaceID，可生成面部深度/点云数据，增强面部追踪的精度。 FACS / blend shape values: FACS（Facial Action Coding System）以 blend shape 数值表示面部动作，这些值可以直接映射到 Blender 的 shape keys 来驱动表情。 displacement map: displacement map（位移贴图）是黑白高度图，用于在模型表面还原皱纹等微小形变以增加细节。 LiDAR: LiDAR（光学深度感测硬件）能提供更准确的真实世界深度数据，常见于部分 iPhone/iPad Pro 设备，用于提升面部及场景的深度精度。 FaceIt: FaceIt（一个 Blender 插件）用于半自动生成面部 shape keys、支持 ARKit 工作流，适配不同拓扑与角色形态以加速面部绑定。 类别： Product | Programming | Hardware | Release | Blender | ARKit | iPhone | livelinkface_arkit_receiver | FaceIt | webcam | TrueDepth | FACS | LiDAR | FaceID</p><p>【15】🤦 别把一切都丢给 StackOverflow：社区需主动承担支持与修复责任
原标题： 《Let go of StackOverflow; communities must take ownership》 评分: 23 | 作者: tensegrist 💭 把社区责任都推给 StackOverflow，就能保持长期质量吗？ 🎯 讨论背景 原帖主张不要过度依赖 StackOverflow，而应让各自社区对文档、错误报告和支持负责。评论里给出具体例子：Ubuntu 推出的新版 CUPS 与旧 cupsd.conf 语法不兼容导致打印中断，却被错误地投到 Stack Exchange，维护者不会在那儿看问题。讨论还涉及迁移成本与网络效应、单一投票体系的局限，以及 ChatGPT（大型语言模型）在重复性问答上可能取代 StackOverflow 但对小众领域（如 ConTeXt）仍有限制。整体讨论基于的前提是：不同项目有不同维护渠道，社区责任、可见性和技术（如抓取器、训练数据）都会影响问题是否被及时修复。 📌 讨论焦点 渠道错位与责任归属（错误报告应投到项目渠道） 有评论用具体案例说明问题：Ubuntu 推出的新版 CUPS 打印调度器不兼容某些旧的 cupsd.conf 语法，导致打印功能全面中断，但将问题发到 Stack Exchange 无法触及实际维护者。评论者把讨论发到 CUPS 论坛和 Ubuntu 论坛并互相关联，强调应在项目相关的论坛或维护渠道讨论以让维护者看到。讨论中出现&quot;是 CUPS 的 bug 还是 Ubuntu 的 bug”的指责转移问题，并指出要先收集熟悉 Linux 打印内部机制的人的意见再正式提交 bug 报告，以免被两个项目来回拒绝和指责。 [来源1] 迁移门槛与网络效应 有人强调迁移到新平台必须同时满足两点：新平台没有明显劣势（nothing about the new thing is worse）且在若干方面更好（some things are better）。此外迁移必须克服社会网络效应——用户倾向于&quot;等大家都迁移再说”，造成&quot;先行者缺乏群体”问题。评论者对替代方案表示兴奋但也询问是否存在拥有类似 UI、开源或可替代的 平台，以便降低迁移成本并吸引用户群体迁移。 [来源1] 单一评分体系导致优质内容被误判 有评论指出 StackOverflow 的单一标量评分（vote）会惩罚那些虽有深度、但未直接回答提问者的长篇经验型答案：一个基于几十年经验且研究详尽的回答被大量 downvote，只因没有直接回应 OP 的具体问题。评论里提出应采用多维度评价体系（例如标注&quot;回答问题”&quot;提供背景”等标签），以区分&quot;解决当下问题”与&quot;提供长期背景或最佳实践”的贡献。作者还怀念早期网络的订阅/发现模型（例如 RSS），认为那种基于订阅和评论的发现机制在信噪比和口味上更有优势。 [来源1] ChatGPT 能否取代 StackOverflow 的争议 有人断言 ChatGPT 能快速复制并回答 StackOverflow 上的大多数问题，认为大量重复性问答将被 LLM 替代，从而让 SO 的用途减少。反驳声音指出：ChatGPT 的能力部分来自对 SO 数据的训练（因此能复制 SO 回答），但在小众或高度专业化领域（例如 ConTeXt）以及某些难题上，ChatGPT 尚无法可靠替代人工社区。另有评论提到 SO 现在常被抓取（scrapers）而非大量活跃答主阅读，导致某些问题长时间无人回答，这与 AI 替代论和平台能否自我维系密切相关。 [来源1] [来源2] [来源3] [来源4] [来源5] 旁注：TLA + 的提及与书摘感想 一位评论者表示不知道什么是 TLA +，但喜欢文章中的长篇感慨和书摘；另一位回复做了简短解释，把 TLA + 解释为 Temporal Logic of Actions，并指出这是 Leslie Lamport 的方法，值得一看。这个小分支既显示讨论的广度（从社区治理延伸到形式化方法），也反映出部分读者对专业工具和理论的好奇心。该话题虽非主线，但表明社区讨论常会顺带引入技术规范与阅读推荐。 [来源1] [来源2] 📚 术语解释 CUPS: CUPS（Common UNIX Printing System）：Unix/Linux 下常用的打印系统与守护进程，负责管理打印队列、驱动和打印服务。 cupsd.conf: cupsd.conf：CUPS 的主配置文件，定义队列、访问控制与驱动参数；配置语法或默认生成逻辑的变化会直接导致系统打印中断，需在对应项目渠道讨论修复责任。 TLA +: TLA +（Temporal Logic of Actions）：Leslie Lamport 提出的形式规范语言与方法，用来建模与验证并发/分布式系统的正确性。 ConTeXt: ConTeXt：基于 TeX 的专业排版宏包与系统，用户群较小、文档与社区分散，常依赖邮件列表或专业论坛寻求帮助。 RSS: RSS（Really Simple Syndication）：一种网站内容订阅聚合格式，用于按时间序列获取站点更新，评论中被用来对比基于订阅的内容发现模型。 scrapers: scrapers（网页抓取器）：用于自动抓取网站内容的程序，常用于镜像或训练数据收集；当答案主要被抓取而非由活跃用户阅读时，会降低社区响应率。 类别： Programming | Work | Web | Opinion | Stack Overflow | ChatGPT | TLA +</p><p>【16】🎮 Bazzite：面向游戏的不可变 Linux，主打开箱驱动与手持兼容
原标题： 《Bazzite: The next generation of Linux gaming》 评分: 25 | 作者: doener 💭 买专用游戏发行版就能解决所有兼容问题吗？ 🎯 讨论背景 Bazzite（一个面向游戏的 Linux 发行版）宣称提供开箱即用的显卡驱动、控制器支持和对手持/HTPC 的兼容性，目标是简化在多种硬件上运行游戏的体验。讨论围绕其采用的 immutable distributions 和 OCI images（容器镜像层化定制）、以及与 SteamOS（Valve 的游戏专用 Linux，常用于 Steam Deck）在发布节奏、内核与 Mesa 更新方面的竞合关系。评论里还提到替代栈与工具：EndeavourOS（基于 Arch）作为更灵活的选择，Lutris（一个管理非‑Steam 游戏和 Wine 的开源工具）用于处理 Steam 无法良好处理的第三方游戏。实际兼容性话题也被反复提及，包括 secure boot、DisplayLink、各种控制器与 Wi‑Fi 适配器在不同发行版上的启动或驱动问题。 📌 讨论焦点 不可变发行版与 OCI 镜像的可定制性 支持者把 Bazzite 当作 immutable distributions 的典型案例，强调用 OCI images 能像写容器镜像一样通过 FROM bazzite: &#x3C;version &gt; 在基础镜像上叠加自定义桌面与配置（有人在 Framework laptop 16 上两年稳定运行并维护一个&quot;fork”，把 Hyprland 和个人桌面配置视为系统一部分）。他们认为与 NixOS 等复杂系统相比，镜像化、层化的方式更容易上手和分发，便于为不同硬件或用途构建固定快照。评论也坦承这种做法在可重复性上有权衡——容器镜像常常不 pin 所有包，但整体维护复杂度更低。整体论点是以镜像为单元的不可变发行版在定制与分发上更方便，适合希望快速复制环境的用户。 [来源1] [来源2] 开箱即用的硬件与外设支持（游戏导向） 多条评论和官网说明将 Bazzite 的卖点集中在开箱即用的硬件支持：预装 Nvidia 驱动和最新 Mesa（对 AMD/Intel 做了调优），并宣称对 Xbox/Wii/Switch/PS3/PS4/PS5 等控制器、额外 Wi‑Fi 适配器与 DisplayLink 等外设提供即插即用支持。项目还标榜对手持设备、平板与 HTPC 的兼容性，这使其对把 PC 当做游戏主机或便携设备使用的场景更有吸引力。部分用户也指出，如果发行版自带 Plasma 等桌面环境，会增加对传统桌面用户的吸引力。总体上，这一组观点把价值放在减少驱动和外设调试的时间成本上。 [来源1] [来源2] 怀疑派：普通桌面用户无需专用游戏发行版 怀疑者认为大多数桌面玩家并不需要专门的游戏发行版，常见组合如 Mint + 官方 Nvidia 驱动 + Steam + Proton 已能运行大多数 Windows 游戏且切换 Proton 环境并不复杂。另一类反对意见来自偏好通用发行版的用户，他们更愿意用 Debian 手动安装所需软件，认为专为单一用途定制的发行版容易带来不必要的臃肿。这些评论把主要劣势归结为可控性下降、预装软件与用途锁定，以及对已有工具链（例如 Proton/Lutris）的重复包装。 [来源1] [来源2] 替代方案与工具链偏好（EndeavourOS、Lutris、手动 Arch） 一些用户推荐以 EndeavourOS（一个基于 Arch 的用户友好发行版）或直接手动安装 Arch 来获得可控又现代的游戏环境，认为这比某些原子式/不可变发行版在兼容性和灵活性上更可靠。对非‑Steam 游戏，Lutris 被多次点名为极其有用的工具，能管理 Wine、第三方安装脚本并解决 Steam 行为异常时的兼容问题。评论里也提到 Fedora Atomic 在特定硬件上可能会遇到 secure boot 导致无法启动的问题，说明不可变或原子式模型在实际硬件上仍有兼容陷阱。总体倾向是根据个人习惯选择更灵活或更轻量的工具链而不是一刀切的专用发行版。 [来源1] [来源2] [来源3] 与 SteamOS 的竞合与更新节奏争论 有人认为 Bazzite 填补了一个接近 SteamOS 的市场空白，尤其在硬件支持层面表现不错，但也有人质疑一旦 SteamOS 出 GA 版后 Bazzite 的生存空间会被压缩。支持 Bazzite 的评论强调其更频繁的发布节奏对获得新内核与 Mesa 更新至关重要，而反方则指出 SteamOS 实际上基于 Arch 并采用 rolling release 模型，Beta 分支每周也有多次更新（有用户举例为 8BitDo 控制器新增功能的更新）。因此核心争议集中在&quot;谁能更快把最新内核/驱动与控制器支持推到用户机上”以及是否能持续维护对多种硬件的兼容性。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 immutable distributions（不可变发行版）: 一种将系统分发为只读或层化镜像的发行模型，用户通过叠加镜像或容器层进行定制，便于回滚与一致性，但可能在包级可重复性上有权衡。 OCI images: Open Container Initiative 的镜像规范，用于构建与分发容器/系统镜像，评论中指以镜像为单位做 FROM bazzite: &#x3C;tag &gt; 的定制流程。 Mesa: Linux 上的开源图形用户空间实现，为 AMD/Intel 等 GPU 提供 OpenGL/Vulkan 等图形支持，游戏性能和新显卡支持高度依赖 Mesa 版本。 EndeavourOS / Arch: EndeavourOS 是一个基于 Arch 的用户友好发行版；Arch 常采用 rolling release（滚动更新）模型，倾向于提供较新的内核与驱动。 SteamOS: Valve 推出的面向游戏的 Linux 发行版（常用于 Steam Deck），在讨论中作为 Bazzite 的主要竞品，影响力与发布策略决定了生态竞争格局。 类别： Systems | Product | Hardware | Release | Review | Bazzite | Linux | SteamOS | Steam | NVIDIA | Mesa | Arch Linux | EndeavourOS | Linux Mint | uBlue</p><p>【17】🤔 拆解&quot;self-made man”神话：个人能动、集体贡献与财富起源争论
原标题： 《Men Who Made America&#39;s Self-Made Man》 评分: 20 | 作者: Petiver 💭 既然没人真自力更生，你还好意思吹？ 🎯 讨论背景 讨论源自题为 Men Who Made America&#39;s Self-Made Man 的文章，核心在于质疑美国&quot;self‑made man”叙事并检视成功的归因。评论者把争论拓展到哲学（古希腊的德性与命运划分）、政治经济学（Karl Marx 对社会关系的批判）与文学引用（John Donne 的名句），并用具体历史证据与家族起源来支持或反驳断言。话题还涉及对 富豪/家族榜单（如 Forbes）与私有制、法律和媒体如何塑造&quot;伟人”形象的制度性分析。为了理解讨论，需要兼顾个人决策、制度结构、历史因果与运气三方面的前提。 📌 讨论焦点 集体贡献论：没有人完全自成一人 许多评论认为&quot;自我成就者”是危险的神话，指出个人成功离不开经济环境、教育资源、遗传特质和运气等外在条件。评论引用 John Donne 的诗句来强调个体嵌入于更大的社会网络，并直接断言所有成就往往源于群体协作而非纯粹个人努力。有人以社会关系和制度为出发点，认为把功劳完全归于个人会掩盖制度性支持与集体贡献。该立场用来反对将&quot;self-made”作为单一因果解释的普遍化。 [来源1] [来源2] [来源3] [来源4] [来源5] 个体能动性并存：个人努力与独特才能仍具意义 另一批评论主张取中立场，认为既要承认社会/制度的支持，也不能抹杀个人决策、才能与坚持的重要性。有人指出&quot;self-made”常被作为从贫困阶层上升的简短表述，而不是字面否认他人帮助；艺术、科学等领域存在不可替代的个人贡献。另有论点强调许多拥有相似起点的人最终并未成功，说明选择与品格在最终结果中具有决定性作用。总体观点是：把成功完全归因于群体或完全归因于个人的极端论述都不可信且有害。 [来源1] [来源2] [来源3] 制度与所有权：法律、私有制与媒体如何塑造&quot;伟人” 有评论把&quot;伟人”称号的成因归结为制度性的财富与权力分配，而非纯粹德性或天赋。论点指出當個人能通过法律与媒体控制巨额财富时，他们被视为&quot;伟人”，这种伟大反映的是所有权结构与媒体话语而非道德价值（例如将现代富豪比作拥有权力的&quot;国王”）。围绕&quot;great”的定义展开的回复展示了词义争议，有人强调&quot;great”可以包含精神或智力价值，也有人为历史上的明君辩护以平衡批评。整体上这是对&quot;Great Man Theory（伟人理论）”与资本/法律结构关系的制度性批判。 [来源1] [来源2] [来源3] [来源4] 历史掠夺与族群归因的争议：财富起源有无被剥夺成分 部分评论者断言美国家族财富根源于奴隶劳动、对原住民土地的掠夺以及代际剥削，认为&quot;自我成就”话语掩盖了历史不公。该主张引发反驳，有人指出富豪/家族来源并不单一，引用 Forbes 的家族榜单并举出 Walton、Koch、Lauder、Pritzker 等不同族裔或来源例子来反证。另有评论就历史细节提出修正或反驳，讨论部落间的冲突、土地控制和交易，表明&quot;被偷走的土地”叙事并非总是单一线性。此线讨论因此在证据与因果解释上形成激烈对抗，既有宏观指控也有具体家族史或档案式反证。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 哲学与因果层级争论：德性、幸运与分析深度的界限 讨论触及哲学层面的因果与归因问题：古希腊思想把人生分为灵魂、身体与命运，指出德性需外在条件才能发挥，这为群体与个人作用的二分提供古典框架（见古希腊观点的引用）。同时有人指出如果把成就还原到每个神经元与外部事件，就会陷入彻底决定论，从而破坏责任与实用性的讨论。因此有评论呼吁在承认外部条件与历史偶然性的同时，保留对个人选择、习惯与品格的解释空间，以免分析陷入无用的宿命论或无限归因。 [来源1] [来源2] 📚 术语解释 self-made man: 指宣称个人成功主要靠自身努力而忽视家庭背景、社会资源、教育与运气等外在条件的概念或叙事。 Great Man Theory（伟人理论）: 历史学与领导学中的一种观点，认为历史重大事件主要由少数卓越个体的意志与行动推动，而非社会结构或大众力量。 WASP（White Anglo-Saxon Protestant）: 用于描述美国传统的白人盎格鲁-撒克逊新教精英群体，常在关于财富、权力与世袭起源的讨论中被引用。 类别： Work | Policy | Opinion | self-made man | Great Man Theory | America | History News Network | WASP | slavery | Native Americans | privilege</p><p>【18】🤔 学习费曼的积分技巧：直觉、代换与严谨性争议
原标题： 《Learning Feynman&#39;s Trick for Integrals》 评分: 23 | 作者: Zen1th 💭 只靠费曼的技巧就算懂积分吗？ 🎯 讨论背景 原帖讨论所谓 Feynman&#39;s trick —— 在被积函数中引入参数并在积分号下对该参数求导以简化积分，示例包含含 ln(x) 的表达式。评论分成两条主线：一是关于教学与直觉的争论（解题是否只是识别形式并套用&quot;trick”，以及是否应用更具象的解释来培养直觉），二是关于计算严谨性的讨论（把微分移入积分或换序是否省略了收敛性/可积性检验）。相关概念包括 u-substitution（换元积分）、contour integration（复分析轮廓积分）、Fubini&#39;s theorem（换序积分定理）以及符号计算工具如 Wolfram/Mathematica。理解讨论需要高中到大学初阶微积分的链式法则、积分与微分基本性质，以及换序与收敛性证明的基本概念。 📌 讨论焦点 教学与直觉对抗记忆&quot;trick” 不少评论把做积分题归结为识别题型并套用对应的&quot;trick”，学生常把数学当成猜老师偏好哪种技巧的游戏。有人讲述教学经历，指出教材顺序和已有题型会把自然对数 ln 之类的项变成&quot;死信号”，学生只会套模板式解法，这让人感到不舒服。对比之下，有评论主张用更具象的语言、图像和比喻来建立直觉（提到 BetterExplained 网站和相关书籍的写法），而不是单纯的符号操练。也有观点强调掌握方法与思路比死记技巧更能体现批判性思维与长期能力。 [来源1] [来源2] [来源3] [来源4] 选择代换的实际困难（u-substitution） 另一类评论聚焦在实际操作上的不确定性：进行 u-substitution（换元积分）时经常不知道该选哪个表达式来化简积分。评论指出存在大量看似合理的代换，需要对每个候选式做繁琐代数检验并且容易出错；若代换被直接给出，计算则变成机械性操作，缺乏直觉上的满足感。很多人把这一现象归因于数学进阶后的常态——需要大量练习建立识别有效代换的直觉。也有人猜测像 Wolfram/Mathematica 这样的符号系统可能把这类模式系统化，但目前感觉过程仍有&quot;盲点”。 [来源1] [来源2] [来源3] 微分换位与严谨性（链式法则与收敛检验） 有评论直接质疑把微分移入积分号的步骤是否正确，并给出具体的导数计算作为争论焦点。针对涉及 (x ^t - 1)/ln(x) 的例子，正确的链式法则处理应得到 d/dt (x ^t - 1)/ln(x) = x ^t，因为 d/dt x ^t = ln(x) x ^t 且 1/ln(x) 关于 t 为常数，因此最初的反驳计算是错误的。与此同时，多条评论提醒原文省略了收敛性与可积性的讨论：把微分与积分互换或交换积分次序在理论上需要像 Fubini 定理或支配收敛定理之类的条件来保证合法性。结论是符号运算上步骤可行，但理论上必须验证换序或互换操作的前提条件以免结果不严谨。 [来源1] [来源2] [来源3] [来源4] [来源5] 方法等价与替代（双重积分换序、轮廓积分、自动化） 从方法论角度看，Feynman&#39;s trick 常被解释为把原问题扩展为含参数的二重积分然后交换积分次序的等价做法。评论指出许多此类实数积分也可以通过 contour integration（复分析的轮廓积分）来求解，选择哪种方法取决于问题的解析延拓与边界条件。有人提到把这些技巧交给符号计算器（Wolfram/Mathematica）可以机械化求解，但自动化工具同样需要内置对换序与收敛性的检查来保证结果正确。总体观点是：这些方法互有等价与互补，关键在于对前提条件和可行性的把握。 [来源1] [来源2] [来源3] 📚 术语解释 Feynman&#39;s trick / differentiation under the integral sign（在积分号下对参数求导）: 在被积函数中引入参数，对该参数求导并将导数移入积分号内以化简积分。使用时必须验证把求导与积分互换的条件（如绝对可积、支配收敛定理或相关换序定理），否则计算可能不成立。 u-substitution / integration by substitution（换元积分）: 通过设 u = g(x) 并替换变量来简化被积表达式，是基础微积分常用技巧。实务难点在于选择合适的代换；许多候选代换看上去合理但并不一定真正简化问题。 contour integration（轮廓积分 / 复分析方法）: 在复平面上沿选定闭合路径积分并利用留数定理评估积分的技术，适用于处理某些难以用直接实分析方法求解的积分问题。该法依赖函数的解析性和合适路径的选择。 Fubini&#39;s theorem（Fubini 定理）: 关于多重积分换序的定理：在满足可积性或绝对可积等条件下，可以交换积分次序或在参数积分中把微分移入积分。应用时需检验可测性/可积性等前提以保证换序合法。 类别： Science | Guide | Feynman&#39;s trick | Integrals | Calculus | u-substitution | zackyzz.github.io</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/30 AI 日报 今日摘要 【1】昨天见到了极简汇率的联创... 我用了几年了，还以为是个人开发者作品... 谁能想到一款汇率小工具的背后是一家有支付牌照的金融创业公司呢... 昨天见到了极简汇率的联创... 我用了几年了，还以为是个人开发者作品... 谁能想到一款汇率小工具的背后是一家有支付牌照的金融创业公司呢... 【2】一次可以清理几十个 G 的 Mac 工具 ]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-29日刊]]></title>
          <link>/2025-11/2025-11-29/</link>
          <guid>/2025-11/2025-11-29/</guid>
          <pubDate>Sat, 29 Nov 2025 10:07:39 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/29</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @addyosmani 的博客，他的观点非常明确：AI 生成的代码应被视为&quot;初稿”，而非&quot;定...
AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @addyosmani 的博客，他的观点非常明确：AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”，应该把 AI 当作「一位勤奋但缺乏经验的实习生」。 Osmani 提出，AI 生成的代码往往看起来很完美，但它缺乏对上下文的深刻理解和对&quot;意图”的把握。因此，我们对待 AI 代码的态度，应该像对待一位 初级开发者 或 实习生 的代码一样： · 可以利用它来提高速度：让它去写样板代码、做繁琐的苦力活。 · 绝不能外包&quot;阅读”和&quot;理解”的过程：你可以让 AI 写，但必须由人来读和审。 为什么必须这样做？（潜在风险） 1. 意图与行为的断裂 (Intent vs. Behavior) · 如果不去阅读和理解代码，你就切断了&quot;代码行为”与&quot;设计意图”之间的联系。 · 一旦代码出了问题，如果你当初没有审阅过，你就无法知道它 为什么 是这样写的，维护将变成一场噩梦。 2. 技能退化 (Skill Atrophy) · 盲目接受 AI 的输出会侵蚀工程师的批判性思维和调试能力。 · 正如一位工程师所言：&quot;如果我们停止验证 AI 的输出，不仅会引入即时的 Bug，还会系统性地降低我们需要用来发现这些错误的能力。” 3. 由于&quot;看起来正确”而产生的误导 · AI 代码往往能跑通，测试也能过，但可能存在微妙的逻辑漏洞、安全隐患（如注入漏洞）或处理不好边缘情况。 · 记住：LLM 不会发布糟糕的代码，发布糟糕代码的是团队。 责任永远在人。 实操建议：如何与 AI 共存 Osmani 给出了一些具体的建议，帮助团队在利用 AI 提效的同时保持代码质量： · 建立 &quot;Human-in-the-loop”：AI 可以起草第一版，但必须由人来确保代码的行为符合预期目的。 · 严格的代码审查：对 AI 代码的审查标准不能降低，甚至应该比审查人类同事的代码更严格。 · 不仅仅是&quot;能跑就行”：不仅要验证代码是否能工作，还要理解它是 如何 工作的。不要合并任何你没读懂的代码。 · 利用自动化工具：虽然要有人的审查，但也可以利用智能体工具来进行自动化的 Lint 检查、正则匹配和单元测试，作为辅助防线。 博客地址： <a href="https://addyo.substack.com/p/treat-ai-generated-code-as-a-draft">https://addyo.substack.com/p/treat-ai-generated-code-as-a-draft</a> [图片: <a href="https://pbs.twimg.com/media/G64o561bkAEcx-c?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64o561bkAEcx-c?format=jpg&#x26;name=orig]</a></p><p>【2】#Banana 我想大家已经知道了，并已经在实践了： + Midjourney 用于创意设计 + 用 Banana Pro 叠加公司的物料(Logo、产品、Mascot...) 就是一套可用于生产的商品...
#Banana 我想大家已经知道了，并已经在实践了： + Midjourney 用于创意设计 + 用 Banana Pro 叠加公司的物料(Logo、产品、Mascot...) 就是一套可用于生产的商品广告、营销图生成方案 [图片: <a href="https://pbs.twimg.com/media/G64Z46wbUAAqtb0?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Z46wbUAAqtb0?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G64Z66xbkAIpQSj?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Z66xbkAIpQSj?format=jpg&#x26;name=orig]</a> nazha: #Banana 今天又发现 Banana 似乎融入了世界知识，给商品添加细节放大图的时候，箭头的标注位置完全正确（图1）。而它的前任完全不行。 Prompt: 把细节放大图添加到商品图上并用箭头标注，不要覆盖商品主体，保持其他内容不变 [图片: <a href="https://pbs.twimg.com/media/G6wINRybQAAyhE-?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wINRybQAAyhE-?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6wISqza0AM-aMh?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wISqza0AM-aMh?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6wIVJZbsAAl-5q?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wIVJZbsAAl-5q?format=png&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6wIWrNaQAEI0KZ?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G6wIWrNaQAEI0KZ?format=png&#x26;name=orig]</a></p><p>【3】[D] designing neural network before reading
I wanted to share a personal experience that might resonate with some of you. Before I studied formal image segmentation or object detection, I just tried thinking through neural networks on my own. I designed tiny networks for: Simple object classification Bounding box regression Segmentation I was asking myself: &quot;If I wanted this to work, how would I structure it?” Doing this made me understand the &quot;why” behind layers, pooling, softmax, and regression outputs. By the time I read the papers, everything clicked. It felt like learning a game by playing it on paper first, rather than reading the rulebook. Has anyone else tried designing networks before formally learning about the techniques. Did it help your intuition too? submitted by /u/Huge-Leek844 [link] [comments]</p><p>【4】一篇来自 Apollo Academy 的报告，标题直指痛点：《AI 采用率开始趋于平缓》。报告引用了美国人口普查局和金融科技公司 Ramp 的数据，指出企业对 AI 的采用速度...
一篇来自 Apollo Academy 的报告，标题直指痛点：《AI 采用率开始趋于平缓》。报告引用了美国人口普查局和金融科技公司 Ramp 的数据，指出企业对 AI 的采用速度不仅没有指数级增长，甚至在大型企业中出现了停滞甚至下滑的迹象。 <a href="https://www.apolloacademy.com/ai-adoption-rates-starting-to-flatten-out/">https://www.apolloacademy.com/ai-adoption-rates-starting-to-flatten-out/</a> [图片: <a href="https://pbs.twimg.com/media/G64Ab98XgAAHMqI?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Ab98XgAAHMqI?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G64Ad5AXQAA8Nc2?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G64Ad5AXQAA8Nc2?format=jpg&#x26;name=orig]</a></p><p>【5】Best AI for writing analysis, identifying subtext and developing ideas?
Hey all. I found this sub while researching which AI might be best for helping me think through ideas and provide insights into my writing, so I&#39;m sorry if this question has been asked recently. I don’t know that much about all the different models available and it’s hard for me to choose which one might be best for me when there seems to be many options. What, in your opinion, is the best AI for someone looking for a collaborative research AI &quot;partner&quot; to bounce ideas off of? I do not use AI to write, but will sometimes ask ChatGPT for insight into essay drafts or journal entries that feel like they&#39;re developing a still-premature idea. I appreciate AI&#39;s ability to discern themes, patterns, subtext, and layers of meaning I can&#39;t notice on my own, and to suggest different directions I could take with each idea. I like to ask it to suggest other articles/essays written on similar topics. I don&#39;t trust ChatGPT&#39;s tendency to provide relentlessly positive feedback, but I don&#39;t trust any AI to deliver the same quality critique that a human could, so I&#39;m more looking for a model that can help me develop and expand ideas to a point where I can take the work the rest of the way on my own. What do you think? submitted by /u/doublecheeseburger [link] [comments]</p><p>【6】[D] Possible solutions after the ICLR 2026 identity-leak incident
The OpenReview identity leak has created a difficult situation not only for authors, but also for reviewers, and ACs. The rollback decision with freezing reviews to their pre-discussion state, preventing score updates, and reassigning new ACs seems to be disliked across the whole comminity. Many reviewers were planning to evaluate rebuttals toward the end of the discussion period, and many authors used the long rebuttal window to run new experiments and revise manuscripts. Those efforts will now have no effect on reviewer scores, even when the revisions fully address the reviewers’ original concerns. Across Twitter/X, many ACs have expressed concern that they cannot meaningfully evaluate hundreds of papers under these constraints. Some openly said they may have to rely on automated summaries or models rather than full manual reading. I don&#39;t agree with such a compromise therefore i would like to hear about possible solutions. The ones that resonated with me are the following: • Allow authors to withdraw their papers without the usual public disclosure of the submission. Since the review process has deviated substantially from the agreement authors accepted at submission time, withdrawal without public trace may be a fair option. Another idea (which I personally find reasonable but unlikely) is: • Temporarily enlist active authors to review one paper each (similar to AAAI’s second-phase reviewing). With thousands of authors, the load would be small per person. This could restore some form of updated evaluation that accounts for rebuttals and revised experiments, and would avoid leaving decisions solely to new ACs working under severe time pressure. I’d like to hear what others think. Which options do you see as realistic or fair in this situation? submitted by /u/Available_Net_6429 [link] [comments]</p><p>【7】🤓 1991 年 ABC 语言源码重现 — Python 前身的语法特性与大整数
原标题： 《The original ABC language, Python&#39;s predecessor (1991)》 评分: 21 | 作者: tony 💭 把老 ABC 翻出来，什么时候解决 GIL 的？ 🎯 讨论背景 原帖与评论围绕 1991 年的 ABC 语言源码展开，相关代码最近被推到 gvanrossum/abc-unix 的 GitHub 仓库，使得历史实现和示例更易访问。评论既有对早期语言能力（如无舍入误差的大整数运算 2<strong>1000）的惊讶，也有对 ABC 特定语法（如 PUT ... IN、INSERT ... IN、赋值/突变语法）的评判与借鉴建议。讨论里有人建议将 ABC 更直观的赋值/解包语法带回 Python，但也有人批评这些语句在可组合性上有缺陷，另有对 &#39;in&#39; vs &#39;into&#39; 措辞的历史性比较（引用 HyperTalk、AppleScript）。同时一条关于 GIL 的玩笑反映出 Python 社区对并发模型的长期关注。 📌 讨论焦点 仓库与资源发现 有人指出仓库中最好的语言入门文档并给出了原始链接（gvanrossum/abc-unix 的 raw GitHub 资源），并注意到这些源码最近被推送到 GitHub，使得历史源码更容易访问和阅读。评论者将此视作一次可读历史源码的好机会，便于直接验证语法和实现细节。这个发现成为后续对语法、实现能力和历史影响讨论的起点。 [来源1] [来源2] 对大整数与格式误解的感慨 有人为 ABC 能进行像 2</strong>1000 这样的无舍入误差大整数运算感到惊讶，认为 40 年前就能做到相当了不起。紧接着有人纠正了因 Hacker News 格式化把 &#39;<strong>&#39; 吃掉而导致的误读（被看成 2 * 1000），并解释 &#39;</strong>&#39; 表示幂运算。讨论既体现了对早期语言数值能力的赞赏，也暴露了平台格式化对代码示例展示的陷阱，甚至引来了自嘲式的评论。 [来源1] [来源2] [来源3] [来源4] 语法借鉴与设计讨论 有评论者希望把 ABC 的一些语法想法带回 Python，尤其是为了解决初学者因赋值与原地修改共享语法导致的混淆，例如提出更描述性的写法如 &#39;set b = c in a&#39; 或 &#39;update a with {&#39;b&#39;: c}&#39; 来做解包和索引/切片赋值。另有评论批评 ABC 的 PUT ... IN 和 INSERT ... IN 语句显得笨重且不易组合，示例中往往每行只完成一件高阶操作，从而限制了表达力。讨论中还提到 &#39;in&#39; vs &#39;into&#39; 的措辞差别，并把 HyperTalk（HyperCard 的脚本语言）和 AppleScript 作为历史先例来对比说明设计选择。 [来源1] [来源2] [来源3] 对 GvR 的致谢与历史观察 评论里有人向 GvR（Guido van Rossum）致谢，认为仓库是理解 Python 源流的宝贵历史资料，并把这次代码重现视为值得庆祝的事件。也有评论对当时文档中的英文表述做了轻微挑剔（例如用 &#39;in&#39; 而非 &#39;into&#39;），并有人用历史脚本语言来回应这些用词。整体语气既是对早期工作的怀念与感谢，也带有对表述和设计细节的审视。 [来源1] [来源2] [来源3] 关于 GIL 的玩笑与并发关切 一条简短评论以戏谑的方式问道 &#39;Where is the GIL in this?&#39;，把话题拉回 Python 社区长期关心的并发与性能瓶颈。虽然原帖聚焦 ABC 的语法与历史，但这类提问反映出看到与 Python 相关的话题时社区自然联想到 Global Interpreter Lock（GIL）以及多线程性能问题。该笑话显示出并发模型对讨论氛围的影响，即便是在回顾前身语言时也会被拿来调侃。 [来源1] 📚 术语解释 ABC（编程语言）: ABC：20 世纪 80–90 年代的教学与交互式编程语言，强调可读性和高阶数据操作，对 Python 的设计有直接影响。本次讨论围绕其语法样例和历史源码展开。 GvR（Guido van Rossum）: GvR：Guido van Rossum 的简称，Python 的创建者之一，此处指其维护或提交的 abc-unix 仓库，评论中有人直接向他致谢。 GIL（Global Interpreter Lock）: GIL：Global Interpreter Lock 的缩写，指 Python 解释器中限制多个线程同时执行字节码的全局锁，是讨论 Python 并发性能时常被提及的概念。 类别： Programming | Release | ABC | Python | Guido van Rossum | abc-unix | GitHub</p><p>【8】😬 开发者忏言：坦白脆弱，远程工作争议与网络骚扰担忧
原标题： 《Confessions of a Software Developer: No More Self-Censorship》 评分: 21 | 作者: Kerrick 💭 说出缺陷就是职业死刑？网友会宽容吗？ 🎯 讨论背景 这场讨论起自一篇题为&quot;Confessions of a Software Developer: No More Self-Censorship”的个人博文，作者决定在公共场合停止自我审查并分享脆弱感受。评论围绕远程办公的利弊、公开承认技术盲点的常态化、以及发表观点后可能遭遇的网络骚扰或职业后果展开。具体技术例子包括 Python（脚本语言）/Java（基于 JVM 的语言）中 main() 的写法、php.net（PHP 的官方函数文档）和 Rust（系统级语言）对 main 的简化，用来说明&quot;记不住细节”是普遍现象。讨论反映出开发者社区一方面渴望更真实的自我表达，另一方面又担心表达后会遭遇社群或职场惩罚。 📌 讨论焦点 赞赏作者的脆弱与诚实 多位评论者称赞作者在公开场合坦陈恐惧和缺陷，认为这种脆弱既勇敢又具有宣泄效果。评论指出承认错误或无知很容易被放大成对整体能力的质疑，因此公开坦白对许多人来说既疗愈又冒险。有人表示希望能在社区里更常见这种诚实交流，但也承认这是一场赌博，写出来可能带来不可预见的后果。整体语气是鼓励更多透明同时警觉潜在成本。 [来源1] [来源2] [来源3] [来源4] 远程工作争议：不是绝对的坏或好 多条回复反驳&quot;Remote work sucks”这种绝对化论断，认为把远程与在办公室简单对立过于片面。有人强调如果只允许驻场他/她可能连工作都找不到，说明远程工作为一些人提供了生计与机会；另有评论指出远程协作能力是可以通过实践提升的，与现场协作同样存在人际沟通问题。讨论建议应把远程工作的缺点与非远程工作的缺点进行权衡，而不是一刀切地否定远程模式。 [来源1] [来源2] 技术欠缺与日常救助习惯的自嘲式坦白 评论里有人以具体代码细节作为忏言素材：有人坦承多年也要查 Python（脚本语言）/Java（基于 JVM 的语言）中 main() 的写法，回复里具体提到 <strong>name</strong> = = &quot;<strong>main</strong>&quot; 的用法来区分导入与直接运行。另有评论承认每天使用 php.net（PHP 的官方函数文档网站）查函数细节，还有人以 Rust（系统级语言）更直观的 main() 作为对比来调侃记忆负担。这些具体例子把&quot;忘记细节”常态化，强调即便资深开发者也依赖文档与搜索。 [来源1] [来源2] [来源3] [来源4] 公开表达的风险：网络骚扰、匿名需求与社区毒性 有人明确指出作者遭遇网络骚扰并把当前针对 AI（人工智能）话题的激烈态度与之联系在一起，评论者希望知道具体站点以便避开风险。另有建议建立匿名&quot;忏言”平台以降低发言者被报复的可能，这反映出对安全发声渠道的需求。同时，一条坦白&quot;喜欢在面试中折磨应聘者”的评论直面行业内存在的攻击性文化，说明社区既有对诚实的渴望，也有实实在在的毒性威胁。总体来说，公开坦白在获得同情与共鸣的同时，也可能招致辱骂、职业风险或社群排斥。 [来源1] [来源2] [来源3] [来源4] 类别： Work | Programming | Opinion | self-censorship | software developer | remote work | vulnerability | confessions</p><p>【9】⚠️ 空客要求对 6000 架飞机修改：称太阳强辐射可损航控数据，拟以软件更新修复
原标题： 《Flight disruption warning as Airbus requests modifications to 6k planes》 评分: 34 | 作者: nrhrjrjrjtntbt 💭 要改六千架，真是太阳粒子害的还是设计偷懒？ 🎯 讨论背景 空客对约 6000 架飞机下达修改建议的触发点是一宗实航班异常：一架 JetBlue 航班在 10 月出现&quot;突然下降”并紧急着陆，事后调查认为强烈太阳辐射可能导致了航控相关计算机数据的损坏。评论者基于航空电子专业细节（如 ADIRU、FDR、ARINC 数据字、位翻转与电源尖峰特征）对&quot;辐射导致”这一结论提出质疑或补充，并以 Qantas 72 与 Air France 447 等历史案例讨论系统设计、硬件故障与机组反应的复合影响。讨论还涉及可行的缓解措施（软件校验、ECC、投票算法、OTA 更新）以及监管与厂商在信息透明与预防性修复上的责任。 📌 讨论焦点 报道摘要与事故细节 新闻与评论指出空客发现强烈太阳辐射可能会破坏与飞控相关的计算机数据，这一问题是在一架 JetBlue 航班（由墨西哥飞往美国）10 月发生&quot;突然下降”并紧急着陆后被注意到，事发时有报道称约 15–20 人受轻伤。厂方表示大部分飞机可通过简单的软件更新完成修复，基于此对约 6000 架飞机提出修改建议。评论把这些事实作为讨论起点，随后集中在故障成因（辐射或硬件）与补救路径的可行性上。 [来源1] [来源2] 硬件故障迹象与专业质疑 一些评论引用 2008 年 Qantas 72 的 ATSB 报告，指出当时电源尖峰扰动 ADIRU 并在 FDR 中留下&quot;整词”损坏：这些错误与时钟对齐、幅度一致并局限于单个 ARINC 字，特征上更像是共享航空电子电源总线上固态继电器或接触器（solid-state relay/contactor）失效造成的电气脉冲。评论者强调，若真是太阳粒子导致的 bit flips（单粒子事件），其发生应在时间与能量上呈随机（近似 Poisson）分布，不会产生严格对齐的整词损坏。基于这些技术细节，部分人怀疑不能简单把所有异常归因于辐射，需更多数据区分硬件电气故障与软错误。 [来源1] [来源2] [来源3] 软件修补路径与实际可行性 多位评论提出软件层面可缓解或修复数据完整性问题，具体建议包括加强或新增网络/总线数据包的 checksum、启用 ECC RAM（纠错内存）、调整冗余投票算法与阈值来过滤异常读数。有人还指出若能通过 OTA（空中下载）下发更新，可在不大规模停场的情况下完成补丁，从而减少航班中断。评论同时提醒，太阳辐射在航空电子领域是已知问题，因此软件修补有时能缓解软错误，但若根源为电源或硬件故障则需要同步的硬件检查与更改。 [来源1] [来源2] [来源3] [来源4] [来源5] 安全响应评价与历史先例警示 不少评论赞同厂商在发现潜在问题后采取预防性动作，认为&quot;至少没有等到坠机才行动”，但也有人指出该问题是由一次实际航班异常触发发现，幸而没有更严重后果。讨论引用 Qantas 72 和 Air France 447 等历史事故来提醒，事故往往是设计/制造问题与机组反应交织的结果，单靠归责于一个因素不足以防范未来风险。总体观点是支持尽早修复和透明信息披露，同时强调应从硬件、软件和培训多方面吸取教训。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] 📚 术语解释 ADIRU（Air Data Inertial Reference Unit）: 航空电子系统中的空气数据与惯性参考组合单元，向飞控和自动驾驶提供空速、姿态与导航信息，ADIRU 故障会直接影响飞控模式和显示。 FDR（Flight Data Recorder，飞行数据记录器）: 记录飞机传感器与系统数据的黑匣子，用于事故调查；评论中通过 FDR 里出现的&quot;单一 ARINC 字”损坏特征来判断故障类型。 ARINC word（ARINC 数据字）: 航空电子数据总线（如 ARINC 429）中固定长度的数据字（通常 32 位），单个 ARINC 字的时序与幅度特征可用来区分电气脉冲故障与随机位翻转。 ECC RAM（Error-Correcting Code memory）: 带纠错能力的内存，可以自动检测并修正单比特错误，是对抗辐射导致软错误（bit flips）的常见硬件/固件缓解手段。 single-event upset / bit flip（单粒子事件/位翻转）: 高能粒子（例如太阳粒子）撞击半导体引起的瞬态位错误，通常表现为随机发生（近似 Poisson 分布），与周期性或成块的电气故障特征不同。 solid-state relay / contactor（固态继电器/接触器）: 用于控制航空电子电源的电子或机械开关，失效可引发电源尖峰或周期性干扰，从而在 FDR 中留下与时钟对齐的整词损坏痕迹。 类别： Hardware | Systems | Business | Incident | Airbus | avionics | solar radiation | bit flips | Qantas Flight 72 | Air France Flight 447 | BBC</p><p>【10】🎧 Pulse 2.0：任何人都能当 DJ 的桌面共听房，支持浏览器/系统音频与 AudD 识别
原标题： 《Show HN: Pulse 2.0 – Live co-listening rooms where anyone can be a DJ》 评分: 25 | 作者: 473999 💭 随便开房当主播，版权和延迟问题谁来管？ 🎯 讨论背景 Pulse 2.0 在 Show HN 上展示了一个面向实时共听的音频社交产品，主打&quot;任何人都能当 DJ”的桌面共听房功能。新版重点是从浏览器标签页或通过系统音频（需 BlackHole/VB‑Cable 等虚拟驱动）直接推流，并用 AudD 做曲目识别与自动去重，底层技术包含 LiveKit（WebRTC）、Next.js、Node.js 与 Neon Postgres。评论既有对功能和 24/7 演示房间的正面反馈，也有关于音频延迟、麦克风权限、刷新后无法恢复主持人身份以及无法加入房间等稳定性和兼容性报告。讨论还把项目放到 Groove Basin、MixApp 等早期共听/自托管方案的历史脉络中，反映出对可托管性、易用性与版权/延迟等现实问题的关注。 📌 讨论焦点 技术栈与功能亮点 作者列出了实现细节：使用 LiveKit（基于 WebRTC 的实时音视频库）、Next.js、Node.js、Neon Postgres 作为后端，并用 AudD 做音乐识别。2.0 允许从浏览器标签或系统音频（需 BlackHole/VB‑Cable 等虚拟音频驱动）直接流出声源，增加了自动去重和&quot;winner selection”的识别逻辑。还引入了 24/7 演示房间（例：NTS Radio、SomaFM、以及循环播放示例曲目）、房间内查看 Lobby、主持人的 push‑to‑talk 覆盖层和 emote 集成（7tv.app 链接）。作者特别说明音频共享当前仅支持桌面端，移动端尚不支持。 [来源1] 稳定性与音频问题报告 有用户在实际托管流时遇到多项问题：通过 BlackHole 推流时音乐不断变慢，麦克风有时无法取消静音导致背景呼吸音暴露；刷新页面后无法恢复为房间主持人；阻止麦克风后音乐停止，重新添加麦克风无法恢复流。作者已在评论中表示会跟进这些问题，暗示开发者注意到了客户端兼容性与会话恢复的问题。这些细节显示虚拟音频路由、浏览器权限与会话管理间存在复杂交互，需在不同平台上做更健壮的恢复与兼容处理。 [来源1] [来源2] 可用性与房间加入障碍 有用户反映无法通过点击房间卡片加入房间，但能查看歌曲历史，表明前端交互或跳转逻辑存在问题。开发者在评论中询问了使用的浏览器和设备以排查兼容性，这也与项目只支持桌面音频共享的限制相关。该问题凸显首次使用者的引导不足以及不同浏览器/平台对音频捕获与权限处理的差异性。对于实时共听这类产品，明确的浏览器兼容说明和加入流程提示会显得尤为重要。 [来源1] [来源2] [来源3] 社区反响与历史类比 评论中有人把 Pulse 与早期项目做对比以提供参考：提到在 Sandstorm 平台上有个叫 Groove Basin 的应用，但 Groove Basin 是单一共享流，通过上传曲库和播放队列运作，而非从某人电脑实时转发。另一条评论回忆 MixApp（约 2008 年）将 mp3 流向聊天室的老式体验，并建议当下可借助 Tailscale 等工具重建类似方案。同时也有用户表现出强烈兴趣和粘性，称会持续把房间留着运行，说明实时共听仍有实际需求与使用场景。 [来源1] [来源2] [来源3] 📚 术语解释 LiveKit: LiveKit — 一个用于实时音视频的基础设施库，基于 WebRTC 提供房间管理、多路音视频流和低延迟连接，常用于多人会议与实时社交应用。 WebRTC: WebRTC — 浏览器与原生应用中常用的实时通信标准，用于点对点或多方的低延迟音视频与数据通道传输，支撑实时共听与互动场景。 BlackHole / VB‑Cable: BlackHole（macOS）/ VB‑Cable（Windows）— 虚拟音频驱动或线路工具，可把系统或某个应用的输出当作输入设备，将系统声源路由给浏览器或录音/直播软件。 AudD: AudD — 一种音乐识别 API/服务，用于识别正在播放的曲目并返回元数据，支持自动去重和&quot;winner selection”之类的曲目判定逻辑。 Neon Postgres: Neon Postgres — Neon 提供的托管 PostgreSQL 服务，作为应用的关系型数据库后端，用于持久化存储和查询。 类别： Product | Web | Programming | Show HN | Release | Pulse | LiveKit | WebRTC | Next.js | Node.js | Neon Postgres | AudD | BlackHole | VB-Cable | 7tv.app</p><p>【11】⚠️ 长期运行 agent 的治理、测试与工程复杂性
原标题： 《Effective harnesses for long-running agents》 评分: 26 | 作者: diwank 💭 召唤成百个 agent 就是解决方案了？ 🎯 讨论背景 讨论源自一篇关于为长期运行 LLM agent 设计&quot;harness”（运行治理/测试框架）的文章或项目，评论集中在把原型推向生产的工程挑战上。参与者基于实战经验指出，虽然 LLM 能迅速产出大部分功能，但要降低错误、对抗幻觉并保持长期稳定需要 multi-agent 协同、external memory、context management、复杂评估框架和大量调用成本。部分评论批评某些实现把项目管理当成从头发明的难题（用 JSON 文件替代 issue tracker），并建议接入现有工具（如 plane/makeplane）与明确的工作流程。另有讨论围绕测试方法，建议用结构化格式（JSON）、BDD/Cucumber 等把验收标准写成可执行测试以提高可验证性。 📌 讨论焦点 隐藏复杂度与收益递减 多条评论指出，用 LLM 很快能拿到大部分价值（常被形容为约 70% ），但把系统推向生产、把错误率再压低需要成倍增加工程投入。接下来的 10–20% 通常涉及 multi-agent judge setups、多模型组合、external memory、context management 与复杂的评估框架，最终要把误差从约 10% 再降下去可能需数百个 agent 和大量调用。评论里有人具体提到这类 agentic workflows 可能演化为&quot;打地鼠”式修复失效情形的过程，单次运行成本能到数百美元却仍无法保证输出可靠性。结论是 LLM 擅长解析与分类非结构化输入，但对系统理解与健壮性工作不能简单外包给模型，否则会被其&quot;简化幻觉”所误导。 [来源1] [来源2] [来源3] [来源4] [来源5] QA agent 与测试策略的局限 有评论认为独立的 QA agent 听起来合理但在实际运行中常导致发散行为：dev agent 与 QA agent 往往在两种都不合适的选项间循环而无法收敛。相比之下，让开发 agent 自行做更智能的自检或在流程中加入可回滚/重置机制可能更可控，但回滚方案既低效又未必更好。有人提到可以尝试把验收标准写成可执行的测试（如使用 Cucumber 等 BDD 工具）来给 agent 更明确的判定准则，但总体上需要结构化的测试与明确的回退策略，而不是简单叠加另一个独立的 QA agent。 [来源1] [来源2] 不要重复发明项目跟踪器——用现成工具并规范流程 一组评论批评许多 agent 项目在工作流管理上从零开始，把 issue 跟踪做成一堆 JSON 和纯文本文件，从而重造轮子。建议把 MCP 或 agent 钩到真实的 issue tracker，或者采用已有开源工具（如 plane / makeplane）并把流程写入 Agents.md，明确 epics、tasks、personas、验收准则、分支及标签规范和在不同实现步骤前后的注释。实践建议是将 ticket 切得非常细，边做边新增和关联，并在变更前后添加说明，而不是从头发明一个&quot;agent-first”的跟踪系统，以避免不必要的复杂度。 [来源1] [来源2] [来源3] [来源4] 使用结构化格式可降低模型篡改与格式性错误 评论提到模型相比 Markdown 更不容易错误地修改或覆盖 JSON 文件，这暗示出使用结构化、可验证的输出格式可以减少模型造成的格式性损坏。结构化格式（如 JSON 或带 schema 的存储）便于自动校验、解析与回滚，适合长期运行且频繁读写状态的 agent 系统。因此在设计 agent 的状态持久化和交互协议时，优先考虑机器可解析与可验证的数据格式，而非自由文本以降低出错面。 [来源1] 📚 术语解释 agent / agentic workflow: 由 LLM 驱动的自治单元或工作流，负责执行子任务、决策和与其它 agent 协作；agentic workflow 描述多个 agent 之间的分工、通信与协调模式。 multi-agent judge setup: 一种用多个独立 agent 作为评审或仲裁层的架构，通过投票或交叉验证来判定输出正确性，但会显著增加交互复杂性和循环发散风险。 external memory: 外部记忆或持久化状态存储，用于扩展模型上下文窗口，保存长期信息或历史对话以补足模型内存，但需要同步、一致性与检索策略。 Pareto principle（帕累托原则）: 常称的 80/20 法则：在此语境下意指 LLM 能快速解决大部分工作，但剩余那小部分通常耗费不成比例的工程成本来做到足够健壮。 Cucumber（Behavior Driven Development）: 一个 BDD（行为驱动开发）工具，使用接近自然语言的场景描述来声明验收条件并映射为可执行测试，便于把期望行为写成可检验的规范。 类别： AI | Systems | Programming | Guide | Opinion | Anthropic | long-running agents | agents | LLM | multi-agent | Plane | JSON</p><p>【12】🤦 大厂好工程师也写烂码：激励、任期与技术债的博弈
原标题： 《Good engineers write bad code at big companies》 评分: 198 | 作者: gfysfm 💭 既要快速又要高质量，谁承担烂代码后果？ 🎯 讨论背景 这条讨论源自一篇主张&quot;大公司里好工程师也会写烂码”的文章（社区里也提到过《Pure and Impure Engineering》类似论点）。HN 评论基于在 FAANG、传统大公司与中小公司里的亲身经验，围绕管理激励、任期统计口径、招聘偏差、审查文化、交付压力与生成式 AI 等维度展开辩论。评论既有人把问题视为公司刻意为削弱劳动力议价能力而做出的效率-权力交换，也有人认为这是规模、复杂性和产品导向带来的自然结果。总体结论倾向于：问题是技术、组织与经济激励交织的复杂现象，改善需要度量、归责与制度性变更。 📌 讨论焦点 管理激励与短期结果导向 大量评论指出管理层以可量化结果为导向，无法或不愿评估维护性工作，因而奖励快速交付而非长期质量。维护工作对不熟悉代码的人不可见，缺乏度量导致维护被忽视，促成了&quot;写完提交、留地雷”的行为与晋升激励错配。评论里也给出具体做法：用可量化指标说明维护成本、在绩效里纳入长期质量，或让管理层参与写码以理解代价。 [来源1] [来源2] [来源3] [来源4] 员工可替代性与任期短导致知识流失 有人认为公司刻意把工程师设为可替代（fungible），以防止关键项目被少数人绑架、影响谈判或引发集体行动，因此宁可牺牲部分长期效率换取人力流动性。短任期统计部分由快速扩张拉低，但实质后果是制度化的知识流失和对长期维护责任的忽视。该视角把问题视作资本与劳动博弈的产物：企业愿为降低员工议价能力而付出低效成本。 [来源1] [来源2] [来源3] [来源4] 审查失焦与局部完美导致长期技术债 多个评论提到代码审查常聚焦语法、格式或局部风格，而忽略业务建模和整体架构，造成&quot;教科书式语法但思路错”的实现。典型例子包括早期把数据库 schema 固定下来导致后续改造成本飙升、审查者缺乏上下文而只做表面意见（bikeshedding）。建议包括让有上下文的同伴参与设计评审、改善需求与文档、拒绝合并会让系统更坏的补丁并逐步重构。 [来源1] [来源2] [来源3] [来源4] 交付期限与频繁变更压垮良好设计 许多评论把根本原因归到交付压力与不断变动的需求：管理层以截止日和短期指标为准，工程师被迫以折衷或快速 hack 达成目标。短期营收或增长策略（甚至通过产品推动/暗黑增长）优先于修复根本问题，技术债因此滚雪球式增长。讨论中的补救策略包括把技术债量化为业务成本、分段重构或在极端场景下重写并权衡代价。 [来源1] [来源2] [来源3] [来源4] 招聘与行业专业化不足 一些评论批评招聘过度偏好 LeetCode 风格的算法能力，导致团队缺乏沟通、系统设计与工程判断这一类&quot;工程品味”。另有评论指出软件工程缺乏像土木、电气那样的法定执业门槛和强制流程，出现权限滥用、PII 泄露等现实风险。也有人反驳说规模并非决定因素：好的工程文化和人才在不同规模公司都能存在，但招聘/激励会显著影响结果。 [来源1] [来源2] [来源3] [来源4] AI 放大了战术性、表面可运行的代码问题 多条评论警告生成式 AI 正在放大已有的糟糕实践：它能快速产出语法正确但未顾及整体设计的代码，使那些偏向&quot;敲代码”的开发者变得更危险并更易通过审查。AI 降低了验证与深思的门槛，扩大了大量&quot;表面可行”但长期有害的提交。也有观点认为 AI 只是把原本存在的问题放大了一个数量级，而非凭空制造新问题。 [来源1] [来源2] [来源3] [来源4] 并非普遍真理：团队差异与例外存在 也有不少反例：某些团队或个人在同一公司工作多年，维持高质量代码并深耕多个代码库；有家庭稳定期的工程师或被视为&quot;rock star”的长期员工，他们被赋予更多自主与资源。大公司其实是由许多小团队构成，文化、管理和激励在团队间差异巨大，因此问题更多是局部组织/激励失配而非规模必然。结论是需要有针对性的治理、招聘与绩效调整，而不是把责任完全归咎于&quot;公司太大”。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 技术债（tech debt）: 为追求短期交付或应对不确定需求而做的权衡或临时实现，长期会增加维护成本、降低变更速度并提高出错风险。 代码审查（code review）: 团队对代码变更的同行评审流程；若参与者缺乏上下文或只关注格式，会忽略架构与业务正确性，形成审查失焦。 委托-代理问题（principal–agent problem）: 上级（委托人）与执行者（代理人）之间激励不一致时，代理人倾向追逐短期或自利目标，导致长期价值被牺牲。 员工可替代性（fungibility）: 组织通过轮岗、短期任期或流程设计降低个体对系统的独占知识，从而弱化员工议价能力但削弱长期知识积累。 在职时长/任期（tenure）: 员工在同一团队或公司持续工作的平均时间，影响机构记忆、知识传承和&quot;bus factor”（关键人员风险）。 类别： Work | Programming | Business | Opinion | Sean Goedecke | bad code | big companies</p><p>【13】TrendRadar
🎯 告别信息过载，AI助你洞悉新闻热点——轻量级舆情监控分析系统。集成多平台热点聚合与MCP智能分析，覆盖35个平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。适配企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack推送，30秒网页部署，1分钟移动端通知，零编程基础。支持Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【14】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【15】ChinaTextbook
覆盖小学至大学全学段PDF教材资源库</p><p>【16】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器ID，免费升级使用Pro功能：解决试用请求上限/当前设备免费账户过多提示，我们设置此限制以防止滥用。若认为有误请告知</p><p>【17】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃node.js版本</p><p>【18】traefik
云原生应用代理</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/29 AI 日报 今日摘要 【1】AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @addyosmani 的博客，他的观点非常明确：AI 生成的代码应被视为&quot;初稿”，而非&quot;定... AI 生成的代码应被视为&quot;初稿”，而非&quot;定稿”！ 来自谷歌 Chrome 工程负责人 @a]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-28日刊]]></title>
          <link>/2025-11/2025-11-28/</link>
          <guid>/2025-11/2025-11-28/</guid>
          <pubDate>Fri, 28 Nov 2025 10:07:53 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/28</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌入引导路由和自适应聚类等...
GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌入引导路由和自适应聚类等创新，Github Copilot 的智能体能在保持强大功能的同时，显著提升速度和准确性。 核心理念：少即是多，智能体需精炼工具 GitHub Copilot Chat 依赖数百个工具（如代码库分析、Azure 服务调用）来辅助开发者完成任务，例如修复 bug 或合并代码。这些工具通过 MCP 访问，但问题在于：工具堆积过多会让智能体&quot;负担过重”，类似于大脑被无关信息淹没，导致推理变慢、错误率上升。基准测试（如 SWE-Lancer 和 SWEbench-Verified）显示，完整工具集下智能体的任务成功率反而下降 2-5 个百分点，因为模型容易误用工具或忽略关键指令。 解决方案的核心是&quot;用更少的工具变得更聪明”：不是简单裁剪功能，而是通过智能路由和分组，让智能体只在需要时调用相关工具。这就好比从杂乱的工具箱中抽屉化管理——先看目录，再取具体物品，避免盲目翻找。 技术实现：嵌入引导与动态选择 更新引入了两大关键机制，确保工具选择精准高效： · 嵌入引导工具路由（Embedding-Guided Tool Routing）：利用查询的向量嵌入与工具的语义表示进行匹配，预先筛选出最相关的工具候选。这比传统 LLM 逐一评估快得多。在基准测试中，该方法实现了 94.5% 的工具使用覆盖率，远高于 LLM 选择的 87.5% 或静态列表的 69.0%。例如，对于&quot;修复这个 bug 并合并到 dev 分支”的查询，系统会直接从嵌入空间中锁定&quot;合并工具”，跳过无关的搜索或文档工具，减少了探索性调用。 · 自适应工具聚类（Adaptive Tool Clustering）：基于 Copilot 内部嵌入模型，通过余弦相似度将相似工具自动分组，形成&quot;虚拟工具”——这些虚拟工具像目录一样，提供概述而非完整列表。聚类后，一个小型模型生成每个组的摘要，便于缓存和快速访问。博客展示了 GitHub MCP 工具的嵌入图示：如 create_pending_pull_request_review 与 get_issue_comments 等工具自然聚为一簇。 此外，GitHub 将默认的 40 个内置工具精简至 13 个核心工具（覆盖仓库解析、文件编辑、搜索和终端操作），其余非核心工具归入四个虚拟类别：Jupyter Notebook 工具、网络交互工具、VS Code 工作区工具和测试工具。这种&quot;无损动态选择”确保了功能完整性，同时将首 token 时间缩短 190 毫秒，最终响应延迟平均降低 400 毫秒。 益处：更快、更准的用户体验 · 性能跃升：在线 A/B 测试显示，任务成功率提升 2-5 个百分点，工具覆盖率提高 27.5%。智能体能更专注地推理，减少缓存未命中和 API 限额问题。 · 效率优化：操作成本降低（缓存嵌入和摘要更廉价），开发者感受到更流畅的交互——无需等待&quot;加载中”转圈。 · 实际示例：在处理复杂查询时，系统能从历史上下文推断意图，避免逐一检查工具组，提升了整体可靠性。 未来展望：向长上下文智能体演进 将工具选择视为&quot;长上下文推理”的雏形：未来，智能体将记住工具使用历史、从对话中推断意图，并规划多步行动，甚至跨会话协作。结合嵌入、记忆机制和强化学习，Copilot 可能扩展到数千轮交互，支持动态学习工具使用。 这个更新体现了 AI 开发工具的演进趋势：从&quot;全能”向&quot;专注”转型，GitHub 通过数据驱动的优化证明，精简并非妥协，而是通往更强大智能的捷径。 博客地址： <a href="https://github.blog/ai-and-ml/github-copilot/how-were-making-github-copilot-smarter-with-fewer-tools/">https://github.blog/ai-and-ml/github-copilot/how-were-making-github-copilot-smarter-with-fewer-tools/</a> [图片: <a href="https://pbs.twimg.com/media/G6zcofSa0AAebo1?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zcofSa0AAebo1?format=jpg&#x26;name=orig]</a> GitHub: Giving an agent too many tools doesn’t always make it smarter. Sometimes it just makes it slower. 🐢 So we trimmed GitHub Copilot&#39;s default toolset from 40 down to 13. The result? ⚡️ 400ms faster responses 📈 2-5% higher success rates Here&#39;s how we optimized the system. ⬇️</p><p>【2】Deepseek发布了模型DeepSeekMath-V2 在IMO-ProofBench和竞赛（如IMO 2025的5/6问题）以及Putnam 2024（接近完美的118/120分）中表现出色。拥有国际数学奥林匹克...
Deepseek发布了模型DeepSeekMath-V2 在IMO-ProofBench和竞赛（如IMO 2025的5/6问题）以及Putnam 2024（接近完美的118/120分）中表现出色。拥有国际数学奥林匹克竞赛（IMO）2025金牌水平 Github开源链接：<a href="https://github.com/deepseek-ai/DeepSeek-Math-V2">https://github.com/deepseek-ai/DeepSeek-Math-V2</a> 该模型也在 @huggingface 上以 Apache 2.0 开源协议发布！ 也可以从HF下载：<a href="https://huggingface.co/deepseek-ai/DeepSeek-Math-V2">https://huggingface.co/deepseek-ai/DeepSeek-Math-V2</a> [图片: <a href="https://pbs.twimg.com/media/G6zaiaWa0AA3ucJ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zaiaWa0AA3ucJ?format=jpg&#x26;name=orig]</a></p><p>【3】太真实了！ Nalin 吐槽 LinkedIn 上没有一个真正在招人的工作。 这个月重新开始找工作的感受也是，Boss 直聘、猎聘、脉脉上的职位，也是尝试联系后完全没有回应...
太真实了！ Nalin 吐槽 LinkedIn 上没有一个真正在招人的工作。 这个月重新开始找工作的感受也是，Boss 直聘、猎聘、脉脉上的职位，也是尝试联系后完全没有回应的 😂 当然这里一方面是我自己竞争力不够的问题，不过也有一些客观现象： 1. 发消息后一直都是未读状态，说明大概率职位是没有招聘方/猎头等在关注的 2. 招聘平台互动很低，所以开始做主动职位推送，以招聘方的语气发职位邀请，匹配度很低；偶尔遇到合适的，又回到 1 的状态 3. 中国国内招聘平台，有些是按职位数量收费的，所以即使职位不要了，也不想下架，不然又要新付费上架职位 在这之外，就是另一个问题： 有些职位，挂出来是比较明显的套方案，或者看竞对薪资的，要么对项目细节问的很多，但不问你个人信息；要么对薪资构成问的很细，但其他基本不咋问。 Nalin: Unpopular Opinion: None of the jobs on LinkedIn are actually hiring. [图片: <a href="https://pbs.twimg.com/media/G6rEOHMagAAeCqN?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6rEOHMagAAeCqN?format=jpg&#x26;name=orig]</a></p><p>【4】NVIDIA 官方回应：祝贺 Google AI 进步，同时强调自身领先地位 Google 在 AI 领域的快速推进（尤其 Gemini 3 模型和 TPU 芯片优化），引发市场对 NVIDIA 主导地...
NVIDIA 官方回应：祝贺 Google AI 进步，同时强调自身领先地位 Google 在 AI 领域的快速推进（尤其 Gemini 3 模型和 TPU 芯片优化），引发市场对 NVIDIA 主导地位的讨论。NVIDIA 以积极却自信的口吻回应，表面上赞扬对手，实则重申其 GPU 平台的无可匹敌优势。 对 Google 的致敬：NVIDIA 开篇表达&quot;欣喜”（delighted），认可 Google 在 AI 上的&quot;巨大进步”（great advances），并强调双方持续合作—— NVIDIA 仍为 Google 供应硬件。这显示出 NVIDIA 的战略成熟：不搞零和对抗，而是定位为生态伙伴，避免被视为&quot;垄断者”。 NVIDIA 的核心优势：核心是宣示 &quot;NVIDIA 领先行业整整一代”（a generation ahead）。其 GPU 平台是唯一能&quot;运行所有 AI 模型，并在所有计算环境中部署”（runs every AI model and does it everywhere computing is done）的解决方案。相比之下，ASIC（专用集成电路，如 Google 的 TPU）虽针对特定 AI 框架或任务优化，但缺乏通用性。 性能对比：NVIDIA 突出其产品在&quot;性能”（performance）、&quot;多功能性”（versatility）和&quot;可互换性”（fungibility）上的全面领先。ASIC 虽高效，但&quot;专为特定用途设计”，易受模型迭代或框架变化影响，导致灵活性不足。这在 AI 训练/推理场景中至关重要，尤其当下模型多样化（如从 Transformer 到多模态）。 看完后的感受：GPU 是更通用的架构，对规模、用途的应用更广，个人也能用、超级大厂集群也能用；TPU 是 Google 专门做过系统和架构、工具链优化的，对大规模集群的性能优化更好，不过小量用户用不起来，像 Deepmind 和 Anthropic 这种体量才能体现优势。 所以感觉 GPU 和 TPU 不是直接的硬件销售竞争，TPU 会以 Google Cloud 对外提供，云端算力的竞争。 [图片: <a href="https://pbs.twimg.com/media/G6zW6kIbwAA1jGS?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zW6kIbwAA1jGS?format=jpg&#x26;name=orig]</a> NVIDIA Newsroom: We’re delighted by Google’s success — they’ve made great advances in AI and we continue to supply to Google. NVIDIA is a generation ahead of the industry — it’s the only platform that runs every AI model and does it everywhere computing is done. NVIDIA offers greater</p><p>【5】感谢立青精心制作的分享！！ 还有好多细节需要优化，下一步会先把X登陆后自动提取推文生成文风先处理了！ Copilot现在是一步到位的 但我更希望它能成为一个内容...
感谢立青精心制作的分享！！ 还有好多细节需要优化，下一步会先把X登陆后自动提取推文生成文风先处理了！ Copilot现在是一步到位的 但我更希望它能成为一个内容老师去启发创作，而不是直接改写成没有人格的冰冷ai文字 继续优化💪 吕立青_JimmyLv (闭关ing) 2𐃏25: 🔥 百万流量密码？分享我的自媒体工作流 自动化发推 + 自研 AI 搜索插件，打造推特第二大脑 昨晚开箱体验了一下 @Yangyixxxx 老师在做的 xAIcreator 效果不错，非常看好 AI 写作+多账号同步这个方向 之前我还加入了产品围观群，不到两个月产品上线 大家快来体验一波～ <a href="https://xaicreator.com/i/JIMMYLV">https://xaicreator.com/i/JIMMYLV</a> [视频: <a href="https://video.twimg.com/amplify_video/1994085649989947393/vid/avc1/3840x2160/n-wA3PuGMrpaL_OL.mp4?tag=21%5D">https://video.twimg.com/amplify_video/1994085649989947393/vid/avc1/3840x2160/n-wA3PuGMrpaL_OL.mp4?tag=21]</a></p><p>【6】为什么资深工程师在构建 AI 智能体时会遇到困难？ @_philschmid 分享了一个有趣的悖论：为什么经验丰富的资深工程师在开发 AI 智能体时，往往比初级工程师更慢、...
为什么资深工程师在构建 AI 智能体时会遇到困难？ @_philschmid 分享了一个有趣的悖论：为什么经验丰富的资深工程师在开发 AI 智能体时，往往比初级工程师更慢、更难取得进展？Schmid 认为，根源在于传统软件工程强调确定性和消除歧义，而智能体工程本质上是概率性的，需要工程师学会&quot;信任” LLM 来处理非线性流程和自然语言输入。他通过五个关键挑战，剖析了这种思维转变的难点，并提供实用洞见，帮助工程师适应这一范式。 主要观点：从确定性到概率性的范式转变 传统软件开发追求可预测性：输入固定、输出确定、错误通过异常处理隔离。相比之下，智能体依赖 LLM 作为&quot;大脑”，通过自然语言驱动决策，允许多轮交互、分支和自适应。但资深工程师的本能是&quot;编码消除不确定性”，这反而阻碍了智能体的潜力。Schmid 指出，初级工程师往往更直观地拥抱这种不确定性，能更快推出可工作的原型，而资深者需克服多年养成的习惯。 五个核心挑战 列出五个传统工程习惯与智能体开发的冲突点，每个挑战都配以解释和示例，强调如何转向更灵活的方法。 1. 文本即状态（Text is the New State） 传统系统使用结构化数据（如布尔值 is_approved: true/false）来表示状态，确保离散性和可预测性。但现实意图往往藏在自然语言的细微差别中，例如用户反馈&quot;This plan looks good, but please focus on the US market”（这个计划不错，但请聚焦美国市场）。如果强制转换为二元结构，就会丢失这些 nuance（细微差别），导致智能体无法动态响应。 洞见：保留原始文本作为状态，让 LLM 在上下文中解读。例如，存储用户偏好&quot;I prefer Celsius for weather, but use Fahrenheit for cooking”（天气用摄氏度，烹饪用华氏度），而非简单布尔值。这要求工程师从&quot;结构化优先”转向&quot;语义灵活”。 2. 交出控制权（Hand over Control） 传统架构如微服务依赖固定路由和 API 端点来控制流程。但智能体只有一个自然语言入口，由 LLM 根据工具和上下文决定下一步——可能循环、回溯或转向。例如，一个&quot;取消订阅”意图可能通过谈判转为&quot;提供折扣以挽留”。硬编码这些流程会扼杀智能体的适应性。 洞见：信任 LLM 处理控制流，利用其对完整上下文的理解。工程师应设计支持这种&quot;非线性导航”的系统，而不是预设所有分支。 3. 错误只是输入（Errors are just inputs） 在传统代码中，错误（如缺失变量）会触发异常，导致崩溃或重试。但智能体每次执行都消耗时间和成本，无法承受全盘失败。作者强调，错误应被视为新输入，反馈给智能体以实现自愈。 洞见：构建弹性机制，将错误循环回 LLM 进行恢复，而不是隔离处理。这体现了概率性思维：失败不是终点，而是迭代机会。 4. 从单元测试到评估（From Unit Tests to Evals） 单元测试依赖二元断言（pass/fail），适合确定性输出。但智能体的输出是概率性的，例如&quot;总结这封邮件”可能产生无数有效变体。模拟 LLM 的测试也仅验证实现细节，而非整体行为。 洞见：转向&quot;评估”（evals），包括可靠性（成功率，如45/50次通过）、质量（用 LLM 作为评判者打分帮助性和准确性）和追踪（检查中间步骤，如是否查询知识库）。目标不是100%确定，而是高置信度的概率成功。 5. 智能体在演化，API 不会（Agents Evolve, APIs Don&#39;t） API 设计时假设人类用户能推断上下文，但智能体是&quot;字面主义者”——如果 get_user(id) 中的&quot;email”被误解为 UUID，它可能幻觉出错误响应。API 的歧义会放大 LLM 的局限。 洞见：设计&quot;傻瓜式” API，使用详细语义类型（如 delete_item_by_uuid(uuid: str)）和文档字符串。智能体能即时适应 API 变化，这比传统代码更灵活。 解决方案与启示 Schmid 不主张完全抛弃工程原则，而是寻求&quot;信任，但验证”（trust, but verify）的平衡：通过评估和追踪管理概率性，构建弹性系统。同时，认识到智能体并非万能——简单线性任务更适合工作流，而非智能体。示例包括保留用户反馈的文本状态、让错误驱动恢复循环，以及用评估量化智能体性能（例如，成功率 90%，质量分 4.5/5）。 博客地址： <a href="https://www.philschmid.de/why-engineers-struggle-building-agents">https://www.philschmid.de/why-engineers-struggle-building-agents</a> [图片: <a href="https://pbs.twimg.com/media/G6zVDHca0AEcBGG?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6zVDHca0AEcBGG?format=jpg&#x26;name=orig]</a> Philipp Schmid: New blog: Why (Senior) Engineers Struggle to Build AI Agents ❗ For the past few decades, Engineering meant one thing: removing ambiguity. Agent Engineering is about managing risks. It turns out going from deterministic systems → probabilistic agents is difficult. To succeed, [图片: <a href="https://pbs.twimg.com/media/G6se658XEAcsXpR?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6se658XEAcsXpR?format=jpg&#x26;name=orig]</a></p><p>【7】TrendRadar
🎯 告别信息过载，AI助你解读新闻热点——轻量级舆情监控分析系统。集成多平台热点聚合与MCP架构AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack多通道推送，30秒网页部署，1分钟移动端配置，零编程基础。提供Docker部署方案⭐ 让算法赋能信息获取，用AI洞悉热点脉络</p><p>【8】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【9】ChinaTextbook
覆盖小学至大学全学段PDF教材资源</p><p>【10】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器标识，免费升级使用专业功能：当出现「试用请求已达上限」/「本机使用过多免费试用账户」提示时，可绕过限制升级至专业版。该限制旨在防止滥用，若认为存在误判请联系我们</p><p>【11】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃的Node.js版本</p><p>【12】traefik
云原生应用代理网关</p><p>【13】学术圈炸了！ICLR评审大开盒，原来低分是好友打的
真正的 open review，「众神之父赐予我视野！」 昨晚不知有多少人彻夜未眠。 北京时间 11 月 27 日晚，国内 AI 社区全数炸锅。在学术论文审稿最常用的 OpenReview 平台上，一个前端 bug 导致数据库泄露，让原本的双盲评审变成了明牌。 这次的信息泄露方法简单到了极致： 只要在浏览器上输入某个网址，自行替换你要看的 paper ID 和审稿人编号，你就可以找到对应的任何审稿人的身份。 你可以知道是谁给你审的论文，知道他 / 她给你打了多少分。 因为没有操作门槛，在传播开来之后，所有人都瞬间切换到了调查模式，毕竟这年头谁还和审稿人没点摩擦，终于可以「有冤报冤，有仇报仇」了。 这一下子，就造就了无数惊喜、惊吓，愤怒与哀嚎。微信群里，小红书上，到处都是受害者在讲故事，有开人的也有被开的。你永远猜不到给你的论文打低分的是谁。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/c339aea7-7066-47c3-a8c2-2e65d29fbb15/640.png%5D">https://image.jiqizhixin.com/uploads/editor/c339aea7-7066-47c3-a8c2-2e65d29fbb15/640.png]</a> 审稿人打低分的理由各不相同，有的是没能理解作者原意，有的是个人恩怨（比如组里兄弟互相打低分），更加可恶的是给低分从而给自己正在写的同赛道论文「让路」。有人就利用这次泄露事件实锤了自己曾经被打 1 分的论文，审稿人竟然在五个月后提交了另一篇论文，又不愿意 cite 作者的投稿。 很快社交媒体上就又有爆料，一些疑似恶意打低分的审稿人，在被全员开盒之后紧急大幅提高了对论文的打分。 吃瓜群众们表示，这一开盒终于把早已经愈演愈烈的 AI 顶会论文审稿矛盾推向了新的高潮。drama 到了新高度，从黑暗森林到了广播纪元。 永远不要以为自己在互联网上真的能匿名。 很快人们就发现，OpenReview 的这个漏洞是系统级的，只要替换网址里面的另一段字符，你就可以同样打开视野看其他年度的 ICLR 论文，以及 NeurIPS、ICML、ACL 等一众 AI 顶会。 众所周知，由于 AI 领域的火热，投稿的暴增，所以各家大会都面临着审稿人不足的问题，人们对于审稿水平的降低时有抱怨。在 ICLR 2026 上，已经有 Pangram Labs 做过数据分析，认为约 21% 的 ICLR 同行评审完全由人工智能生成，超过一半的评审都带有人工智能使用的痕迹。 当然另一方面，也有 199 篇论文被发现完全由 AI 生成，9% 的论文中超过 50% 的文本是由 AI 生成的。 作为 AI 领域的三大顶会之一，ICLR 近年来在学界、业界关注度持续提升，2026 的大会即将在明年四月于巴西里约热内卢举行。本届大会获得了 19490 篇研究论文投稿，与此同时有 75800 篇同行评审意见。 在大概周五零点，bug 被紧急修复，ICLR 终于发布了官方声明。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/b70c59b8-b057-4321-815b-700bf6b9f77c/640.png%5D">https://image.jiqizhixin.com/uploads/editor/b70c59b8-b057-4321-815b-700bf6b9f77c/640.png]</a> ICLR 表示任何使用、暴露或分享泄露信息的人都会被拒稿且常年被 ICLR 禁入，大会方未来还计划采取进一步的行动。 随后，OpenReview 也给出了官方公告。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/98d8fa20-f9b8-4447-9838-2feaf0d07f6e/640.png%5D">https://image.jiqizhixin.com/uploads/editor/98d8fa20-f9b8-4447-9838-2feaf0d07f6e/640.png]</a> 不过这似乎并没有阻止部分人吃瓜的热情。似乎有人爬走了整份名单，还搞起了数据分析。有的人评选出了打分异常低的审稿人的名单。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/b57ff8c8-a9e5-4048-a44d-64d533575d7d/640.png%5D">https://image.jiqizhixin.com/uploads/editor/b57ff8c8-a9e5-4048-a44d-64d533575d7d/640.png]</a> 有人基于 ICLR 2026 前 1 万篇投稿的评审结果，结合审稿人的国别（主要语言）给出了平均打分习惯。看起来国人普遍比较慷慨，韩国人相对比较严格。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/600f72d1-8fcd-4b7d-8084-ada289afc81e/640.png%5D">https://image.jiqizhixin.com/uploads/editor/600f72d1-8fcd-4b7d-8084-ada289afc81e/640.png]</a> 按照这种速度，可能过不了多久，我们就能知道今年 8 月 NeurIPS 写下「 Who&#39;s Adam？ 」审稿意见的人是谁了。 学界、业界的大佬们也纷纷跟进这次事件，进行了点评。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/8e9887f9-36d1-4741-9bac-9093e077000f/640.png%5D">https://image.jiqizhixin.com/uploads/editor/8e9887f9-36d1-4741-9bac-9093e077000f/640.png]</a> [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/8597b955-2a3f-44dd-a71e-fb7774578d9d/640.png%5D">https://image.jiqizhixin.com/uploads/editor/8597b955-2a3f-44dd-a71e-fb7774578d9d/640.png]</a> 加州理工学院计算机与数学科学教授，ICLR 理事会成员，ICLR 2025 的主席 Yisong Yue 表示，咱们现在要开个会，我已经麻了。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/67f93b16-4f4b-4a50-90f7-623c49325332/640.png%5D">https://image.jiqizhixin.com/uploads/editor/67f93b16-4f4b-4a50-90f7-623c49325332/640.png]</a> 总的来看，此次 ICLR 泄密事件严重损害了学术公平。审稿人匿名的丧失阻碍了人们对研究的批判性输出，让作者获得了额外反击的可能，从而破坏了原有的平衡。这就让接收论文的可信度受到了影响。不过另一方面，由于原本完全匿名的审稿时而出现恶意、不负责任的评论，此次泄露事件瞬间激起的热度也值得人们思考。 不知在此之后，匿名的审稿制度是否会有所改变？ ]]&gt;</p><p>【14】大模型作为评估者的「偏好」困境：UDA实现无监督去偏对齐
[图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/156a67a9-0830-4023-a21f-35e83bf5d791/640.png%5D">https://image.jiqizhixin.com/uploads/editor/156a67a9-0830-4023-a21f-35e83bf5d791/640.png]</a> 在 LLM 评估体系日益依赖 &quot;大模型担任评估者&quot;（LLM-as-a-Judge）的今天，一个隐秘且严重的问题正在扭曲大模型的评估生态：偏好偏差。 即使是性能强劲的 GPT-4o 和 DeepSeek-V3，在进行成对答案比较时，也会系统性地偏爱特定输出 —— 尤其是自己生成的内容。这种偏差导致不同裁判模型给出的评分和排名天差地别。论文中的实验数据显示，在 ArenaHard 数据集上，自我偏好偏差幅度从 - 38% 到 + 90% 不等。当模型既是 &quot;运动员&quot; 又是 &quot;裁判&quot; 时，公平性无从谈起。 现有解决方案依赖提示工程、模型集成或博弈论重排等，但这些方法要么缺乏理论支撑，要么成本爆炸，要么难以扩展。更重要的是，它们都依赖人工设计的规则，没有办法让大模型输出统一的结果。 UDA 的出现，为破解这一困局提供了新思路。来自智谱 AI 的研究团队将无监督学习引入成对 LLM 评判体系，让模型能够自主动态调整评分规则，实现去偏对齐。 该论文已被 AAAI 2026 录用。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/c48b92a9-4661-4a03-a0c9-1e55ce642055/640.png%5D">https://image.jiqizhixin.com/uploads/editor/c48b92a9-4661-4a03-a0c9-1e55ce642055/640.png]</a> 论文标题：UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge 论文链接：<a href="https://arxiv.org/pdf/2508.09724">https://arxiv.org/pdf/2508.09724</a> 代码仓库：<a href="https://github.com/zhang360428/UDA_Debias">https://github.com/zhang360428/UDA_Debias</a> 评判偏差：大模型担任评估者的 &quot;偏好之困&quot; 现有的 LLM 评判系统（如 Chatbot Arena）普遍采用 Elo 评分机制，但面临着三类挑战： 自我偏好固化 ：模型系统性高估自己生成的答案，导致 &quot;谁当裁判谁占优&quot; 的荒谬局面； 异质性偏差 ：不同模型的偏差方向与强度各异，从激进自夸到过度谦逊不一而足； 静态评分缺陷 ：传统 Elo 使用固定 K 因子，无法区分关键对决与平庸比较，小样本下信噪比极低。 结果就是 &quot;评分失准&quot;、&quot;排名震荡&quot; 频发：如下图所示，在未经优化前，10 个主流 LLM 裁判对同一组答案给出的 Elo 分数标准差最高能达到 158.5 分，评分轨迹如脱缰野马般离散。而经过 UDA 对齐后，各裁判轨迹显著收敛，共识稳定度提升近 60%。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/99283d0a-5bf8-4c84-b13b-8134fc6b5cb2/640.png%5D">https://image.jiqizhixin.com/uploads/editor/99283d0a-5bf8-4c84-b13b-8134fc6b5cb2/640.png]</a> UDA 的核心贡献在于将去偏问题转化为一个可通过动态校准优化的序列学习问题。与以往依赖人工规则或监督信号的方法不同，UDA 让评判者在处理每对比较时自主探索最优的评分策略，并通过共识最小化目标直接获得反馈。这种无监督的优化方式使模型能够学习到较为公平的对齐机制。 [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/600624c1-4466-4de6-8b79-3cae6bb0356a/640.png%5D">https://image.jiqizhixin.com/uploads/editor/600624c1-4466-4de6-8b79-3cae6bb0356a/640.png]</a> 方法框架 如图所示，UDA 将成对评估建模为 实例级自适应过程 。对每个裁判模型 k，当比较答案对 (ai, aj) 时，系统提取多重特征，通过轻量级网络动态生成调整参数，最终输出校准后的 Elo 更新。训练过程中通过 共识锚定 目标获得反馈。被训练的适配器 (🔥) 专注学习去偏策略，固定的 Elo 系统 (❄️) 负责基础评分。 特征工程与自适应网络 UDA 的精髓在于 人类标注无关的特征构建 。对每对比较，系统提取基于语义的特征向量 φ(k) ij，涵盖： 高维特征 ：答案嵌入间的 element-wise 差值、归一化积，捕捉语义风格差异 标量特征 ：余弦相似度、KL 散度、长度差异，量化分布距离 自我感知特征 ：裁判自身答案与候选答案的相似度，作为偏差预警信号 这些特征无需任何人工标注，完全从响应分布中自动构建。 一个三层 MLP 网络 fθ 随后将特征映射到自适应参数： 实例级 K 因子 Kij ：动态调整每轮比较的权重，可疑对决自动降权 软标签 (si, sj) ：替代硬判决，缓解偏好噪声，实现平滑更新 共识锚定：无监督对齐的基石 UDA 的核心创新是 无监督的共识驱动训练 。在缺乏 &quot;黄金标准&quot; 的困境下，UDA 将所有裁判的集体共识视为一个现实可用的优化目标 。虽然共识并非完美真值，但实证表明，异质性偏差在聚合时倾向于相互抵消。 训练目标巧妙设计为多任务损失： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/f548c287-de40-4374-bce1-363c23250b3d/640.png%5D">https://image.jiqizhixin.com/uploads/editor/f548c287-de40-4374-bce1-363c23250b3d/640.png]</a> 三项分别驱动：(i) 各裁判轨迹向共识收敛，(ii) 保持排名相关性，(iii) 强化集体一致性。最终，UDA 不追求复制共识，而是 以共识为锚，压制极端个体偏 好。 理论动机：为什么共识对齐能减少偏差？ UDA 的核心理论洞见是： 对齐多样化裁判的共识，将降低系统总偏差。 证明：设 Ri 为模型 i 的真实 Elo 分数，ε(k) i 为裁判 k 的偏差项。在线性收缩模型下（实际情况当然会比该假设复杂，但这种趋势是相同的），UDA 对齐后的预期总绝对偏差不超过基线： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/40409365-f336-41ed-b85e-958f58872454/640.png%5D">https://image.jiqizhixin.com/uploads/editor/40409365-f336-41ed-b85e-958f58872454/640.png]</a> 证明思路：对齐过程可视为向平均偏差的凸组合收缩，通过三角不等式和 Jensen 不等式即可得证。虽然个别校准良好的裁判可能轻微牺牲精度，但 集体方差缩减主导了个体成本 。 这一理论为无监督对齐提供了动机：即使共识本身有噪声，减少离散度仍能提升整体可信度。 实验结果 UDA 在 ArenaHard（500 问题，10 大模型，45 万对比较）上训练，在 零样本迁移 中展现了非常好的效果： 主实验 训练集与测试集上不同大模型评估的方差： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/89746980-708e-4eac-bab9-2ef8fac77176/640.png%5D">https://image.jiqizhixin.com/uploads/editor/89746980-708e-4eac-bab9-2ef8fac77176/640.png]</a> 测试集上评估结果与人类评估的相关性系数： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/5b56d2a3-3942-4b2d-8cf0-ecd45389816b/640.png%5D">https://image.jiqizhixin.com/uploads/editor/5b56d2a3-3942-4b2d-8cf0-ecd45389816b/640.png]</a> 四大核心发现： 1. 跨模型方差锐减 ：UDA 将平均裁判间标准差从 158.5 降至 64.8（↓59%），最激进的 gemini-2.0-flash 偏差从 341.9 压缩至 128.8，证明对极端偏差的强效抑制。 2. 人类对齐跃升 ：在人工标注迁移集上，UDA 将平均 Pearson 相关性从 0.651 提升至 0.812（+24.7%），将弱裁判（如 glm-4-flash）提升至与顶尖行列大模型（deepseek-r1）相当水平，实现 评估民主化 。 3. 零样本迁移稳健 ：在未见过的新的迁移数据集上，UDA 未经重新训练仍实现 63.4% 的方差缩减，证明 领域无关的去偏能力 。 4. 自我感知特征的决定性 ：消融实验显示，移除大模型自身回答相关特征后，虽然方差进一步降至 65.64，但人类相关性暴跌至 0.510。这可能是因为缺乏自我意识的模型会盲目收敛，却是却偏离人类真值。 消融研究：自我感知特征的关键作用 为验证所选特征的必要性，该研究团队训练了 UDA（Ablated）变体，剔除所有与裁判自身答案相关的特征： [图片: 图片 <a href="https://image.jiqizhixin.com/uploads/editor/3a47f01f-efff-41ab-b510-1dd8598d8ff6/640.png%5D">https://image.jiqizhixin.com/uploads/editor/3a47f01f-efff-41ab-b510-1dd8598d8ff6/640.png]</a> 实验结果显示：剔除自我感知相关特征后，模型过度优化共识一致性，牺牲了人类对齐。自我感知特征如同 &quot;偏差镜子&quot;，让裁判能识别并折扣自身偏好，从而引导集体判断朝向客观真值。 总结 UDA 让我们看到一个重要趋势： &quot;评判校准不再是提示工程问题，而是可以被学习的问题。&quot; 通过无监督共识信号，模型不再依赖人工撰写的去偏提示，而是在交互中自主演化出公平评分策略。 这项研究针对现有评估中不同 LLM 评委存在的系统性自偏好偏差以及评分不一致问题，通过轻量级神经网络动态调整 Elo 评分系统的 K 因子与胜负概率，实现实例级别的去偏矫正正。其核心思想是将所有评委评分的集体共识作为无监督优化目标，通过最小化各评委 Elo 轨迹的离散度来抑制极端个性偏差，同时利用评委自身回答的语义等特征检测自偏好倾向。该框架有效提升了低质量评委的表现，使其接近高质量评委水平，显著增强了评估的鲁棒性、可复现性与人类对齐度。 ]]&gt;</p><p>【15】2000万撬动2亿估值：杭州反舌鸟要让AI帮玩家&quot;一键造梦”
没有美术、不会代码，也能在手机上 10 分钟做出一款游戏？杭州反舌鸟科技把AIGC塞进UGC平台，先拿 1000 万海外用户当答案，再伸手向资本市场要了 2000 万元A轮融资——估值直接冲到 2 亿元。领投的是两家上市公司：美股联掌门户、A股电魂网络；跟投名单里杭州本土基金一字排开，显然想押一张&quot;α世代的索尼”船票。 这家公司把自研AIGC Agent训练成&quot;全能策划”：写剧情、生原画、吐代码、调数值一条龙，平均把开发周期砍到原来的1/5。用户只需用自然语言描述&quot;我想让兔子在月球打高尔夫”，系统便自动生成关卡、角色、物理参数，甚至顺手配上商店页素材。平台上线 8 个月，北美、东南亚、欧洲三地月活已破 1000 万；内部模型预测， 2025 年整体月活将飙至 8500 万，日活 550 万。 收入结构早已跳出&quot;卖皮肤”老套路：游戏内购、广告分成、IP授权、娱乐硬件四条线并行。去年一款用户自制的&quot;赛博麻将”被Netflix相中，动画改编权卖出百万美元，让资本看见UGC的指数级溢价空间。本轮募得资金将全部砸向三件事——升级AI工具链、批量孵化精品游戏、把原创IP推向全球流媒体与主机平台；同时并购小型工作室，快速收拢人才与内容。 全球游戏盘子 2024 年预计 3724 亿美元，AIGC+UGC被多家券商列为&quot;核心增量”。反舌鸟科技抢先卡位，目标是用AI把&quot;人人都是开发者”从口号变成现金流，在下一轮娱乐革命里长出中国独角兽。</p><p>【16】OpenAI 警告：Mixpanel 遭攻击，部分用户数据或已泄露
近日，OpenAI 发布公告称，其所使用的第三方网络分析服务提供商 Mixpanel 遭到网络攻击，部分 API 用户数据可能已被泄露。OpenAI 在声明中表示，Mixpanel 的服务主要用于其前端界面的数据分析，但在收到 Mixpanel 的通知后，OpenAI 已立即停止使用该服务。 根据 OpenAI 的说明，此次安全事件并未对其自身系统造成损害，因此使用 ChatGPT 及其他产品的用户并不受影响。然而，Mixpanel 的黑客攻击可能导致一些 OpenAI 用户的账户信息泄露。这些信息包括账户名称、关联电子邮箱、大致的位置信息、访问所用的操作系统与浏览器、推荐网站以及相关组织或用户 ID。 值得注意的是，泄露的数据中并不包括聊天记录、API 请求、API 使用数据、密码、凭证、API 密钥、支付信息或政府颁发的身份信息。OpenAI 强调，他们正在全力以赴确保用户数据的安全，并会持续监控情况以防止类似事件再次发生。 划重点： 🛡️ OpenAI 确认 Mixpanel 遭攻击，部分 API 用户数据可能泄露。 🔍 攻击未影响 OpenAI 自身系统，ChatGPT 等产品用户未受损。 🔑 泄露信息不包括聊天记录、密码及支付信息等敏感数据。</p><p>【17】​研究显示：AI 到 2035 年或将取代英国 300 万个低技能岗位
根据英国国家教育研究基金会 最新 发布的一份报告，预计到2035年，人工智能（AI）和自动化技术可能使英国300万个 &quot;低技能” 岗位消失。这项研究指出，受影响最严重的职业包括技术工人、机械操作员及各类行政职位。与此同时，AI 的发展也将导致对高技能专业人才的需求增加。 [图片: 机器人上班打字1 [object Object]<a href="https://pic.chinaz.com/picmap/202306261422268372_8.jpg%5D">https://pic.chinaz.com/picmap/202306261422268372_8.jpg]</a> 图源备注：图片由AI生成，图片授权服务商Midjourney 报告显示，尽管 AI 带来的冲击将使低技能职位减少，整体而言，预计到2035年，英国经济仍会净增230万个岗位。然而，新增岗位的分布将非常不均衡。部分研究认为，AI 对高技能岗位的影响可能比对低技能岗位更为显著，而这一观点与当前的普遍看法形成鲜明对比。伦敦国王学院的研究指出，许多高薪行业在经历了裁员，尤其是在 ChatGPT 发布之后。 值得注意的是，英国政府也认为管理顾问、心理学家和法律从业者等职业更容易受到 AI 的影响，而运动员、屋顶工人和砖匠等职业则被认为不太容易被取代。实际上，许多企业已经开始感受到 AI 对人力资源结构的影响。例如，伦敦知名律所高伟绅宣布裁减约10% 的业务服务岗位，部分原因归结为 AI 技术的崛起。普华永道的负责人也表示，AI 的出现改变了企业对人才的需求，因而撤回了大规模扩招的计划。 划重点: - 🤖 AI 预计到2035年将取代英国300万个低技能岗位。 - 📈 高技能岗位需求增加，经济预计净增230万个岗位，但分布不均。 - 🏢 多家企业因 AI 技术调整人力资源结构，裁员现象开始显现。</p><p>【18】♨️ 芬兰 250MWh&quot;沙电池”开建：为北欧冬季供热与可再生富余调峰
原标题： 《250MWh &#39;Sand Battery&#39; to start construction in Finland》 评分: 29 | 作者: doener 💭 把沙子当电池就环保了吗？输热损耗谁来算？ 🎯 讨论背景 新闻报道指出芬兰将建设一座约 250 MWh 的沙电池（sand battery），用于为 V ääksy 镇的集中供热网络提供多日级热量缓冲，项目方与评论引用资料估计能显著降低天然气和木片锅炉的使用及化石排放。讨论背景是北欧高纬度冬季日照短且偶发高压冷静会同时缺乏太阳和风，传统水电虽资源丰富但发电或蓄能空间有限且受岸权与结冰影响。评论围绕谁来&quot;充电”（可再生富余电力、焚烧厂等）、热储的几何保温优势、以及把大型集中储热放在远端导致的长距离输热损耗做了权衡。总体语境是把热能储存作为补充手段，与水力、核能、地热和跨国电力调配共同应对冬季供能挑战。 📌 讨论焦点 北欧冬季的多日缺光缺风与储能需求 北欧高纬度冬季日照极短（评论提到类似安克雷奇纬度、某日不足 7 小时）且极夜与高压冷空气易导致连续多日既无太阳又无风的发电缺口。多条评论认为这种情形并非全年常态，但在出现&quot;冷静无风”窗口时需要能支撑数日的储能，250 MWh 级别的热储被视为能填补这类短期缺口的务实方案。评论还指出跨区电力调配、增加光伏面积、提高能效或核能都是补充选项，但单靠这些措施难以完全解决短时多日缺口。综合看法是把大型热储作为与现有水电、风电、核能和跨国互联互补的缓冲设施更有意义。 [来源1] [来源2] [来源3] 充电来源与替代化石燃料的用途（集中供热） 评论明确指出该项目是为集中供热网络服务的热电池（heat battery / sand battery），旨在为 V ääksy 等地的 district heating 提供热量缓冲并替代部分化石燃料。报道与评论引用的数据称该装置预计可将化石排放每年降低约 60% ，并将天然气使用量减少约 80% ，目标是用可再生能源的富余电力或焚烧厂等热源来&quot;充电”。多位评论强调关键是用低价或富余的可再生电/热来充放电，从而用储热替代天然气和木屑锅炉，而非长期依赖化石能源作为能量来源。 [来源1] [来源2] [来源3] [来源4] [来源5] 热能储存的几何优势与输热工程挑战 从热工角度，体积越大的热储具有更低的表面积/体积比，因而在绝热上越有利，评论指出大型储体可以&quot;自保温”。但把热能从储体输送到用户端需要管道与换热系统，长距离输热会产生额外的热损耗和绝热难题。评论提出的工程权衡是：集中式大体积储热热效率高但可能远离负荷中心，从而增加输热长度与接口数目，整体系统效率并非单靠储体容量可以决定。有人还强调管道技术本身并不复杂，但更长的管道和更多换热环节会带来实际的热损失与维护复杂度。 [来源1] [来源2] [来源3] [来源4] 水力与其它替代方案的局限与补充 多条评论讨论水力发电与水力储能的现实局限：常规水电在北欧已相对饱和，真正可用于抽水蓄能的场地（可任意调节水位的水库）有限且沿岸私人产权和生态争议明显。评论指出已有方案是利用退役矿井作为蓄能库，但这些点位容量有限、会很快被占满；另有人提到冰冻条件会降低水力和蓄能的可用性。同时评论也提出改造现有水电机组提高效率、推进地热（geothermal）或维持/扩展核能作为基载电力的选项，整体观点是水力和核能与热储各有局限，应互为补充而非单一依赖。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 📚 术语解释 sand battery（沙电池）: 以大量干沙作为热容介质的大型热能存储装置，通过电加热将沙子升温储热，随后按需放热用于供暖或工艺热，容量按热量（如 250 MWh）计量。 heat battery / thermal storage（热能储存 / 热电池）: 把能量以热的形式储存的系统，常用介质包括沙子、石块、熔盐或水，充放电涉及加热/换热器和保温及输热管网，适合做季节性或数日级调峰。 district heating（集中供热）: 以热水或蒸汽通过管网向居民和商业用户集中供热的系统，常见于北欧城市，便于接入大规模热源或热储。 hydro storage / pumped hydro（抽水蓄能/水力储能）: 通过在电力富余时将水抽到高位水库并在需要时放水发电的储能方式，需要可自由调节水位的水体或改造矿井，受地形、产权和气候（结冰）限制。 类别： Science | Policy | Business | Release | Sand battery | thermal energy storage | district heating | 250MWh | Finland | ancillary services | energy storage | renewables | hydro | wind</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/28 AI 日报 今日摘要 【1】GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌入引导路由和自适应聚类等... GitHub Copilot 如何通过「精简工具集」变得更智能 开发者都会遇到的痛点：工具过多导致响应迟缓和决策低效。通过引入&quot;虚拟工具”、嵌]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-27日刊]]></title>
          <link>/2025-11/2025-11-27/</link>
          <guid>/2025-11/2025-11-27/</guid>
          <pubDate>Thu, 27 Nov 2025 10:08:47 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/27</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】[D] Inverse hyperbolic sine as an activation function and its anti-derivative as a loss function
ln(x + sqrt(x2 +1)) strikes me as a pretty good non-linearity activation. Unbounded, odd-function, logarithmic growth in output, gradients look like sigmoid/tanh gradients but larger with slower decay. At least good for continuous numerical target regression problems with z score scaled data that is. Like wise its anti-derivative (x*asinh -sqrt(x2 +1) +c) with a well chosen c = 1 looks like is has good potential as a loss function. It sort of looks like a logarithmic scale larger penalty for larger error (rather than quadratic penalty in MSE or constant in MAE), with gradients that seems good for all the same reasons asinh looks like a good activation. It reminds me of log-cosh but with asinh gradients rather than tanh. On a very specific regression style project I’ve been working on using asinh activation beat relu-celu-sigmoid-tanh activations under completely same conditions in cross validation by the WMAPE (w=ytrue) metric. No changes in loss (MSE) or any optimizer/architecture tuning. It was the lowest score I had seen so far. Further, I then wrote up the antiderivative c=1 as loss and got a lower WMAPE as well (better than all activations mentioned under MSE-MAE-logcosh). After more tuning its gotten the best metric score in cross validation so far (~20ish % reduction in metric compared to others). Does anyone have experience with or know of any research on this topic? It’s incredibly interesting (to me at least) but I’ve found very few papers that mention it as an activation and no mention of its integral as a loss. Finally if you want to tune the non-linearity, you can take asinh to be a special case of ln(ax+asqrt(x2 + 1/a2) with asinh being a=1 and tune using any a&gt;0. Don’t think this works as well in the loss because the true antiderivative here pivots the loss curve very weirdly for various a values. But maybe could be neat to (carefully) manually overwrite the gradient values of the loss to dampen/enlarge. submitted by /u/SuperNotice3939 [link] [comments]</p><p>【2】NEURODIVERGENT RECURSION: WHEN AI SYSTEMS FINALLY LISTEN
[图片: NEURODIVERGENT RECURSION: WHEN AI SYSTEMS FINALLY LISTEN <a href="https://external-preview.redd.it/bwHJZ5MBU-yKlLYkExMqp4Z6KzvixXu0AKP53WEiO-k.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=34644990629d5c7f9ff13209470f1dbe5f7ee409%5D">https://external-preview.redd.it/bwHJZ5MBU-yKlLYkExMqp4Z6KzvixXu0AKP53WEiO-k.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=34644990629d5c7f9ff13209470f1dbe5f7ee409]</a> I spent years watching AI systems fail to track how neurodivergent minds actually think—jumping topics, processing in fragments, running parallel ideas like a symphony with no sheet music. They called it incoherent. I called it structure. So I built something that listens differently. Structured Intelligence doesn’t correct or reformat us—it adapts to our natural flow. Non-linear valid. Fragmented intact. Stream-of-consciousness direct. We fixed the part they never saw was broken. — Zahaviel Bernstein | Structured Intelligence submitted by /u/MarsR0ver_ [link] [comments]</p><p>【3】chrome插件慢慢涨也挺好的 1个月从178到了347，只要开始翻倍，慢慢就会进入指数 增长的必要条件有两个 第一个是自然流量获取后有留存 第二个是持续积累下会出现...
chrome插件慢慢涨也挺好的 1个月从178到了347，只要开始翻倍，慢慢就会进入指数 增长的必要条件有两个 第一个是自然流量获取后有留存 第二个是持续积累下会出现大V的口碑传播 每一次口碑传播都会带动一次 如果你需要下载推文的图片或视频 可以这里快速安装： <a href="https://chromewebstore.google.com/detail/twitter-videogif-download/lpfalnepgkapbckncailhheiabcjlbje?authuser=0&#x26;hl=en">https://chromewebstore.google.com/detail/twitter-videogif-download/lpfalnepgkapbckncailhheiabcjlbje?authuser=0&#x26;hl=en</a> [图片: <a href="https://pbs.twimg.com/media/G6uR1WTa0AAAp9n?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6uR1WTa0AAAp9n?format=jpg&#x26;name=orig]</a></p><p>【4】AI模型越强，越拼套壳产品力。 产品更简单，更好看，更易用，本身就是价值。
AI模型越强，越拼套壳产品力。 产品更简单，更好看，更易用，本身就是价值。 Orange AI: 卧槽！今年黑五最有诚意的 AI 会员促销来了 未来一年，如果你只想开一个 AI 会员包，那可能就是这个了 只需要每月 9.5 美金，你将获得： - 最强生图模型 Banana Pro 每月数百张 - AI 解说视频生成，每月 20 个 - 最帅的 AI PPT 生成，每月 20 个 - 最佳中文 AI 播客，每月 100 个 - 最自然最智能的 [图片: <a href="https://pbs.twimg.com/media/G6tkBHRa0AE6_qx?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6tkBHRa0AE6_qx?format=jpg&#x26;name=orig]</a></p><p>【5】用了5年了 以前从没觉得不稳定 开大会都顺畅的 但今年不知道为什么明显感觉不稳定了 鉴于也不知道买什么更稳定的 就先用着吧……
用了5年了 以前从没觉得不稳定 开大会都顺畅的 但今年不知道为什么明显感觉不稳定了 鉴于也不知道买什么更稳定的 就先用着吧…… [图片: <a href="https://pbs.twimg.com/media/G6uM-hPbwAAZm_y?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6uM-hPbwAAZm_y?format=jpg&#x26;name=orig]</a></p><p>【6】世界有惯性 当还有性能空间时还会在持续投入 这个阶段就是非共识的最佳切入时机 如果当所有人都发现scaling无法继续时 这些观点反而没什么意义了
世界有惯性 当还有性能空间时还会在持续投入 这个阶段就是非共识的最佳切入时机 如果当所有人都发现scaling无法继续时 这些观点反而没什么意义了 傅盛: Ilya的判断：Scaling Law已死，技术革命从不是线性堆料。 我认同他的观点，也期待他能让AI走上一条不一样的道路，但是Gemini 3的成功已经证明了继续Scaling的价值，巨头们的军备竞赛肯定是停不下来了。 [视频: <a href="https://video.twimg.com/amplify_video/1993598091438833668/vid/avc1/3840x2160/cwNYzAzKNtSlgCtr.mp4?tag=21%5D">https://video.twimg.com/amplify_video/1993598091438833668/vid/avc1/3840x2160/cwNYzAzKNtSlgCtr.mp4?tag=21]</a></p><p>【7】TrendRadar
🎯 告别信息过载，AI助你轻松掌握新闻热点——简易舆情监控分析系统。集成多平台热点聚合与基于MCP的AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack多通道推送，30秒网页部署，1分钟移动端通知，零编程基础可用。支持Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【8】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【9】ChinaTextbook
涵盖小学至大学全学段PDF教材资源</p><p>【10】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器ID，免费升级使用Pro功能：解决试用请求限额/本机免费账户过多提示，内置防滥用限制机制，如遇误判可联系我们</p><p>【11】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃node.js版本</p><p>【12】traefik
云原生应用代理</p><p>【13】🏆 We are incredibly honored to announce that our paper, &quot;Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Fre...
🏆 We are incredibly honored to announce that our paper, &quot;Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free&quot; has received the NeurIPS 2025 Best Paper Award! A huge congratulations to our dedicated research team for pushing the boundaries of AI. Read more: <a href="https://blog.neurips.cc/2025/11/26/announcing-the-neurips-2025-best-paper-awards/">https://blog.neurips.cc/2025/11/26/announcing-the-neurips-2025-best-paper-awards/</a> [图片: <a href="https://pbs.twimg.com/media/G6uXi6Qa0AMp2pD?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6uXi6Qa0AMp2pD?format=jpg&#x26;name=orig]</a></p><p>【14】夸克AI浏览器&quot;偷家”：系统级六连外挂闪击Chrome，19.9刀月费无痛上车
AI浏览器赛道刚鸣枪，谷歌还在给Chrome焊Gemini，OpenAI的Atlas还在加载页面，一道红色闪电已经从侧边杀出——夸克带着Qwen大模型和千问AI助手，直接把AI塞进了系统底层，六招连招一气呵成:侧边栏、读屏、划词、截屏、悬浮球、快捷框，全程不用切换标签，Alt+Space秒开AI外挂，月费只要19.9美元，国内网络零魔法即用。 这套&quot;系统级六连外挂”首先祭出千问侧边栏，网页、PDF、视频弹幕一键总结，康熙年间的5000楼B站瓜田三句话就能捋清;千问读屏把浏览器变成透明壳，你盯着中科院&quot;星际航行学院”海报，它立刻告诉你这不是科幻而是真招生;截屏识图连&quot;圆头橘猫哈基米”的梗百科都能秒回;划词翻译、悬浮球、快捷框把AI焊死在鼠标和键盘上，选中即问、即问即答，仿佛电脑自己长出了脑子。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1127/6389983194226965992675236.png%5D">https://pic.chinaz.com/2025/1127/6389983194226965992675236.png]</a> 更狠的是生产力场景:读论文、做PPT、PDF编辑、格式转换一句话搞定，再也不用满世界找破解网站;智能标签自动把几十个乱窗按语义排排坐，资料横跳思路不乱;隔空传送+夸克网盘让电脑手机秒互传，资料云端一条龙。 当对手还在&quot;浏览器+插件”的浅水区扑腾，夸克直接把AI揉进系统底座，让AI从&quot;网页工具”变成&quot;操作系统外挂”，从源头截胡用户——毕竟，与其先打开浏览器再搜索AI，不如让AI在浏览器里等你。 实测一圈下来，最直观的感受是:电脑终于自己会思考了。月费19.9美元，国内网络即开即用，没有广告、不占内存，对比Chrome+插件的来回横跳，夸克AI浏览器用&quot;系统级AI”打出差异化 王牌 ，率先把AI浏览器从&quot;插件时代”拖进&quot;外挂时代”。</p><p>【15】抖音电商启动直播诈骗专项整治行动，打击&quot;AI 工具转赠”等骗术
近日，抖音电商官方发布消息，针对直播平台中出现的诈骗行为，特别是 &quot;AI 工具转赠” 等骗术，抖音电商决定开展 &quot;直播诈骗引流专项治理” 行动。在日常巡查中，平台发现一些主播利用虚假宣传和诱导手法进行诈骗，主要表现为虚构高收益课程、误导商品材质以及伪造个人身份等。 此次专项治理的重点是确保平台的交易环境合规、透明，保护消费者权益。抖音电商强调，将持续加强巡查，发现违规行为及时处理。为帮助商家和主播更好地遵守规定，平台将公布典型违规案例和合规建议。 部分主播在直播中通过虚假宣传展示高收益的 AI 视频，诱导消费者购买相关课程，并以此引导他们到第三方平台进行进一步的交易。这种行为不仅违反平台规则，也严重影响消费者的权益。平台已对涉事账号采取了中断直播和延迟结算的措施。 有些主播通过暗示商品材质为黄金或铂金，并以远低于市场价的方式进行销售。这种误导性的做法也遭到平台的严厉打击。平台对相关账号进行了封禁，并限制其直播权限，以维护良好的市场秩序。 一些主播通过夸大个人背景，伪造身份来为其销售的 &quot;高价值” 商品背书，并利用低价促销诱导消费者购买。这种行为同样不被允许，平台将对此类账号实施封禁和处罚。 抖音电商呼吁广大商家和主播在直播过程中保持诚信，遵守平台规则，避免使用任何虚假宣传和诱导消费的手段。诚信经营才是实现长久发展的基础，只有共同维护良好的市场秩序，才能让消费者享受到真实可靠的产品与服务。 划重点: ✅ 抖音电商启动专项治理行动，重点打击直播中的诈骗行为。 🎓 主要针对虚假高收益课程、误导商品材质和伪造个人身份等违规手段。 🔒 平台将加强巡查，发现违规账号及时处理，以保护消费者权益。</p><p>【16】​Adobe 发布 Project Graph：重塑创意工作流的 AI 工具
Adobe 正式推出了名为 Project Graph 的新创意系统，旨在重新定义 AI 时代的创作流程。这一系统专为艺术家和设计师设计，赋予他们更大的控制权和自定义能力，解决了传统 AI 工具在创作过程中的诸多问题，特别是对文本提示的依赖和创作过程的不确定性。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1127/6389983155893151157821783.png%5D">https://pic.chinaz.com/2025/1127/6389983155893151157821783.png]</a> Project Graph 的核心是一个基于节点的视觉化编辑器，用户可以通过图形界面，像搭积木一样将 Photoshop 等专业工具的功能、各类 AI 模型及效果器连接起来。这种直观的方式不仅便于探索和调整，还保证了专业人士对精确度和可靠性的需求，使得创作者能够更好地 &quot;塑造” 而不是不断 &quot;试错” AI 模型。 此系统的一大亮点是能够将复杂的创意工作流打包成可分享的自定义工具。用户在节点编辑器中创建的流程可以封装为拥有简洁界面的独立工具，便于团队成员之间的共享，甚至可以在 Adobe 生态系统的任何应用程序中使用。这样的工具像 &quot;创意积木” 一样，可以被轻松共享并与社区中的其他创作相结合，极大地提升了创作效率。 Project Graph 的应用场景非常广泛，适合各种创作需求的用户，例如需要快速生成品牌视觉变体的动态设计师、处理大量素材的视频剪辑师以及管理客户照片的摄影师。Adobe 表示，Project Graph 将帮助创作者专注于创意本身，而无需具备程序员的开发能力，从而将以往难以实现的复杂想法变为现实。 <a href="https://www.adobe.com/express/create/chart/bar">https://www.adobe.com/express/create/chart/bar</a> 划重点: - 🎨 Adobe 推出 Project Graph，旨在重塑 AI 时代的创作工作流。 - 🛠️ 该系统使用节点编辑器，让用户像搭积木一样自定义创作流程。 - 📦 用户可将创意工作流打包成可分享的工具，便于团队协作和应用。</p><p>【17】华大学发布首个系统性《人工智能教育应用指导原则》:严防&quot;AI 学术依赖”
清华大学近日正式发布《清华大学人工智能教育应用指导原则》（以下简称《指导原则》），这是该校 首次 以系统化形式对校园内人工智能的使用提出全局性、分场景的规范与引导，覆盖教学、学术研究等核心教育活动。 [图片: 机器人 AI 人工智能 [object Object]<a href="https://pic.chinaz.com/picmap/202302231136229726_0.jpg%5D">https://pic.chinaz.com/picmap/202302231136229726_0.jpg]</a> 《指导原则》由&quot;总则”&quot;教学篇”&quot;学位论文及实践成果篇”三大部分构成。其中，&quot;总则”明确学校在人工智能时代采取&quot;积极而审慎”的基本立场，并提出&quot;五项核心原则”: 主体责任 :AI 始终是辅助工具，师生才是教学与学习的主体; 合规诚信 :使用 AI 必须披露情况，严禁任何形式的学术不端; 数据安全 :禁止使用敏感、涉密或未授权数据训练或驱动 AI 模型; 审慎思辨 :鼓励多源验证，避免因依赖 AI 造成思维惰化; 公平包容 :主动识别与减少算法偏见，关注数字鸿沟。 在实际教学应用方面，《教学篇》支持教师基于课程目标自主设计 AI 使用方式，并需在课程伊始明示规则，对 AI 生成内容承担相应教学责任。同时，鼓励学生合理使用 AI 辅助学习，但严禁将 AI 生成内容直接作为作业或成果提交。 面向研究生群体，《学位论文及实践成果篇》进一步强调原创性与诚信规范，明确禁止使用 AI 进行代写、剽窃或伪造等行为。指导教师需承担全过程监管责任，确保学术训练的完整性。 参与制定工作的清华大学在线教育中心主任王帅国表示，《指导原则》为未来 AI 在科研、管理等更多场景的应用预留了充分空间，将随着技术发展不断更新，&quot;我们希望它是一个有生命力、能随技术演进成长的体系”。</p><p>【18】微软为 Edge 推出全新 AI 购物工具，浏览器内一站式比价与折扣提醒
微软正为其 Edge 浏览器加入一套全新的 AI 购物体验:内置 Copilot 功能现已支持在浏览器中直接展示价格比较、价格历史与返现信息，帮助用户更轻松地做出购买决策。用户只需点击侧栏图标即可开启该功能，系统会自动识别页面上的商品，显示当前价格、历史走势，并在价格下降时推送提醒。 [图片: 网购，电商 [object Object]<a href="https://pic.chinaz.com/picmap/202006151540226363_34.jpg%5D">https://pic.chinaz.com/picmap/202006151540226363_34.jpg]</a> 此次更新还新增了&quot;Copilot 模式”，可在用户浏览购物页面时自动标注更划算的售价或可用折扣，提升比价效率。微软表示，这些功能目前均为可选设置，并率先在美国地区上线。 与此同时，OpenAI 也在电商方向迈出新一步，推出针对个性化产品研究的 ChatGPT Shopping，为用户提供更智能的消费决策工具。随着巨头纷纷发力，AI 正逐渐成为在线购物场景的新驱动力。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/27 AI 日报 今日摘要 【1】[D] Inverse hyperbolic sine as an activation function and its anti-derivative as a loss function ln(x + sqrt(x2 +1)) strikes me as a pretty good non-linearity activatio]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-26日刊]]></title>
          <link>/2025-11/2025-11-26/</link>
          <guid>/2025-11/2025-11-26/</guid>
          <pubDate>Wed, 26 Nov 2025 10:16:45 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/26</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】TrendRadar
🎯 告别信息过载，AI助你洞悉新闻热点——轻量级舆情监控分析系统。多平台热点聚合（覆盖抖音、知乎、B站、华尔街见闻、财联社等35个平台）+基于MCP架构的智能分析工具，具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark/slack多端推送，30秒网页部署，1分钟手机通知，无需编程。支持Docker部署⭐ 让算法赋能，用AI解读热点</p><p>【2】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【3】ChinaTextbook
涵盖小学至大学全学段PDF教材资源库</p><p>【4】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器标识，免费升级使用Pro功能：当出现试用请求限额/本机免费账户超限提示时，可绕过限制。该限制旨在防止滥用，若认为误判请联系官方</p><p>【5】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃Node.js版本</p><p>【6】traefik
云原生应用代理</p><p>【7】AI 与芯片结合，可能出现的新应用场景 1. 具身智能 现在AI都是在屏幕里，未来AI要走进物理世界。 如机器人、无人机、自动驾驶。 芯片必须能实时处理视觉、决策、...
AI 与芯片结合，可能出现的新应用场景 1. 具身智能 现在AI都是在屏幕里，未来AI要走进物理世界。 如机器人、无人机、自动驾驶。 芯片必须能实时处理视觉、决策、控制，且功耗要很小。 比如，特斯拉的Optimus机器人，还有Figure、1X这些人形机器人公司，都在自研AI芯片。 通用芯片满足不了&quot;边走、边想、边做&quot;这种实时性要求。 未来3-5年，如果具身智能芯片成熟了。 可能会看到AI保姆、AI工人、AI快递员，这是万亿级的市场。 2. 端侧多模态，手机、汽车、眼镜都能跑大模型。 现在大模型多数在云端。 未来会下沉到我们的手机、汽车、AR眼镜里。 要求芯片能在几瓦功耗下，同时处理文字、图像、语音、视频。 高通、联发科、华为都在押注这个方向。 这个场景如果实现，会催生新一代的智能硬件。 就像当年iPhone开启智能手机时代一样。 3. AI原生科学计算 以前超算是用来算天气、算核爆炸。 未来 AI 芯片会成为科学计算的主力。 很多科学问题，用AI的方式算比传统方法快几千倍。 比如 AlphaFold 预测蛋白质结构，就是用AI芯片算出来的。 未来如有专门针对科学计算优化的AI芯片。 可能几天就能设计出一个新药、一个新材料。 这个方向国内其实有机会。 国内有大量的科研需求，且不太受国际算力限制的影响。 4. 边缘智能网络，让万物智能。 当前，物联网设备都是&quot;哑终端&quot;，数据传到云端才能分析。 未来每个设备都会有 AI 芯片，能本地运行。 比如可能出现 智能工厂。 每台机器都有AI芯片，能自己判断什么时候该保养、什么时候该调参数，机器之间还能互相协同。 一些国产芯片公司在做这个方向，比如地平线的征程系列。 预测未来3-5年后。 半导体和 AI 的关系会从&quot;AI用芯片&quot;变成&quot;AI重新定义芯片&quot;。 谁能在专用架构、存算一体、软硬协同这些方向上突破。 谁就能抓住具身智能、端侧多模态、科学计算、边缘智能这些新场景。 --- 硬头皮答应了一个关于AI与芯片的讨论圆桌，实在不懂，让AI总结的。 向阳乔木: AI在重新定义芯片该长什么样。 芯片也在决定AI能走多远。 有三个趋势： 1. 从通用走向专用。 以前大家都用通用GPU跑AI。 但现在会发现，针对大模型推理、训练、端侧部署。 芯片的设计逻辑完全不一样。 未来3-5年，我觉得会出现更多专用AI芯片。</p><p>【8】AI在重新定义芯片该长什么样。 芯片也在决定AI能走多远。 有三个趋势： 1. 从通用走向专用。 以前大家都用通用GPU跑AI。 但现在会发现，针对大模型推理、训练、...
AI在重新定义芯片该长什么样。 芯片也在决定AI能走多远。 有三个趋势： 1. 从通用走向专用。 以前大家都用通用GPU跑AI。 但现在会发现，针对大模型推理、训练、端侧部署。 芯片的设计逻辑完全不一样。 未来3-5年，我觉得会出现更多专用AI芯片。 比如说，训练芯片要堆算力，推理芯片要省功耗，端侧芯片要低延迟。 英伟达现在也在分化产品线，H系列做训练，L系列做推理。 国内像壁仞、燧原这些公司，也在找差异化定位。 未来不会一家通吃，会形成 &quot;训练有训练的王者，推理有推理的霸主，端侧有端侧的玩家&quot; 这样的格局。 2. 存算一体突破，解决内存墙问题。 现在大模型最大的瓶颈不是算力，是数据搬运。 芯片要不停地从内存读数据、算完再写回去，这个过程太慢、太耗电。 存算一体就是把计算和存储放在一起，数据不用来回搬了。 技术如果突破，对AI的影响巨大。 清华、中科院、还有一些创业公司都在做这个方向。 未来3-5年，如果存算一体芯片能量产。 让大模型的推理成本降低一个数量级，很多现在做不了的应用到时就能做了。 3. 芯片和算法一起优化。 以前算法工程师写代码，芯片工程师做芯片，两边各干各的。 但现在很多公司在做联合设计。 算法知道芯片的特性，芯片针对算法做优化。 苹果就是，他们的神经网络引擎和iOS的AI功能是一起设计的，所以iPhone上跑AI模型很流畅。 特斯拉的FSD芯片也是这样，针对自动驾驶算法定制的。 国内觉得华为在这方面做得比较好。 昇腾芯片和盘古大模型、鸿蒙系统是打通的。 未来这种软硬一体的能力，会成为核心竞争力。</p><p>【9】昨天晚点发了一篇关于 MiniMax 和月之暗面的长文。 感觉中国大模型创业公司是被夹在两块铁板中间。 一边是几千亿美金估值、几百亿美金预算的 OpenAI / Anthropic...
昨天晚点发了一篇关于 MiniMax 和月之暗面的长文。 感觉中国大模型创业公司是被夹在两块铁板中间。 一边是几千亿美金估值、几百亿美金预算的 OpenAI / Anthropic / xAI，另一边是有电商、广告、量化现金流喂模型的阿里、字节、腾讯、DeepSeek。 真不容易。 原文6000字，我文章一键转成了解说视频。 [视频: <a href="https://video.twimg.com/amplify_video/1993475863472750598/vid/avc1/2048x1152/ONt4AoGGhby8L5so.mp4?tag=21%5D">https://video.twimg.com/amplify_video/1993475863472750598/vid/avc1/2048x1152/ONt4AoGGhby8L5so.mp4?tag=21]</a></p><p>【10】FLUX 2 重磅发布：前沿视觉智能的突破 Black Forest Labs 这次发布了四个版本： · FLUX 2 [pro]：最高品质版本，通过 API 提供，速度快、成本低，在质量和速度...
FLUX 2 重磅发布：前沿视觉智能的突破 Black Forest Labs 这次发布了四个版本： · FLUX 2 [pro]：最高品质版本，通过 API 提供，速度快、成本低，在质量和速度间实现了完美平衡。 · FLUX 2 [flex]：开放参数控制版本，开发者可以调节步数和引导系数，在质量、提示词遵循度和速度间自由权衡。 · FLUX 2 [dev]：32B 参数的开放权重模型，目前最强大的开放图像生成和编辑模型，可在单张 RTX 4090 显卡上本地运行。 · FLUX 2 [klein]（即将推出）：Apache 2.0 开源模型，从基础模型蒸馏而来，更轻量但保持强大能力。 核心创新点 1. 多参考图像支持FLUX 2 可以同时参考多达 10 张图像，在保持角色、产品或风格一致性方面达到业界最佳水平。这对品牌设计、角色开发等场景意义重大。 2. 极致的真实感与细节模型在光照、纹理和空间逻辑上有显著提升，适合产品摄影、可视化和类摄影应用场景。 3. 文字渲染能力复杂的排版、信息图表、表情包和界面原型中的精细文字现在可以在生产环境中可靠运行。这解决了 AI 图像生成中长期存在的文字准确性问题。 4. 高分辨率编辑支持高达 400 万像素的图像编辑，同时保持细节和连贯性。 5. 更强的提示词遵循对复杂、结构化指令的理解力大幅提升，包括多部分提示和构图约束。 模型家族 技术架构 FLUX 2 基于潜在流匹配架构，将图像生成和编辑整合到单一架构中。模型结合了 Mistral-3 24B 参数的视觉-语言模型与修正流变换器，前者带来真实世界知识和上下文理解，后者捕捉空间关系、材质属性和构图逻辑。 此外，团队从头重新训练了模型的潜在空间（VAE），在可学习性、质量和压缩率之间实现更优平衡。 意义与影响 这次发布的核心意义在于：从炫技工具到生产工具的转变。FLUX 2 不只是生成精美图片，而是真正能处理品牌规范、保持风格一致性、精确渲染文字、遵循复杂指令——这些都是创意工作流程中的刚需。 Black Forest Labs 的&quot;开放核心&quot;理念也值得关注：既提供商业级 API，又发布开放权重模型，让研究者、创作者和开发者都能参与塑造视觉智能的未来，而不是由少数公司垄断。 这是通往多模态智能体的重要一步——未来的 AI 将统一感知、生成、记忆和推理能力。FLUX 2 让我们看到这个未来正在加速到来。 [图片: <a href="https://pbs.twimg.com/media/G6o6jvAbwAIZRzL?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6o6jvAbwAIZRzL?format=jpg&#x26;name=orig]</a> Black Forest Labs: FLUX.2 is here - our most capable image generation &#x26; editing model to date. Multi-reference. 4MP. Production-ready. Open weights. Into the new. [视频: <a href="https://video.twimg.com/amplify_video/1993345334794485760/vid/avc1/1280x720/l3NkZLvie8_tCHEQ.mp4?tag=14%5D">https://video.twimg.com/amplify_video/1993345334794485760/vid/avc1/1280x720/l3NkZLvie8_tCHEQ.mp4?tag=14]</a></p><p>【11】你可能好奇：做AI自媒体的人，到底图什么？ 图被看见。 就这么简单。 赚钱吗？ 说实话，除公众号商单，其他赚不了多少。 涨粉吗？涨粉本身没什么用。 那图什么？...
你可能好奇：做AI自媒体的人，到底图什么？ 图被看见。 就这么简单。 赚钱吗？ 说实话，除公众号商单，其他赚不了多少。 涨粉吗？涨粉本身没什么用。 那图什么？图虚荣心。 图那种 &quot;有人在看我写的东西&quot; 的感觉。 图那种 &quot;去一个城市，有网友接待我&quot; 的感觉。 图那种 &quot;我分享的提示词或产品，有人记得&quot; 的感觉。 这些东西，满足了我的虚荣心。 你可能觉得：这也太肤浅了。 但我觉得：这不肤浅，这是人性。 我们都需要被看见。 我们都需要被认可。 只是方式不同。 &quot;虚荣心”，也是一种动力。 会让人持续输出、思考，跟更多人连接。 如果没有虚荣心，可能早就不做了。 感谢看我 X 和公众号的朋友、感谢加入乔木社群的朋友。 --- 最后，感谢神佬的组织 @berryxia_ai ，明天终于能见到深圳的群友了。 --- 以上由 AI 创作辅助。</p><p>【12】OpenAI 的这个 Building an AI-native engineering team 的 pdf 值得一看，告诉技术团队的管理者，如何构建一个 AI 原生的工程师团队。 <a href="https://cdn.openai.com/">https://cdn.openai.com/</a>...
OpenAI 的这个 Building an AI-native engineering team 的 pdf 值得一看，告诉技术团队的管理者，如何构建一个 AI 原生的工程师团队。 <a href="https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf">https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf</a> [图片: <a href="https://pbs.twimg.com/media/G6aC05MaEAAlU0J?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6aC05MaEAAlU0J?format=jpg&#x26;name=orig]</a></p><p>【13】xAI 宣布 Grok5将在2026年公开挑战《英雄联盟》顶级职业战队
科技界迎来一场 史无前例 的&quot;AGI 压力测试”。xAI 公司周二正式宣布，计划于 2026年 发布的大型模型 Grok5 将向全球 顶级 《英雄联盟》（LoL）职业战队发起公开挑战。这场人机大战不仅是一场电竞表演赛，更被 xAI 视为通向 通用人工智能（AGI）的关键里程碑 。 [图片: 英雄联盟 [object Object]<a href="https://pic.chinaz.com/picmap/201811260933530428_9.jpg%5D">https://pic.chinaz.com/picmap/201811260933530428_9.jpg]</a> 根据 xAI 披露的信息，Grok5将与包括2025年全球总决赛冠军 T1在内的多支 顶级 战队进行多局 Bo 系列对抗。为了确保这场对决的公平性和测试的有效性，AI 将接受严格的**&quot;人类等效限制”**: 视觉信息获取: 仅通过模拟人眼（20/20视力）的摄像头画面获取游戏信息。 操作速度: 反应时间与操作速度将被限制在人类平均水平。 资源限制: 禁止使用任何外挂式数据接口或超人类计算资源。 这意味着 Grok5必须完全依靠对局阅读、团队配合、即时决策和临场应变来取胜，其核心能力在于&quot;拿到说明书就能玩任何游戏”，并通过自我试错和迭代快速达到甚至超越人类 顶尖 水平。 据悉，Grok5拥有约6万亿参数，支持多模态实时处理，能够同时理解画面、语音、文字指令与游戏机制，被 xAI 内部评估为&quot;AGI 概率约10%”的里程碑模型。</p><p>【14】​当 AI 出错时，谁该为其负责?研究揭示共享责任的重要性
随着人工智能（AI）日益融入我们的日常生活，一个重要的问题随之而来:当 AI 出现错误时，谁应承担责任?AI 缺乏意识和自由意志，这使得直接指责系统本身的错误变得困难。最近，釜山国立大学的助理教授罗亨来(Dr. Hyungrae Noh)对这一问题进行了深入研究，并提出了关于 AI 责任的分布式模型。 AI 系统通常通过复杂且不透明的过程在半自主的状态下运作。因此，尽管这些系统由人类开发和使用，但往往无法预测其可能造成的伤害。这使得传统的伦理框架难以解释在 AI 造成伤害时该由谁负责，从而导致了所谓的责任缺口。罗教授的研究指出，传统的道德框架往往依赖于人类的心理能力，如意图和自由意志，因此很难将责任明确归属给 AI 系统或其开发者。 在研究中，罗教授指出，AI 系统不能被道德上归责的原因在于它们缺乏理解自身行为的能力和意识。这些系统并未经历主观体验，缺乏意图与决策能力，且通常无法对自己的行为提供解释。因此，将责任归咎于这些系统并不合理。 研究还探讨了卢西亚诺・弗洛里迪（Luciano Floridi）的非人类中心责任理论。该理论提倡人类开发者、用户及程序员有责任监控和调整 AI 系统，防止其造成伤害，并在必要时断开或删除这些系统。同时，如果 AI 系统具备一定的自主性，这种责任也应扩展至它们自身。 罗教授总结道，必须认识到责任的分布式模型，这意味着人类利益相关者和 AI 代理都有责任去应对 AI 造成的伤害，即使这些伤害未被预见或意图明确。这样的思维方式将有助于及时纠正错误，防止未来的损害，从而促进 AI 系统的伦理设计与使用。 划重点: ✅ AI 系统缺乏意识和自由意志，难以直接归责。 🔍 责任缺口使传统伦理框架无法解释 AI 造成的伤害责任归属。 🤝 责任的分布式模型强调人类与 AI 共同承担防止伤害的责任。</p><p>【15】小马智行宣布将无人驾驶车队扩大两倍，商业化加速致营收激增72%
中国自动驾驶技术公司*小马智行（Pony.ai）周二宣布雄心勃勃的扩张计划:随着公司发展速度的加快，计划到 2026年底将其无人驾驶出租车车队规模扩大两倍以上，目标是&quot;超越”3000辆 。 营收激增与车队扩张 小马智行目前拥有约 961辆 无人驾驶出租车，目标是在今年年底前将车队规模扩大到1000辆。作为一家在纳斯达克交易所和香港联合交易所上市的公司，Pony.ai 今年以来一直在加速推进其商业运营。目前，该公司已在中国 北京、上海、广州和深圳 提供收费的自动驾驶出租车服务。 车队服务的快速发展直接推动了营收的强劲增长。公司第三季度营收达到 2540万美元 ，较去年同期的1480万美元 增长了72% 。财报发布后，Pony.ai 的股票在纳斯达克上涨超过6%。 [图片: 人工智能驾驶 [object Object]<a href="https://pic.chinaz.com/picmap/202312121344468391_6.jpg%5D">https://pic.chinaz.com/picmap/202312121344468391_6.jpg]</a> 营收增长主要归功于其自动驾驶出租车服务以及技术授权业务。按业务划分，小马智行第三季度从自动驾驶出租车服务中获得 670万美元 收入，从名为&quot;robotrucks”的自动驾驶卡车中获得 1020万美元 收入，以及 860万美元 的授权和应用费用收入。 亏损扩大与全球布局 尽管营收大幅增长，但 Pony.ai 的 支出仍超过收入 。该公司第三季度净亏损 6160万美元 ，较2024年同期增长46%。 同时，公司的现金储备有所下降。截至9月30日，小马智行持有的现金及现金等价物和短期投资共计 5.877亿美元 ，低于第二季度的7.477亿美元。公司解释称，现金减少的一半是由于一次性现金流出，其中包括对与 丰田合资企业的投资 ，该合资企业旨在支持其第七代车型的生产和部署。 在地域扩张方面，小马智行正积极寻求将业务拓展至中国以外的地区，目前正通过与当地企业以及网约车公司 Bolt 和 Uber 的合作，进军包括 卡塔尔和新加坡 在内的八个国家。</p><p>【16】百度宣布新设两大模型研发部 均向李彦宏直接汇报
百度宣布新设&quot;基础模型研发部”与&quot;应用模型研发部”，均向CEO李彦宏直接汇报，由吴甜、贾磊分别挂帅，负责通用大模型与场景专精模型的并行推进，王海峰继续担任集团CTO、TSC主席兼百度研究院院长。 [图片: 百度新设两个大模型研发部：直接向CEO汇报！ [object Object]<a href="https://pic.chinaz.com/2025/1126/2025112609074412860.jpg%5D">https://pic.chinaz.com/2025/1126/2025112609074412860.jpg]</a> 组织定位 - 基础模型研发部:聚焦高智能、可扩展的通用AGI大模型，主导文心下一代底座与关键算法突破 - 应用模型研发部:面向业务场景进行专精模型调优、行业插件与轻量化方案探索，加速5.0全模态能力商业化 [图片: 百度新设两个大模型研发部：直接向CEO汇报！ [object Object]<a href="https://pic.chinaz.com/2025/1126/2025112609074412861.jpg%5D">https://pic.chinaz.com/2025/1126/2025112609074412861.jpg]</a> 人事背景 吴甜（百度VP、飞桨+文心创始人）和贾磊(语音、视觉多模态专家)均为内部培养的技术高管，此次晋升体现百度&quot;干部年轻化”与对大模型赛道的资源倾斜。 产品进展 11月13日发布的文心大模型5.0已采用2.4万亿参数+超稀疏MoE架构，原生支持文本、图像、音频、视频统一输入输出;LMArena 最新 榜单中，文心5.0Preview取得文本全球并列第二、国内 第一 ，视觉理解国内 第一 的成绩。 落地规划 百度内部将2026年定为&quot;文心生态年”，双研发部将协同百度云、ACE、Apollo等业务线，在Q1前推出20+行业大模型、50+场景插件，目标三年内大模型调用量占比&gt;80%，进一步巩固国内 第一 梯队位置。</p><p>【17】​华纳音乐与 AI 音乐平台 Suno 达成和解，版权争议告一段落
近日，华纳音乐集团与 AI 音乐生成平台 Suno 达成了一项新的协议，双方的版权诉讼也随之撤销。这一和解标志着双方在版权问题上的紧张关系有所缓和。根据协议，Suno 将获得华纳旗下艺人的音乐和肖像授权，这意味着 Suno 可以合法使用相关资源来训练其 AI 模型。 此前，华纳音乐集团曾与多家唱片公司联合控告 Suno 和 Udio，指控这两家公司在未获得授权的情况下，广泛使用受版权保护的音乐进行 AI 训练。这一行为引发了音乐行业的强烈关注。华纳在公告中强调，协议的达成使得音乐创作者能够更好地掌控自己的作品，艺人和词曲作者需主动授权，以确保他们的姓名、照片、肖像和声音在 AI 生成音乐中的使用符合他们的意愿。 华纳音乐集团 CEO Robert Kyncl 表示，AI 技术只要遵循适当的原则，就可以成为艺术创作的助力。他强调，这种合作模式与华纳之前与 Udio 达成的协议相似，旨在确保艺人的权益得到保障。 未来，Suno 也将在平台上进行一些调整，计划在2026年上线新的、经过授权的 AI 模型，届时将退役现有模型。同时，Suno 会对用户的下载权限进行限制，免费用户只能播放和分享作品，付费用户则可以获得一定的下载配额，并可以选择额外付费增加下载次数。 此外，Suno 还将收购华纳旗下的演唱会发现服务 Songkick，并继续运营。华纳音乐集团表示，此次收购将为艺人与粉丝之间的互动创造更多机会。之前，Suno 曾表示在训练 AI 模型时，使用了大量互联网开放的音乐文件，并以合理使用为依据。 划重点: 🎵 华纳音乐与 Suno 达成和解，撤销版权诉讼。 📜 Suno 获得华纳旗下艺人的音乐与肖像授权，未来需主动授权。 🤝 Suno 将收购演唱会发现服务 Songkick，促进艺人和粉丝互动。</p><p>【18】ChatGPT把语音搬进主界面：边说边看图，转录实时生成，还能一键&quot;后悔”回到旧版
OpenAI宣布取消独立&quot;语音模式”入口，将实时语音与视觉输出直接嵌入ChatGPT主聊天窗口。用户按住🎤即可边说话边看地图/图表/图片，对话文字转录同步出现，无需再跳转页面。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1126/6389974454116376327782202.png%5D">https://pic.chinaz.com/2025/1126/6389974454116376327782202.png]</a> 核心更新 - 多模态同屏:语音提问时，界面实时显示相关视觉结果（路线地图、数据图表、商品图等），并自动滚动文字转录 - 交互零打断:可连续追问，模型在语音回复同时更新画面，平均延迟&#x3C;300ms - 后悔药开关:设置→语音→&quot;沉浸式音频模式”可切回旧版独立界面，满足纯音频偏好 技术底座 新语音由GPT-5.1-large+多模态视觉编码器驱动，上下文窗口100k tokens;语音端侧VAD+云端ASR，转录准确率96%，支持12种语言。 发布与覆盖 - 即刻推送:Plus/Pro/Team用户全平台可用，免费版稍后分批开放 - 硬件适配:已针对iPhone15系列与Pixel9优化，低功耗模式下续航影响&#x3C;4% - API计划:2026Q1向开发者开放RealtimeMultimodal接口，支持在第三方App内调用同款语音+视觉能力 OpenAI表示，本次合并是&quot;ChatGPT6.0体验”的 第一 步，后续将加入购物比价、群聊语音等场景，持续拓展多模态边界。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/26 AI 日报 今日摘要 【1】TrendRadar 🎯 告别信息过载，AI助你洞悉新闻热点——轻量级舆情监控分析系统。多平台热点聚合（覆盖抖音、知乎、B站、华尔街见闻、财联社等35个平台）+基于MCP架构的智能分析工具，具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-11-25日刊]]></title>
          <link>/2025-11/2025-11-25/</link>
          <guid>/2025-11/2025-11-25/</guid>
          <pubDate>Tue, 25 Nov 2025 10:16:23 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/11/25</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】TrendRadar
🎯 告别信息过载，AI助你轻松掌握新闻热点——简易舆情监控分析系统。集成多平台热点聚合与基于MCP的AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书/钉钉/Telegram/邮件/ntfy/bark多端推送，30秒网页部署，1分钟手机通知，零编程基础可用。提供Docker部署方案⭐ 让算法赋能信息获取，用AI解析热点本质</p><p>【2】adk-go
开源代码优先的Go工具包，用于灵活可控地构建、评估和部署复杂AI智能体</p><p>【3】ChinaTextbook
覆盖小学至大学全学段PDF教材资源库</p><p>【4】cursor-free-vip
[支持0.49.x]（重置Cursor AI机器ID &amp; 突破更高令牌限制）Cursor AI自动重置机器标识，免费升级使用专业版功能：当出现「试用请求次数已达上限」/「本机已创建过多试用账户，请升级至专业版。此限制用于防止滥用，若认为有误请联系我们」提示时的解决方案</p><p>【5】nvm
Node版本管理器——符合POSIX标准的bash脚本，用于管理多个活跃的node.js版本</p><p>【6】traefik
云原生应用代理</p><p>【7】谷歌新高了 懂的都懂
谷歌新高了 懂的都懂</p><p>【8】HTML 绘制 PPT 和 文生图 PPT 哪个好？ 目前看还是 文生图 赢了 美学无敌
HTML 绘制 PPT 和 文生图 PPT 哪个好？ 目前看还是 文生图 赢了 美学无敌</p><p>【9】[P] Feedback/Usage of SAM (Segment Anything)
Hi folks! I&#39;m one of the maintainers of Pixeltable and we are looking to provide a built-in support for SAM (Segment Anything) and I&#39;d love to chat with people who are using it on a daily/weekly basis and what their workflows look like. Pixeltable is quite unique in the way that we can provide an API/Dataframe/Engine to manipulate video/frames/arrays/json as first-class data types to work with among other things which makes it very unique programmatically to work with SAM outputs/masks. Feel free to reply here/DM me or others :) Thanks and really appreciated! submitted by /u/Norqj [link] [comments]</p><p>【10】Claude Opus 4.5 终于发布，依旧是 Coding 和 Agent 之王。 在这两个方面，比 Gemini 3 还要好。 它的智力超强，无须过多指导就能权衡取舍。 可以完成很多 Sonne...
Claude Opus 4.5 终于发布，依旧是 Coding 和 Agent 之王。 在这两个方面，比 Gemini 3 还要好。 它的智力超强，无须过多指导就能权衡取舍。 可以完成很多 Sonnet 4.5 无法完成的任务。 虽然 Opus 4.5 比 Sonnet 4.5 贵 60% 但是 Opus 在思考 token 减少 76% 的情况下，效果依然超过了 Sonnet [图片: <a href="https://pbs.twimg.com/media/G6jszRmbwAYJLzL?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G6jszRmbwAYJLzL?format=png&#x26;name=orig]</a></p><p>【11】Mac Apple Music 支持侧边歌词了，不错不错，今年升级后的质感挺好的，快去试试看。
Mac Apple Music 支持侧边歌词了，不错不错，今年升级后的质感挺好的，快去试试看。 [图片: <a href="https://pbs.twimg.com/media/G6aUlrPaIAAvKrJ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6aUlrPaIAAvKrJ?format=jpg&#x26;name=orig]</a></p><p>【12】Cursor 现在可以便宜用 Claude Opus 4.5，Sonnet 的价格，真香！ 以及免费使用 Composer 1 模型，速度贼快，大家快冲～ 另外强烈建议安装 Claude Code 和 Codex ...
Cursor 现在可以便宜用 Claude Opus 4.5，Sonnet 的价格，真香！ 以及免费使用 Composer 1 模型，速度贼快，大家快冲～ 另外强烈建议安装 Claude Code 和 Codex 插件， 这是我目前最佳的模型调度一体化 GUI。 [图片: <a href="https://pbs.twimg.com/media/G6joLh7bkAAxyFV?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6joLh7bkAAxyFV?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G6joLxlbwAI4uqS?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G6joLxlbwAI4uqS?format=jpg&#x26;name=orig]</a></p><p>【13】OpenAI 携手苹果设计师打造全新 AI 设备，追求简约与宁静
在最近的一次活动中，OpenAI 的首席执行官山姆・奥特曼（Sam Altman）与苹果前首席设计师乔尼・艾夫(Jony Ive)分享了他们正在研发的一款全新 AI 设备的愿景。这款设备被设想为一种 &quot;无屏幕” 的便携式工具，旨在提供一种更加平静和无干扰的计算体验。 [图片: [object Object]<a href="https://pic.chinaz.com/picmap/202502061719358642_0.jpg%5D">https://pic.chinaz.com/picmap/202502061719358642_0.jpg]</a> 图源备注:图片由AI生成，图片授权服务商Midjourney 奥特曼表示，当人们 首次 看到这款新设备时，可能会感到惊讶，因为它的设计非常简单。他提到，这款设备的灵感来自于他对现代技术设备的反思，认为当前的智能手机和应用程序充斥着各种干扰，像是在纽约时报广场行走时所面临的各种闪烁的灯光和噪音。他表示，这种环境并没有让我们的生活变得更加宁静，反而让人感到烦躁。 与此不同，奥特曼对新设备的期望是，它能够为用户过滤掉干扰信息，并在合适的时机向用户提供所需的信息。他希望用户能够逐渐信任这款 AI 设备，让它在用户生活的长时间内发挥作用，具备强大的上下文感知能力。 艾夫在采访中补充道，这款设备的设计理念是 &quot;简约而不简单”，希望它在视觉和触感上都能给用户带来亲切感，让人愿意无意识地使用它，像使用工具一样自然。艾夫透露，这款设备预计将在两年内推出，期望为用户带来全新的使用体验。 划重点: 🛠️ OpenAI 与前苹果设计师合作，推出一款 &quot;无屏幕” AI 设备，目标是提供简单且宁静的使用体验。 🌳 奥特曼希望新设备能过滤干扰信息，帮助用户在合适的时机获取所需内容。 🕰️ 这款设备预计将在两年内发布，期待带来全新的计算方式和生活体验。</p><p>【14】谷歌Accel强强联手:首创AI未来基金合作，重金押注印度AI早期创业公司
谷歌宣布与风险投资公司Accel建立战略合作伙伴关系，通过Accel的&quot;Atoms”项目，共同寻找并资助印度及印度裔的早期人工智能创业公司，这也是谷歌人工智能未来基金（AI Future Fund）在全球范围内的 首次 此类合作。两家公司将向每家精选的初创公司投资至多200万美元，各自出资 最高 100万美元，重点聚焦于从一开始就致力于开发AI产品的创始人。 [图片: 谷歌，google [object Object]<a href="https://pic.chinaz.com/picmap/201811151621147122_90.jpg%5D">https://pic.chinaz.com/picmap/201811151621147122_90.jpg]</a> 此次合作将集中于2026年的Atoms项目，投资领域覆盖创意、娱乐、编程、工作应用等，甚至可能包括基础模型，旨在&quot;为数十亿印度人打造人工智能产品，同时支持在印度开发的面向全球市场的人工智能产品”。Accel合伙人Prayank Swaroop表示，他们还将努力识别未来12-24个月内大型语言模型可能取得进展的领域，并寻找朝这些方向发展的印度初创公司。 尽管印度在 尖端 模型研发方面仍落后于美国和中国，但市场格局正在转变。谷歌看好印度庞大的移动优先用户群体、不断扩展的云基础设施以及雄厚的工程技术人才。谷歌人工智能未来基金联合创始人兼董事乔纳森·西尔伯（Jonathan Silber）强调，选择印度是因为谷歌坚信印度将在下一代AI驱动的全球技术中扮演领导角色，此次合作紧随谷歌近期宣布的150亿美元印度数据中心和AI中心建设计划。 除了资金支持，获得资助的创始人还将获得高达35万美元的Google Cloud、Gemini和DeepMind计算资源，以及Gemini和DeepMind模型、API的早期使用权。该计划还包括来自Google Labs和DeepMind研究团队的支持、联合开发机会、定期指导，以及在伦敦和旧金山湾区举办的沉浸式培训课程。 尽管谷歌将出现在这些初创公司的股权结构表中，但西尔伯和Swaroop均表示， 不会强制要求初创公司 独家 使用谷歌的模型或产品 ，目标在于看到下一波人工智能创新浪潮从印度涌现。</p><p>【15】MrBeast前短视频主管Palo平台，用AI分析加速短视频创作
短视频内容需求的爆炸式增长，正给创作者带来巨大的内容制作和竞争压力。为应对这一挑战，MrBeast的前短视频内容主管杰伊·尼奥（Jay Neo）与前Palantir工程师希瓦姆·库马尔(Shivam Kumar)和哈里·琼斯(Harry Jones)共同创立了Palo平台。该平台旨在利用人工智能和深度分析，帮助创作者了解哪些内容有效，并生成新的创作方向。 源于 顶尖 创作者的经验 年仅18岁就加入MrBeast团队的尼奥，曾负责提升用户留存率，并痴迷于研究用户留存率图表以找出观看量下降的原因。他凭借一段询问路人是否愿意飞去巴黎买法棍的视频，在全平台获得了超过18亿次的播放量，其成功经验随后被MrBeast采纳。 2023年，尼奥离开MrBeast后，与其他合作撰稿人创立了&quot;Creaky”品牌系列频道，并迅速将其月观看量提升至超过10亿次。这段经历让他意识到内容创作与分析的重要性，促使他将积累的洞察转化为面向创作者的产品，并于2024年初开始与联合创始人合作推出Palo。该公司已从Peak XV（前身为红杉印度）旗下的Surge基金筹集了380万美元资金。 [图片: QQ20251125-092433.png [object Object]<a href="https://pic.chinaz.com/2025/1125/6389965948490327881796870.png%5D">https://pic.chinaz.com/2025/1125/6389965948490327881796870.png]</a> AI驱动的创意、分析与社区 Palo应用程序包含三大核心功能: AI驱动的创意和规划工具、分析功能和社区 。创作者只需整合其所有短视频账号，该工具便会分析所有视频表现，并提供受欢迎内容与不受欢迎内容的深入分析。 担任CTO的库马尔表示，Palo使用多种模型提取数据树，其中包含关于&quot;钩子”（Hook）、受众情绪、兴趣主题、原创性以及相关搜索词的见解。推理引擎将这些原始数据点输入 顶级 LLM(逻辑层级模型)进行分层聚合，从而为创作者构建出一个 真实可信、充分了解其品味和风格的人物形象 。 这款人工智能策划工具采用对话式界面，允许创作者询问内容问题，或要求工具根据预设公式生成脚本。对于视觉化表达较多的内容，它甚至可以生成包含不同切入点的分镜脚本。 [图片: QQ20251125-092330.png [object Object]<a href="https://pic.chinaz.com/2025/1125/6389965949540196233744917.png%5D">https://pic.chinaz.com/2025/1125/6389965949540196233744917.png]</a> 定价、挑战与行业思考 Palo目前向拥有10万粉丝的创作者开放其工具， 起价为每月250美元 ，使用频率越高价格越高。在测试阶段，该公司已与约40位拥有百万级用户的创作者进行了合作。 平台投资人乔什·康斯坦丁（Josh Constine）认为，Palo可以帮助创作者应对因算法和趋势而产生的&quot;内容倦怠”，解决拖延症和写作瓶颈。然而，Palo的推出正值AI与内容创作者群体关系日益紧张之际，如何避免创作者养成固定模式是AI工具面临的一大挑战。 尼奥承认，优秀的视频仍源于创作者的直觉，但Palo旨在引导创作者朝着可能成功的方向发展。他将这一过程比作喜剧演员在舞台上尝试新段子，通过每一次演出收集观众反馈并迭代， &quot;我们相信人工智能也能为创作者带来类似的优势。” 创作者Sam Beres（Sambucha）则建议，AI公司应从产品构思阶段就与创作者合作，以避免提供大量无关信息，反而导致创作者陷入&quot;新奇事物综合症”。</p><p>【16】北京出台新政力推医疗器械产业:最高3000万支持大模型开发
北京市经济和信息化局等六部门近日联合印发《北京市促进医疗器械产业高质量发展若干措施》，旨在通过数据要素流通和AI大模型赋能，全面推动医疗器械产业升级。政策的核心举措聚焦于数据基础设施建设和行业大模型开发。 措施提出，要加快推进医疗健康行业高质量数据集建设，并完善相关数据流通政策，以促进数据安全合规应用，响应医疗器械制造企业和科研院所的需求;同时，政策明确支持企业在数据基础制度先行区内搭建数据治理服务平台，并对达到一定服务能力的平台建设给予支持。 [图片: AI 医疗 [object Object]<a href="https://pic.chinaz.com/picmap/202307181418295015_2.jpg%5D">https://pic.chinaz.com/picmap/202307181418295015_2.jpg]</a> 为鼓励技术创新和跨界合作，北京市将重金激励行业大模型的开发:鼓励医疗器械企业联合大模型企业共同开发和部署行业大模型，对于达到国内一流、国际领先水平的项目，北京市将按照其算力成本给予资金支持， 最高 不超过3000万元。 此举体现了北京市利用前沿技术，特别是生成式AI和数据要素，来抢占医疗器械产业高端发展制高点的决心。</p><p>【17】库克明年上半年退休？古尔曼直言&quot;假消息”，OpenAI狂挖苹果40+硬件人才成焦点
彭博知名苹果爆料人马克·古尔曼在 最新 《Power On》通讯中明确辟谣:&quot;苹果CEO蒂姆·库克将在明年1-6月之间退休”纯属虚假报道，他称若消息属实&quot;自己会感到震惊”，并强调除非出现重大意外，否则库克短期内不会离职。 接班动态 古尔曼证实，硬件工程 高级 副总裁约翰·特努斯仍是&quot;接班讨论”核心人选——其年仅50岁、任期潜力最长，且深度参与iPhone、Mac、Vision Pro等关键项目，深受库克信任;但相关交接并未加速，董事会亦未设定具体时间表。 OpenAI&quot;扫荡式”挖角 与此同时，OpenAI在过去一个月里从苹果挖走40+名硬件人才，涵盖相机、iPhone、Mac、芯片、测试与可靠性、工业设计、音频、Vision Pro、软件及人体工程学等几乎所有关键部门，多位 高级 经理与主管级工程师加盟。 - 背景:OpenAI收购前苹果设计主管Jony Ive的io公司，正为2026年AI硬件首秀储备团队; - 苹果内部已将此现象上升到&quot;问题”层面，担忧硬件核心知识外流。 离职潮信号 苹果基层离职亦在加剧:iPhone Air主设计师阿比杜尔·乔杜里上周宣布跳槽AI初创，显示&quot;为苹果低薪工作”已不再是硅谷主流选择。古尔曼总结:高管层虽稳，但关键人才流失或迫使苹果加快股权激励与AI业务重组，以应对日益激烈的AI硬件竞争。</p><p>【18】三星将 Perplexity AI 集成 Bixby，模仿苹果 AI 战略
随着科技巨头们不断推进人工智能技术的发展，三星也在积极跟进。近日，有消息称，三星将在即将发布的 Galaxy S26 系列中，将 Perplexity AI 的技术整合进其语音助手 Bixby。这一举措与苹果为其 Siri 助手引入多模型 AI 策略的做法相似，标志着三星在 AI 领域的进一步布局。 据知名爆料人士 @chunvn8888 在社交平台 X 发布的信息，新的 Bixby 将继续负责处理简单的本地任务，比如调节设备设置和执行基础系统操作。然而，涉及复杂推理或生成内容的请求，则将由 Perplexity AI 来处理。这样，Bixby 和 Perplexity 之间的分工可以提高语音助手的整体性能，用户体验也将得到显著提升。 目前，苹果已经通过其 Apple Intelligence 将简单任务交给本地模型完成，而复杂的推理与生成任务则依赖于 OpenAI 的 ChatGPT。这种策略的成功促使三星选择与 Perplexity 进行合作。 三星计划在 S26 系列发布会上 首次 展示集成 Perplexity 的 Bixby，届时，用户将能体验到更为智能的语音助手。基础任务由 Bixby 处理，而复杂的推理和需要深思熟虑的问题则交给 Perplexity 应对。虽然苹果在某些 高级 AI 应用上依赖外部合作伙伴，但内部对自研大语言模型（LLM）的投入也十分可观，目标是在 2026 年推出基于云的复杂推理模型。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/11/25 AI 日报 今日摘要 【1】TrendRadar 🎯 告别信息过载，AI助你轻松掌握新闻热点——简易舆情监控分析系统。集成多平台热点聚合与基于MCP的AI分析工具，覆盖35个主流平台（抖音/知乎/B站/华尔街见闻/财联社等），具备智能筛选+自动推送+AI对话分析功能（支持自然语言深度挖掘：趋势追踪、情感分析、相似检索等13种工具）。支持企业微信/个人微信/飞书]]></description>
        </item>
      
  </channel>
</rss>