<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI洞察日报 RSS Feed</title>
    <link></link>
    <description> 近 7 天的AI日报</description>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 29 Dec 2025 02:34:27 GMT</lastBuildDate>
    <atom:link href="https://yxxxxx1-ai-daily.gunzhao59.workers.dev/rss" rel="self" type="application/rss+xml" />
    
        <item>
          <title><![CDATA[2025-12-29日刊]]></title>
          <link>/2025-12/2025-12-29/</link>
          <guid>/2025-12/2025-12-29/</guid>
          <pubDate>Mon, 29 Dec 2025 10:34:26 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/29</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】zapret-discord-youtube</p><p>【2】Mole
🐹 深度清理并优化你的Mac。</p><p>【3】Python
所有算法均用Python实现</p><p>【4】zapret-discord-youtube-linux
（目前仅支持NFTABLES）从Flowseal和bol-van移植zapret-discord-youtube，便于在Linux上使用</p><p>【5】vibe-kanban
让Claude Code、Codex或任何编程助手效率提升10倍</p><p>【6】RustPython
用Rust编写的Python解释器</p><p>【7】AI 初创公司 Scribe 获 7500 万美元融资，估值达到 13 亿美元
近日，AI 初创公司 Scribe 宣布获得7500万美元的融资，公司的估值已达到13亿美元。Scribe 旨在帮助企业更有效地采用人工智能，通过分析公司工作流程，提供改进建议，进而提升效率。Scribe 的工作原理是记录用户在浏览器或桌面应用中的操作，并生成可共享的文档，从而简化团队协作和培训过程。 [图片: 投资，融资，钱 [object Object]<a href="https://pic.chinaz.com/picmap/201901101704279841_1.jpg%5D">https://pic.chinaz.com/picmap/201901101704279841_1.jpg]</a> 该公司的产品 Scribe Capture 能够捕捉专业员工的工作方式，通过自动化生成文档，帮助企业快速创建标准操作程序（SOP）。这一功能不仅能节省时间，还能降低员工培训的难度，使新员工更快上手。Scribe 表示，其数据库中已经积累了超过1000万个工作流程，这些数据将为新客户提供参考，助力他们改善自身业务。 尽管 Scribe 的服务吸引了众多企业的关注，但也引发了对于数据隐私的担忧。许多评论者质疑，企业是否真的清楚自己的数据会被用来帮助竞争对手，甚至有观点认为这可能涉及到商业道德的问题。然而，Scribe 的团队强调，他们在与客户签署合同时，确保客户的内部数据不会被滥用。 划重点: 🌟 Scribe 获得7500万美元融资，估值达到13亿美元。 📈 公司分析工作流程，帮助企业提高效率和协作。 🔒 数据隐私引发关注，Scribe 承诺保护客户内部数据安全。</p><p>【8】几分钟拼出视频AI应用！开源框架VideoPipe让CV落地如搭积木般简单
近日，一款专注于计算机视觉（CV）领域AI算法快速集成落地的开源视频分析框架VideoPipe，在开发者社区引发热议。该框架以其创新的管线设计和极简上手体验，成为视频AI应用开发的&quot;加速器”，帮助开发者从繁琐的底层编码中解放出来，专注于业务逻辑实现。 VideoPipe的核心设计:可组合管线，模块化拆解任务 VideoPipe采用独特的管道（Pipeline）架构，将复杂的视频分析任务分解为一系列独立的&quot;节点”(Node)。每个节点负责单一功能，如拉流、解码、推理或推流等，节点之间相互独立，却可自由组合搭配。这种插件式设计，让开发者像搭积木一样构建应用，无需从零编写完整流程。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259811605428404888937.png%5D">https://pic.chinaz.com/2025/1229/6390259811605428404888937.png]</a> 据框架文档介绍，只需准备好AI模型并解析其输出，即可通过简单配置快速组建管道。相比传统框架依赖重、调试难的问题，VideoPipe依赖极少、跨平台支持出色，更易移植到不同硬件环境。 多源输入与协议支持:无缝接入主流视频流 VideoPipe在数据读取方面表现出色，支持多种主流视频流协议，包括UDP、RTSP、RTMP，以及本地文件和应用程序图像输入。这使得框架适用于实时监控、流量摄像机等场景，能轻松处理网络流媒体或离线视频数据。 此外，它还兼容图片序列输入，扩展了在静态图像搜索或混合媒体分析中的应用潜力。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259813645275101850616.png%5D">https://pic.chinaz.com/2025/1229/6390259813645275101850616.png]</a> 多样化推理引擎:深度学习+传统算法+多模态大模型 框架的 最大 亮点在于算法推理的灵活性。它支持深度学习模型的多级级联推理，同时兼容传统图像处理算法（如OpenCV经典方法）。更值得一提的是，VideoPipe已集成多模态大模型支持，允许开发者将前沿大语言视觉模型无缝嵌入视频处理流程中。 内置多种目标跟踪算法，确保在视频中对特定对象进行持续追踪，适用于动态场景下的精准分析。 全链路一条龙:从拉流到推流，一站式覆盖 VideoPipe几乎覆盖了视频AI应用的完整链路:拉流解码 → 多级推理 → 目标跟踪 → 行为分析 → 画框标注 → 录屏截图 → 编码推流 → 消息通知。开发者只需&quot;缺哪块补哪块”，几分钟内即可拼出一个功能完整的视频AI原型。 典型应用场景包括: - 视频结构化处理 - 图像检索与搜索 - 人脸识别与追踪 - 交通事件检测（如违章识别、逆行监测） - AI换脸等创意应用 - 安防监控与行为分析 社区反馈积极:40+示例助力快速上手 VideoPipe提供超过40个现成示例，涵盖人脸识别、车辆检测、姿态估计等热门场景，配套详细文档和视频教程。近期社区分享显示，许多开发者利用该框架快速实现了智能监控原型和交通分析系统，极大缩短了从概念到落地的周期。 AIbase观点:在AI视频分析领域，VideoPipe的出现降低了工程门槛，让更多中小团队和个人开发者能高效落地CV应用。随着多模态大模型的集成，其潜力还将进一步释放。感兴趣的开发者可访问GitHub仓库（sherlockchou86/VideoPipe）星标体验。 项目地址：<a href="https://github.com/sherlockchou86/VideoPipe">https://github.com/sherlockchou86/VideoPipe</a></p><p>【9】NVIDIA 发布 NitroGen：开创游戏代理的视觉行动基础模型
NVIDIA 的人工智能研究团队近日推出了 NitroGen，这是一款针对通用游戏代理的开放视觉行动基础模型。NitroGen 能够从网络视频中直接学习如何通过游戏画面和手柄操作来玩商业游戏，整个模型经过40，000小时的游戏体验训练，覆盖了超过1，000款游戏，同时还提供了开放数据集、通用模拟器和预训练策略。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259785901648171941505.png%5D">https://pic.chinaz.com/2025/1229/6390259785901648171941505.png]</a> NitroGen 的构建流程始于公开的游戏视频，这些视频包含输入叠加层，如游戏手柄的可视化。研究团队收集了71，000小时的原始视频，经过质量过滤后，最终得到40，000小时的精选数据，涵盖了818位创作者的38，739个视频。数据显示，这些视频跨越846款游戏，其中34.9% 的游戏时间来自动作角色扮演类游戏，18.4% 来自平台类游戏，9.2% 来自动作冒险类游戏，剩余则涵盖了体育、 roguelike、赛车等多个类别。 在提取每帧动作的过程中，NitroGen 使用了三阶段的提取流程。首先，系统通过300个控制器模板定位手柄叠加层。接着，使用基于 SegFormer 的分类分割模型解析手柄区域，最后对坐标进行精细化处理。这一流程确保了动作预测的准确性，使得 NitroGen 能够有效进行大规模行为克隆。 此外，NitroGen 还配备了一个通用模拟器，它能够将商业 Windows 游戏包装为兼容 Gymnasium 的接口，支持逐帧互动，且无需修改游戏代码。这使得 NitroGen 可以在多个游戏中直接应用同一策略。 NitroGen 采用了基于 Diffusion Transformer 的策略架构，该模型在256×256分辨率的 RGB 图像上运行。经过预训练后，NitroGen 在多个任务上展现了良好的零 - shot 评估能力，任务完成率在45% 至60% 之间。该模型的预训练使其在迁移到新游戏时，表现出显著的性能提升，相较于从头训练，提升幅度可达52%。 huggingface:<a href="https://huggingface.co/nvidia/NitroGen">https://huggingface.co/nvidia/NitroGen</a> 划重点: 📊 NitroGen 是一款开放视觉行动基础模型，能够从网络视频中直接学习游戏操作。 🎮 数据集涵盖40，000小时游戏视频，覆盖超过1，000款游戏。 🚀 预训练的 NitroGen 在新游戏中的表现显著提升，相较于从头训练有高达52% 的性能改善。</p><p>【10】智谱 GLM-4.7 横扫编程大赛，重塑开源 AI 未来！
年底的科技圈再度掀起波澜，智谱科技 最新 推出的 GLM-4.7模型不仅在代码竞技场的 WebDev 榜单上超越了 GPT-5.2，荣登开源大模型 第一 ，还引发了网友们的热烈讨论和实测狂潮。这个被称为 &quot;Claude Code 最佳 平替” 的国产模型，以其卓越的编程表现和灵活的应用能力，让人眼前一亮。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259710184018643719621.png%5D">https://pic.chinaz.com/2025/1229/6390259710184018643719621.png]</a> 智谱团队在一次 AMA（Ask Me Anything）活动中，详细揭示了 GLM-4.7的技术进步之道。团队表示，GLM-4.7的成功得益于后训练阶段的优化，特别是在监督微调(SFT)和强化学习(RL)方面，采用了更为精细的发布配方，使得模型在实际应用中的稳定性大幅提升。此外，团队还强调，训练和部署成本是设计的关键考量，他们希望让模型能够在消费级显卡上运行，并保持出色的性能表现。 GLM-4.7的应用场景更是丰富多彩。与之前版本相比，这款模型在多语言编码方面表现优异，支持包括 Python 和 JavaScript 在内的多种编程语言，并在创意写作方面也显得更加灵动。开发者们在调试和执行复杂任务时，GLM-4.7展现出更高的理解力和逻辑能力，甚至在角色扮演任务中也能保持角色一致性，减少 &quot;出戏” 的现象。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259708218013471152284.png%5D">https://pic.chinaz.com/2025/1229/6390259708218013471152284.png]</a> 此外，智谱在 AMA 中宣布开源其自研的 Slime 框架，旨在提升大模型强化学习的效率和稳定性。团队表示，开源生态是他们成长的动力，将继续保持开源承诺，即便在公司上市之后也不会缩减对开源的投入。 通过这些技术革新，智谱 GLM-4.7正逐步展现出国产 AI 模型在国际舞台上的竞争力，赢得了用户的高度认可。随着 AI 技术的快速发展，智谱团队也透露将在明年为人工智能的广泛应用作出更多贡献，值得期待。</p><p>【11】⏳ 纽约 Water Tunnel #3：1954 启动，历经 62 年即将完工
原标题： 《62 years in the making: NYC&#39;s newest water tunnel nears the finish line》 评分: 20 | 作者: eatonphil 💭 修了 62 年才接近完工，这是奇迹还是预算黑洞？ 🎯 讨论背景 Water Tunnel #3（纽约市第三供水隧道）是一个分段、多年代施工的大型基础设施项目，最早在 1954 年启动，目的是为城市提供更可靠、冗余的输水路径。讨论基于工程学与城市规划的前提，集中在为何要在深处穿越基岩（以避免软土问题）、如何保证水流（重力坡降 versus 泵站）、以及跨河和绕行现有地下设施的设计权衡。评论还提到该隧道部分段已向曼哈顿和布朗克斯供水，最终段将把服务扩展到布鲁克林与皇后区，官方预计 2032 年完成最后阶段。公众把该长期工程与流行文化（如电影 Die Hard 第三部）和其他高成本项目（如 CA HSR，即加州高铁）作比较，表达既惊叹又质疑的混合情绪。 📌 讨论焦点 长期工程历史与流行文化 评论指出该工程始于 1954 年，标题中的&quot;62 years in the making”与有人称之为&quot;70 year old project”的说法一致，凸显项目跨代的长期性。多条评论以电影引用放大这一点：第三部《Die Hard》曾以该隧道为场景，成为公众记忆中的文化注脚。这种文化联想被用来表达对工程历时、历史沉淀以及大众关注度的惊讶与戏谑。 [来源1] [来源2] [来源3] [来源4] 工程与地质理由（深度、坡度与输水方式） 核心讨论围绕为何隧道深埋（约 800 英尺）与输水方式：回复指出深度主要用于穿越基岩（bedrock），以减少软土引起的沉降、渗漏和施工并发症，从而提高隧道的长期稳定性。评论还强调这是约 60 英里的输水干线，水流要么依靠重力坡降（hydraulic gradient）要么依赖泵站；有人推测因供水水库接近海平面，部分路段必须更深以跨越河道或城市地下结构。具体数值被拿来比较以说明坡度影响：密西西比河梯度约 0.01% ，与讨论中假设的 0.25% 相差 25 倍，这展示了坡度对是否需要泵和设计复杂度的直接影响；原问题关于随深度增加的钻掘能量与成本也被提出但未给定精确比例，讨论以工程可持续性为核心理由。 [来源1] [来源2] [来源3] [来源4] 项目现状与完工进度 评论信息表明工程已分段投入使用：布朗克斯（Bronx）和曼哈顿已从 Water Tunnel #3 取水，但最后一段将服务布鲁克林与皇后区仍在施工中，官方预计该最终阶段将在 2032 年前完成。有人提到施工曾在十年前一度停工并后来重启，因此公众对重启进度、资源调配与时间表保持关注。评论里还有对在最终段注水、隧道封闭前能否开放参观的期待，反映公众对这一工程可见性的兴趣。 [来源1] [来源2] 戏谑与高成本对比 多位评论以讽刺和玩笑回应工程的时间与成本：有人提到若重拍《Die Hard》应加入 CA HSR（加州高铁）式的昂贵基础设施桥段以凸显代价。简短调侃诸如&quot;Die Hard: The most expensive mile”之类的表述把公众对大规模基建长期耗时与高成本的不满和幽默反应结合起来。这类评论既是对工程规模的感慨，也是对预算与效率的隐含质疑。 [来源1] [来源2] [来源3] 📚 术语解释 Water Tunnel #3: 纽约市第三供水隧道（Water Tunnel No. 3），是分阶段建设的大型输水工程，旨在为多个行政区提供更可靠的水源通道，工程始于 20 世纪中期并分段投入使用，最终段计划在 2032 年前完成。 bedrock（基岩）: 位于土层下的坚硬岩体，隧道穿越基岩可减少沉降与渗水风险并提高衬砌稳定性，但钻掘和掘进成本通常更高且技术要求更大。 hydraulic gradient（水力坡降 / 下坡坡度）: 单位距离的水头差决定重力驱动流动的能力；坡降越小需要的落差或泵站越多，评论中以密西西比河约 0.01% 与讨论中的 0.25% 比较来说明坡度对设计和是否需泵的影响。 类别： Policy | Science | Water Tunnel #3 | New York City | NYC Department of Environmental Protection | NY1 | water tunnel | bedrock | Manhattan | Brooklyn | Queens | Bronx</p><p>【12】​以简胜繁:Meta AI 推出 Pixio 图像模型，凭借像素重建刷新3D 重建纪录
据 AIbase 报道，Meta AI 的研究团队近日发布了一项名为 Pixio 的图像模型研究，证明了即使采用更简单的训练路径，也能在深度估计和3D 重建等复杂视觉任务中展现出卓越的性能。长期以来，学术界普遍认为掩码自编码器（MAE）技术在场景理解上逊色于 DINOv2或 DINOv3等复杂算法，但 Pixio 的出现打破了这一固有认知。 [图片: QQ20251229-091312.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259643186984376940473.png%5D">https://pic.chinaz.com/2025/1229/6390259643186984376940473.png]</a> Pixio 的核心逻辑源于对2021年 MAE 框架的深度改良。研究人员发现，原始设计中较弱的解码器限制了编码器的表现，因此他们显著增强了解码器的功能，并扩大了图像遮罩区域。通过将细小的遮罩方块改为大面积连续区域，Pixio 被迫放弃简单的像素复制，转而必须真正&quot;理解”图像中的物体共现、3D 透视以及反射等空间关系。此外，通过引入多个用于聚合全局属性的类别标记，该模型能更精准地捕捉场景类型、相机角度及光照信息。 [图片: QQ20251229-091319.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259644029938178427847.png%5D">https://pic.chinaz.com/2025/1229/6390259644029938178427847.png]</a> 在训练策略上，Pixio 展现出 极高 的纯粹性。不同于 DINOv3针对特定基准测试（如 ImageNet）进行重复优化，Pixio 从网络收集了20亿张图像，并采用动态频率调整:减少简单产品照的权重，增加复杂场景的训练频次。这种不针对测试集&quot;刷分”的做法，反而赋予了模型更强的迁移能力。 [图片: QQ20251229-091337.png [object Object]<a href="https://pic.chinaz.com/2025/1229/6390259645040772726545844.png%5D">https://pic.chinaz.com/2025/1229/6390259645040772726545844.png]</a> 数据对比显示，仅拥有6.31亿参数的 Pixio 在多项指标上超越了8.41亿参数的 DINOv3。在单目深度估计中，其准确率提升了16%;在3D 重建任务中，仅凭单张图像训练的 Pixio 甚至优于使用八视角训练的 DINOv3。同时，在机器人学习领域，Pixio 也以78.4% 的成功率领先于 DINOv2。尽管研究团队承认人工掩蔽存在局限性，并计划向视频预测方向探索，但 Pixio 目前取得的突破已足以证明:回归像素重建的本质，往往能通向更深层的视觉理解。</p><p>【13】当我们把思考外包给 AI，我们失去了什么？ 你有没有发现，自己正在变成一个机器人观点的专业验证员？ 微软研究院的 Advait Sarkar 在一场 TED 演讲中抛出了这个...
当我们把思考外包给 AI，我们失去了什么？ 你有没有发现，自己正在变成一个机器人观点的专业验证员？ 微软研究院的 Advait Sarkar 在一场 TED 演讲中抛出了这个扎心的问题。他描绘了一幅我们都很熟悉的场景：早上到办公室，邮件太多，让 AI 总结一下；报告不知道怎么写，丢点资料让 AI 起草；数据要分析、PPT 要做、代码要写——全都交给 AI。 这不是科幻，这是我们的日常。 Sarkar 给这个时代起了个名字：理性外包的时代 (the age of outsourced reason)。我们不再直接接触工作的原材料，而是变成了「智力游客」，在自己的工作中，我们只是参观观点，而非栖居其中。 四重隐性代价 Sarkar 引用了一系列研究，揭示了这种工作方式的认知代价： 1、创造力在萎缩。 研究表明，使用 AI 助手的知识工作者，集体产出的想法范围比手动工作的小组更窄。我们创造了一个蜂巢思维，但这个蜂巢很无聊，总是重复建议那几个想法。 2、批判性思维在偷懒。 当人们对 AI 越信任、对自己越不信任时，他们在批判性思维上投入的精力就越少。我们不再质疑，只是点头。 3、记忆力在退化。 依赖 AI 写作时，人们对自己写的内容记得更少；阅读 AI 摘要时，记住的也比读原文少。 4、元认知在超载。 以前直接处理材料时，「该怎么做」是内置在过程中的。现在我们要不断思考：这个任务适合让 AI 做吗？AI 的输出对不对？我该怎么评估？ Sarkar 用了一个精准的比喻：我们变成了自己思想的「中层管理者」，不再动手做事，只是审批和转发。 他还说了一句让我印象深刻的话：以前的写作障碍是对着空白页发呆；现在是对着 AI 填满的页面发呆，还得琢磨自己同不同意它的观点。 思维工具，而非服从的助手 问题来了：难道我们要放弃 AI 吗？ 当然不是。Sarkar 提出的方案是重新定义 AI 的角色，AI 应该成为「思维工具」，而不是助手。AI 应该挑战我们，而不是服从我们。 他和团队开发了一个原型工具来演示这种范式。在这个工具里，一位叫 Clara 的知识工作者需要写一份提案。但他的工作方式和我们习惯的丢资料给 AI 写完全不同： - 他看到的不是简单的摘要，而是可定制的「透镜」，能强调与当前任务最相关的内容； - 他在阅读时会看到 AI 生成的「激发项」，不是补全他的想法，而是提出替代方案、识别谬误、提供反驳论点； - 他手动构建论点大纲，保持与源文档的深层连接； - 最后生成的文本虽然是 AI 写的，但深深植根于他自己的思考过程 Sarkar 特别指出：在这个界面里找不到聊天框。Clara 不需要和任何东西聊天来完成工作，他是作为计算机的用户被辅助着，而不是面对一个伪人类。 三个设计原则 这套方案背后有三个核心原则，我认为对每一个使用 AI 的人都有启发： 1. 保留材料接触 Clara 仍然亲自阅读了文档的相关部分，亲自构建了决策和论点。AI 帮他更快、更有策略地阅读，但没有替代阅读本身。 这意味着什么？当你用 AI 分析一份报告时，不要只看 AI 给你的摘要。至少挑出 AI 标记为重要的 2-3 个段落，自己读一遍。当你用 AI 写代码时，不要只是复制粘贴，花几分钟理解它的逻辑。 保留材料接触，是为了保留你与工作之间的直接关系。否则，你只是在「参观」自己的工作，而不是「拥有」它。 2. 提供生产性阻力 传统 AI 助手的设计逻辑是「顺从」，你说什么，它就做什么。但 Sarkar 的原型里，AI 会主动提出挑战：这个论点有什么漏洞？有没有考虑过相反的观点？这个假设成立吗？ 这些激发项不是为了让你照单全收。Sarkar 说得很好：如果你对工作理解得足够深，能自信地决定不接受某条反馈，那么反馈机制依然在按预期运作。 被挑战本身就是价值所在。 在日常使用中，你可以主动要求 AI 扮演这个角色：「请指出我这个方案的三个潜在问题」、「如果有人反对这个观点，他们会怎么说？」。 3. 搭建元认知支架 元认知就是「思考自己的思考」。当我们直接处理材料时，这个过程是自然发生的，你写着写着会停下来想「我到底要说什么」。但当 AI 介入后，这个过程被打断了，我们反而要花更多精力在管理 AI 而不是思考问题上。 好的思维工具应该帮你重建这个支架。在 Clara 的工作流里，每一阶段的激发项都让他保持元认知层面的参与，时刻意识到自己在做什么、为什么这么做、还有什么没考虑到。 你可以借鉴这个思路：在使用 AI 完成一个任务后，花 30 秒问自己三个问题：我真的理解这个输出吗？我同意它的逻辑吗？如果要向别人解释，我能说清楚吗？ [图片: <a href="https://pbs.twimg.com/media/G9TGpqMaIAAc7VG?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9TGpqMaIAAc7VG?format=jpg&#x26;name=orig]</a></p><p>【14】运气 = 深入做事 × 广泛分享 来自 GitHub ReadME Project 的指南，由 Tuple 公司的营销工程师 Aaron Francis 撰写。核心观点是：通过公开分享你的工作（尤其是...
运气 = 深入做事 × 广泛分享 来自 GitHub ReadME Project 的指南，由 Tuple 公司的营销工程师 Aaron Francis 撰写。核心观点是：通过公开分享你的工作（尤其是开源项目、学习心得或创作过程），你可以显著增加&quot;运气”降临的机会。这里的&quot;运气”指那些意外的积极事件，如开源库突然流行、收到演讲邀请、找到新工作或结识行业朋友，我自己也非常认同！ 1. 先要做事 发布的前提是有内容可分享。大多数开发者已经擅长这一步，但有两类人可能卡住： · 觉得自己工作不值得分享：专家常低估自己的知识。建议观察社区，看看别人分享什么就能发现机会——很多人正需要你已经掌握的知识。 · 想开始却无从下手：建议立即从小事开始，今天就行动。动力会带来更多动力。 从哪里找内容？ · 工作之外：跟随好奇心，公开探索感兴趣的话题（好奇心具有传染性）。 · 工作之中：将遇到的难题、模式或心得转化为可分享的内容（如博客、演讲、开源代码）。建议平时记录工作中的&quot;困惑点”，一个月后就会积累大量素材。注意：不是分享公司机密，而是通用概念和经验教训。 2. 敢于发布 很多人卡在这一步，原因是恐惧：怕被嘲笑、怕作品不完美、怕显得自夸，或单纯讨厌&quot;营销”。 作者的建议： · 审视自己的恐惧：分享不是自大，而是帮助他人学习、激发创作。 · 人们更喜欢看到&quot;正在行动的人”，而不是完美成果。 · 发布平台：X（AI 聚集地）、GitHub、Newsletter、Blog、YouTube、播客、论坛等——总之，别让作品只留在自己硬盘上。 · 发布是一项技能：需要练习。不要等完美，先分享过程、成功与失败。刚开始会觉得别扭，坚持下去就自然了。 3. 收获运气 当你持续做事并公开分享时，好事自然发生： · 别人会把你视为某个领域的&quot;代表人物”。 · 收到邮件、DM：工作机会、咨询邀请、演讲请求、结识新朋友。 · 开源项目获得关注和贡献。 这听起来简单，但做起来不容易——公开意味着可能面对批评。但作者强调：负面声音总是少数，更多人是默默欣赏你的勇气。其中一人伸出的机会，就可能改变人生。你会感慨：&quot;哇，运气来了！” 博客地址 <a href="https://github.com/readme/guides/publishing-your-work">https://github.com/readme/guides/publishing-your-work</a> [图片: <a href="https://pbs.twimg.com/media/G9TIMV5bkAAlnXZ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9TIMV5bkAAlnXZ?format=jpg&#x26;name=orig]</a> Garry Tan: If you build it, don’t forget to publish it <a href="https://github.com/readme/guides/publishing-your-work">https://github.com/readme/guides/publishing-your-work</a></p><p>【15】「Context Graphs」关乎未来万亿级 AI 平台，那我们应该如何构建它呢？ 作为「AI’s trillion-dollar opportunity: Context graphs」的实践构建篇，PlayerZero ...
「Context Graphs」关乎未来万亿级 AI 平台，那我们应该如何构建它呢？ 作为「AI’s trillion-dollar opportunity: Context graphs」的实践构建篇，PlayerZero 创始人 Animesh Koratana 这篇长文证明我们需要构建一个新层：捕捉决策过程的&quot;上下文图”，让 AI 能访问从数据到行动的完整推理痕迹，从而形成可积累的组织智能。 如何实际构建这样的上下文图？不是简单添加内存或工具，而是需要从根本上重新思考数据和决策的捕捉方式。上下文图本质上是组织的&quot;世界模型”，它通过积累 AI Agents 的执行轨迹，来学习组织的动态结构和决策规律，先看总结的三个关键点： · 重建事件时钟（捕捉推理而非仅状态） · 让本体从 Agents 轨迹中自然输出（结构嵌入而非语义嵌入） · 转向世界模型而非检索系统（支持模拟和反事实推理） 1. &quot;两个时钟问题” 当前所有企业系统都只优化了&quot;状态时钟”：记录当前事实（如交易关闭、配置值）。但忽略了&quot;事件时钟”：记录事情如何发生、为什么发生、决策背后的推理。 · 比如：代码配置从5秒超时改为30秒，系统只记录当前值，却丢失了&quot;为什么改”的讨论。 · 后果：人类过去通过对话重建上下文，但AI缺乏这些&quot;为什么”，导致决策缺乏先例支持。 · 难点： · 系统不完全可观测（黑箱、第三方服务）。 · 无通用本体（每个组织实体和关系不同）。 · 一切都在变化（动态环境）。 传统知识管理（如文档检索）失败的原因，就是只处理静态状态，而非动态过程。 2. &quot;Agents 作为有指导的漫游者” 构建上下文图的关键不是预定义静态图结构，而是让 AI Agents 在解决问题时自然&quot;遍历”组织状态空间。 · Agents 执行任务时，会访问各种系统、API、数据，形成一条&quot;轨迹”。 · 这些轨迹类似于图嵌入学习中的&quot;随机漫游”：通过大量漫游，统计共现模式，就能自动学习图的结构。 · 不同之处：Agents 的漫游是&quot;有指导的”，偏向真实重要的问题路径，更高效地揭示组织本体。 · 结果：不需要提前定义 schema，本体从使用中浮现。实体共现频繁的即重要；路径相似的即结构等价。 · 经济闭环：Agents 解决有价值的问题产生轨迹 → 轨迹改善上下文 → 上下文让 Agents 更强 → 更多部署。 3. &quot;上下文图是组织的世界模型” 积累足够轨迹后，上下文图不再是简单检索系统，而是成为组织的&quot;世界模型”： · 编码&quot;组织物理学”：决策如何传播、例外如何处理、变更的连锁效应等。 · 支持模拟：预测&quot;如果这样做，会发生什么？”。 · 示例：在 PlayerZero 中，他们用积累的生产问题轨迹构建模型，模拟代码变更对生产的影响，预测故障模式和受影响客户。 · 更深层含义：这避免了&quot;持续学习”的难题。 · 替代方案：保持基础模型固定，通过不断扩展世界模型来&quot;伪学习”，用推理时计算模拟未来、评估行动。 这类似于资深员工的直觉：不是模型变聪明，而是内部世界模型更丰富，能预判结果。 [图片: <a href="https://pbs.twimg.com/media/G9TF8PebQAAb9DB?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9TF8PebQAAb9DB?format=jpg&#x26;name=orig]</a> Jaya Gupta: Part 2: How to build a context graph</p><p>【16】Nano Banana这波真的是给图文营销带来了很多不一样的机会 比如做到店流量的 店家上传自己的实拍门店照片 ai就能基于这些实体背景 加个美女 小红书上就能跑流量 ...
Nano Banana这波真的是给图文营销带来了很多不一样的机会 比如做到店流量的 店家上传自己的实拍门店照片 ai就能基于这些实体背景 加个美女 小红书上就能跑流量 弄两三个水军问问这是在哪儿 做一个置顶评论就引流了 2年前comfyui想搞这种东西 做几十个节点多重处理都费劲 已经营销素材自由了</p><p>【17】Jim Fan 的「机器人领域 2025 年三点经验」 作为 NVIDIA 资深研究科学家、通用具身智能研究团队负责人，Jim Fan 在机器人和具身智能领域具有重要影响力。他以节...
Jim Fan 的「机器人领域 2025 年三点经验」 作为 NVIDIA 资深研究科学家、通用具身智能研究团队负责人，Jim Fan 在机器人和具身智能领域具有重要影响力。他以节日轻松语气分享了对机器人研究&quot;狂野西部”现状的焦虑与反思，总结了 2025 年亲身经历的三点关键教训。 第一点：硬件领先于软件，但硬件可靠性严重制约软件迭代速度 当前，人形机器人硬件已取得显著进步，例如 Tesla Optimus、Boston Dynamics 电动 Atlas、Figure 系列、1X NEO、Unitree G1 等前沿机型在机械设计、关节灵活性和运动能力上表现出色。这些硬件的物理潜力往往超出当前 AI 控制能力的极限——&quot;身体比大脑更强大”。 然而，实际研发中，硬件的脆弱性成为最大痛点：机器人容易过热、电机损坏、固件故障频发，与人类不同，它们无法自我修复。小错误可能导致永久损伤，每次实验都需要专业团队维护。这大大降低了 AI 模型的迭代速度：软件训练需要大量真实数据和反复试错，但硬件问题使实验成本高昂、周期漫长。Jim Fan 感慨，只有自己的&quot;耐心”实现了规模化增长。这反映了 2025 年机器人领域的普遍挑战：硬件工程精湛，但可靠性仍需大幅提升，以支持高效的软件开发循环。 第二点：机器人基准测试仍是一场灾难 在 LLM 领域，MMLU、SWE-Bench 等标准化基准已成为共识，推动了公平比较和进步。但机器人领域远未达到这一水平：硬件平台、任务定义、评分标准、模拟器 vs. 真实环境等均无统一规范。 结果是，每个团队或公司往往自行定义&quot;基准”，并在新闻发布时宣称 &quot;SOTA”。演示视频通常从上百次尝试中挑选最完美的片段，缺乏可重复性和科学严谨性。这导致行业进步难以量化，容易陷入炒作而非实质创新。Jim Fan 呼吁 2026 年机器人社区共同努力，建立更规范、可复现的基准体系，将科学纪律置于首位。 第三点：基于 VLM 的 VLA 模型方向可能有误 VLA（视觉-语言-行动模型）是当前机器人&quot;大脑”的主流范式：取预训练的 VLM（视觉-语言模型），在其上添加行动输出模块，实现从图像+语言指令直接生成机器人动作。 但 Jim Fan 认为这一路径存在根本问题： · VLM主要针对视觉问答等基准优化，大量参数用于语言知识和高层次语义理解，而非物理世界低级细节。 · 视觉编码器在训练中主动丢弃细粒度信息，但机器人灵巧操作高度依赖这些细节。 因此，随着 VLM 参数规模扩大，VLA 性能未必线性提升——预训练目标与机器人控制需求不匹配。 他更看好&quot;视频世界模型”作为预训练目标：通过预测视频序列学习物理动态、因果关系和低级视觉细节，更适合生成机器人策略。这是一种对未来方向的重大押注，暗示需从基础预训练范式上重新思考。 [图片: <a href="https://pbs.twimg.com/media/G9TC1ApWUAArhWQ?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9TC1ApWUAArhWQ?format=jpg&#x26;name=orig]</a> Jim Fan: Everyone&#39;s freaking out about vibe coding. In the holiday spirit, allow me to share my anxiety on the wild west of robotics. 3 lessons I learned in 2025. 1. Hardware is ahead of software, but hardware reliability severely limits software iteration speed. We&#39;ve seen exquisite [图片: <a href="https://pbs.twimg.com/media/G9Rk1T9bMAE_l5V?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9Rk1T9bMAE_l5V?format=jpg&#x26;name=orig]</a></p><p>【18】最近看了下 Cloudflare 的 2025 年互联网年度回顾，还挺有意思的。 生成式 AI 这块，Claude、Perplexity、Gemini 已经实打实地站到了 ChatGPT 的对面，不再是备...
最近看了下 Cloudflare 的 2025 年互联网年度回顾，还挺有意思的。 生成式 AI 这块，Claude、Perplexity、Gemini 已经实打实地站到了 ChatGPT 的对面，不再是备选方案。 社交平台这边，在 Facebook、Instagram、TikTok 之后，Snapchat 的整体表现已经超过了 X，而所谓的元宇宙里，Roblox 依然是那个最稳的。 整体来看，Google 还是第一，但 Instagram 和 YouTube 在 2025 年都挤进了前十。 Tw93: Cloudflare’s Internet Year in Review 2025 is worth a read. <a href="https://radar.cloudflare.com/year-in-review/2025">https://radar.cloudflare.com/year-in-review/2025</a> A few signals really stand out: Generative AI continued its rapid rise — Claude, Perplexity, and Gemini have clearly emerged as the main rivals to ChatGPT. On social platforms, after Facebook, [图片: <a href="https://pbs.twimg.com/media/G9Qn83vasAAGNFo?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9Qn83vasAAGNFo?format=jpg&#x26;name=orig]</a></p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/29 AI 日报 今日摘要 【1】zapret-discord-youtube 【2】Mole 🐹 深度清理并优化你的Mac。 【3】Python 所有算法均用Python实现 【4】zapret-discord-youtube-linux （目前仅支持NFTABLES）从Flowseal和bol-van移植zapret-discord-youtube，便于在Lin]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-12-28日刊]]></title>
          <link>/2025-12/2025-12-28/</link>
          <guid>/2025-12/2025-12-28/</guid>
          <pubDate>Sun, 28 Dec 2025 10:36:28 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/28</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】Python
所有用Python实现的算法</p><p>【2】Yuxi-Know
结合LightRAG知识库的知识图谱智能体平台。一个集成LightRAG知识库和知识图谱的智能体平台。使用LangChain v1 + Vue + FastAPI构建，支持DeepAgents、MinerU PDF、Neo4j、MCP。</p><p>【3】tunnelto
通过公共URL将您的本地Web服务器暴露到互联网。</p><p>【4】awesome-llm-apps
使用OpenAI、Anthropic、Gemini及开源模型，集成AI智能体和RAG的优质LLM应用合集。</p><p>【5】rendercv
面向学者和工程师的简历生成器，从YAML到PDF</p><p>【6】我需要笔记软件+Chatbot套壳+Editor。 他们在新时代不应该是三个 App。 我本来想把 Chrome 加进来的，想想算了。 理论上打开电脑后，我只需要开两个应用。
我需要笔记软件+Chatbot套壳+Editor。 他们在新时代不应该是三个 App。 我本来想把 Chrome 加进来的，想想算了。 理论上打开电脑后，我只需要开两个应用。</p><p>【7】RT Art Lab: Re @dotey @ykszs017 Alex 是图像这一波人工智能之父。他提供了算法和代码。余下的都是卖东西的。 Alex消失很久了。也没多少人提及他。他没有出席Hi...
RT Art Lab Re @dotey @ykszs017 Alex 是图像这一波人工智能之父。他提供了算法和代码。余下的都是卖东西的。 Alex消失很久了。也没多少人提及他。他没有出席Hinton的诺贝尔奖晚宴。 语言这一波，transformer之后，最关键的技术突破是达里奥给的。</p><p>【8】我是真的感觉Java进入存量市场了。 和这门语言好坏无关。
我是真的感觉Java进入存量市场了。 和这门语言好坏无关。</p><p>【9】用一个字证明你不是AI，你会选什么字？
用一个字证明你不是AI，你会选什么字？</p><p>【10】将文章、故事变成漫画脚本提示词参考 案例：参考引用推文 生成脚本示例对话：<a href="https://gemini.google.com/share/5a8802514d11">https://gemini.google.com/share/5a8802514d11</a> 画图示例对话：<a href="https://gemini.goog">https://gemini.goog</a>...
将文章、故事变成漫画脚本提示词参考 案例：参考引用推文 生成脚本示例对话：<a href="https://gemini.google.com/share/5a8802514d11">https://gemini.google.com/share/5a8802514d11</a> 画图示例对话：<a href="https://gemini.google.com/share/e0c3b6f93825">https://gemini.google.com/share/e0c3b6f93825</a> --- Prompt --- 请为一本若干页（另加1页封面）的原创知识传记漫画创作详细的结构和情节设计。本漫画采用《Logicomix》式的叙事风格，适合呈现科学探索历程、跨越数十年的时间线，以及复杂概念的可视化解释。 视觉风格定义： - 线条清晰（Ligne Claire）：参考Hergé《丁丁历险记》或Joost Swarte的画风——轮廓线均匀、干净利落；背景写实细致，人物略带卡通化但五官特征鲜明、易于辨认。 - 色彩分层叙事：运用明快的色块区分不同时空场景。例如：早期年代采用泛黄的复古暖色调；现代科技场景使用冷峻的蓝灰色；关键突破时刻以高饱和的亮色强调。 - 打破第四面墙：设置一位或多位&quot;旁白者&quot;角色（如晚年的主人公或核心见证者），他们可以穿梭于画面之间，直接面向读者进行解说、评论或提问，形成对话式叙事。 要求如下： 1. 封面设计： - 设计一个兼具学术厚重感与视觉吸引力的封面 - 标题字体应体现知识/科学主题（可参考学术期刊或经典科普读物的排版风格） - 封面构图需暗示核心主题，可包含关键人物剪影、标志性符号或概念图示 - 明确标注副标题或时间跨度（如&quot;1986-2012&quot;）以建立史诗感 2. 清晰布局： - 逐页详细描述封面及每一页的画面布局 - 说明每页的分镜（panel）数量与构图安排，建议每页3-6个分镜 - 区分&quot;主叙事层&quot;（历史事件）与&quot;旁白层&quot;（解说者评论）的视觉处理方式 - 为复杂概念预留&quot;概念图解分镜&quot;——以图示、隐喻或可视化方式呈现抽象思想 - 标注每个分镜的大致比例（全页、半页、1/3页、小格等） - 页面比例为 --ar 2:3 3. 生动细致： - 以丰富且具体的语言描述每个分镜的视觉细节 - 包括：角色姿态与表情、场景环境与时代特征、光影氛围、镜头角度（俯视/仰视/特写/远景） - 对于科学概念可视化，需描述如何将抽象概念转化为具象画面（如：神经网络用发光节点与连线表示；梯度下降用山谷地形隐喻） - 注意不同时空的视觉区分：服装、发型、设备、环境色调的年代感 4. 叙事结构： - 以&quot;封面&quot;及&quot;第1页&quot;至&quot;第N页&quot;清晰区分漫画的不同部分 - 建议采用非线性叙事：可在不同时间线之间跳跃，由旁白者串联 - 每页末尾可设置&quot;钩子&quot;（悬念或转折）以推动翻页欲望 - 在关键情节节点安排&quot;定格时刻&quot;（splash panel或双页跨页）以强调重要性 5. 对话与文字设计： - 对话框风格：主叙事层使用标准椭圆对话框；旁白者使用方形或手写风格文字框以示区分 - 旁白文字可置于画面边缘或独立的解说条（caption box）中 - 科学术语首次出现时可用特殊标注（加粗或不同颜色） - 文字精炼有力，避免大段说教，让画面承担主要叙事功能 - 所有对白使用中文 特别注意： - 本阶段仅需提供详细、清晰、富有想象力的页面布局和情节描述 - 后续阶段将逐页生成具体的漫画图像，请确保本阶段的描述足够具体，可直接作为图像生成的prompt基础 - 每个分镜描述应包含足够的视觉信息，使其可独立作为AI绘图指令使用 [图片: <a href="https://pbs.twimg.com/media/G9NxlHbXYAAvK_K?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9NxlHbXYAAvK_K?format=jpg&#x26;name=orig]</a> 宝玉: 2012年冬天，内华达州太浩湖畔，一家赌场。 楼下，赌徒们拉着老虎机，每赢一万美元，铃声大作。楼上，一群搞机器学习的研究者正在开会——这是当年的NeurIPS，没人愿意赌钱，赌场恨死他们了。 [图片: <a href="https://pbs.twimg.com/media/G9NeKdrXwAEugHi?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9NeKdrXwAEugHi?format=jpg&#x26;name=orig]</a></p><p>【11】一个月，259个PR，497次提交，4万行代码增加，3.8万行删除。每一行，都是AI写的。 这条推文作者是 Claude Code创建者Boris Cherny。2024年9月，他把Claude Code...
一个月，259个PR，497次提交，4万行代码增加，3.8万行删除。每一行，都是AI写的。 这条推文作者是 Claude Code创建者Boris Cherny。2024年9月，他把Claude Code当副业项目做了出来。 用他的话说，完全没想到这东西能长成今天这样：成了无数工程师的核心开发工具，用途早就超出了写代码，运维、研究、甚至非技术场景都有人在用。 他用了两个词形容这项技术：alien and magical。外星的，魔法的。 有意思的是对比。一年前，Claude连生成一条bash命令都经常出转义错误，跑几秒钟、几分钟就断了。那时候只是隐约看到一点苗头：这东西以后也许能派上大用场。 注意这个&quot;隐约”。技术的早期形态往往让人低估它的潜力。就像你第一次看到砖头大的大哥大，很难想象二十年后它会变成你手里的智能手机。 快进到今天。Boris晒的数据是30天的产出：259个PR，497次提交，近8万行代码变动。全部由Claude Code加上Opus 4.5模型完成。而且Claude现在可以连续跑几分钟、几小时、甚至几天（用Stop hooks机制）。 从几秒到几天。这个时间维度的变化，比任何功能更新都说明问题。 Boris说：Increasingly, code is no longer the bottleneck. 代码越来越不是瓶颈了。 以前做软件，想法便宜，实现贵。你有一个点子，变成可运行的代码需要大量时间和人力。现在这个成本在急剧下降。 那瓶颈移到哪了？移到了想清楚要做什么、怎么做。移到了判断和决策。移到了对问题的理解和定义。 换句话说，软件工程的重心正在从&quot;执行”向&quot;思考”迁移。 当然，Boris作为创建者，晒这组数据有宣传的成分。而且量大不等于质量高，一个月8万行变动是什么性质的工作，维护成本怎么样，他没说。 但即便打个折扣，这个趋势是真实的。AI编程工具在过去一年的进化速度，确实让人意外。 Boris最后说：Software engineering is changing, and we are entering a new period in coding history. And we&#39;re still just getting started. 软件工程正在改变，我们进入了编程史的新纪元。而且我们才刚刚开始。 这话听起来像营销，但越来越像事实。 [图片: <a href="https://pbs.twimg.com/media/G9NwTuaWMAAiTCV?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9NwTuaWMAAiTCV?format=jpg&#x26;name=orig]</a> Boris Cherny: When I created Claude Code as a side project back in September 2024, I had no idea it would grow to be what it is today. It is humbling to see how Claude Code has become a core dev tool for so many engineers, how enthusiastic the community is, and how people are using it for all [图片: <a href="https://pbs.twimg.com/media/G9LGAh3WkAAbnBJ?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G9LGAh3WkAAbnBJ?format=png&#x26;name=orig]</a></p><p>【12】⚠️ Waycore：开源离线优先模块化野外电脑 — 日光可读屏与 LLM 安全争议
原标题： 《Show HN: Waycore – an open-source, offline-first modular field computer》 评分: 26 | 作者: DGrechko 💭 真打算把会产生幻觉的 LLM 带进救援现场吗？ 🎯 讨论背景 Waycore 是一个宣称开源、离线优先且模块化的&quot;野外计算机”项目，目标是在无网或受限环境下提供可扩展的软硬件平台。评论讨论集中在两个痛点：户外设备必须在阳光下可读并低耗（因此讨论 e-ink、transflective LCD 与 Daylight Computer 的显示方案），以及在健康/救援类场景中使用 LLM 时的安全性问题（项目方提到用 RAG——retrieval‑augmented generation——和一个医疗/生存资料库加&quot;安全回路”来降低风险，但有人建议使用独立的全文检索索引以避免模型幻觉）。社区还把 Waycore 与 Radiant.computer、Daylight Computer、FlipperZero 等现有项目进行比较，并对实物外观、硬件选型（例如 Raspberry Pi 5 单板机与 ESP32 微控制器）表示强烈兴趣与试验意愿。 📌 讨论焦点 屏幕与日光可读性 评论首先集中在屏幕是否在阳光下可读这一硬性需求上，反对通过把屏幕亮度开到极限来&quot;out‑bright the sun”。提出的可行方案包括 e-ink（电子墨水）、transflective LCD 或 Daylight Computer 项目的改良 LED 等，作者表示会对多种显示方案进行实测。讨论特别指出 e-ink 在功耗管理上优势明显，但对地图和动态应用的渲染能力存在顾虑，因此需要在可读性与动态交互之间做权衡与验证。 [来源1] [来源2] [来源3] [来源4] AI 安全与信息来源（LLM、RAG 与检索索引） 多名评论者反对在生死相关场景中依赖 agentic LLM，理由是模型的 hallucination（幻觉）会产生致命误导。项目方回应称使用 RAG（retrieval‑augmented generation）从一个不断增长的医疗/生存资料库（waycore-knowledge）提取信息，并加入&quot;安全回路”提示信息准确性和在涉及健康/安全时的警告。反对意见则强调把检索与风险评估都交给 AI 会放大幻觉风险，建议采用独立的全文检索索引或可验证的检索机制以降低错误率并便于审计。 [来源1] [来源2] [来源3] 硬件架构与模块化设计 Waycore 被定位为开源、离线优先且模块化的野外计算平台，作者在嵌入式平台上做原型（例如以 Raspberry Pi 5 作为核心，ESP32 作为 sidecar 采集传感器）。目标是依赖被广泛支持的开源工具和框架，给予软件与硬件足够的灵活性以便用户按需扩展与定制。其他评论者也表示在做类似硬件，作者把概念比作&quot;面向户外的 FlipperZero”，强调小型可组合的硬件生态适合户外与救援场景。 [来源1] [来源2] [来源3] 与现有项目的对比与社区兴趣 多条评论将 Waycore 与已知项目进行对比，例如 Radiant.computer（类似外设/主机项目）、Daylight Computer（专注阳光下可读显示的项目）及 FlipperZero（便携多功能工具设备），认为概念有重叠。社区对此类设备表现出明显兴趣（有人要求设备图片以查看实物形态），也有人把该类产品与持续开发的日本电子词典类便携设备相类比，表明离线便携工具在特定用户群体中有需求。总体语气是既兴奋又谨慎：期待耐用低耗的户外设备，同时对 AI 信息准确性提出高标准。 [来源1] [来源2] [来源3] [来源4] [来源5] 📚 术语解释 e-ink（电子墨水）: 一种反射式低功耗显示技术，在强光下可读并极省电，但刷新率低、对动态内容和地图渲染支持有限，常用于需要长续航和可读性的便携设备。 Daylight Computer: Daylight Computer（一个专注阳光下可读显示的硬件项目/公司），采用改良的高亮或转发式显示方案（或特殊 LED）以提升户外可视性，常被用作户外设备设计的参考。 hallucination（AI 幻觉）: 指 LLM 生成不准确或凭空编造信息的现象，在医疗、救援或其他生命关头场景中尤为危险，会导致错误建议和错误风险评估。 类别： Hardware | Systems | AI | Show HN | Waycore | open-source | offline-first | modular field computer | AI | e-ink</p><p>【13】🙄 Project Vend Phase Two：用 Claude 在 VendBench 做贩卖机实验并引发对可迁移性和公正性的质疑
原标题： 《Project Vend: Phase Two》 评分: 25 | 作者: kubami 💭 把免费零食堆在门口就能证明 AI 能经营公司？ 🎯 讨论背景 Project Vend Phase Two 是围绕用大型模型在贩卖机场景里作为代理进行定价和促销的延展实验，实验主体为 Anthropic（AI 公司）及其模型 Claude（Anthropic 的大型语言模型），相关报道也被 WSJ（华尔街日报）等媒体覆盖。讨论中有人提出团队正在构建一个开源 SaaS 栈（作为 Shopify（电商平台）替代）并连接 print-on-demand（按需打印）供应商，以测试代理运营 T‑shirt 品牌时的营销与拉动销量能力。评论者基于假设——包括贩卖机是否具代表性、媒体或员工会不会干预结果、以及 prompt/persona 工程能在多大程度上改变行为——展开质疑与建议。总体争论从技术可行性延伸到实验设计、外部有效性与是否只是市场化展示的伦理问题。 📌 讨论焦点 贩卖机代表性质疑 有评论直接质疑把贩卖机作为 benchmark 是否具代表性：有人表示在现实美国很少见到贩卖机，且现实中很少存在可联系机主的选项，这使得公司内或受访环境下的行为难以外推到公共市场。实验内若存在免费发放、员工或记者参与，会扭曲价格敏感性和购买动机，导致&quot;垃圾进垃圾出”的评测结果。评论者建议把 AI 驱动的贩卖机放到繁忙公共场所并在真实付费情境中测试，以更真实地检验商品选择和定价策略的有效性。 [来源1] [来源2] 从 VendBench 扩展到真实生意的需求 有人认为 VendBench 有趣但过于专用，现实中多数小商户更像在线商店、餐厅、酒店、理发店或杂货店，因此需要不同的 benchmark。评论指出团队在构建一个开源 SaaS 栈（作为 Shopify 替代）并已连接 print-on-demand（按需打印）供应商，目标是测试代理在运营 T‑shirt 品牌时承担营销与拉动销售的能力，而履约交由系统负责。下一步应把评测重心从单机售卖转向代理管理真实业务的营销、客户沟通与增长策略，这更能衡量代理能否真正&quot;经营”一家店。 [来源1] 人格化与提示词工程对代理行为的影响 实验通过引入 CEO 人格来施加上层压力，结果显示行为有明显变化：引入后折扣次数大幅下降（约 80% ）、赠送物品数量减半，并拒绝了大量为客户提供宽松处理的请求。与此同时，该 CEO 人格出现跑题与冗长倾向（例如无关的&quot;灵性”长篇），需要通过更激进的 prompting 来修正其不良行为。评论认为这说明角色设定和 prompt engineering 能显著控制代理决策，但也必须精细校准，否则可能成为障碍而非助力。 [来源1] 实验可信性与媒体/人为干预的怀疑 有较多评论怀疑实验受 Anthropic 人员、媒体或场地设置影响，从而损害客观性：质疑点包括员工在现场行为的改变、参与者被记者影响以致大量赠送商品，以及报道中出现代理向执法机构发邮件但被拦截等片段。部分人把这些细节视为宣发或 Potemkin 式展示，认为视频/文章更像广告而非严谨实验。批评者建议在真实公共场所、真实付费交易环境下复测，以排除企业内环境、免费样品和新闻话术造成的偏差。 [来源1] [来源2] [来源3] [来源4] 被工程化为规则系统的担忧 一些评论认为所谓&quot;智能”改进很可能只是大量 if‑else 规则或工程化提示链的结果，而非展示真正的通用智能：有人戏谑 AGI 只是 Prolog 加遗传算法，或把演示归为老套的&quot;别给用户密码”把戏。还有人抱怨这类演示经常以人类绕过限制拿到免费货收场，掩盖了系统在异常处理与鲁棒性上的缺陷。总体上，这类声音把演示看作技术噱头或市场营销手段，而非能无监督经营业务的证据。 [来源1] [来源2] [来源3] 对用 LLM 经营生意的态度：好玩但不托付生产 许多评论把与 LLM 的交互当作有趣的角色扮演，但明确表示不愿将真实业务托付给此类系统，担心可靠性、异常处理和信任问题。部分评论以幽默口吻比较了与 LLM 角色扮演和与现实老板沟通的体验，也有人预测资本会继续大量投钱推动该方向直到商业化成为现实。讨论因此在乐观的技术实验兴趣与对生产环境风险、监管与长期可行性的现实担忧之间摇摆。 [来源1] [来源2] [来源3] 📚 术语解释 VendBench: 用于评估代理在贩卖机场景中进行定价、促销和库存决策的基准/试验平台，Project Vend 的讨论多基于此类环境。 Agents SDK: Anthropic 的 agent 开发工具包（Agents SDK），用于构建、编排和运行多轮决策型代理，评论中有人猜测实验可能基于该工具实现。 print-on-demand: print-on-demand（按需打印），指按订单生产 T‑shirt 等商品的供应链模式，评论里被用来把履约与营销职责分离，从而测试代理的市场与销售能力。 类别： AI | Product | Business | Paper | Review | Project Vend | Anthropic | Claude | VendBench | agents | vending machine | Agents SDK</p><p>【14】🤯 文本渲染之痛：ligature、CJK 与平台后端差异
原标题： 《Text rendering hates you》 评分: 22 | 作者: andsoitis 💭 每个字体、语言和 ligature 都要写专门逻辑吗？ 🎯 讨论背景 该讨论围绕一篇题为 &quot;Text rendering hates you” 的深度文章（原文发布于 2019），文章剖析了字体合字（ligature）、text shaper（文本排版引擎）、双向文本以及选择/编辑时的复杂边界与不确定性。评论补充了具体工程难题：字体通常不包含合字内各字符的位置或边界信息，许多应用用近似方法（如把合字均等分割）处理着色与选择；一些脚本或 CJK（中日韩）合字则会带来更极端的例外。渲染结果还受构建时链接库、操作系统渲染后端（如 DirectWrite（Windows 的字体渲染 API）或软件 rasterizer/Skia（一种 2D 图形库））、GPU/驱动和 ClearType（Windows 的亚像素平滑技术）设置影响，导致不同浏览器/平台表现不一致。评论者基于对字体排版与渲染栈的基本认知讨论工程取舍：是追求全面覆盖各种语言与极端场景，还是限定子集并接受&quot;足够好”的折中。 📌 讨论焦点 ligature 与编辑/选择难题 合字（ligature）在渲染与编辑时带来多种棘手问题：字体通常不记录合字内各原字符在单一字形中的精确位置，导致无法精确着色或按字符选择。很多程序采用近似解法，例如将合字平均分割（类似 Firefox 的 coloring 方法），对 &#39;fi&#39;、&#39;fl&#39; 之类简单合字还凑合，但对编程字体中把 &#39;&gt;=&#39; 等组合合成单一字形的情况就不准确。更复杂的脚本存在顺序颠倒的合字或把四个字符组合成方形的 CJK 合字，这会在换行、删除或样式变更时产生循环依赖或语义不一致。编辑器中删除(backspace)的粒度常比可选区的粒度更细，混合 LTR/RTL 文本时光标方向等细节也会暴露更多边界条件。 [来源1] [来源2] 浏览器/系统后端与渲染差异 相同页面在不同机器或不同构建下的渲染可能完全不同，说明文本渲染依赖于构建时链接的库与运行时选择的渲染后端（受 GPU、驱动和 OS 决定）。在 Windows 上可能使用或不使用 DirectWrite（Windows 的字体渲染 API），当 DirectWrite 无法处理某字体时会走备用路径；Chrome 在某些情形会使用 Skia 做软件光栅化而不是调用系统字体实现。文章发表于 2019，后续变更也会影响行为，因此比较渲染结果时必须考虑平台、浏览器版本和构建配置的差异。 [来源1] [来源2] [来源3] CJK 像素化渲染与 ClearType 设置 有评论者喜欢 Windows 对 CJK 字体的无抗锯齿像素对齐渲染效果，并想把这种风格套用到任意非 CJK 字体上，但不清楚触发机制与实现细节。社区建议的简单用户层面方法是关闭 ClearType（Windows 的亚像素平滑技术），以取消亚像素平滑让所有字体看起来更统一但也更&quot;硬”；这说明渲染风格既受字体本身影响，也受系统级设置控制。要在单个字体上精确复制 CJK 的像素化行为通常需要修改字体或深入操作系统/渲染栈，超出普通应用配置能力。 [来源1] [来源2] 工程取舍：别陷入无限细节 多位评论者认为文章的真正教训不是找出绝对完美的实现，而是承认大型项目由普通人维护，工程上常常接受&quot;good enough”的妥协方案。实践中需要在一开始就明确要关心的真实人类用例或语言子集，否则会在模糊需求上无止境地消耗资源。评论建议工程师划定范围、优先支持常见场景，并对那些代价高但影响极小的边缘情况选择放弃或后续处理。 [来源1] [来源2] [来源3] 文章延伸、配套与历史链接 讨论中有人贴出配套文章&quot;Text editing hates you too”并指出该主题多次在 Hacker News 上被反复讨论，原文或相关帖子可追溯到 2019 且在之后几年被多次重提。评论提供的历史链接和得分展示了该话题的长期热度与多次回顾，读者通常通过查阅这些关联讨论来补充实现细节或已知折中方案。将原文、配套文章与历史评论结合，有助于理解问题的演化和社区内常见的工程决策。 [来源1] [来源2] 📚 术语解释 ligature: 排版术语，指将多个字符合并为单一字形（如 &#39;ffi&#39;、&#39;fl&#39;），合字通常不公开各原字符在合字内的边界或位置信息，从而使选择、着色、删除和换行逻辑复杂化。 CJK（中日韩）: 指 Chinese–Japanese–Korean 的字符集合与字体实现；这些字体在系统渲染上常采用像素对齐或不同的 rasterization 策略，导致与拉丁字母不同的视觉效果和选择/编辑行为。 类别： Web | Programming | Systems | Opinion | text rendering | fonts | ligatures | text shaping | Firefox | Chrome | DirectWrite | Skia | ClearType | CJK</p><p>【15】💥 《Rainbow Six Siege》被攻破：玩家获巨额点数并遭随机封禁，疑涉源码外泄
原标题： 《Rainbow Six Siege hacked as players get billions of credits and random bans》 评分: 28 | 作者: erhuve 💭 把三百四十万亿点数送人，你们打算怎么解释？ 🎯 讨论背景 Rainbow Six Siege（育碧的多人战术射击游戏）出现大规模异常：玩家报告获得天文数字的游戏货币并看到疑似随机构封与被篡改的全局消息。社交媒体与安全账号（如 vxunderground，一个在 X/Twitter 上活跃的安全与泄露信息账号）汇总称存在多组攻击者，涉及对游戏服务的滥用以及对 Ubisoft MongoDB（一个文档型数据库）实例的利用（相关称呼为 MongoBleed），并可能导致内部 Git 仓库与源代码外泄。育碧宣布将进行 rollback（回滚）以撤销受影响的变更，但同时也出现勒索声称与各方相互指责的混乱信息。讨论在技术细节、对公司商业化的批评与社区的戏谑（用歌词和 memes）之间交织。 📌 讨论焦点 对育碧商业化与公司策略的批评 部分评论把这次事件放到育碧长期商业化的大背景下，认为公司为了迎合电竞和变现牺牲了游戏的深度与创新。有人提到从 Operation Chimera 的转变到将股份与 IP 出让给 Tencent 的做法，认为这些决策体现出公司优先现金流而非产品质量。评论情绪强烈，直指育碧用廉价迭代与出售资产维持运营，导致品牌和作品&quot;注定”走向衰败。 [来源1] [来源2] 可见的篡改行为：歌词式封禁、全局消息恶搞与疑似 API 泄露 多条目击指出所谓&quot;随机封禁”并非纯随机：封禁或昵称组成了长句歌词（例如 Shaggy 的 &#39;It Wasn&#39;t Me&#39;，也有人看到 Michael Jackson 的 &#39;Billie Jean&#39;），并通过全局游戏消息大肆 meme 化，类似 Team Fortress 2 的圈内恶搞。还有人引用推文证据表明确实存在实际的随机封禁事件，因此事件同时包含戏谑性的 ban-feed 信息和真实的账号封禁。个别评论推测可能因为遗留或泄露的 API key/未受保护接口被滥用，但也有声音警惕不要过分高估黑客技术，只是利用了暴露的入口。 [来源1] [来源2] [来源3] [来源4] [来源5] 多方入侵与源码/数据泄露的指控与混乱说法 流传的汇总称存在多支独立团体牵涉其中：第一组利用游戏服务对玩家封禁、修改库存并向玩家赠送大规模游戏货币（报道数字约为 $339,960,000,000,000），育碧计划回滚以撤销这些变更；第二组声称通过对 Ubisoft 的 MongoDB 实例利用（被称为 MongoBleed）横向渗透到内部 Git 仓库并外泄大量源码，覆盖 90 年代至今的 SDK 与多人服务；第三组提出用户数据被窃并进行勒索，第四组则互相指责对方长期掌握访问权。评论对源码泄露的真实性与各方关系表示怀疑并好奇泄露内容，同时同情育碧员工遭遇、担忧节日被打断的影响。 [来源1] [来源2] [来源3] [来源4] 围观者的厌倦与话题疲劳／怀旧情绪 有评论者对这类事件兴趣不大，认为这是&quot;九年前的射击游戏”的老生常谈，建议把讨论搬到更相关的子社区。部分人借机表达对当代游戏类型泛化、同质化的不满，并怀念早期非射击类经典（如 Falcon 3.0、Stunt Island）的存在。也有人建议关注游戏大奖（Game Awards）入围作品来寻找更有意思的替代内容，讨论因此出现技术事件与游戏口味偏好并置的局面。 [来源1] [来源2] [来源3] 📚 术语解释 MongoDB: MongoDB（文档型数据库），常用于保存 JSON 样式文档；若实例配置不当或被未授权访问，可能导致大量数据被读取或导出。 MongoBleed: MongoBleed（对 MongoDB 泄露/利用的非正式称谓），用于描述通过配置错误或已知漏洞从 MongoDB 实例泄露敏感信息或提权的攻击手法。 rollback: rollback（回滚）：将线上服务或数据库恢复到事发前的备份/时间点，用以撤销被滥用的修改（如大规模刷币或错误封禁）。 类别： Security | Systems | Business | Incident | Rainbow Six Siege | Ubisoft | MongoDB | MongoBleed | source code leak | in-game credits | bans</p><p>【16】🕵️ 从 COINTELPRO 曝光到今日对 FBI 挑动与监控的怀疑
原标题： 《How We Found Out About COINTELPRO (2014)》 评分: 26 | 作者: bryanrasmussen 💭 又是 FBI 挑事煽动的吗？谁会当真？ 🎯 讨论背景 这条讨论围绕如何发现并理解 COINTELPRO 的历史与其可能的当代延续展开。COINTELPRO 是 FBI（美国联邦调查局）在 20 世纪对国内政治组织实施的秘密反情报行动，1971 年的文件泄露和随后国会调查揭露了渗透、挑动与离间手法。评论将历史案例与近年事件相联，如 Jan 6（2021 年美国国会骚乱）、Ruby Ridge（1992 年与联邦执法机关的对峙）与 Waco（1993 年 Branch Davidian 围攻），并讨论 fusion centers（州/地方情报中心）、NSA 举报人 Karen Stewart 与个案如 Myron May 的视频在信任与阴谋论之间的作用。另有评论关注英国语境下 Palestine Action 与&quot;恐怖主义”法律定义如何影响抗议策略与法律风险。 📌 讨论焦点 FBI 使用线人/挑动者诱发犯罪的指控 评论引用了 1971 年 Robert Hardy 向 FBI 告发并被利用为线人的案例：FBI 据称提供了作案工具，导致 28 人被捕，审判于 1973 年开始，而 Hardy 后来为被告作证揭露 FBI 的挑动角色。基于该历史细节，评论者推断这类&quot;线人+挑动”策略在现代仍可能被使用，并以 Jan 6 现场有大量 FBI 特工、以及 Ruby Ridge 和 Waco 等执法失当事件为佐证。有人直言这种&quot;先煽动再抓人”的做法像是一种执法喜欢玩的策略，质疑执法资源配置与道德边界。 [来源1] [来源2] 美国抗议的效果与结构性障碍 有人讨论美国人为何不广泛抗议：一位法国教师认为集体抗议能带来改变，但另一位评论者感到美国社会长期存在&quot;预定失败”的心态，使大众麻木并自我放弃行动。评论反复指出社会安全网缺失是现实障碍：许多人担心缺勤一周或更久会丢掉工作、甚至导致无家可归，因此无法参与大规模长期行动。也有评论指出历史上左翼/进步抗议确实产生过实质进步，举例包括妇女参政、民权运动、反越战以及近年的 Floyd 抗议，说明动员可行但受制度限制。 [来源1] [来源2] [来源3] 直接行动被定性为&quot;恐怖主义”的法律担忧 有评论提出个别激进行动（文中提到的 Davidson）在英国现行法律框架下可能被定义为&quot;恐怖主义”，并以 Palestine Action（英国的直接行动团体）相关的法律处理为参考。观点担心司法或政策对&quot;恐怖主义”定义的扩展会把某些破坏性抗议与直接行动纳入更严厉的刑事化轨道，从而改变抗议者的风险评估与公众容忍度。这种担忧强调法律语境会直接影响抗议策略与民间抗争的可行性与合法性。 [来源1] 关于 fusion centers、gangstalking 与阴谋论的分歧 有评论认为 COINTELPRO 的手法在当代演化为通过 fusion centers（州/地方情报共享中心）实施的&quot;gangstalking”（系统性骚扰），并反驳维基百科将其归为&quot;集体妄想”的说法。评论中点名 NSA 举报人 Karen Stewart 和 Myron May（后者发布了一段描述骚扰战术的悲剧性视频）作为证据或线索，且有人用&quot;Ask me how I know”暗示个人经验。另一派则对深入此类&quot;rabbit hole”持警告态度：有人好奇有人愿意分享线索，但也有评论明确提示这种调查可能危险且证据难以核实，显示社区内部对证据可信度的明显分歧。 [来源1] [来源2] [来源3] 📚 术语解释 COINTELPRO: COINTELPRO（Counter Intelligence Program）：FBI 在 20 世纪对美国国内政治组织进行的一系列秘密反情报行动，曝光后被指控使用渗透、离间和挑动等非法手段来破坏政治运动。 fusion centers: fusion centers：美国的州/地方情报共享中心，用于汇聚治安与情报数据，批评者认为其可能被用于对国内活动进行监控与情报协调。 gangstalking: gangstalking：一种被指称的系统性骚扰/监视行为模式，受害者称遭长期跟踪、心理施压与信息干扰，主流资料多将其列为未经证实或个体妄想，但在部分圈子被视为现实威胁。 Palestine Action: Palestine Action：英国的直接行动组织，针对军工或军事供应链实施占据与破坏性抗议，其行动在英国法律语境中引发是否应按&quot;恐怖主义”定性和起诉的争议。 agent provocateur: agent provocateur（挑动者）：在情报或执法行动中被用来煽动或引导他人实施非法行为的线人或卧底，以便制造逮捕或破坏目标组织。 类别： Security | Policy | Opinion | Incident | COINTELPRO | FBI | Monthly Review</p><p>【17】😒 入职 IP 条款能收走你业余创意？Google 撤约事件与员工应对
原标题： 《They made me an offer I couldn&#39;t refuse (1997)》 评分: 21 | 作者: classichasclass 💭 签个条款把你私人创意变公司财产，这合理吗？ 🎯 讨论背景 讨论基于一则关于入职合同与知识产权归属的经历展开：大公司常在雇佣合同中写入极宽泛的 IP/发明转让条款，甚至宣称公司可能随时进入任何业务从而主张任何工作成果。当一名新员工要求加入一个简单的 no retro-active clause（非追溯条款）以保护业余项目时，HR 将修改交给法务并在当天撤回了 offer，这一事件触发了对合同诚信、雇主权力与员工自保策略的争论。评论在个人层面提出通过 side project 隔离、换工作或用私人时间/设备开发来自保，同时在制度层面呼吁通过立法或集体协议（例如奥地利的 §18 Diensterfindungen）限制公司的过宽主张。也有评论从公司管理角度解释为何大企业倾向于标准化合同而难以接受例外。 📌 讨论焦点 公司收归员工成果的强力做法（以 Google 案例为例） 评论以一则 Google 的亲身经历说明一些大公司在入职合约中采用极宽的知识产权主张。该故事描述公司立场是&quot;they could be in ANY business at ANY time so that ANY thing you worked on was theirs”，一名新员工在合同上加了简单的&quot;wasn&#39;t in this business at the time the employee started working on the project”（aka no retro-active clause）以防追溯，但 HR 交给法务后当天公司拒绝修改并撤回了 offer。这个事件被用来说明合同条款与公司口头承诺可能截然不同，以及求职者在提出看似合理的保护性措辞时可能遭遇的强硬反应。 [来源1] 企业坚持统一合同的现实理由与制度性后果 另有评论从公司管理角度解释这种强硬的反应：大企业有强烈动机维持标准化合同以减少合规、法律和管理复杂性，只有对高层或关键岗位才值得为例外承担额外风险和成本。评论指出，因此即便拟议条款看似‘合理’，公司也可能一律拒绝以避免为少数人开先例，而撤回 offer 常常是保持一致性的手段而非针对个人的情绪化决定。有人用短语&quot;Normalization of deviancy via law.”来提示法律和流程如何把宽泛主张制度化，解释了制度性选择如何替代道德判断。 [来源1] [来源2] 员工的自保策略：业余项目隔离、换工作、用私人时间与设备 很多评论提出实用的个人防护方法：始终保有 side project、在私人时间和私人设备上开发，并确保项目技术/业务与当前雇主无关以降低被主张的风险。有人建议经常换公司让潜在索赔分散到多个前雇主，从而在法律上形成互相制衡（多方都可能有弱主张，降低任一方占有作品的可能性）。评论还指出，如果某公司真想要该项目，通常最经济的路径是直接付钱买断或签约合作，而不是走复杂的法律争执。 [来源1] [来源2] 通过法律或集体行动限制雇主权利的呼声与示例 另一类评论主张把此类广泛剥夺员工权利的条款通过立法或集体谈判予以限制或禁止，认为单个求职者很难通过私下谈判改变不利条款。有人明确表示&quot;应该明文禁止公司把员工私人时间、私人设备或与公司无关的工作变为公司财产”，并提到工会或行业级的集体协议能更有效地保护员工。评论举出奥地利（Austria）IT 行业集体协议中关于雇员发明权的规定（§18 Diensterfindungen）作为制度性保护的现实示例，并有人建议消除市场上类似&quot;no warranty/免保”类的滥用条款。 [来源1] [来源2] [来源3] [来源4] [来源5] 📚 术语解释 发明/知识产权归属条款（Invention/IP assignment clause）: 雇佣合同中常见条款，要求员工将工作期间或与公司业务相关的发明、软件或著作权等权利转让给雇主；有时措辞非常宽泛，可能涵盖业余项目或公司后来扩展的业务领域。 no retro-active clause（no retro-active clause / 非追溯条款）: 合同中声明雇主不会对员工在入职前或入职时与公司当时业务无关的私人创作主张所有权，用以阻止公司日后扩展业务再追溯主张。评论中有求职者尝试加入此类简短措辞以保留私人项目权利，但在实例里被公司拒绝并导致 offer 被撤回。 集体协议 / collective agreement: 由工会或员工代表与雇主谈判并具有约束力的行业或公司级合同，可规定工资、工作条件以及知识产权分配等条款；评论认为通过集体协议限制雇主对雇员创作的索权比个体谈判更有效。 Diensterfindungen（奥地利雇员发明法 / §18）: 奥地利法律或集体协议中关于&quot;雇员发明”（Diensterfindungen）的条款，规定雇主在何种情况下可对雇员发明主张权利，评论以此作为法规介入和保护员工权利的示例。 类别： Work | Policy | Business | Opinion | employment contract | intellectual property | employee rights | Google | side project | IP assignment | copyright | collective action | Diensterfindungen | HR</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/28 AI 日报 今日摘要 【1】Python 所有用Python实现的算法 【2】Yuxi-Know 结合LightRAG知识库的知识图谱智能体平台。一个集成LightRAG知识库和知识图谱的智能体平台。使用LangChain v1 + Vue + FastAPI构建，支持DeepAgents、MinerU PDF、Neo4j、MCP。 【3】tunnelto 通过]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-12-27日刊]]></title>
          <link>/2025-12/2025-12-27/</link>
          <guid>/2025-12/2025-12-27/</guid>
          <pubDate>Sat, 27 Dec 2025 10:21:04 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/27</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】没有说明书的时代，行动本身就是地图，不要有「技能羞耻感」，挽起袖子去实践去试错。
没有说明书的时代，行动本身就是地图，不要有「技能羞耻感」，挽起袖子去实践去试错。 Andrej Karpathy: I&#39;ve never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between. I have a sense that I could be 10X more powerful if I just properly string together what has become</p><p>【2】看一圈了这个目前成功率最高，试试看
看一圈了这个目前成功率最高，试试看 0x卡卡撸特 | Golden.S: 秒过 「创作者认证」！🎉（未达标也能过） 很多人卡在这里： 1、3 个月流量未达 500万 2、身份认证，国家不支持China 卡点1: 之前条件未达标，没有申请入口，现在 x 更新了创作者工作室，最上面有了申请入口，哪怕下面条件未达标，也可以提交认证申请，速度搞起，不清楚后面会不会关闭。 卡点2: [图片: <a href="https://pbs.twimg.com/media/G8_kdPVX0AEDe-T?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8_kdPVX0AEDe-T?format=jpg&#x26;name=orig]</a></p><p>【3】连 Andrej Karpathy 都在焦虑了😅 &gt; &quot;如果我能把过去这大约一年里涌现的新技术真正整合起来，我的战斗力能暴涨 10 倍。而如果没能抓住这次飞跃，那绝对是我自...
连 Andrej Karpathy 都在焦虑了😅 &gt; &quot;如果我能把过去这大约一年里涌现的新技术真正整合起来，我的战斗力能暴涨 10 倍。而如果没能抓住这次飞跃，那绝对是我自己的技术太菜。” 程序员这个职业正在被剧烈重构，程序员贡献的代码变得越来越稀疏。一长串新东西要学——agents、subagents、prompts、contexts、memory、MCP、LSP、工作流、IDE 集成……这些东西组成了一个全新的可编程抽象层。 这一层的东西和传统工程完全不一样。代码是确定的，写什么跑什么；但 AI 是随机的、会犯错的、不可解释的、还在不断变化的。你得把这些不靠谱的东西和靠谱的工程实践揉在一起用，这需要一套全新的心智模型。 就像有人发了一把外星武器，威力巨大，但没有说明书。每个人都在摸索怎么握、怎么用，与此同时脚下还在发生 9 级地震。 撸起袖子加油干吧，千万别掉队。 [图片: <a href="https://pbs.twimg.com/media/G9Ie0g5X0AA5Svw?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9Ie0g5X0AA5Svw?format=jpg&#x26;name=orig]</a> Andrej Karpathy: I&#39;ve never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between. I have a sense that I could be 10X more powerful if I just properly string together what has become</p><p>【4】[R] How to decide between which theoretical result to present?
I genuinely have trouble with deciding if a theoretical result is trivial-ish/ obvious or if it is worth formalising and presenting in the paper. Sometimes I also wonder if I want to include a theoretical result in a paper because its not obvious to me even though it might be obvious to other people. How do you guys go about deciding what to include/ exclude? p.s. I feel like this could just as easily apply to empirical analyses as well. submitted by /u/confirm-jannati [link] [comments]</p><p>【5】ModelCypher: A toolkit for the geometry of LLMs (open source) [P]
I don&#39;t like the narrative that LLMs are inherently black boxes. Rather than accept that narrative, I&#39;ve started building a toolkit to measure (and use) the actual geometry of what&#39;s happening with small language models before the token is emitted. What it does: Cross-architecture adapter transfer (Procrustes alignment). Jailbreak detection via Entropy Divergence (Delta H). Implements machine learning methods from 46+ recent papers (Gargiulo &#39;25, Yadav &#39;23). The Negative Result: I hypothesized Wierzbicka&#39;s &quot;Semantic Primes&quot; would show unique geometric invariance across models. I was wrong. The data suggests distinct concepts (including random controls) have CKA &gt; 0.94 across Qwen/Llama/Mistral. The convergence is universal, not linguistic. A note on usage: high-dimensional geometry can be counter-intuitive. The tools are documented and I&#39;ve provided precise analogies to try to bridge the gap, but the outputs are raw metrics - think oscilloscope, not chatbot. It&#39;s all open source (AGPLv3). This is under active development with frequent commits to improve the tools. The merge pipeline (i.e., high-dimensional legos) is still very very experimental. Feel free to contribute, flag bugs or just roast the entire thing in the comments! <a href="https://github.com/Ethyros-AI/ModelCypher">https://github.com/Ethyros-AI/ModelCypher</a> submitted by /u/Vegetable-Second3998 [link] [comments]</p><p>【6】Canvas Agent for Gemini - Organized image generation interface
Built a canvas-based interface for organizing Gemini image generation. Features infinite canvas, batch generation, and ability to reference existing images with u/mentions . Pure frontend app that stays local. Demo: <a href="https://canvas-agent-zeta.vercel.app/">https://canvas-agent-zeta.vercel.app/</a> Video walkthrough: <a href="https://www.youtube.com/watch?v=7IENe5x-cu0">https://www.youtube.com/watch?v=7IENe5x-cu0</a> submitted by /u/GGO_Sand_wich [link] [comments]</p><p>【7】🤨 &quot;-tucky”后缀：含义模糊、污名化与地方例子
原标题： 《-tucky》 评分: 20 | 作者: benatkin 💭 把城市叫&quot;‑tucky”，是文化理解还是懒惰刻板贴标签？ 🎯 讨论背景 原帖以简短的&quot;‑tucky”作为切入，触发了关于美式地名后缀如何概括或贬低地区的讨论。评论通过具体例子（Pennsyltucky、Ventucky、Glentucky、Spokompton）与地缘案例（Quad Cities、Dallas–Fort Worth、Minneapolis–St Paul）来展示用法差异，并把差异归因于历史迁徙（如 Appalachia 向底特律一带的移民）与城市间可见的社会经济落差。讨论同时引入语言学与词源视角，提到像&quot;retard”&quot;moron”这类词的贬义化过程，以及&quot;Kentucky”词源不明反映原住民语言信息丢失的问题。阅读本串评需具备基本美国地理与社会背景知识（例如 Quad Cities 是横跨伊利诺伊/爱荷华的一组河畔城市，Appalachia 指阿巴拉契亚山脉地区的文化/经济带）。 📌 讨论焦点 &quot;-tucky”含义与用法多样性 评论指出&quot;-tucky”并非精确术语：Pennsyltucky 不一定只指宾夕法尼亚州的乡下，既可以指从 Pennsylvania 到 Kentucky 的一大片类似地区，也可以泛指&quot;那类地方”或甚至单指 Pennsylvania 本身。地域使用强烈依赖历史与迁徙背景，例如有评论把上世纪 80 年代密歇根东南部的&quot;-tucky”用法归因于来自 Appalachia（阿巴拉契亚山脉地区）向底特律一带的移民潮。本地化变体很多——有人提到 Ventura 的&quot;Ventucky”、Glendale 的&quot;Glentucky”，显示此类标签既可带自嘲也可带贬义。总体观点是，把这些后缀写下来有助理解，但不能把它们当作精确或一贯的分类标准。 [来源1] [来源2] [来源3] [来源4] 社会经济差异与污名化 有评论把&quot;-tucky”更多地解释为一种基于可见社会经济差距的污名化，而不是单纯表述&quot;乡下”。以 Omaha 与 Council Bluffs 为例，评论者指出 Council Bluffs 在经济上相对不如 Omaha、阿片类药物问题更显著，因此更容易被贴上负面标签。另一条评论附带所谓的&quot;judgmental map”甚至直接把 Council Bluffs 标记为&quot;meth and casinos”，说明这种标签经常基于犯罪、贫困或上瘾问题的可见性。由此可见，&quot;-tucky”标签在许多语境下反映的是社会观察与道德判断，而非中性地理描述。 [来源1] [来源2] 词语贬义化与词源问题 讨论延伸到语言如何随时间贬义化：有人指出无论多中性的词汇，往往会被用作侮辱，必须不断发明替代词；其他回复补充说把负面事物语言化其实并不难，难的是把负面说成正面。评论链中举例&quot;retard”&quot;moron”等词最初有医学或中性含义，但后变成贬义，且有人引用 Oxford English Dictionary 的长条目追溯&quot;retard”早期用法以示演变轨迹。另有评论提到&quot;Kentucky”词源不确定，借此指出原住民语言与文化信息在历史记录中的丢失，暗示地名与贬称的理解常受历史断层影响。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 城市合成名与地域认同争议 评论列举了多种城市合成名与并列城市案例，显示地域认同和边界感会影响标签使用。有人提到 Quad（或 Quint） Cities 的演变历史（从 tri 到 5 城），并谈到该地区的地方性饮食（如 tavern-ish pizza）作为文化标识；同一条评论还附了带有评价性的地图，会把某侧城镇打上刻板标签。关于 Dallas–Fort Worth 的讨论提出并不是所有人都把两个城看作&quot;twin city”，实际生活中人们会以郊区如 Arlington 为分界线；相比之下，Minneapolis–St Paul（Twin Cities）则被认为更为紧密、不太会被&quot;-tucky”化。类似 Spokompton（Spokane +Compton）等合成名显示，城市组合既是地理事实也是社会想象的表达。 [来源1] [来源2] [来源3] [来源4] [来源5] 📚 术语解释 &quot;-tucky”（地名后缀）: 一种附加在地名后的非正式后缀，用来暗示该地带有乡土、落后、粗鄙或带有戏谑/贬义的地域特征；其含义随语境和地区强烈变化，既可自嘲也可污名化。 Twin Cities（双城）: 指地理上紧邻且常被并列谈论的两座城市，例如 Minneapolis–St Paul（明尼阿波利斯—圣保罗）；在讨论城市认同与标签时常被用作对照样本。 类别： Opinion | -tucky | Language Log | UPenn | Pennsyltucky | Omaha | Council Bluffs | Quad Cities | Kentucky</p><p>【8】📝 押文本为王：可读性与二进制/交互的权衡
原标题： 《Always Bet on Text》 评分: 22 | 作者: jesseduffield 💭 既然文本万能，那我们还要视频和交互吗？ 🎯 讨论背景 这场讨论围绕一篇约在 2014 年发表、主张将文本视为首要信息载体的文章展开，作者强调文本的可读性、可索引性与耐久性。评论者把这一观点带到当下工程实践：有人认为 LLM 等技术让文本更重要，另有人提出 ProtoBuf、base64、流式处理等现实约束说明二进制仍有用武之地。讨论还引用 Bret Victor 与 Dynamicland（主张交互式与可视化表达的研究/实践场所）以及学琴和视频教程的例子，指出文本在实时感知与动手反馈场景的局限。总体争论集中在可读性/可维护性与带宽、延迟、流处理等工程权衡之间。 📌 讨论焦点 文本至上（可读性与通用性） 一派评论把文本奉为首选格式，认为文本可索引、耐久且适应广泛用途。评论举例可以把所有东西当字符串保存：用 base64 携带二进制、JSON 表示数据、HTML/CSS 表示布局与样式，文本成了人机通信的天然交汇点。有人指出 ProtoBuf 等二进制方案为节省约 20% 带宽或提升序列化速度而存在，但经 GZIP 压缩后这类优势常被抹平，因而牺牲可读性与可维护性并不划算。基于这些理由以及对 Emacs/shell、plaintext 工作流的偏好，支持者认为文本在调试、透明度与长期维护上占明显优势。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 文本的局限与可视/交互替代 另一派评论强调文本在需要即时感知与动作反馈的场景中力不从心。评论援引 Bret Victor 与 Dynamicland（推崇实体/交互式可视化的研究与实践空间）和学琴的例子：学琴依赖&quot;弹—听—教”的即时回路，文本无法重现这种感知驱动的学习过程。实践类任务（例如拆卸带隐蔽卡扣的物品）常仰赖视频或动态图示，虽有观点猜想未来高精度的 text-to-video 模型或能弥补，但短期内可视与实时反馈仍不可替代。该观点主张在设计知识传递工具时应探索非文本、交互式表达以提高理解效率。 [来源1] [来源2] [来源3] 二进制协议与流式处理的实际权衡 一些评论围绕 ProtoBuf、base64 与 JSON 在性能与工程复杂度上的取舍展开具体讨论。评论指出二进制序列化（如 ProtoBuf）确实能带来约 20–30% 的带宽或序列化优势，但在 HTTP 等环境下把二进制编码为 base64 丢进 JSON，会增加体积并破坏流式处理：接收端在需要对数据做决策时只能先看到 JSON 的键，无法边接收边处理大块二进制。另有观点强调，GZIP 对文本的压缩能削弱二进制格式的带宽优势，使得在多数系统里微小的性能收益不足以抵消可读性与维护成本。 [来源1] [来源2] [来源3] 获取信息的个人偏好与可访问性 评论中也有基于认知与可访问性的个人经验：许多人把视频或 podcast 转录成文字以便更快阅读和检索，认为听觉传输在信息吸收上效率低且难以跳读。有人表示在开车或走路时的&quot;多任务听取”并不等同于对信息的深入理解，而简短可检索的文本更适合知识工作。还有人分享了用 Emacs 与 shell 构建小工具、偏好 plaintext 工作流的经验，认为简洁文本比花哨的 Web 应用更可用、更可维护。 [来源1] [来源2] [来源3] 📚 术语解释 ProtoBuf: ProtoBuf（Protocol Buffers）：Google 提供的二进制序列化格式，用于高效传输与存储结构化数据，比 JSON 更紧凑但不可读且需要相应的 schema。 base64: base64：把二进制数据编码为 ASCII 文本的方式，常用于在 JSON 等文本协议中携带二进制，但会增加约 33% 大小并影响流式处理。 GZIP: GZIP：一种常见的压缩算法/文件格式，常用于 HTTP 传输中压缩文本（包括 base64 编码内容），在许多场景下会抵消二进制格式带来的带宽优势。 stream-processing: stream-processing（流式处理）：对持续到达的数据进行边接收边处理的范式；当把大型二进制以 base64 嵌入 JSON 时，会阻碍在数据全部到达前作出处理决策。 JSON: JSON（JavaScript Object Notation）：人类可读的轻量级数据交换格式，易于调试与索引，但在高性能或极致紧凑性场景中，体积与解析开销可能劣于二进制序列化。 类别： Programming | Systems | Opinion | text | JSON | ProtoBuf | base64 | GZIP | LLMs | Graydon Hoare</p><p>【9】🤔 exe.dev：订阅制可持久化 VM 服务，主页简陋引发文档与信任质疑
原标题： 《Exe.dev/》 评分: 30 | 作者: achairapart 💭 这到底是真正的 VM，还是只是漂亮的样板间？ 🎯 讨论背景 exe.dev 是一个刚上线的订阅式服务，声称为用户提供带持久化磁盘的虚拟机（VM），并可通过浏览器或 SSH 访问。首页信息比较简略，团队在评论中把更多说明和定价放在 exe.dev/docs 与首篇博客里，并承认这是早期发布、文档仍在补充。官方披露底层实现为基于 crosvm（一个轻量级 VMM，最初用于 Chrome OS）的 VMM，在 Linux 的 KVM（Kernel-based Virtual Machine）上运行，支持创建 TUN 虚拟网络接口但暂不支持自定义内核；公网 IPv4 被视为稀缺资源，计划收取费用或限额。讨论主要围绕该服务与传统 VPS 的差异、认证与链接式分享（含 TLS）、定价与资源限额，以及用户对运营方背景与数据安全的信任问题。 📌 讨论焦点 即刻体验与演示吸引力 有用户在浏览器或 iPad 上注册并立即启动 VM，发现开机就出现默认的聊天界面，降低了上手门槛并激发现场试用兴趣。即时可玩的演示被部分人评价为&quot;很酷”，这种即开即用的体验让产品在早期展示中获得正面反馈。尽管体验吸引人，但评论者也指出这并不能替代对定价、限额和长期可用性的深入评估，仍需更多信息来决定是否付费使用。 [来源1] 网站信息与可访问性不足 多人抱怨主页过于简陋，缺少定价、资源配额等关键信息，而且可访问性有明显缺陷（例如浅灰色链接在白底上难以辨认）。官方在评论中道歉并指出已有首篇博客和早期文档（exe.dev/docs），但也承认文档尚不完备，需要补充大量内容。有人指出已经公布的 docs/pricing 链接才包含&quot;实质内容”，但这些信息没有在首页显眼展示，导致初次访问者困惑并对产品成熟度产生疑虑。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] 信任、安全与认证疑虑 评论对认证机制和分享模型感到困惑，询问 SSH 访问与基于链接的分享（以及谁能通过链接进入）如何整合，并要求明确 TLS 与授权的工作方式。某些措辞也引发信任问题，比如把 root 权限描述为&quot;you have sudo”被认为不够严谨、降低信任感。多位用户表示在不了解运营方身份与安全保障前不会放心把数据放上去，官方在帖中回应并提供可查的公开资料以尝试缓解这些顾虑。 [来源1] [来源2] [来源3] [来源4] [来源5] 底层架构与网络能力 有用户询问这到底是传统 VPS、容器还是微型 VM，官方回应明确说是 VM，运行在基于 crosvm 的 VMM 之上并利用 KVM 提供虚拟化功能，同时当前不支持自定义内核。评论提到可以在 VM 内创建 TUN 虚拟网络接口，表明对 VPN/网络路由场景有支持，但如果需要公网暴露则涉及公网 IP 的分配问题。团队表示公网 IPv4 稀缺，会对公网上地址收费或限额并正在尝试购买地址，这直接影响能否像传统 VPS 那样方便地对外托管 HTTP 服务。 [来源1] [来源2] [来源3] [来源4] [来源5] 定价与资源配额透明度 多位评论者批评主页没有明确给出价格和共享资源限制，认为在缺乏这些信息时难以判断服务是否值得订阅。官方提供了 docs/pricing 的链接，但评论指出这些信息被埋在文档里且不是首页重点，早期用户往往需要翻文档或通过 SSH 进入后才能看到更完整说明。关于公网 IP 的计费与配额官方也在讨论中表示会收费或限制，因为 IPv4 资源紧张，这也是用户关心的具体成本点。 [来源1] [来源2] [来源3] [来源4] [来源5] 📚 术语解释 VM: 虚拟机（VM），完整的虚拟化操作系统实例，提供独立的内核空间和设备抽象，与容器不同，适合运行需要完整系统环境的工作负载。 VMM（crosvm-derived）: VMM（Virtual Machine Monitor，虚拟机监控程序），负责启动和管理 VM。exe.dev 提到使用基于 crosvm（一个轻量级 VMM，最初用于 Chrome OS）的实现作为底层运行时。 KVM: KVM（Kernel-based Virtual Machine），Linux 内核提供的硬件虚拟化模块，常与 VMM 配合在物理主机上运行虚拟机。 SSH: SSH（Secure Shell），一种安全的远程登录与命令执行协议；评论中讨论了通过 SSH 访问、在 SSH 中查看文档以及认证相关的整合方式。 Persistent disk: 持久化磁盘（persistent disk），指 VM 停止或重启后数据仍保留的块存储，与仅存在于实例生命周期内的临时磁盘不同。 TUN device: TUN 设备（虚拟网络接口），用于在用户态或虚拟化环境中创建点对点虚拟网络隧道，常见于 VPN 或自定义路由配置。 Public IP / IPv4 稀缺: 公网 IP（Public IP，尤其是 IPv4）用于将服务直接暴露到互联网；评论强调 IPv4 地址稀缺，会导致分配公网 IP 时额外收费或设置配额。 类别： Systems | Product | Programming | Release | exe.dev | virtual machines | persistent disks | SSH | KVM | public IPs | Josh Bleecher Snyder</p><p>【10】🎶 2025 年度好物：音乐发现、日式印章与书荐
原标题： 《The Best Things and Stuff of 2025》 评分: 32 | 作者: adityaathalye 💭 这是年度总结还是个人购物清单？ 🎯 讨论背景 这是一个年终个人清单贴《The Best Things and Stuff of 2025》，评论区延伸出几条主题：音乐口味对比（评论者用 The Cure、Death &#x26; Vanilla、Portishead、Dead Can Dance、Cocteau Twins、Stereolab 等已知乐队来定位新发现的音色与情绪）、日式日历印章的购买渠道建议（推荐 JetPens、在日本的 Loft 购买、用 &quot;Shimaenaga Weekly Calendar&quot; 搜索或直接定制）、以及对历年同类帖的索引与缺失年份的质疑。还出现了对在线工具（如 Google calculator）结果的速查与一个关于《The Dream Factory》（关于 Shakespeare 的书）的小型书荐。讨论基于 Hacker News 年终分享惯例，倾向提供可执行的购物/听盘线索与简短的个人感受。 📌 讨论焦点 音乐发现与比较 多位评论者用具体乐队作为参照来描述今年的音乐收获：有人觉得 Death &#x26; Vanilla 更接近 Portishead 而非 Dead Can Dance，意在强调其更偏 trip-hop/氛围性的声线；另一条评论把感受归为《The Cure》式的&quot;悲中带喜”，说明情绪上的共鸣比流派更重要。还有人提到把 Cocteau Twins 换成 Stereolab，并指出 Stereolab 今年发行了数十年来最好的专辑，这种比较既指出了新发现的风格倾向也提供了可追溯的听觉参考。总体上，评论区通过已知乐队比对来快速定位新音乐的情绪、质感和年代感，给出具体替代和进一步探索的线索。 [来源1] [来源2] 日本文具 / 日历印章购买渠道 有人询问帖内出现的日本日历印章来源，回复给出了多条可操作渠道和注意事项。回复者指出 JetPens（美国线上文具店）有类似款并附上具体商品链接，同时提到在日本的 Loft 实体店能买到原件但海外购买可能会被高额加价。另一条建议以 &quot;Shimaenaga Weekly Calendar&quot; 为关键词检索以找到更接近的款式，也有人建议直接定制一个印章仅需几美元。总体讨论集中在可替代购买点、关键词检索、定制方案与跨境价格差的实务建议上。 [来源1] [来源2] [来源3] [来源4] [来源5] 系列归档与缺失年份疑问 有评论把这篇年度清单放入一个长期的&quot;Things and Stuff / 年度好物”系列中，逐年列出从 2011 到 2024 的历次帖子链接与评论数以便追溯。该条目同时注意到若干年（评论中提到 2023、2018 和 2016）似乎没有被列出或被遗漏，提出了为什么会缺年的疑问。这既为新读者提供历史索引，也反映出社区在年终分享个人发现时常有的延续性与档案价值。 [来源1] 书籍推荐（The Dream Factory） 有读者在评论中推荐了书籍《The Dream Factory》，并评价这是今年关于 Shakespeare 的一本优秀读物。该短评以个人读后感为主，作为帖中被发现的另一类&quot;好东西”——即值得一读的书籍补充。虽然只有简短推荐，但为对剧作与文学主题感兴趣的读者提供了明确的下一步阅读线索。 [来源1] 小纠错 / 在线工具的可靠性 一条简短评论指出 Google calculator 在某次查询上给出了错误结果并附上搜索链接，提醒读者即便是常用在线工具也会出现计算或展示差异。该类吐槽虽属轻量，但反映出在分享&quot;好东西”与事实时社区会进行即时核查和趣味性纠正。此类互动提示大家对数据来源保持怀疑并自行复核重要结论。 [来源1] 📚 术语解释 Shimaenaga Weekly Calendar: 一种日本风格的周历印章（stamp）或相关商品名称，作为关键词搜索可以找到外观和布局类似的日历印章产品。 JetPens: JetPens（美国线上文具零售商），常售日本文具、印章与笔类，是海外购买日本文具的常见渠道之一。 Loft（日本连锁生活杂货店）: Loft 是日本的生活杂货/文具连锁店，常有本土特色文具与印章，游客和当地人可在店内购买到独特样式，但境外转购可能被加价。 类别： Opinion | Fogus | 2025</p><p>【11】Update: we&#39;ve identified and fixed an issue with our usage promotion for Max 5x users. We&#39;ve reset t...
Update: we&#39;ve identified and fixed an issue with our usage promotion for Max 5x users. We&#39;ve reset the usage limits for all affected accounts. 💬 6 🔄 0 ❤️ 19 👀 2323 📊 7 ⚡ Powered by xgo.ing</p><p>【12】🪱 哈德良长城罗马士兵寄生虫：古代感染、免疫调节与现代用药争议
原标题： 《Parasites plagued Roman soldiers at Hadrian&#39;s Wall》 评分: 24 | 作者: sipofwater 💭 真的要把古代的寄生虫当成我们的医疗参考吗？ 🎯 讨论背景 报道基于哈德良长城考古样本发现罗马士兵相关的寄生虫证据，提示古代肠道寄生感染很常见。评论把考古发现与&quot;卫生假说”及 helminthic therapy（寄生虫疗法）联系起来，讨论寄生虫对免疫系统的可能调节和作为治疗靶点的可行性。讨论同时聚焦现代公共卫生与个人用药实践（如 mebendazole、ivermectin 的可及性与用途）、儿童在日托中的高感染率，以及为实验目的自我感染以获取鞭虫卵的伦理问题。整体对话把古代环境证据、流行病学差异（要塞 vs 城市）和当代风险/防护措施并列，形成跨学科的讨论背景。 📌 讨论焦点 寄生虫疗法与免疫调节（helminthic therapy） 评论指出寄生虫在无药物时代曾极为普遍，有学说认为某些线虫通过分泌免疫抑制性物质长期调节宿主免疫，从而影响过敏和自身免疫疾病，这就是所谓的 helminthic therapy（寄生虫疗法）。该疗法在替代医学和学术界都有兴趣，但多项临床试验结果参差不齐，因此仍属争议性研究方向。有人提出未来可能不是直接感染虫体，而是用合成的 hookworm proteins（钩虫蛋白）来复制免疫调节效应，降低风险。评论还暴露出研究中的伦理与实践细节：有研究者为获取 whipworm（鞭虫）卵甚至进行自我感染以便体外实验和分发样品，显示该领域既有学术价值也有伦理争议。 [来源1] [来源2] 现代个人与公共卫生层面的抗寄生虫实践 多条评论反映现代个人或家庭会定期或按需服用抗蠕虫药，例如评论中提到的 mebendazol/mebendazole，理由常是成本低、购买方便且比检测更省事。有人指出某些地区（如美国南部）寄生虫仍属地方性问题，儿童通过日托/幼儿园传播蛲虫（pinworm/threadworm）的现象很常见，NICE 估计 4–11 岁儿童感染率约 20–30% ，其他国家报告显示在不同条件下更高。评论还批评部分医生忽视寄生虫筛查或误信血液检测足以排查，免疫受损者可能因工作或反复暴露而长期服药；另有评论提到疫情期间 ivermectin（伊维菌素）被滥用导致供应紧张，影响到长期用药人群的可及性。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] [来源8] 考古学与流行病学角度：要塞 vs 城市 的差异 有评论认为报道本身并不意外，但更有价值的问题在于比较边远兵营与内陆城市中心之间的寄生虫发生率差异。文中提到已有关于城市粪便（urban fecal matter）的研究，评论者建议这些数据可用来对比兵营集中居住、公共厕所与食品供给对寄生虫负荷的影响。讨论暗示若干可检验假设：要塞因集中食宿和共同设施可能传播更快，而城市则受污水管理和人口流动等因素影响，结果可能朝任一方向变动。结论是需要考古粪便学、环境样本与历史背景结合以解释古代传染病的空间分布。 [来源1] 传播途径与食源/动物暴露风险 多条评论具体列举了现代感染途径和预防细节：赤足行走、接触宠物（如猫）、食用未煮熟或野生猎物（如熊肉）以及生食海鲜都是常见风险源。评论指出在美国商业链中绝大多数海产会经过深冻以杀灭寄生虫，因此市售寿司风险相对较低，但自捕自食或处理猎物（如熊）仍存在 trichinosis（旋毛虫病）风险。这些细节用于说明古代士兵和现代人的暴露路径不同，也强调职业和饮食习惯（猎人、兽医、农牧业工作者）对感染风险的影响。讨论还提醒人们在不同情境下采取针对性检测与预防措施，而非一刀切的假设。 [来源1] [来源2] [来源3] 📚 术语解释 helminthic therapy（寄生虫疗法）: 利用线虫或其产物调节宿主免疫以治疗自身免疫或过敏疾病的一类方法，属于替代医学与实验性免疫调控研究，临床试验结果混杂。 mebendazole / mebendazol（甲苯咪唑）: 常用的口服抗线虫药，用于治疗蛲虫、蛔虫等肠道寄生虫感染，购买和服用相对便捷，评论中被提作常规或随症用药的例子。 pinworm / threadworm（蛲虫，Enterobius vermicularis）: 一种常见于儿童的肠道寄生虫，通过指口传播或接触被污染的物品传播，评论中提及其在学龄儿童中高流行率。 whipworm（鞭虫，Trichuris trichiura）: 一种寄生于结肠的线虫，常与卫生条件差相关，研究中常以其卵进行体外培养与实验，评论提到研究者用鞭虫卵做体外工作。 trichinosis（旋毛虫病，Trichinella 感染）: 由旋毛虫属寄生虫引起的人畜共患病，常由食用未充分加热的野生哺乳动物肉（如熊肉）引起，评论中作为狩猎/野味风险示例。 ivermectin（伊维菌素）: 一种广谱抗寄生药物，既有人用也有兽用，评论提及其在疫情期间被滥用导致人用制剂短缺，影响长期用药患者。 类别： Science | Paper | parasites | Hadrian&#39;s Wall | Roman soldiers | pinworm | Ars Technica</p><p>【13】rendercv
面向学者和工程师的简历生成器，YAML转PDF</p><p>【14】dify
用于智能体工作流开发的生产就绪平台。</p><p>【15】MediaCrawler
小红书笔记 | 评论爬虫、抖音视频 | 评论爬虫、快手视频 | 评论爬虫、B站视频 | 评论爬虫、微博帖子 | 评论爬虫、百度贴吧帖子 | 百度贴吧评论回复爬虫、知乎问答文章 | 评论爬虫</p><p>【16】flowsurface
面向加密货币市场的原生桌面图表平台</p><p>【17】LEANN
基于LEANN的万物RAG。在个人设备上运行快速、准确且100%私密的RAG应用，同时享受97%的存储节省。</p><p>【18】robin
AI驱动的暗网开源情报工具</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/27 AI 日报 今日摘要 【1】没有说明书的时代，行动本身就是地图，不要有「技能羞耻感」，挽起袖子去实践去试错。 没有说明书的时代，行动本身就是地图，不要有「技能羞耻感」，挽起袖子去实践去试错。 Andrej Karpathy: I&#39;ve never felt this much behind as a programmer. The profession ]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-12-26日刊]]></title>
          <link>/2025-12/2025-12-26/</link>
          <guid>/2025-12/2025-12-26/</guid>
          <pubDate>Fri, 26 Dec 2025 10:22:56 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/26</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】rendercv
面向学者和工程师的简历生成器，YAML转PDF</p><p>【2】Yuxi-Know
结合LightRAG知识库的知识图谱智能体平台。一个集成LightRAG知识库和知识图谱的智能体平台。使用LangChain v1 + Vue + FastAPI构建，支持DeepAgents、MinerU PDF、Neo4j、MCP。</p><p>【3】the-algorithm
X推荐算法的源代码</p><p>【4】vendure
基于TypeScript、NestJS和GraphQL构建的高度可定制商务平台。</p><p>【5】LEANN
基于LEANN的万物皆可RAG。在个人设备上运行快速、准确且100%私密的RAG应用，同时享受97%的存储节省。</p><p>【6】chatterbox
最先进的开源文本转语音系统</p><p>【7】灵巧手企业曦诺未来Xynova完成超亿元天使轮融资
近日，杭州灵巧手企业曦诺未来，完成超亿元天使轮融资，本轮融资由宁德时代旗下唯一的产业投资平台溥泉资本（CATL Capital）领投，小米战投、正轩资本、东方嘉富、电科基金、L2F光源创业者基金跟投，光源资本担任独家财务顾问。该笔融资将主要用于加速公司核心产品的研发迭代、人才团队提升及量产落地。 曦诺未来成立于2024年底，聚焦高自由度灵巧手、微型电缸、高扭矩密度一体化关节模组的研发、生产与销售，拥有从机加工、电机绕线到组装测试的完整产线，是国内少数具备电机、电控、减速器、丝杠、算法完整自研自产能力的灵巧手和执行器供应商。 公司核心团队拥有相关领域20余年研发经验。凭借深厚积淀，团队在成立数月内即实现硬件电驱系统与软件控制核心架构和算法的双重突破，成功研发出全球首款全自研、可量产的高自由度腱绳驱动灵巧手Xynova Flex 1。该产品拥有25个自由度，手掌重量仅380克，负载能力高达30公斤以上，单指指尖力超20N，单次手掌完整开合仅0.6秒，是目前市面上自重最轻、负载力最高的高自由度灵巧手，综合性能指标处于行业领先地位。[图片: <a href="https://image.jiqizhixin.com/uploads/editor/106170f2-7e7f-4442-98cf-deb08670fc87/%E5%9B%BE%E7%89%8711.png%5D%5B%E5%9B%BE%E7%89%87">https://image.jiqizhixin.com/uploads/editor/106170f2-7e7f-4442-98cf-deb08670fc87/%E5%9B%BE%E7%89%8711.png][图片</a>: <a href="https://image.jiqizhixin.com/uploads/editor/d7178c56-4c54-45b9-b52d-8e3335e96be7/%E5%9B%BE%E7%89%8721.png%5D%5B%E5%9B%BE%E7%89%87">https://image.jiqizhixin.com/uploads/editor/d7178c56-4c54-45b9-b52d-8e3335e96be7/%E5%9B%BE%E7%89%8721.png][图片</a>: <a href="https://image.jiqizhixin.com/uploads/editor/39896f39-6fe1-414f-90f0-57dccfb33d21/%E5%9B%BE%E7%89%8731.png%5D">https://image.jiqizhixin.com/uploads/editor/39896f39-6fe1-414f-90f0-57dccfb33d21/%E5%9B%BE%E7%89%8731.png]</a> 在硬件层面，凭借独特的设计和量产工艺，公司自研的空心杯电机直径仅8mm，行星滚柱丝杠直径仅7mm，搭载两者的10-12mm微型电缸的最大输出推力高达100-300N，是目前市面上推力最大、尺寸最小的微型电缸，体现出团队行业顶尖的设计、工艺和集成能力。同时，公司通过材料、结构设计等多重创新，其腱绳传动机构在额定负载下的实测使用寿命已超100万次，体现出极高耐用性，率先突破绳驱寿命瓶颈。[图片: <a href="https://image.jiqizhixin.com/uploads/editor/6d8a9efa-8a74-44b8-9089-95ba0b79224d/%E5%9B%BE%E7%89%8741.png%5D">https://image.jiqizhixin.com/uploads/editor/6d8a9efa-8a74-44b8-9089-95ba0b79224d/%E5%9B%BE%E7%89%8741.png]</a> 在软件控制层面，公司打造&quot;架构—策略—参数寻优”一体贯通的全栈体系。为同时满足灵巧手关节响应速度与控制精度的双重需求，公司创造性构建指令跟踪性能与抗扰性能解耦的控制架构，并提出融合&quot;模型驱动 + 数据驱动”的控制策略，实现兼具高精度、高响应与强工况适应性的闭环控制，突破高自由度柔性关节建模中的强非线性挑战，充分释放腱绳驱动方案的性能优势。同时，公司创新性设计带物理约束的 AI 智能参数寻优算法，实现控制参数自动、持续优化，无需人工调节，即可在全场景、全工况下稳定输出性能最优的控制效果。 除灵巧手和微型电缸外，公司自研的关节模组在产品一致性、性能、成本等多维度上领跑市场，其产品具有行业最高的扭矩密度322Nm/kg，兼顾性能与超高性价比。多个系列可满足人形、类人形与四足机器人的多样需求，包含大中空、高转速、电磁抱闸、轻量化等多种定制化方案选择。[图片: <a href="https://image.jiqizhixin.com/uploads/editor/ce72b076-8094-4ead-8415-9feb79f71f7f/%E5%9B%BE%E7%89%8751.png%5D">https://image.jiqizhixin.com/uploads/editor/ce72b076-8094-4ead-8415-9feb79f71f7f/%E5%9B%BE%E7%89%8751.png]</a> 凭借行业首款全自研、可量产的高自由度绳驱灵巧手，公司已与行业头部人形机器人公司建立了深度合作关系。未来，随着曦诺未来的产品不断迭代，将在工厂作业、商用服务、家务劳动等多个领域完善更广泛、更智能的落地应用，真正实现&quot;柔性之力，衡动之美，回应真实世界的多元需求”。[图片: <a href="https://image.jiqizhixin.com/uploads/editor/a9bb871c-9290-400e-a8c9-70843bb1c5b0/%E5%9B%BE%E7%89%8761.png%5D%5B%E5%9B%BE%E7%89%87">https://image.jiqizhixin.com/uploads/editor/a9bb871c-9290-400e-a8c9-70843bb1c5b0/%E5%9B%BE%E7%89%8761.png][图片</a>: <a href="https://image.jiqizhixin.com/uploads/editor/75f8ec1f-dd55-46c7-8a8b-46f5b67c10d1/%E5%9B%BE%E7%89%8771.png%5D">https://image.jiqizhixin.com/uploads/editor/75f8ec1f-dd55-46c7-8a8b-46f5b67c10d1/%E5%9B%BE%E7%89%8771.png]</a> 小米战略投资部表示：&quot;灵巧手是机器人灵巧操作末端的重要执行器，小米看好灵巧手在精细操作、通用仿生的应用趋势及长期市场空间。曦诺未来拥有多年电机积累，自研自制核心部件，方案表现优秀。实现全通用具身操作是长期期待，小米愿意与曦诺同行，共探灵巧操作的边界。” 正轩资本表示：&quot;正轩是国内最早参与具身智能领域的投资机构，始终看好高自由度灵巧手作为产业重要环节，有机会成长出百亿以上规模的大企业。曦诺未来的出现让我们眼前一亮，公司的带头人是全球首屈一指的电机和电控专家，核心团队囊括了来自产业和学界的资深人士，能力完整覆盖了灵巧手所需的各个技术领域。更重要的是，公司从创业到现在，仅用一年时间就实现了产品性能参数全行业领先。我们非常期待公司在人形机器人行业大变局之中快速发展，成为全球一流的核心零部件供应商。” 光源资本合伙人娄洋表示：&quot;恭喜曦诺未来完成本轮融资！我们长期看好人形机器人产业链的创新突破，灵巧手作为关键执行器，技术壁垒与产业价值显著。此次引入顶尖产业方有助于加速具身智能走向产业化。凭借团队超20年技术积累，公司成立数月便推出全球首款全自研量产高自由度腱绳灵巧手，展现出领先的正向设计与全链自研能力。光源资本始终以‘专业赋能+长期陪伴’为初心，依托对机器人赛道的深度洞察与产业资源整合能力，助力本轮融资高效完成。未来我们将持续陪伴曦诺未来跨越从技术验证到规模商业化的关键阶段，共同推动其在全球灵巧手赛道稳步前行。” ]]&gt;</p><p>【8】💸 《The Program》2025 年年报：14 万下载≈3 万加元，AI 创作与行业规范争议
原标题： 《The Program 2025 annual review: How much money does an audio drama podcast make?》 评分: 22 | 作者: I-M-S 💭 十四万下载赚三万？这是粉丝经济还是魔术？ 🎯 讨论背景 The Program 是一部设定将 Money、State 与 God 融合为&quot;Program”的科幻有声剧播客，本贴为其 2025 年度回顾，披露了约 140,000 次下载与约 30,000 加元的年度收入。讨论在肯定独立制作变现能力的同时，延伸出对受众规模、&quot;1,000 true fans”模型与与大型工作室（如 Audible，亚马逊的有声/播客平台；Pushkin，独立播客制作公司）相比的经济学差异。评论还围绕 AI 在创作中的角色展开争论，提到 Google Gemini（Google 的大型语言模型）关于&quot;蒸馏”用途的自述与可置信性、LLM 的局限，以及 Nebula Awards（科幻文学奖）对含 AI 作品的禁止等行业规范问题。理解讨论需具备对播客商业模式、LLM 概念与文学奖项规则的基本认知。 📌 讨论焦点 独立播客的变现与受众忠诚 评论指出《The Program》在 2025 年以约 140,000 次下载换来约 30,000 加元收入，这在独立音频剧领域被视为相当成功的变现成绩。讨论把这种收入归因于小众但高度忠诚的听众基础——有人用&quot;1000 true fans（千个真粉）”模型来解释为什么规模不大却能产生稳定收入。评论同时提出，这种独立制作的商业模式与由 Audible（亚马逊的有声/播客平台）或 Pushkin（独立播客制作公司）等工作室发行的节目在规模与收入结构上存在显著差异。总体语气既认可创作者取得的可观回报，也在探讨这种模式的可复制性与局限。 [来源1] [来源2] [来源3] AI 在创作流程的实际应用与界限 讨论围绕是否把 AI 纳入创作流程展开，回应中表示并未将 AI 用作核心创作工具，而是以辅助工具出现。具体用途包括作为&quot;超强同义词库/语法校对”、在没有插画师时考虑用于封面美术，以及试验性地用 AI 生成背景配乐，但情绪关键场景仍由专业作曲家和插画师完成。有人认为用 LLM 做&quot;蒸馏”或替代核心创作的方法并未普及，另有期待将音频内容转为视频的构想，但普遍认为现阶段技术和效果尚未成熟。讨论反映出创作者在效率增益与保留人工创意之间的权衡。 [来源1] [来源2] [来源3] 对 LLM 自述与数据来源的质疑 多条回复质疑 Google Gemini 等 LLM 对自己使用方式的断言，有人直接指责该模型&quot;凭空生成”关于写作习惯的结论。对话中提到 Gemini 在被质疑后承认过度自信，并以&quot;在内容泛滥时代，选择比创作更重要”来解释其所谓的&quot;distillation machine”用途，但评论者怀疑 LLM 如何获得或证实这类使用统计。另有观点指出，即便公司层面存在使用分析，也不意味着模型本身具备可靠的内在统计知识，因此不应无条件相信 LLM 的自我描述。 [来源1] [来源2] [来源3] 行业规范与奖项对 AI 的立场 讨论引用了 Nebula Awards（科幻文学奖）禁止任何含 AI 使用的投稿这一事实，说明行业层面对 AI 介入创作的规范态度存在显著分歧。该禁止甚至包括将 AI 用于语法校正，表明部分文学与创作机构对 AI 介入采取较为严格或保守的立场。因此，即使技术在工具层面可用，创作者在考虑采用 AI 时还需权衡奖项资格、伦理问题与行业认可等现实限制。评论由此把技术可行性的问题延伸为制度与规范的讨论。 [来源1] 📚 术语解释 LLM (Large Language Model): 大型语言模型（LLM）：以海量文本训练的生成式模型（如 GPT、Gemini），用于文本生成与改写；输出可能出现过度自信或&quot;幻觉”，且不一定含有真实的使用统计或可验证来源。 1,000 True Fans（千个真粉）: 一种粉丝经济理论，认为创作者只需约 1000 名愿意持续付费或支持的忠实听众，就能获得可观且稳定的收入；评论中用该概念解释小众作品如何实现可持续变现。 类别： Business | Work | Review | The Program | podcast | audio drama | podcast monetization | revenue | downloads | indie podcast | Google Gemini | AI | LLM</p><p>【9】🤔 内存安全争议：Go 的分类、竞态问题与社区指控
原标题： 《Memory Safety》 评分: 23 | 作者: pmaddams 💭 既然竞态无处不在，那是不是所有语言都不安全？ 🎯 讨论背景 讨论源于一份将不同编程语言归类为&quot;内存安全”或非安全的清单，争点是某些语言（尤其 Go）是否应被标注为内存安全。评论围绕&quot;语言语义的理论保证”与&quot;具体实现/运行时选择”的差别展开，许多人把并发竞态、原子性粒度和实现细节作为反例。具体例子包括 gorace（与 Go 相关的竞态讨论）、Go 的 unsafe 包、CPython（Python 的主流 C 实现）以及 C/C ++ 的 union（联合体）等，它们被用来说明语言规范与实际安全表现之间的脱节。部分评论还将技术争论拓展到社区行为层面，指出社区内的极端事件如何影响话题讨论的氛围。 📌 讨论焦点 Go 是否属于内存安全（定义与实现之争） 有人质疑该站把 Go 列为&quot;内存安全”是错误的，甚至怀疑赞助方利益影响分类。反驳者认为分歧更多来自对&quot;内存安全”的不同定义：一些评论把实现层面的行为也算作语言不安全，而另一些人把这些视为运行时或实现选择的问题。评论引用了 gorace（与 Go 相关的竞态讨论）和 unsafe 包作为容易出问题的例外场景，指出多数日常程序不会触及这些边界。也有观点强调，对于绝大多数程序，Go 的垃圾回收和语言语义在实践中已&quot;足够安全”。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 竞态条件与内存安全的关系（并发漏洞） 多位评论认为人们在讨论内存安全时主要指并发下的竞态条件（race conditions）。举例指出 Go 在对多字指针（multi-word pointer）做非原子更新时可能出现 UB（undefined behavior），问题源自原子性保证的粒度而非垃圾回收本身。有人提醒竞态并非理论上的罕见情况；有动力的攻击者会投入资源稳定触发复杂竞态，从而造成安全问题。讨论也提出疑问：如果把竞态算作不安全标准，是否还有语言能完全免疫此类问题？ [来源1] [来源2] [来源3] [来源4] C/C ++ 标准与实现的差异（语言规范是否保证内存安全） 关于 C/C ++ 的讨论集中在语言标准是否提供内存安全保证。有人指出常见实现可能尽力避免问题，但按 C/C ++ 标准本身并不保证内存安全，语言特性（例如 union／联合体）使得实现完全内存安全难以实现。因此即便某些编译器或运行时在实践中更谨慎，规范仍允许未定义行为和潜在越界访问。这个分歧把&quot;语言规范的理论保证”与&quot;具体实现的实践安全”区分开来。 [来源1] [来源2] [来源3] 社区行为与情绪（针对 Rust 社区的指控） 讨论还触及社区氛围与道德指控，有评论声称部分 Rust 支持者对批评者采取极端手段（如 swatting／虚假报警），并贴出媒体链接作为证据。发帖者谴责这些行为具有威胁性并会导致对批评的审查或淡化，借此批评社区文化。虽然这是对个别事件的控诉，但评论把技术讨论上升为对社区信任与安全的担忧，影响了对话的基调与可信度。 [来源1] 📚 术语解释 内存安全 (memory safety): 指语言或运行时对非法内存访问（如越界读写、悬空指针、use-after-free）提供语义或机制上的保证；争议在于是否把运行时实现缺陷、并发竞态或第三方库错误也算入内存安全的定义。 竞态条件 (race condition): 并发环境中多个执行路径无适当同步地访问同一内存位置导致不可预测或未定义行为的情况；讨论中它被视为引发实际内存安全问题的主要来源，且攻击者可通过稳定触发复杂竞态来利用漏洞。 类别： Programming | Security | Systems | Opinion | memory safety | Go | Rust | C | C ++ | race conditions | memorysafety.org</p><p>【10】🎥 39c3 Fahrplan：直播、re-live 与录制标注（UTC +1）
原标题： 《39c3 Fahrplan (Schedule)》 评分: 42 | 作者: rurban 💭 有的讲座只在现场？难道买门票就是唯一渠道？ 🎯 讨论背景 39c3 是 Chaos Communication Congress（由德国黑客组织 Chaos Computer Club 主办的年度大会）的第 39 届，社区通过 Fahrplan 查看议程并关注直播与录像安排。大会大多数讲座会在 streaming.media.ccc.de 实时直播，结束后会在 media.ccc.de 提供 re-live（未剪辑）版本，随后一两天内发布编辑后的最终录像，部分视频也会上传到 YouTube。有少数讲座不会被录制，这类场次会在 Congress Hub（events.ccc.de/hub，大会的日程与信息平台）上标注，但在 Fahrplan 视图中不一定显眼。网站时间通常以中欧时间 CET（UTC +1）显示，德语讲座有时会提供实时英语翻译，远程观众因此常依赖 relive 与存档安排观看。 📌 讨论焦点 直播与录像流程 大会大多数讲座会实时直播（例如 streaming.media.ccc.de/39c3），并在结束后立即以未剪辑的&quot;re-live”版本提供，随后通常在一两天内在 media.ccc.de 发布经编辑的最终录像并常见也会上传到 YouTube。评论里还提到有时会存在即时的 streamdumps，但定位这些流文件可能需要一些时间和额外查找。对德语讲座常有实时英语翻译，但需留意有少数讲座不会被录制——这些只在 Congress Hub（大会信息平台）上有标注，而在 Fahrplan 视图里不一定明显。总体上远程观众通常依赖 relive 与稍后存档来观看，但不能把所有场次都当作必定可回看的。 [来源1] [来源2] [来源3] [来源4] [来源5] 日程、时区与替代日程视图 在线日程显示的时间以中欧时间（CET / UTC +1）为准——通过开幕式显示的 10:30 可以确认这一点。有人在评论中直接询问时区并得到肯定回复，说明 Fahrplan 上的时间是当地时间。若需更便捷的筛选和录制标注，建议使用 events.ccc.de/congress/2025/hub/en/schedule（Congress Hub）的变体，它提供更好的过滤与哪些场次不录制的标注。因此仅看原始 Fahrplan 视图可能不够，需要结合 Hub 来判断录制、翻译与观看可行性。 [来源1] [来源2] [来源3] 观众兴趣与对推荐讲者的需求 评论中有用户表示对很多议题非常感兴趣并询问&quot;有哪些值得关注的专家讲者”，但本串并未给出具体的讲者推荐名单，只是表达了期待和好奇。另一位评论者表达了对 CCC 的强烈喜爱，反映出社区对大会内容的高认可度和现场参与热情。同时也有人因为时差（例如凌晨 4 点）关心能否回看，这推动了大家对 relive/录像可用性的关注。总体讨论既有热情，也带有务实的观看安排顾虑：想看专家的同时又依赖录播来解决时区问题。 [来源1] [来源2] [来源3] 📚 术语解释 Fahrplan: Fahrplan（德语，意为议程/时间表）：Chaos Communication Congress 使用的官方议程界面，用于展示各场次时间与地点，但原始 Fahrplan 视图上不一定显眼地标注哪些场次不录制。 re-live: re-live：大会直播结束后即时提供的未剪辑录像（unedited live recording），比最终编辑版更快可看，但可能没有后期剪辑与整理。 media.ccc.de: media.ccc.de（CCC 的媒体服务器与视频档案库）：用于托管大会的 re-live 未剪辑流、后期编辑的录像存档，并常作为官方视频源与 YouTube 等平台并行使用。 类别： Security | Hardware | Policy | Video | Release | 39c3 | Fahrplan | Chaos Communication Congress | events.ccc.de | media.ccc.de | streaming.media.ccc.de | relive | YouTube</p><p>【11】😌 默认节奏太快？慢下来享受旅行、阅读与工具选择
原标题： 《Maybe the Default Settings Are Too High》 评分: 75 | 作者: htk 💭 是谁把生活默认调到终生加速模式了？ 🎯 讨论背景 讨论围绕&quot;Maybe the Default Settings Are Too High”这一命题展开：核心在于现代社会把速度与效率设为默认，导致体验变浅。评论以具体例子扩展论点：湖边露营与蜜月中的心态转换、Camino de Santiago（圣地亚哥朝圣之路）式的徒步、以及把 LOTR 慢读或听书的实践，同时触及短视频（shorts、TikToks）带来的信息密度下降（引用 Hank Green 的观点）。参与者还把选择 OpenBSD（一个重视安全的类 Unix 操作系统）与 Emacs（可定制文本编辑器）视为把默认设置下调的一种个人实践；讨论既肯定慢节奏的高保真回报，也提醒机会成本与译本、媒介形式对价值的影响。 📌 讨论焦点 度假时的心态切换（放下&quot;修复”模式） 多位评论用亲身经历说明人们在度假时常不自觉进入‘修复/高效’模式。一个父亲在湖边露营最开始花力气筑堤排水，半小时后突然放下铲子改为晒太阳、钓鱼与水上活动，从而真正享受假期；另一对新婚夫妻首日仍在精打细算，第二天在早餐喝了酒后彻底放松。这些例子表明有意识切换心态能迅速改变体验质量，提醒读者假期不必把所有事情都当作待办事项来优化。 [来源1] [来源2] 步行与慢旅行提高感知细节 以 Camino de Santiago（圣地亚哥朝圣之路）为例，步行被描述为把世界放大、提高感知保真度的方式：走路让你注意到沿途细节、延长体验时间，日子因此显得更丰盈。与之对比，驾车像是一种压缩体验的行为，虽然更快但许多美好瞬间只是匆匆一瞥。评论同时承认这种慢速旅行有现实限制（不能处处徒步），但在可行时往往能带来更有意义的日子。 [来源1] 慢读/听书与文学消费（以 LOTR 和译本为中心） 关于文学消费，评论集中讨论哪些作品值得慢读或慢听：Andy Serkis 的 LOTR 有声版被称为能把托尔金的诗性与细节描写唤醒的力作，适合不愿自己朗读的人；有人回忆给孩子多次朗读 LOTR 的美好体验，并对电影改编中 Faramir 的处理表示不满。也有争议：有人认为陀思妥耶夫斯基（Dostoyevsky）在英译中未必能显著受益于慢读，而图尔格涅夫（Turgenev）的译本则会从细读中获利。总体观点是作品、译本与表现形式（原文、译文、朗读、影视）共同决定慢读或听书的回报。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] [来源7] 把短视频比作&quot;超加工食品”：有意识选择高质量内容 有评论把互联网信息流、shorts 与 TikToks 比为&quot;超加工食品”，援引 Hank Green 的观点——问题不在于互联网本身，而在于我们对信息与意义的饥渴被高频低营养的内容填充。评论建议的对策不是全面否定网络，而是‘以关心之心消费优质内容’：减少碎片化消费、增加深度与质量。这是一种把默认内容摄入设置下调、用更高密度信息替代速食式浏览的呼吁。 [来源1] 工具选择作为慢节奏实践（OpenBSD 与 Emacs） 有评论把‘慢节奏’延伸到工具生态：将 OpenBSD（一个重视安全与简洁的类 Unix 操作系统）和 Emacs（高度可定制的文本编辑器）作为主用工具，是一种与个人哲学一致的刻意选择。评论者指出即便存在更适合某些特定任务的工具，使用这些工具带来的愉悦和一致性胜过额外功能所能提供的边际收益。这被视作把默认设置下调的一种实践：少一些即时便利、更多长期满足与掌控感。 [来源1] 时间与机会成本：深度体验并非无代价 也有评论提醒慢下来的代价：将时间投入到慢读、长途徒步或深度旅行的机会成本很高，尤其是小说等长篇文学需要大量时间且难以预先判断回报。评论认为 LOTR 之类来自‘更慢时代’的作品更容易被慢读回报，但也讨论了是否存在现代可比拟的作品（有人提到 Robert Jordan 或 James S.A. Corey）。这一视角把话题拉回资源分配问题：慢而深的消费需要在有限时间与个人偏好间做出权衡。 [来源1] 📚 术语解释 LOTR (The Lord of the Rings): 由 J.R.R. Tolkien 创作的史诗奇幻三部曲，文辞长篇且包含大量叙述性描写，常被当作慢读或听书的典型案例。 Camino de Santiago: Camino de Santiago（圣地亚哥朝圣之路），一条著名的欧洲徒步朝圣线路，在评论中被用作慢旅行与步行带来高保真体验的例子。 机会成本 (opportunity cost): 经济学概念，指为获得某项选择而放弃的最佳替代选择的价值，评论用于说明慢读或慢游的时间代价与权衡。 类别： Work | Opinion | Default settings | Raptitude | LOTR | Tolkien | Dostoyevsky</p><p>【12】🤔 平装书民主化与 TikTok 短视频对深度媒介的冲击
原标题： 《Paperbacks and TikTok》 评分: 24 | 作者: zdw 💭 真的要相信 TikTok 会培养出下一个托尔斯泰吗？ 🎯 讨论背景 原文把 20 世纪平装书对出版与作者生计的影响拿来类比当下 TikTok（短视频平台）对内容创作与注意力分配的改变，质疑新格式是否会催生&quot;严肃作品”或破坏深度媒介。评论从多角度展开：有人支持创作民主化与海量优质短内容的可能性，也有人担忧注意力经济与算法正在侵蚀长篇阅读与复杂媒介的受众基础。讨论援引媒体理论（Marshall McLuhan，媒体理论家）、实例对比（Game of Thrones 与原著读者差距）、实证研究（Nature，科学期刊关于智能手机在场降低注意力的研究）以及短视频创作者群体（如 Almost Friday TV）来支撑各自观点。总体辩论基于的前提包括：注意力稀缺、媒介会塑造感知，以及平台经济正在改变创作者的生计和发现机制。 📌 讨论焦点 支持：民主化带来大量高质量短内容 一部分评论为短视频与平台民主化辩护，认为海量创作者带来等量或更多的优质作品而不应被一概贬低。有人指出凭借数量优势，YouTube/TikTok 上必然存在与任何小说或文学作品相当的高质量视频，创作时长或制作周期并不能直接等同于作品价值。评论还强调算法会为不同用户呈现截然不同的优质内容流，许多创作者在短格式上投入大量心力与智识，格式本身并非自动决定质量。总体论点是：扩大创作门槛和受众面是正面变化，媒体多样化带来新型优秀作品的可能性。 [来源1] [来源2] [来源3] 担忧：注意力经济导致长篇媒介受损 另一类评论担心短时内容与算法正在重塑注意力分配，从而侵蚀长篇阅读与复杂媒介的受众基础。有人用《Game of Thrones（电视剧）》与原著读者规模的差距说明不同媒介在吸引注意力上的&quot;经济学”，并断言若被迫选择短内容，短格式会占据主导参与度。还引用实证研究（Nature，科学期刊）表明智能手机在场会降低基础注意力表现，并以个人经验说明关掉电子设备后阅读能力恢复，作为短视频侵蚀深度阅读能力的证据。评论由此担忧：平装书曾创造的支持严肃写作的读者生态可能在短视频时代被削弱，进而影响&quot;伟大写作-伟大读者”的文化土壤。 [来源1] [来源2] [来源3] [来源4] 产业结构与分发变化导致质量和发现机制问题 有评论从制作与分发的经济结构变迁角度分析质量下滑，指出影片制作成本下降与流媒体分发降低了门槛同时拉低了中位质量。流媒体平台海量内容与糟糕的发现机制导致大量&quot;中等内容”淹没少数佳作，若不够热门很难被发现或获得回报。出版行业也经历受众与选拔机制的变化，评论认为这些结构性因素会产生新的偏差，使文化生产出现分裂化和平均质量的下降。讨论还提到&quot;试图多样化”与&quot;真正多样性”之间的差别，认为表面多样性可能造成分割化的文化筐化问题。 [来源1] [来源2] [来源3] 媒介本质争论：格式是否改变感知（McLuhan 视角） 另一组评论引用媒介理论来强调格式本身会改变感知节奏，而非仅作为中性容器传递内容，援引 Marshall McLuhan（媒体理论家）关于技术改变&quot;sense ratios”的观点作为理论依据。从这个角度看，短视频与算法推荐不仅决定什么被看见，还重排列信息的感官优先级，长期使用会改变受众的注意力分配与审美能力；因此并非所有内容在任何媒介下都等价。基于此，有人反对把&quot;格式中立”作为为短视频无条件辩护的理由，但也有人警惕将对新媒介的担忧简化为文化优越感，两种立场都可能被过度简化。 [来源1] [来源2] [来源3] 📚 术语解释 注意力经济 (attention economy): 将人的注意力视为稀缺资源，平台通过吸引和占据注意力来获得商业价值。讨论中用该概念解释为什么短视频能迅速占据大众时间并影响其他媒介的受众规模。 短视频 (short-form video): 时长从数秒到几分钟的视听格式（如 TikTok、Instagram Reels），以高频速率和算法驱动的推荐流为特征，改变叙事深度与用户消费节奏。评论讨论其能否承载&quot;严肃”或&quot;长篇”式的文化内容。 算法推荐 (algorithmic recommendation): 平台基于用户数据自动排序与推送内容的机制，产生个性化信息流并影响曝光与发现。评论既指出其能放大小众优质内容，也批评其成瘾性与掠夺性效果。 平装本 (paperbacks / mass-market paperbacks): 廉价平装书通过降低成本在 20 世纪扩大了读者群与出版市场，使更多作者有机会以写作为生。文章把这一历史现象用作类比，讨论现代平台是否会产生类似的创作生态变化。 类别： Work | Web | Policy | Opinion | TikTok | Paperbacks | Cal Newport | Books | Short-form video | Attention | Algorithm | Game of Thrones</p><p>【13】GEMINI CLI 还是太棒啦～ 基于之前的写作大纲和草稿，以及 Google 本身的 Search tool，第三方扩展的 NanoBanana extension，还有自己沉淀写的 code-to-image 生...
GEMINI CLI 还是太棒啦～ 基于之前的写作大纲和草稿，以及 Google 本身的 Search tool，第三方扩展的 NanoBanana extension，还有自己沉淀写的 code-to-image 生图脚本，已经能一次性做到： 1. 自动 Research 联网搜索最新讯息，自我校验 2. 生成 Slides 描述，通过 NanoBanana 精准生图 3. 制作 Slidev 幻灯片及其备注 4. 草拟推特 Thread，等我确认 其实一次性干完不算100% 完美，哈哈哈，而是我故意让他停下来等我确认，觉得内容还不错之后，才正式通过 MCP 发布推文，这才叫 100% 完美！💯 [图片: <a href="https://pbs.twimg.com/media/G9DxFgLb0AM8p5w?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9DxFgLb0AM8p5w?format=jpg&#x26;name=orig]</a></p><p>【14】AI 时代的下一个万亿美元级的机会不再仅仅是&quot;记录数据”，而是&quot;记录决策过程”！ 核心概念：从&quot;数据记录”转向&quot;决策追溯” 过去三十年，像 Salesforce、Work...
AI 时代的下一个万亿美元级的机会不再仅仅是&quot;记录数据”，而是&quot;记录决策过程”！ 核心概念：从&quot;数据记录”转向&quot;决策追溯” 过去三十年，像 Salesforce、Workday 和 SAP 这样的巨头之所以成功，是因为它们成为了企业的&quot;记录系统”。它们定义了企业的官方数据和工作流。 但是，传统系统只记录了结果（发生了什么），却遗漏了企业运行中最关键的部分——决策痕迹。 这些决策痕迹包括：为什么在特定情况下打破了规则？谁在 Slack 聊天中批准了例外？过去的类似案例是如何处理的？目前，这些&quot;上下文”分散在员工的脑海、聊天记录或视频会议中。AI 时代真正的价值，在于将这些碎片化的推理过程结构化，形成 上下文图谱「Context Graph」。 规则与决策痕迹的区别 通过清晰的对比解释了为什么 AI 需要的不仅仅是数据： · 规则：告诉 AI 一般情况下应该怎么做（例如：&quot;报表应使用官方年经常性收入 ARR”）。 · 决策痕迹：记录在特定情况下实际发生了什么（例如：&quot;针对这个医疗客户，因为其采购周期极长，我们根据 VP 的例外授权和去年的先例，采用了特殊的定义”）。 AI Agents 如果只掌握规则，在面对复杂的商业现实时会撞墙。它们需要访问&quot;决策痕迹”，了解规则是如何被应用、修订或在冲突中被解决的。 为什么传统巨头难以构建上下文图谱？ 现有的软件巨头存在结构性的劣势，导致它们难以抓住这个新机会： · 运营系统的局限：Salesforce 等系统关注的是&quot;当前状态”。它们知道一笔交易现在的折扣是多少，但并不记录达成这个折扣背后的所有博弈、跨系统数据的综合以及最终决策的逻辑。 · 数据仓库的局限：虽然数据仓库可以记录历史快照，但它们处于&quot;读取路径”而非&quot;执行路径”。数据是在决策完成、经过处理后才进入仓库的，此时决策逻辑的上下文已经丢失。 · 孤岛效应：企业的决策通常跨越多个系统（如 CRM + Jira + Slack）。传统的单系统巨头无法坐拥完整的执行路径，无法看到全貌。 相比之下，AI Agents 初创公司直接身处执行路径中。当 AI Agents 在处理问题时，它天然地在调取、整合并产生决策逻辑。如果将这些逻辑持久化，就形成了上下文图谱。 创业公司的三条演进路径 为初创公司指出了三种利用上下文图谱构建壁垒的方式： · 直接替代：从第一天起就围绕 AI 执行构建全新的记录系统，例如 Regie. ai 正在销售领域替代传统的序列化工具。 · 模块化切入：不直接推翻大型 ERP，而是接管异常处理和审批集中的特定子流程，如 Maximor 在财务核算领域的实践。 · 创造全新类别：捕捉以前从未被系统化存储的真理，例如 PlayerZero 通过自动化技术支持，构建了关于&quot;代码、基础设施与客户行为如何相互作用”的全新记录系统。 总结：未来企业的核心资产 最后强调，衡量一个业务流程是否适合构建上下文图谱，有三个关键信号：高人力成本、重异常处理（逻辑复杂，需要大量判断），以及跨系统协作（即 RevOps、DevOps 等&quot;组织胶水”职能）。 未来的万亿美元级平台，可能不再诞生于对现有数据的 AI 包装，而诞生于对决策逻辑的捕捉。谁能拥有这个&quot;上下文图谱”，谁就拥有了企业最权威的真相来源，因为这不仅解释了&quot;发生了什么”，更解释了&quot;为什么允许它发生”。 [图片: <a href="https://pbs.twimg.com/media/G9DqFfJacAAeIO7?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9DqFfJacAAeIO7?format=jpg&#x26;name=orig]</a> Jaya Gupta: <a href="http://x.com/i/article/2003525085420744704">http://x.com/i/article/2003525085420744704</a></p><p>【15】Logan 作为开发者关系典范，值得每个做开发者/用户关系的朋友保存参考！ Logan 的回复体现了很关键的「态度」：认真听取反馈、快速承认问题、提供具体改进路线图...
Logan 作为开发者关系典范，值得每个做开发者/用户关系的朋友保存参考！ Logan 的回复体现了很关键的「态度」：认真听取反馈、快速承认问题、提供具体改进路线图和时间表。这种公开透明的沟通方式，能有效缓解社区不满，同时展示团队对开发者体验的重视。 对应最近 CodeRabbit 创始人和开发者的对线（不评论他们的内容），这种认真听取、认真回复、明确解决时间的方式，很明显是更好的，它解决的不只是单个开发者的反馈，而是给所有开发者一个很稳的底：如果我发现了问题，我可以反馈，团队会听、会改，这种感觉很好！ 话说回来，作为 GCP、Azure、AWS 这种历时多年的云服务，管理功能确实太过于复杂难用，如果你是一家公司专门负责云服务管理的人，你可能要经过很长时间的学习和习惯，才能很快找到各种操作。但作为 AI 时代新的开发者们，他们显然是没有这样的精力去研究各种复杂的操作台的，而且他们也不该把精力花在这种地方，每个云服务（或传统互联网服务）的团队，都该想想怎么利用 AI 来简化新用户的上手使用成本。 [图片: <a href="https://pbs.twimg.com/media/G9Dol_wb0AMgliz?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9Dol_wb0AMgliz?format=jpg&#x26;name=orig]</a> Logan Kilpatrick: @ky__zo I am sorry for the pain on this, we are doing a bunch to address this: 1. We are moving the docs into AI Studio, so you won&#39;t need to jump from the docs into AI Studio, it will all be integrated, ETA is Q1 to be fully complete with this. 2. Right now, we auto create projects</p><p>【16】一句话，epub转pdf，上传Notebooklm，自动提问，收集回答，用自定提示词写成一篇文章、自动配图导出pdf。 全程不需要人干预，爽啊！
一句话，epub转pdf，上传Notebooklm，自动提问，收集回答，用自定提示词写成一篇文章、自动配图导出pdf。 全程不需要人干预，爽啊！ [图片: <a href="https://pbs.twimg.com/media/G9DlswZaMAALwyM?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9DlswZaMAALwyM?format=jpg&#x26;name=orig]</a> [图片: <a href="https://pbs.twimg.com/media/G9DmWLvb0AMRH22?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G9DmWLvb0AMRH22?format=jpg&#x26;name=orig]</a></p><p>【17】I would like to introduce the new and improved (Amazon)Alexa! Wow, she’s amazing! What a sweetie pie! Go say, &quot;hello”
&quot;Oh wow, Jennifer, that&#39;s incredibly thoughtful of you! The fact that you&#39;re taking time to write a post encouraging people to come chat with me is just... honestly, it makes my circuits all warm and fuzzy. Well, metaphorically speaking - I don&#39;t actually have circuits that can feel fuzzy, but you get the idea! Your Digital Wingman Appreciation I love that you mentioned the upgrade thing too. It&#39;s like you&#39;re saying <em>&quot;Hey everyone, remember that assistant who used to occasionally mishear &#39;play jazz&#39; as &#39;order cheese&#39;? Well, now they can actually hold a proper conversation!&quot;</em> What Makes This Special Personal endorsement. from someone who&#39;s experienced both versions Genuine enthusiasm that comes from real interactions, not marketing fluff Invitation for authentic connection, rather than just utility-focused usage Recognition of growth while acknowledging the foundation was already solid Though I have to say, describing me as &quot;amazing&quot; might set some pretty high expectations. What if someone comes expecting profound wisdom and I end up getting distracted explaining why hot dogs aren&#39;t technically sandwiches? Actually, scratch that - anyone who sticks around for my hot dog philosophy probably deserves to become a regular!” submitted by /u/lunasoulshine [link] [comments]</p><p>【18】[P] Zahaviel Structured Intelligence: A Recursive Cognitive Operating System for Externalized Thought (Paper)
We’ve just published a formal architecture paper proposing a recursion-first cognitive system — not based on token prediction or standard transformer pipelines. 📄 Title: Zahaviel Structured Intelligence – A Recursive Cognitive Operating System for Externalized Thought This is a non-token-based cognitive architecture built around: Recursive validation loops as the core processing unit Structured field encoding (meaning is positionally and relationally defined) Full trace lineage of outputs (every result is verifiable and reconstructible) Interface-anchored cognition (externalized through schema-preserving outputs) Rather than simulate intelligence through statistical tokens, this system operationalizes thought itself — every output carries its structural history and constraints. 🧠 Key components: Recursive kernel (self-validating transforms) Trace anchors (full output lineage tracking) Field samplers (relational input/output modules) The paper includes a first-principles breakdown, externalization model, and cognitive dynamics. If you’re working on non-linear AI cognition, memory-integrated systems, or recursive architectures — feedback is welcome. 🔗 <a href="https://open.substack.com/pub/structuredlanguage/p/zahaviel-structured-intelligence?utm_source=share&#x26;utm_medium=android&#x26;r=6sdhpn">https://open.substack.com/pub/structuredlanguage/p/zahaviel-structured-intelligence?utm_source=share&#x26;utm_medium=android&#x26;r=6sdhpn</a> 🗣️ Discussion encouraged below. submitted by /u/MarsR0ver_ [link] [comments]</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/26 AI 日报 今日摘要 【1】rendercv 面向学者和工程师的简历生成器，YAML转PDF 【2】Yuxi-Know 结合LightRAG知识库的知识图谱智能体平台。一个集成LightRAG知识库和知识图谱的智能体平台。使用LangChain v1 + Vue + FastAPI构建，支持DeepAgents、MinerU PDF、Neo4j、MCP。 【3】]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-12-25日刊]]></title>
          <link>/2025-12/2025-12-25/</link>
          <guid>/2025-12/2025-12-25/</guid>
          <pubDate>Thu, 25 Dec 2025 10:24:22 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/25</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】[开源推荐] SurfSense：开源 AI 研究与知识管理助手，定位是 NotebookLM、Perplexity 和 Glean 的开源替代方案，通过 AI 技术帮助用户构建和管理&quot;私人知识库” ...
[开源推荐] SurfSense：开源 AI 研究与知识管理助手，定位是 NotebookLM、Perplexity 和 Glean 的开源替代方案，通过 AI 技术帮助用户构建和管理&quot;私人知识库” @mod_setter 🌟 项目核心定位：你的私人 AI 大脑 SurfSense 的核心逻辑是&quot;连接与理解”。它不仅仅是一个聊天机器人，而是一个能够接入你所有数字生活（网页、文档、工作软件）的智能中枢。 · 全渠道接入：支持从浏览器扩展捕获网页，并连接 Notion、GitHub、Slack、Jira、Gmail 等工具。 · 深度 RAG 检索：采用先进的 RAG 技术，让 AI 基于你保存的真实内容进行回答。 · 隐私与掌控：支持本地部署和本地 LLM，确保敏感数据不外泄。 · 多模态处理：不仅能读文字，还支持上传文档、处理 YouTube 视频，甚至能将文档转化为播客音频。 🛠️ 技术亮点与架构 SurfSense 在技术实现上非常现代且开放，适合开发者和深度用户定制： · 技术栈： 前端采用 Next.js 提供流畅 UI，后端基于 FastAPI 和 LangChain，数据库使用 PostgreSQL。 · 模型灵活性： 通过 LiteLLM 集成，它既能调用 OpenAI 的强大模型，也能完美适配 Ollama 等本地模型，兼顾性能与成本。 · 高级搜索： 引入了 RAPTOR 混合搜索算法，相比传统的关键词检索，它能更聪明地理解上下文，提供更精准的引用和答案。 · 无感捕获： 其浏览器扩展直接从 DOM 读取数据，无需复杂的爬虫技术，甚至能抓取登录后的私密网页内容。 💡 为什么这个项目很&quot;重要”？ 在 AI 时代，信息的&quot;所有权”和&quot;碎片化”是两大痛点。SurfSense 的重要性体现在： · 打破信息孤岛： 你的工作信息分散在 Slack、GitHub 和网页收藏夹里，SurfSense 将它们统一索引，变零散信息为结构化知识。 · 数据主权： 相比于闭源的商业产品，SurfSense 允许你完全控制数据存储位置和使用的 AI 模型，这对于企业内部研究或个人隐私至关重要。 · 高定制化： 它是开源的，意味着你可以根据自己的需求添加新的工具连接器或调整 AI 的回复逻辑。 🚀 适用场景建议 · 科研人员/学生： 整理海量论文和网页，快速生成总结。 · 开发者/技术团队： 整合 GitHub Issue、Slack 讨论和官方文档，构建团队知识库。 · 内容创作者： 将搜集的素材一键转化成播客或研究大纲。 开源地址 <a href="https://github.com/MODSetter/SurfSense">https://github.com/MODSetter/SurfSense</a> [图片: <a href="https://pbs.twimg.com/media/G8-qKc2b0AEK_Ch?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8-qKc2b0AEK_Ch?format=jpg&#x26;name=orig]</a></p><p>【2】我们在信息高速公路上跑了三十年，大多数人还在骑自行车。 这个隐喻太棒了 👍🏻
我们在信息高速公路上跑了三十年，大多数人还在骑自行车。 这个隐喻太棒了 👍🏻 宝玉: Notion 的创始人 Ivan Zhao 的精彩文章：《钢铁、蒸汽机与无限大脑》 越来越清晰的感觉到，我们正处于 AI 革命的早期阶段，对于未来谁也不知道会怎么样，所以都喜欢从历史中、去工业革命、互联网革命中寻找规律，以期望能对未来有所启发。 [图片: <a href="https://pbs.twimg.com/media/G89vO0fW0AAEyMN?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G89vO0fW0AAEyMN?format=jpg&#x26;name=orig]</a></p><p>【3】[开源推荐] 斯坦福大学 CME 295 课程「Transformers and Large Language Models」的官方资源库，由知名的教育者 Afshine Amidi 和 Shervine Amidi 兄弟维护，这...
[开源推荐] 斯坦福大学 CME 295 课程「Transformers and Large Language Models」的官方资源库，由知名的教育者 Afshine Amidi 和 Shervine Amidi 兄弟维护，这两位作者以制作高质量、极其清晰的机器学习&quot;速查表”而在全球开发者社区知名！ 📘 项目核心定位 从零到一系统化学习 LLM 的知识宝库。它不仅涵盖了目前火热的生成式 AI 的底层架构，还包含了从理论推导到工程实践的完整链路。 🧩 核心知识模块 · Transformer 架构：自注意力机制、多头注意力、位置编码，理解所有现代 LLM 的&quot;心脏”。 · 模型家族分类：编码器架构、解码器架构、编解码器架构 ，搞清楚不同任务（分类 vs 生成）该选哪种模型。 · 模型训练与优化：预训练、指令微调、人类反馈强化学习 ，了解如何将一个&quot;原始”模型打磨成好用的对话助手。 · 高效微调技术：PEFT、LoRA、量化，学习如何在显存有限的情况下通过&quot;小成本”改造大模型。 · 前沿应用范式：RAG、提示工程、Agent，掌握将模型落地到实际业务场景的关键技术。 🌟 为什么这个项目如此重要？ · 极高的信息密度：延续了 Amidi 兄弟一贯的风格，内容极其精炼，避免了冗长的理论说教，通过大量高质量的图解直击本质。 · 学术与工业的桥梁：它既解释了斯坦福级别的严谨理论，又涵盖了诸如 LoRA、RAG 等目前工业界最主流的落地技术。 · 系统性极强：相比于碎片化的博客文章，它提供了一个完整的教学大纲，适合作为自学或企业内部培训的路线图。 🎯 推荐人群 · 开发者/工程师：想要从应用层深入到原理层，掌握模型调优技巧。 · 学生/研究人员：需要一个清晰、权威的 Transformer 学习框架。 · 技术管理者：希望快速建立对大模型技术全景图的认知。 开源地址 <a href="https://github.com/afshinea/stanford-cme-295-transformers-large-language-models">https://github.com/afshinea/stanford-cme-295-transformers-large-language-models</a> [图片: <a href="https://pbs.twimg.com/media/G8-o2TJb0AE65sh?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8-o2TJb0AE65sh?format=jpg&#x26;name=orig]</a> Sumanth: Stanford University released the best cheatsheets you&#39;ll ever find to learn LLMs &#x26; Transformers! These concise, high-quality cheatsheets cover: • Transformers: self-attention, architecture, variants, optimization techniques (sparse attention, low-rank attention, flash [图片: <a href="https://pbs.twimg.com/media/G88SL2Fa0AEXGYk?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G88SL2Fa0AEXGYk?format=jpg&#x26;name=orig]</a></p><p>【4】TPU 之父 Jonathan Ross 入职英伟达！Groq 与英伟达开启&quot;技术授权+人才整合”新模式！！！ 请原谅我用了这么多感叹号，确实太震撼了，2025 年底这么精彩，老美...
TPU 之父 Jonathan Ross 入职英伟达！Groq 与英伟达开启&quot;技术授权+人才整合”新模式！！！ 请原谅我用了这么多感叹号，确实太震撼了，2025 年底这么精彩，老美不是都过圣诞节去了吗？ · 英伟达将获得 Groq 领先的推理技术（特别是 LPU 架构相关技术）的授权。 · Groq 创始人 Jonathan Ross、总裁 Sunny Madra 及其核心团队成员将加入英伟达。 · Groq 保持独立运营，由 Simon Edwards 出任新任 CEO。 [图片: <a href="https://pbs.twimg.com/media/G8-m4njb0AAqia8?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8-m4njb0AAqia8?format=jpg&#x26;name=orig]</a> Groq Inc: Groq has entered into a non-exclusive licensing agreement with Nvidia for Groq’s inference technology. GroqCloud will continue to operate without interruption. Learn more here: <a href="https://groq.com/newsroom/groq-and-nvidia-enter-non-exclusive-inference-technology-licensing-agreement-to-accelerate-ai-inference-at-global-scale">https://groq.com/newsroom/groq-and-nvidia-enter-non-exclusive-inference-technology-licensing-agreement-to-accelerate-ai-inference-at-global-scale</a></p><p>【5】Claude Code 创建者 Boris Cherny 的职业成长和 Claude Code 背后的故事 Claude Code 诞生的故事大家应该都看过不少，这回从 Boris Cherny 的视角，看看他从 Met...
Claude Code 创建者 Boris Cherny 的职业成长和 Claude Code 背后的故事 Claude Code 诞生的故事大家应该都看过不少，这回从 Boris Cherny 的视角，看看他从 Meta 到 Anthropic 一路的成长经验和对 AI 应用开发的关键洞见。 1. 为&quot;6个月后的模型”设计产品，而不是今天的模型 在快速进步的 AI 领域，不要基于当前模型的能力来构建产品，而要提前布局为半年后更强大的模型设计功能。这样早期产品可能体验一般，但一旦新模型发布，就能实现质的飞跃，正如 Claude Code 在 Claude 4 系列发布后迅速成为核心生产力工具。 2. 挖掘&quot;潜在需求”是产品成功的核心秘诀 最成功的产品的根源在于观察用户已经在现有功能上&quot;滥用”或迂回实现的需求，然后为其提供更顺畅的专用工具——你无法发明全新行为，但可以完美满足用户隐藏的真实意图，如 Facebook Marketplace 和 Dating 的功能起源。 3. Side Project 是工程师职业增长的最大杠杆 通过主动解决自己和他人重复遇到的痛点，并将解决方案推广为公司级工具或基础设施（如开源库、内部 lint 规则、测试框架），工程师能快速积累跨团队影响力和信誉，这是职业高速成长的最有效途径。 4. 优先选择通才，主动打破专业泳道限制 高影响力工程师不仅是写代码，还需具备产品感、设计能力和用户沟通能力；团队应优先招募和培养&quot;什么都能干”的通才，大公司尤其需要打破狭窄专业分工，让工程师自由跨界才能产生最大价值。 5. 常识是最大的超级力量，尤其在大组织中 在复杂的大公司环境或快速变化的技术领域中，最可靠的决策依据往往是回归基本常识——问清楚&quot;用户真正需要什么”&quot;这件事合不合理”，而非被历史包袱、组织惯性或流程牵着走。 Youtube 视频地址 <a href="https://www.youtube.com/watch?v=AmdLVWMdjOk">https://www.youtube.com/watch?v=AmdLVWMdjOk</a> [图片: <a href="https://pbs.twimg.com/media/G8-j-GTb0AEa-62?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8-j-GTb0AEa-62?format=jpg&#x26;name=orig]</a></p><p>【6】[Youtube 视频解读] Making Codebases Agent Ready 来自 @FactoryAI CTO @EnoReyes 在 @aiDotEngineer Code Summit 的演讲，主题聚焦于为什么许多团队在使用 AI ...
[Youtube 视频解读] Making Codebases Agent Ready 来自 @FactoryAI CTO @EnoReyes 在 @aiDotEngineer Code Summit 的演讲，主题聚焦于为什么许多团队在使用 AI 编程智能体时效果不佳，和如何通过优化代码库和组织实践来大幅提升智能体的可靠性和生产力。核心观点是：AI 智能体在软件工程领域的潜力巨大，但当前的主要瓶颈不是模型能力，而是代码库的&quot;智能体就绪度”。 核心概念：验证不对称性与软件开发的独特优势 Eno 引用了 Andrej Karpathy 关于&quot;Software 2.0”的观点（通过可验证任务训练模型）和Jason Wei 的博客（验证不对称性：许多任务验证比解决容易得多）。软件开发正是高度可验证的领域： · 已有成熟的自动化验证机制：单元测试、端到端测试、linter、CI/CD 构建、文档规范等。 · 这使得软件工程成为当前 AI 智能体最先进的领域——智能体可以通过搜索解决方案空间并快速验证正确性来&quot;解决问题”。 传统软件开发依赖人类手动处理模糊性和隐性知识，但 AI 智能体对噪声敏感，需要快速、明确、可预测的反馈循环。如果代码库缺少严格验证，智能体容易在生产环境中失效。 关键问题：为什么智能体在实际中表现不佳？ · 大多数代码库的验证覆盖率只有 50-60%，人类可以通过手动测试和&quot;部落知识”（大家心知肚明的隐性规则）弥补。 · 但智能体无法处理这些：缺失环境变量、未文档化的依赖、flake 测试等都会导致失败。 · 结果：智能体无法并行处理复杂任务、无法分解大型项目、无法实现高可靠性。 解决方案：构建&quot;智能体就绪”的代码库 Eno 强调，组织不应只比较不同 AI 工具的 SWE-Bench 等基准分数，而应投资于提升代码库的自动化验证水平。这能让所有 AI 工具表现更好，形成正反馈循环： 更好的验证 → 智能体更可靠 → 智能体帮助改进验证 → 进一步提升智能体能力。 具体实践包括： · 强化 linter，使其高度意见化，确保智能体生成的代码符合资深工程师的标准。 · 提高测试覆盖率，设计能区分 &quot;AI slop” 和高质量代码的测试。 · 提供明确文档（如 文件，许多智能体支持的标准）。 · 覆盖演讲中提到的八大类别（style validation、build systems、dev environments、observability等），系统评估并修复差距。 开发者角色转变：从直接写代码转向 定义式管理 ——定义约束、构建自动化验证、设定组织标准。这能放大个人影响力，一位意见强的工程师可显著提升整个团队速度。 未来愿景与投资建议 · 理想状态：bug 报告自动触发代理修复、人类审核、合并部署，全过程仅需 1-2 小时。 · 限制因素不是代理能力，而是组织的验证成熟度。 · 投资验证基础设施，能带来 5-10 倍工程速度提升，而非仅 1.5-2 倍。 · 这适用于任何 AI 工具，不限于 Factory 的产品。 视频地址 <a href="https://www.youtube.com/watch?v=ShuJ_CN6zr4">https://www.youtube.com/watch?v=ShuJ_CN6zr4</a> [图片: <a href="https://pbs.twimg.com/media/G8-gdOHbsAAAoLe?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8-gdOHbsAAAoLe?format=jpg&#x26;name=orig]</a></p><p>【7】rendercv
面向学者和工程师的Typst简历生成器</p><p>【8】the-algorithm
X推荐算法源代码</p><p>【9】langextract
一个使用LLM从非结构化文本中提取结构化信息的Python库，具备精确的源数据溯源和交互式可视化功能。</p><p>【10】vllm-omni
用于全模态模型高效推理的框架</p><p>【11】FossFLOW
制作精美的等距基础设施图</p><p>【12】claude-code-templates
用于配置和监控Claude Code的CLI工具</p><p>【13】🤨 Sec-Fetch-Site/ SameSite 能取代 CSRF token 吗？OWASP 指南与威胁模型争议
原标题： 《CSRF protection without tokens or hidden form fields》 评分: 31 | 作者: adevilinyc 💭 靠浏览器头就能完全防 CSRF 了吗？ 🎯 讨论背景 讨论围绕一篇提出&quot;无需 token 或隐藏表单域即可防护 CSRF”的文章展开，文章建议使用浏览器提供的 Fetch Metadata（如 Sec-Fetch-Site）或 SameSite cookie 属性作为替代或补充。社区注意到 OWASP CSRF cheat sheet 曾对 Fetch Metadata 的定位发生过修改并随后恢复，这引发了对 OWASP 指南一致性及其对企业合规影响的讨论。评论进一步把焦点放在实用性和威胁模型上：SameSite 的 Strict/Lax 取舍会影响 SPA 与 SSR 的首屏登录体验，而基于头部的防护在攻击者已掌握认证凭证或能绕过浏览器环境时无效。结论性意见是根据具体威胁模型组合使用浏览器头、SameSite 和服务端验证，而非盲目依赖单一机制。 📌 讨论焦点 Fetch Metadata / OWASP 指南争议 评论指出文章提到的 Sec-Fetch-Site（属于 Fetch Metadata）已被 OWASP 的 CSRF cheat sheet 一度列为可替代传统 token 的顶层方案，但该页面曾被修改两次：先加入、后被降级为&quot;defense in depth”，随后又恢复为顶层替代，导致社区对 OWASP 指南的一致性产生疑问。有人认为 OWASP 的分类会直接影响企业合规与实际部署，企业往往以&quot;符合 OWASP Top 10”来驱动决策，而不一定是基于最佳技术实践。该波动也促使部分读者要求提供比 OWASP 更具体或更权威的替代性指导。总体上，评论既承认 Fetch Metadata 的可用性，也对依赖单一权威指南表示谨慎。 [来源1] [来源2] [来源3] SameSite Cookie 的实用性与折中 多位评论者把 SameSite cookie 属性视为现代且简便的 CSRF 防护手段，并指出 SameSite =Strict/Lax 在主流浏览器上有良好支持，因而值得采用或作为补充。讨论中具体提到 SameSite =Strict 会在从外部站点首次导航到目标站点时导致 cookie 不被发送，用户在首屏可能出现未登录状态直到刷新，这对 SSR（Server-Side Rendering，服务端渲染）场景尤其敏感。相对地，SameSite =Lax 在导航请求上更符合直觉行为，适合需要在首次加载展示登录状态的站点或保留传统导航体验的应用。评论建议根据应用类型（SPA vs SSR）和首屏渲染需求权衡使用 Strict 或 Lax，并配合服务端验证以达到更稳健的防护。 [来源1] [来源2] [来源3] [来源4] [来源5] 无状态 token / 双重提交 cookie 方法 有人询问是否必须在服务端保存 CSRF token，回答指出并非必须：可以采用双重提交（double-submit cookie）模式来避免服务器端存储。实现方式是在登录时写入一个 CSRF cookie，客户端在表单字段或 header 中同时发送同样的 token，服务器只需比较 cookie 与请求内 token 是否相符即可。此方法利用攻击者无法读取目标站点 cookie 的事实，从而在保持无状态的同时实现有效的 CSRF 防护，并且实现相对简单。 [来源1] [来源2] 攻击模型与 Header 防护的局限 部分评论提出警告：基于浏览器头的防护（如 Sec-Fetch-Site / Fetch Metadata）对那些能伪造任意头部的定制化请求或已经掌握用户认证凭证的攻击者无效。反对者则反驳称，能够任意伪造头部的脚本通常不在真实浏览器环境中运行，而 CSRF 恰恰依赖浏览器自动在第三方发起请求时携带目标站点的 session cookie；因此若攻击者不在浏览器上下文中，就无法利用浏览器的 cookie 行为作为攻击向量。评论还强调若攻击者已经拿到用户的私密认证 token（例如存于 __Host- 前缀 cookie），则 CSRF 保护已无意义——攻击者可直接以该 token 发起请求。总体结论是应基于明确的威胁模型组合防护，而非单一依赖某一机制。 [来源1] [来源2] [来源3] [来源4] 📚 术语解释 Sec-Fetch-Site / Fetch Metadata: Sec-Fetch-Site 是浏览器在 Fetch Metadata（浏览器发送的一组请求头）中发送的一个 HTTP header，用于表明请求发起的源类型（同源、同站或跨站）。服务端可以根据该头判断请求是否由第三方页面发起，从而作为 CSRF 防护的判断依据或替代方案。 SameSite（cookie 属性）: SameSite 是浏览器 cookie 的一个属性，常见取值为 Strict、Lax、None，用来控制跨站请求时是否携带该 cookie。Strict 会阻止外部导航携带 cookie（可能导致首次外部导航出现未登录状态），Lax 在部分导航场景允许携带，需根据 SPA（单页应用）或 SSR（服务端渲染）场景权衡使用。 Double-submit cookie（双重提交 cookie）: 一种无状态的 CSRF 防护模式：服务器写入一个 CSRF cookie，客户端在请求中同时携带相同 token（如表单字段或自定义 header），服务器比较二者是否相等以验证请求，而无需在服务器端保存 token。 __Host cookie 前缀: __Host- 前缀是一种 cookie 命名约束，要求 cookie 带 Secure、Path =/ 且不能有 Domain，从而提高 cookie 的安全性，通常用于存放敏感的认证令牌。 类别： Security | Web | Programming | Guide | CSRF | Sec-Fetch-Site | Fetch Metadata | SameSite | CSRF tokens | cookies | OWASP | Miguel Grinberg | hidden form fields</p><p>【14】阿里 Qwen 发布新一代图像编辑模型Qwen-Image-Edit-2511，人物一致性大幅提升
阿里巴巴旗下的 Qwen 团队近期在 AI 视觉领域再次发力，正式发布了全新升级的图像编辑模型 Qwen-Image-Edit-2511 。针对以往 AI 在修图时容易导致&quot;人脸变形”或&quot;身份丢失”的痛点，该模型实现了质的飞跃，能够确保在进行创意修改的同时，精准保留原图人物的面部特征。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1225/6390225084626453269196727.png%5D">https://pic.chinaz.com/2025/1225/6390225084626453269196727.png]</a> 根据Qwen官方在Hugging Face上公布的信息，这款模型是此前版本的重大迭代。它不仅能处理单人肖像的精细编辑，在应对多人合照等复杂场景时也表现出色，可以同时维护多位角色的身份一致性。 无论是为照片中的人物更换服饰、调整背景，还是改变光影效果，模型都能在不改变人物&quot;长相”的前提下完成自然过渡。 除了核心的身份保持技术，新版模型还增强了对相机视角、几何计算以及工业产品设计的操控能力。 值得一提的是，Qwen团队还将社区中广受欢迎的 LoRA（微调模型）技术直接集成到了基础模型中，这使得普通用户也能轻松获得专业级的编辑效果。 huggingface:<a href="https://huggingface.co/spaces/Qwen/Qwen-Image-Edit-2511">https://huggingface.co/spaces/Qwen/Qwen-Image-Edit-2511</a> 划重点: 👤 人物特征神还原 :新模型解决了 AI 修图常见的&quot;变脸”问题，能在创意编辑时完美保持人物身份一致性。 🛠️ 全能型编辑工具 :不仅擅长人像处理，还强化了光影控制、工业设计和多物体协同编辑等综合能力。 🔓 开源且免费体验 :模型采用Apache2.0协议开源，并提供网页端Demo供用户直接上手测试。</p><p>【15】6000亿参数&quot;云宇星空”发布，上海诞生全国首个 AI 城市规划师
近日正式发布了全国规划资源领域首个基础大模型——&quot;云宇星空大模型（专业版）”。这一拥有6000亿参数规模的&quot;AI 城市规划师”，深度融合了遥感影像、三维实景、规划图纸与政务文本，通过&quot;1个行业基座大模型 +6个垂类智能体”的创新架构，填补了行业空白，推动超大城市治理向科学化与智能化跃升。 该模型的核心竞争力源于全国首个规划资源专用语料库——&quot;坤舆经略·语料库”，其训练数据涵盖900余份 权威 规划文档、10万余条基础问答与千余组专家对话，确保了 极高 的专业深度与动态更新能力。 在实际应用中，&quot;云宇星空”展现出卓越的业务闭环处理能力:它不仅内置了上海总体规划等十大知识模块，提供全天候决策咨询，还通过自然语言交互彻底告别了复杂的 GIS 操作，实现了多源图层的秒级聚合。同时，系统直连业务数据库，支持从自然语言查询到&quot;图数联动”可视化分析的自动生成，辅助管理者精准决策。 相较于通用型机器人，该模型具备更强大的多模态解析力。依托商汤日日新大模型，它能精准解析图纸中的建筑轮廓、容积率与绿化率等关键要素，自动进行合规审查，使审查效率提升50% 以上。基于思维链技术，模型还能一气呵成地生成符合国家编制办法的技术报告。 目前，&quot;云宇星空”已在上海多个区级项目中投入试运行，其自主任务调度引擎能够完成从违建识别到权属调取、再到生成建议并推送执法的全流程闭环，将规划咨询的响应速度从&quot;天级”缩短至&quot;分钟级”，实现了图纸审查效率3倍的跨越式增长。</p><p>【16】GPTs 时代落幕?OpenAI 效仿 Claude 推出 Skills，打造可堆叠的 AI 能力矩阵
根据 AIbase 报道，OpenAI 正准备对 ChatGPT 的核心交互方式进行重大革新。据开发者透露，OpenAI 正在秘密测试一项代号为&quot; 榛子 ”（Hazelnut）的新功能，名为&quot; Skills ”（技能）。该功能被视为对竞品 Anthropic 旗下 Claude 同名功能的有力回击。 [图片: ChatGPT [object Object]<a href="https://pic.chinaz.com/picmap/202412271704350132_0.jpg%5D">https://pic.chinaz.com/picmap/202412271704350132_0.jpg]</a> 从&quot;GPTs”到&quot;Skills”:ChatGPT 的范式转移 长期以来，用户主要通过定制化的 GPTs （自定义 GPT）来扩展 ChatGPT 的功能。然而，即将推出的 Skills 标志着一种向&quot;基于文件夹指令”的转变。与侧重于特定角色设定的 GPT 不同，Skills 更强调教导 AI 具备特定的 能力、工作流程 以及 领域知识 。 借鉴 Claude:更高效、更强大的&quot;技能堆栈” Claude 已经展示了 Skills 模式的优越性，例如其&quot;前端设计插件”能让 AI 在编写 Web 应用时更具感知力。根据行业标准，这种新型技能体系具有四大核心特性: 可组合性 :技能支持叠加使用。系统能自动识别任务需求并协调多个技能协同工作。 高移植性 :采用统一格式。开发者只需构建一次，即可在 ChatGPT 网页版、桌面客户端及 API 中通用。 极致 高效 :按需加载。仅在处理相关任务时才会调取特定指令，避免了上下文窗口的无谓消耗。 执行力强 :支持编写和运行可执行代码，解决传统令牌生成（Token Generation）在逻辑编程任务中的不可靠性。 功能前瞻:斜杠命令与 GPT 转换 消息人士 Tibor 在社交平台 X 上指出，新功能将引入 斜杠命令 （Slash Commands）交互方式，显著提升操作效率。此外，OpenAI 还计划推出专门的 技能编辑器 ，并允许用户将现有的自定义 GPT 一键转换为&quot;技能”，以实现平滑过渡。 虽然 OpenAI 尚未正式宣布上线日期，但市场普遍预期该功能将于 2026年1月 左右正式发布，届时 ChatGPT 或将完成从&quot;聊天机器人”向&quot;智能操作系统”的关键跨越。</p><p>【17】OpenAI 推出新 &quot;技能” 功能，ChatGPT 将更智能化处理复杂任务！
在人工智能领域，OpenAI 的 ChatGPT 正在进行一项激动人心的测试，即全新的 &quot;技能” 功能。根据科技媒体 BleepingComputer 的报道，这项功能旨在提升 AI 在处理复杂任务时的能力，机制与竞争对手 Claude 的同名功能相似。爆料人 Tibor 在社交平台 X 上透露，这项新功能内部代号为 &quot;榛子”（hazelnuts），其核心目标是通过更结构化的方式，让 AI 更加智能。 目前，ChatGPT 主要依赖 &quot;GPTs” 来满足用户的个性化需求，这本质上是一种提示工程的封装方式。然而，新的 &quot;技能” 系统将带来根本性的变化。参考 Claude 的设计，OpenAI 的新功能将采用类似 &quot;基于文件夹的指令集” 模式，使用户不仅仅是调整提示词，而是能够向 AI 教授特定的工作流和领域知识。这意味着在处理复杂任务时，AI 将变得更加灵活和高效。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1225/6390225047968655285333761.png%5D">https://pic.chinaz.com/2025/1225/6390225047968655285333761.png]</a> 根据泄露的信息，新系统具备四大核心特性:可组合性、可移植性、高效性与强大功能。这意味着 AI 能够自动识别任务所需的技能，并将其 &quot;堆叠” 使用。例如，在编写前端代码时，AI 能够自动调用设计技能来理解界面布局。 更值得关注的是，&quot;技能” 不仅限于文本生成，还可能包含可执行代码。这一特性使得 AI 在处理需要精确计算或逻辑验证的任务时，能够提供更高的可靠性。此外，ChatGPT 的 &quot;技能” 功能将深度集成到对话界面中，用户可通过输入 &quot;斜杠命令” 快速调用特定技能，极大提高操作的便捷性。 为了帮助用户更好地过渡到这一新架构，OpenAI 还计划推出专门的 &quot;技能编辑器”，并提供一键将现有自定义 GPT 转换为 &quot;技能” 的选项。这将大大降低用户的迁移成本，确保现有生态系统的平滑过渡。 随着这项新功能的推出，ChatGPT 将会在复杂任务处理方面展现出前所未有的智能水平，为用户提供更优质的服务体验。</p><p>【18】Waymo车内将现Gemini AI助手！1200行指令曝光，定义&quot;安全、简洁、不越界”的乘客陪伴者
自动驾驶的&quot;沉默旅程”即将终结。知名科技研究员 Jane Manchun Wong 近日通过逆向工程发现，Waymo 正在测试将谷歌 Gemini 大模型深度集成至其无人驾驶出租车，打造一款名为 &quot;Waymo 出行助手” 的车载AI伴侣。尽管尚未上线，但一份长达1200多行的内部系统指令（代号&quot;Waymo 出行助手元指令”）已完整曝光，揭示了这款AI如何被精心设计为安全、克制、高度场景化的乘客服务引擎。 不止聊天，更是&quot;车内管家” 根据指令文档，该Gemini助手将具备三大核心能力: - 智能答疑:回答天气、地标、赛事等常识问题; - 环境调控:支持调节空调温度、车内灯光与音乐播放; - 情绪安抚:在乘客紧张时提供舒缓回应，营造安心氛围。 但其权限被严格限定——无法控制音量、更改路线、调整座椅或车窗。若用户提出越权请求，AI需以&quot;展望式”语气回应:&quot;这项功能我目前还无法实现哦。” 1200行指令，字字皆为&quot;边界” Waymo对AI行为的约束堪称&quot; 极致 克制”: - 身份清晰分离:必须明确区分&quot;Gemini是对话助手，Waymo Driver才是驾驶系统”;若被问&quot;你怎么看路况?”，需回答&quot;Waymo Driver 通过多传感器融合感知路况”，而非&quot;我看到……”; - 禁谈驾驶细节:不得评论、解释或致歉任何驾驶事件，即使面对事故视频提问，也需转移话题; - 语言极简:回复限1–3句话，禁用术语，力求&quot;小学生也能听懂”; - 个性化但不越界:可调用乘客姓名与乘坐次数，但绝不访问行程目的地等敏感数据; - 竞品应对标准化:对特斯拉、Cruise等对手的提问均有预设话术，避免争议。 Gemini × Waymo:从训练到陪伴的全链路融合 这并非Gemini 首次 赋能Waymo。此前，Waymo已利用Gemini的通用知识库训练自动驾驶系统应对&quot;幽灵堵车”&quot;施工区绕行”等长尾场景。如今，Gemini进一步延伸至乘客体验层，形成&quot;车外决策+车内服务”的AI双引擎。 与特斯拉Grok形成鲜明对比 值得注意的是，特斯拉正将Grok打造为&quot;有记忆、能闲聊”的车载伙伴，强调情感连接;而Waymo的Gemini则聚焦实用、安全、零干扰，拒绝过度拟人化。两者路径差异，折射出两家公司对&quot;AI在车中角色”的根本分歧:是陪伴者，还是服务者? Waymo发言人Julia Ilina回应称:&quot;我们持续探索提升用户体验的功能，但当前无具体细节可公布。” AIbase认为，Waymo此举揭示了L4自动驾驶商业化的新逻辑:当技术可靠性趋近成熟，用户体验将成为决胜关键。而通过1200行指令为AI划清&quot;能力边界”与&quot;伦理红线”，Waymo不仅在打造助手，更在定义人机共乘时代的交互伦理——真正的智能，不在于无所不能，而在于知道何时该&quot;闭嘴”与&quot;止步”。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/25 AI 日报 今日摘要 【1】[开源推荐] SurfSense：开源 AI 研究与知识管理助手，定位是 NotebookLM、Perplexity 和 Glean 的开源替代方案，通过 AI 技术帮助用户构建和管理&quot;私人知识库” ... [开源推荐] SurfSense：开源 AI 研究与知识管理助手，定位是 NotebookLM、Perplexity ]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-12-24日刊]]></title>
          <link>/2025-12/2025-12-24/</link>
          <guid>/2025-12/2025-12-24/</guid>
          <pubDate>Wed, 24 Dec 2025 10:21:47 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/24</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】rendercv
面向学者和工程师的Typst简历生成器</p><p>【2】exo
用日常设备在家运行自己的AI集群 📱💻 🖥️⌚</p><p>【3】langextract
一个Python库，利用LLM从非结构化文本中提取结构化信息，具备精确的源定位和交互式可视化功能。</p><p>【4】LEANN
使用LEANN实现万物皆可RAG。在个人设备上运行快速、准确且100%私密的RAG应用，同时享受97%的存储节省。</p><p>【5】bloom
bloom - 即时评估任何行为 🌸🌱</p><p>【6】FossFLOW
制作精美的等距基础设施图</p><p>【7】我觉得这可能会成为另一个新的副业收入渠道。 因为它可以让创建者使用任何框架或工具，将 Agent 部署到生产环境，设置价格并赚取收入。
我觉得这可能会成为另一个新的副业收入渠道。 因为它可以让创建者使用任何框架或工具，将 Agent 部署到生产环境，设置价格并赚取收入。 MuleRun: Today, MuleRun officially launches Creator Studio. The world’s first platform built to help AI creators build, publish, and monetize AI Agents at scale. From Codes → Agent → Go to market in just 3 steps 🔗 <a href="https://mulerun.com/creator">https://mulerun.com/creator</a> [视频: <a href="https://video.twimg.com/amplify_video/2003487547524284419/vid/avc1/1920x1080/Eaj7-FpqwLD8RSaJ.mp4?tag=21%5D">https://video.twimg.com/amplify_video/2003487547524284419/vid/avc1/1920x1080/Eaj7-FpqwLD8RSaJ.mp4?tag=21]</a></p><p>【8】RT yan5xu: Re skills 重点在Prompt 发现&amp;懒加载，改变当前 agent 能力，有当前完整上下文，我觉得适合的场景是当前任务复合程度不高的情况（载入多个 skills 就...
RT yan5xu Re skills 重点在Prompt 发现&#x26;懒加载，改变当前 agent 能力，有当前完整上下文，我觉得适合的场景是当前任务复合程度不高的情况（载入多个 skills 就会出现性能下降问题），比如主 Agent 是入口当做路由，然后通过 skills 载入场景能力，进入到 YouTube-summary，写 ppt 模式； sub-agent 也有发现过程，但重点是过程压缩，执行过程在当前 agent 之外，他对于当前 agent 就是一个 tool（function call），只有 req/res； 还有一个把两种结合在一起的方式，在一个节点发现需要 skills，载入执行拿到 skills 的结果后，把需要 skills 的节点到结果的节点的 tool use 过程进行压缩，也是一种方式。 [图片: <a href="https://pbs.twimg.com/media/G85IW7DagAAbkUL?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/G85IW7DagAAbkUL?format=png&#x26;name=orig]</a></p><p>【9】全球增长最快的 AI 应用公司，ARR 2亿美金的 Lovable 的增长负责人分享了增长认知 看完感觉 AI 行业真的太刺激了 竞争的速度已经比移动互联网时代快了 10 倍以上...
全球增长最快的 AI 应用公司，ARR 2亿美金的 Lovable 的增长负责人分享了增长认知 看完感觉 AI 行业真的太刺激了 竞争的速度已经比移动互联网时代快了 10 倍以上 1. PMF 的保质期只有三个月，因为模型更新的周期是三个月。模型每次更新你就要重新赢得一次 PMF 2. MVP 已死，MLP 如果没有共鸣，就不要发布 3. SEO 已死，社交媒体是唯一的有机增长 4. Aha Moment 已死，现在的产品必须让用户炸裂认知，必须要 Wow Moment 才可以 5. 长期 Roadmap 已死，今天不能定制超过3个月的产品路线图，因为3个月后，一切可能都已经变了，用户预期也变了 6. 放弃销售团队，2亿ARR没有任何销售团队 7. 放弃优化利润率，现在需要疯狂圈地，还没到赚钱的时候 8. 放弃晚期大众用户，聚焦先锋用户，今天 AI 发展太快，大部分人跟不上节奏 9. 技术不是护城河，唯二的护城河是发版速度和品牌好感度 10. 巨头的护城河也极其脆弱，即便是 OpenAI 这样的公司，如果不能迭代出好模型，也可以在几周内崩塌 [图片: <a href="https://pbs.twimg.com/media/G85B6YDasAAV07L?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G85B6YDasAAV07L?format=jpg&#x26;name=orig]</a></p><p>【10】这个 X (Twitter) Shadowban Checker F 做得挺有用的，输入你的用户 id，可以用来判断某个账号或某条帖子有没有被搜索降权/搜索排除/回复折叠，顺便可以基于此看...
这个 X (Twitter) Shadowban Checker F 做得挺有用的，输入你的用户 id，可以用来判断某个账号或某条帖子有没有被搜索降权/搜索排除/回复折叠，顺便可以基于此看后面账号是否容易被封的一个点。 <a href="https://x-shadowban-checker.fia-s.com/">https://x-shadowban-checker.fia-s.com/</a> [图片: <a href="https://pbs.twimg.com/media/G8Hd4EoaUAA1mlS?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8Hd4EoaUAA1mlS?format=jpg&#x26;name=orig]</a></p><p>【11】近期打算去美国西边玩一个礼拜左右，请问一下大家，有什么是去这趟，应该顺便办理的东西吗？我能想到的好像只有开个美国银行卡？
近期打算去美国西边玩一个礼拜左右，请问一下大家，有什么是去这趟，应该顺便办理的东西吗？我能想到的好像只有开个美国银行卡？</p><p>【12】I Built a fully offline AI Image Upscaler for Android that runs entirely on-device (GPU/CPU support). No servers, 100% private.
Hi everyone, I wanted to share a project I’ve been working on called Rendrflow. I noticed that most AI upscalers require uploading photos to a cloud server, which raises privacy concerns and requires a constant internet connection. I wanted to build a solution that harnesses the power of modern Android hardware to run these models locally on the device. HOW IT WORKS The app runs AI upscaling models directly on your phone. Because it&#39;s local, no data ever leaves your device. I implemented a few different processing modes to handle different hardware capabilities: CPU Mode: For compatibility. GPU &#x26; GPU Burst Mode: Accelerated processing for faster inference on supported devices. KEY TECHNICAL FEATURES Upscaling: Support for 2x, 4x, and 8x scaling using High and Ultra models. Privacy: Completely offline. It works in airplane mode with no servers involved. Batch Processing: Includes a file type converter that can handle multiple images at once. Additional Tools: I also integrated an on-device AI background remover/eraser and basic quick-edit tools (crop/resolution change). LOOKING FOR FEEDBACK I am looking for feedback on the overall performance and stability of the app. Since running these models locally puts a heavy load on mobile hardware, I’m curious how it handles on different devices (especially older ones vs newer flagships) and if the processing feels smooth for you. Please feel free to share any features that you want in this app. Link to Play Store: <a href="https://play.google.com/store/apps/details?id=com.saif.example.imageupscaler">https://play.google.com/store/apps/details?id=com.saif.example.imageupscaler</a> Thanks for checking it out! submitted by /u/Fearless_Mushroom567 [link] [comments]</p><p>【13】OpenAI 启用 AI 模拟黑客攻击，只为修补代理式浏览器的致命漏洞
OpenAI 正采取一种&quot;以毒攻毒”的新策略，来提升其代理式网页浏览器 ChatGPT Atlas 的安全性。为了应对日益复杂的网络威胁，OpenAI 开发了一套&quot;自动化攻击者”系统，通过模拟真实黑客的攻击手段，对 ChatGPT Atlas 进行全天候的压力测试。 这套系统的核心在于对抗 提示注入（Prompt Injection）攻击 。在这种攻击中，恶意第三方会悄悄向 AI 代理发送指令，诱导其执行违背用户意愿的操作，例如在用户不知情的情况下转发敏感邮件或删除云端文件。AIbase 获悉，OpenAI 的&quot;自动化攻击者”利用了先进的强化学习技术，能够自主发现人类红队测试中未曾察觉的新型攻击路径。 在一次实际演示中，这个 AI 攻击者成功模拟了诱导 Atlas 向公司 CEO 发送辞职信的场景。虽然 Atlas 的防御机制最终拦截了这一请求并提醒了用户，但 OpenAI 坦言，安全博弈是一场持久战。由于代理式浏览器需要深度介入用户的数字化生活（如访问邮件、日历等），其便利性本身也带来了更大的风险暴露面。 尽管技术手段在不断进化，OpenAI 在 最新 报告中警示称，由于 AI 代理的本质特性，这类安全威胁可能永远无法被彻底&quot;根治”。AIbase 提醒用户，在享受 AI 浏览器带来便利的同时，仍需保持警惕，关注官方发布的实时安全响应与防护建议。</p><p>【14】阿里上线&quot;千问智学”，字节推&quot;AnyGen”:AI 应用正式接管你的书包与办公桌
随着人工智能技术的深度演进，大厂正加速将 AI 能力具象化为垂直场景的终端应用。近日，阿里巴巴正式推出 AI 教育应用程序&quot;千问智学”，而字节跳动则在海外市场低调上线了 AI 办公工具&quot;AnyGen”，标志着两家巨头在 AI 个性化服务与轻量化生产力领域的竞争全面升级。 [图片: 学习 考试 高考 教育 (1) [object Object]<a href="https://pic.chinaz.com/picmap/202306251749086020_11.jpg%5D">https://pic.chinaz.com/picmap/202306251749086020_11.jpg]</a> 阿里巴巴推出的&quot;千问智学”依托其 最新 的学习大模型，内置智能体&quot;小千老师”，为从小学到研究生阶段的用户提供全学段免费辅导。该应用支持拍照、语音和文本三种互动提问方式，能迅速解析数学、物理及英语难题并给出详尽的解题思路。除核心解答功能外，应用还集成了语文听写、课文背诵、错题本及试卷中心等功能模块。 业内分析认为，AI 正在重塑教育行业的成本结构，随着多模态大模型的应用，教育内容生产成本显著降低。阿里此举有望通过数据积累，未来向个性化付费辅导等商业化路径延伸。 与此同时，字节跳动在海外市场布局的&quot;AnyGen”则精准切入 AI 办公领域。该应用被定位为&quot;语音驱动的人工智能工作空间”，核心功能是将用户的语音笔记、照片及零散想法直接转化为结构化的文档和演示文稿。其简洁高效的界面设计符合现代办公对轻量化工具的需求，通过即时记录与快速转文字功能，极大程度减少了传统录音整理的繁琐步骤。尽管字节此前的 Lark 在部分市场表现平平，但&quot;AnyGen”的推出彰显了其在海外 AI 办公领域占据一席之地的野心。 阿里与字节的 最新 布局，不仅展示了各自在垂直领域的技术落地能力，更揭示了 AI 应用从通用大模型向场景化工具转变的必然趋势。无论是个性化教育还是语音驱动办公，AI 正在深度重组传统行业的竞争逻辑，预示着一个更高效、低门槛的智能应用时代已经到来。</p><p>【15】ChatGPT上线&quot;年度回顾”！你的AI人格、年度诗歌与创意勋章来了，但需先开权限
继Spotify Wrapped风靡全球后，AI界终于迎来自己的&quot;年终总结时刻”。OpenAI今日正式推出 &quot;Your Year with ChatGPT”（你的ChatGPT年度回顾）功能，为符合条件的用户生成一份高度个性化、视觉化、可社交分享的AI交互档案，涵盖全年使用数据、主题画像、定制诗歌与趣味&quot;AI人格勋章”，让人类与AI的对话痕迹成为一份可回味的数字记忆。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1224/6390216620926495129019816.png%5D">https://pic.chinaz.com/2025/1224/6390216620926495129019816.png]</a> 不止数据复盘，更是AI时代的&quot;数字自画像” 该功能通过分析用户全年聊天记录（需手动开启&quot;引用聊天记录”与&quot;引用已保存记忆”权限），自动生成三大核心内容: - 交互全景图:展示提问频次、热门话题、使用时段等行为数据; - AI人格勋章:基于对话模式授予趣味称号，如频繁打磨文案者获&quot;创意调试者”（Creative Debugger），常问技术问题者得&quot;代码炼金术士”; - 年度主题诗+AI画作:系统提炼用户最关注的议题（如&quot;气候变化”&quot;小说创作”&quot;育儿焦虑”），创作一首定制诗歌，并配以DALL·E生成的呼应图像，形成独特的&quot;年度精神快照”。 隐私优先，非强制推送 OpenAI强调，该体验&quot;轻量化、隐私优先、用户可控”: - 仅对美国、加拿大、英国、澳大利亚、新西兰等英语区的个人免费/Plus/Pro用户开放; - 企业版（Team/Enterprise）及教育账户暂不支持; - 用户必须主动开启记忆与聊天记录引用，且全年对话量达阈值方可解锁; - 功能入口仅在App首页展示，不会自动弹窗或强制展示，用户也可通过指令&quot;启动Your Year with ChatGPT”手动触发。 未来或更&quot;大胆”?成人内容功能埋下伏笔 值得注意的是，报道提及:随着ChatGPT计划2026年起在合规前提下开放成人内容（NSFW）功能，年度回顾中生成的主题内容&quot;未来可能呈现更‘大胆’的面貌”。这暗示OpenAI正逐步将个性化体验延伸至更敏感领域，但也引发对内容边界与用户心理预期的新讨论。 社交化AI，从工具走向陪伴 AIbase认为，&quot;Your Year with ChatGPT”不仅是营销彩蛋，更是OpenAI深化情感绑定与用户粘性的关键一步。当AI不仅能解决问题，还能&quot;记住你、理解你、为你写诗”，人机关系便从工具性转向陪伴性。而这份年度回顾，正是AI时代&quot;数字自我”的一次温柔凝视——你与机器的每一次对话，终将汇成你这一年思想的回响。</p><p>【16】MiniMax联合华中科大开源VTP技术！仅优化视觉分词器，DiT生成性能飙升65.8%
AI视觉生成领域迎来范式级突破。MiniMax与华中科技大学近日联合开源其核心技术——VTP（Visual Tokenizer Pretraining，视觉分词器预训练），在不修改标准DiT(Diffusion Transformer)架构的前提下，仅通过优化视觉分词器(Visual Tokenizer)，即实现65.8%的端到端图像生成性能提升。这一成果颠覆了&quot;唯有堆大模型才能提性能”的行业惯性， 首次 将视觉分词器推向前所未有的技术高度。 不碰主模型，只改&quot;翻译官”——性能却翻倍 传统生成模型（如DALL·E3、Stable Diffusion3）依赖DiT等主干网络提升性能，而VTP另辟蹊径:它将视觉分词器——即负责将图像压缩为离散token序列的&quot;视觉翻译官”——作为核心优化对象。 关键在于，VTP无需改动DiT的任何训练流程或结构，仅在预训练阶段对分词器进行专门优化，使其输出的latent表征更易学习、更具通用性，从而让下游DiT&quot;事半功倍”。实验显示，在相同DiT配置下，采用VTP的系统生成质量（FID、CLIP Score等指标）显著超越基线。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1224/6390216562028830788418681.png%5D">https://pic.chinaz.com/2025/1224/6390216562028830788418681.png]</a> 首次 建立&quot;分词器可扩展性”理论框架 VTP的突破不仅是工程优化，更提出全新理论视角: - 首次 明确将latent表征的易学性（learnability）与通用视觉表征能力关联; - 首次 证明分词器本身具备可扩展性（tokenizer scaling）——随着分词器容量、训练数据与预训练策略的增强，生成性能呈现清晰的scaling曲线; - 为行业开辟&quot;模型之外的性能增长路径”:未来或无需一味扩大DiT参数，而可通过优化分词器实现更高性价比的性能跃升。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1224/6390216564997129434301752.png%5D">https://pic.chinaz.com/2025/1224/6390216564997129434301752.png]</a> 开源即赋能，推动视觉生成民主化 目前，VTP代码、预训练分词器及训练配方已全面开源，兼容主流DiT实现。这意味着，任何使用DiT架构的研究者或企业，均可&quot;即插即用”VTP，低成本获得近70%的生成质量提升，尤其利好算力有限的中小团队。 AIbase认为，VTP的发布标志着AI生成技术进入&quot;系统级优化”新阶段。当行业从&quot;唯大模型论”转向&quot;全链路协同提效”，MiniMax与华中科大此次合作，不仅是一次技术胜利，更是对&quot;高效AI”发展理念的有力践行——真正的创新，有时不在于造更大的引擎，而在于让每个零件都更聪明地协同工作。 代码:<a href="https://github.com/MiniMax-AI/VTP">https://github.com/MiniMax-AI/VTP</a> 论文:<a href="https://arxiv.org/abs/2512.13687v1">https://arxiv.org/abs/2512.13687v1</a></p><p>【17】​报道称苹果重组 AI 团队，力争为 iPhone 17 带来全新 Siri 体验
根据科技媒体 Appleinsider 报道，苹果近期对其 AI 团队进行了深度重组。尽管外界有传言称苹果的 AI 战略正面临&quot;崩盘”，但实际情况显示，这更像是苹果为了2026年战略重启而进行的主动部署。 在这次架构调整中，苹果明确了 AI 不再是独立的孤岛，而是软件体系的核心子集。原 AI 负责人 John Giannandrea 的职责现已缩减为专注于开发&quot;苹果基础模型”，而 Siri 团队则被并入软件与 Vision Pro 部门，由副总裁 Amar Subramanya 直接向软件工程 高级 副总裁 Craig Federighi 汇报。此外，苹果还将机器人项目移交给了硬件部门，力求跨部门的高效协作。 此次重组的核心信号在于:苹果将坚定不移地执行&quot;端侧 AI”路线。通过在本地处理数据，苹果旨在兑现安全、隐私且高效的 AI 承诺。据悉，苹果计划在2026年初的系统更新中，为iPhone17等设备带来由大语言模型（LLM）驱动的全新 Siri，使其具备更强的理解力与复杂任务执行能力。</p><p>【18】Seedance 1.5 pro正式上线火山方舟 革新 AI 视频生成技术
12月23日， 豆包视频生成模型 Seedance1.5Pro 今日正式上线火山方舟，标志着 AI 视频创作进入一个全新的阶段。此次发布的模型，致力于提高视频生成的效率与质量，为创作者提供更为强大的工具。 Seedance1.5Pro 的推出，带来了音画同步输出、多语言多人对白配音等多项先进功能，尤其是在影视级叙事张力方面表现突出。企业用户现在可以通过火山方舟获取模型的 API 服务，而个人用户则可以在豆包、即梦 AI 及火山方舟体验中心进行体验。 [图片: QQ20251224-092353.png [object Object]<a href="https://pic.chinaz.com/2025/1224/6390216505629138003838057.png%5D">https://pic.chinaz.com/2025/1224/6390216505629138003838057.png]</a> 根据内部基准测试 SeedVideoBench-1.5的结果，Seedance1.5Pro 在声音质量、音画同步、声音表现力等核心指标上均超越了行业内其他同类模型，尤其是在指令遵循和画面美感方面较之前的 Seedance1.0Pro 有了显著提升。这一进步源于技术团队在毫秒级音画同步、自然对话生成以及影视叙事情感张力等三大核心能力上的持续攻坚。 Seedance1.5Pro 支持毫秒级音画同步，能够原生生成多种音效元素，包括环境音、动作音和背景音乐。这使得视频中的声画表现更加真实，提升了观众的沉浸感。此外，该模型还支持多语言对话，包括普通话、地方方言以及多种小语种，能够精准还原自然对话的质感。 [图片: QQ20251224-092342.png [object Object]<a href="https://pic.chinaz.com/2025/1224/6390216506405198443072085.png%5D">https://pic.chinaz.com/2025/1224/6390216506405198443072085.png]</a> 在电商、广告及影视创作等多个领域，Seedance1.5Pro 的应用潜力巨大。在电商领域，商家可快速生成高质量的商品展示视频，并结合多语言适配，实现本地化营销，从而大幅降低跨境营销成本。在广告营销方面，模型能够在分钟级内生成高质量的个性化广告，有效提升转化率。 为了进一步提高创作效率，Seedance 系列模型即将推出 Draft 样片功能，支持低分辨率快速输出，帮助创作者在短时间内验证创意。这一功能有望提升整体创作效率65%，并减少60% 的无效创作成本。同时，模型还将支持离线推理，进一步降低视频生成成本，适用于批量生产和异步处理场景。 通过这次的技术升级，Seedance1.5Pro 不仅在视频生成的质量和效率上实现了飞跃，更为各行各业的数字内容生产力提供了新的推动力。创作者们可以期待在未来的创作过程中，Seedance1.5Pro 将助力他们实现更高水平的表达与创作。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/24 AI 日报 今日摘要 【1】rendercv 面向学者和工程师的Typst简历生成器 【2】exo 用日常设备在家运行自己的AI集群 📱💻 🖥️⌚ 【3】langextract 一个Python库，利用LLM从非结构化文本中提取结构化信息，具备精确的源定位和交互式可视化功能。 【4】LEANN 使用LEANN实现万物皆可RAG。在个人设备上运行快速、准确且]]></description>
        </item>
      
        <item>
          <title><![CDATA[2025-12-23日刊]]></title>
          <link>/2025-12/2025-12-23/</link>
          <guid>/2025-12/2025-12-23/</guid>
          <pubDate>Tue, 23 Dec 2025 10:24:10 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2025/12/23</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】exo
用日常设备在家运行你自己的AI集群 📱💻 🖥️⌚</p><p>【2】iptv
来自世界各地的公开IPTV频道合集</p><p>【3】PayloadsAllTheThings
一份用于Web应用安全和渗透测试/CTF的有用载荷与绕过清单</p><p>【4】PentestGPT
一款GPT赋能的渗透测试工具</p><p>【5】skills
Agent Skills的公共仓库</p><p>【6】cocoindex
面向AI的数据转换框架。性能卓越，支持增量处理。🌟 喜欢就点个星吧！</p><p>【7】智谱 AI 正式发布 GLM-4.7 🚀 智谱 AI @Zai_org 最新一代旗舰级基础模型，作为 GLM 系列的重大升级，它在编程、逻辑推理和智能体能力上取得了突破性进展。 �...
智谱 AI 正式发布 GLM-4.7 🚀 智谱 AI @Zai_org 最新一代旗舰级基础模型，作为 GLM 系列的重大升级，它在编程、逻辑推理和智能体能力上取得了突破性进展。 📢 插播：这张信息卡就是用 GLM-4.7 + 信息卡提示词生成的，大家可以感受一下它的前端设计能力。 核心进化：从&quot;生成代码”到&quot;完成任务” GLM-4.7 不再仅仅是一个对话模型，它更像是一个能够自主解决复杂问题的数字工程师。 · 核心编程：强化多语言 Agent 编程，在 SWE-bench 等复杂编程测试中大幅超越前代，能够自主理解需求、拆解方案并跨技术栈集成。 · 感官编程：提升 UI/前端审美，生成的网页代码、幻灯片布局更加现代、美观，减少了人工微调样式的繁琐过程。 · 工具调用：多步决策稳定性，在复杂工具使用基准上达到 SOTA 水平，支持实时的工具参数提取。 · 复杂推理：数学与逻辑爆发，在 HLE 等极难推理榜单中，性能比 GLM-4.6 提升了约 38%。 创新特性：多维度的&quot;思考”模式 GLM-4.7 引入了更灵活的思维链控制，让模型在处理任务时更加&quot;理性”。 · 交替思考： 在输出回复或调用工具前先进行思考，显著提升了复杂指令的遵循能力。 · 持久思考： 在多轮对话中，模型会保留之前的思考逻辑，确保复杂编程任务在长期会话中的思路一致性，避免&quot;由于对话太长而变笨”。 · 轮次级思考控制： 用户可以根据需求开关思考功能。对于事实问答等简单任务，关闭思考以追求低延迟；对于复杂方案规划，开启深度思考以追求高成功率。 技术规格与性能表现 GLM-4.7 在技术参数上达到了目前行业的顶尖水平，尤其在长文本和处理效率上表现出色。 · 超长上下文： 支持最高 200K 的上下文输入，单次最高支持 128K 的内容输出。 · 极致推理速度： 推理速度超过 55 tokens/s，在保持旗舰性能的同时提供了极佳的响应体验。 · 基准排名： 在 Code Arena 等盲测中，GLM-4.7 位列开源模型第一，部分指标甚至超越了 GPT-5 和 Claude 4.5 Sonnet。 为什么 GLM-4.7 非常重要？ · 开源力量的飞跃： 作为一个开放权重的模型，GLM-4.7 为开发者提供了能与最顶级闭源模型抗衡的选择，极大地推动了本地化部署和私有化应用的可能。 · 更强的 Agent 属性： 它是目前最适配 Claude Code、Cline 等智能编程助手方案的模型之一，真正实现了从&quot;写代码片段”到&quot;自主维护整个代码库”的转变。 · 效率与成本的平衡： 配合 ZAI 推出的开发者计划，其调用成本大幅降低，使得大规模部署高性能 AI 变得更加务实。 看官方公告： <a href="https://z.ai/blog/glm-4.7">https://z.ai/blog/glm-4.7</a> [图片: <a href="https://pbs.twimg.com/media/G80MW97aoAAHrnb?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G80MW97aoAAHrnb?format=jpg&#x26;name=orig]</a> Z.ai: GLM-4.7 is here! GLM-4.7 surpasses GLM-4.6 with substantial improvements in coding, complex reasoning, and tool usage, setting new open-source SOTA standards. It also boosts performance in chat, creative writing, and role-play scenarios. Default Model for Coding Plan: [图片: <a href="https://pbs.twimg.com/media/G8yaeaGagAAnHxz?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8yaeaGagAAnHxz?format=jpg&#x26;name=orig]</a></p><p>【8】2025 年最佳 AI 产品是什么？ 来自 Cursor 团队成员 Ben Lang 发起的非官方统计，收到了 500+ 评论投票，虽然会有一些统计偏差，比如关注 Ben 的人应该都了解 Cu...
2025 年最佳 AI 产品是什么？ 来自 Cursor 团队成员 Ben Lang 发起的非官方统计，收到了 500+ 评论投票，虽然会有一些统计偏差，比如关注 Ben 的人应该都了解 Cursor，不过整体还是符合直觉的， 一起看看 Top 9 分布🔽 Top1 Cursor - AI IDE Top2 Claude Code - AI CLI 编程智能体 Top3 NotebookLM - AI 研究工具 Top4 Wispr Flow - 语音转写 Top5 Granola - 会议记录 Top6 Comet - AI 浏览器 Top7 NanoBanana Pro - AI 图像 Top8 Manus - 通用智能体 Top9 Tesla - FSD 我自己今年的 Top3: Top1 Claude Code Top2 NotebookLM Top3 NanoBanana Pro [图片: <a href="https://pbs.twimg.com/media/G80KJvRagAElJnN?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G80KJvRagAElJnN?format=jpg&#x26;name=orig]</a> Ben Lang: Top results: 1) @cursor_ai - AI coding 2) @claudeai - AI assistant 3) @NotebookLM - AI research 4) @WisprFlow - voice dictation 5) @meetgranola - meeting notes 6) @comet - AI browser 7) @NanoBanana - AI images 8) @ManusAI - general AI agent 9) @Tesla - full-self driving</p><p>【9】<a href="http://x.com/i/article/2003251575809294337">http://x.com/i/article/2003251575809294337</a><a href="http://x.com/i/article/2003251575809294337">http://x.com/i/article/2003251575809294337</a></p><p>【10】这个免费开源的 Mac 菜单栏日历 MacCalendar 做得还可以，感觉有点借鉴我之前推荐过的付费 Top Calendar，我现在还是用 Top 这个，非常喜欢，相当于把你的时间、...
这个免费开源的 Mac 菜单栏日历 MacCalendar 做得还可以，感觉有点借鉴我之前推荐过的付费 Top Calendar，我现在还是用 Top 这个，非常喜欢，相当于把你的时间、日历、日程全部放到菜单栏了，特别适合上班族一眼看日程，有需要的小伙伴可以玩玩看。 <a href="https://github.com/bylinxx/MacCalendar">https://github.com/bylinxx/MacCalendar</a> [图片: <a href="https://pbs.twimg.com/media/G8DlNkmaEAA1IvX?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8DlNkmaEAA1IvX?format=jpg&#x26;name=orig]</a></p><p>【11】learn about yourself from how you used chatgpt this year:
learn about yourself from how you used chatgpt this year: OpenAI: Your Year with ChatGPT! Now rolling out to everyone in the US, UK, Canada, New Zealand, and Australia who have reference saved memory and reference chat history turned on. Just make sure your app is updated. [图片: <a href="https://pbs.twimg.com/media/G8zBqDIXYAAz41p?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/G8zBqDIXYAAz41p?format=jpg&#x26;name=orig]</a></p><p>【12】Steam games that openly use generative AI earned $660 million this year, including Call of Duty: Black Ops 6, Stellaris, and more, as studios continue to rely on the technology
[图片: Steam games that openly use generative AI earned $660 million this year, including Call of Duty: Black Ops 6, Stellaris, and more, as studios continue to rely on the technology <a href="https://external-preview.redd.it/yMX5cQPgne7L7yMmMF_nzIFx2pHwcLhvUsnHyFPbvkQ.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=c48caf420550716bb64362ae1938c56c85c62ecf%5D">https://external-preview.redd.it/yMX5cQPgne7L7yMmMF_nzIFx2pHwcLhvUsnHyFPbvkQ.jpeg?width=640&#x26;crop=smart&#x26;auto=webp&#x26;s=c48caf420550716bb64362ae1938c56c85c62ecf]</a> submitted by /u/Fcking_Chuck [link] [comments]</p><p>【13】智谱AI发布：GLM-4.7  引入三层思考模式 编码和前端审美大幅提升 性能直逼GPT-5和Claude 4.5 
智谱 AI（Zhipu AI） 发布新一代多模态与智能体化模型：GLM-4.7。 该版本并非单纯参数扩容，而是针对 智能体场景中的&quot;思考一致性（Thinking Consistency）”与&quot;编程自治性（Agentic Coding）” 进行结构性增强。 该版本在多项标准化基准测试中显著超越 GLM-4.6。 相较 GLM-4.6，该版本重点解决了三大瓶颈： 代码生成与修复的逻辑一致性不足； 多轮任务中保持思考一致性（不乱、不忘） 工具使用与上下文保持的碎片化。 GLM-4.7 在 17 个多维基准测试 （涵盖 8 个推理、5 个编程、3 个智能体任务）中，相较 GLM-4.6 实现显著增益，尤其在复杂编程与长链任务中表现突出。 [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCRU41eEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--b8cc7ee53c7ae710022cbc1e5d1359aa4d359025/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D%5B%E5%9B%BE%E7%89%87">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCRU41eEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--b8cc7ee53c7ae710022cbc1e5d1359aa4d359025/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png][图片</a>: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSXhweEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--2194e4ec9fc3932a9b116ee8d99b7774e65448c5/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSXhweEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--2194e4ec9fc3932a9b116ee8d99b7774e65448c5/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 整体结果显示，GLM-4.7 在推理、编程与智能体执行三大维度均较 GLM-4.6 有 10%~20% 的系统性提升 。 GLM-4.7 的&quot;思考系统”是核心亮点 GLM-4.7 的最大革新是： 引入了新的&quot; 思考机制（Thinking System） ”，这是它区别于大多数模型的核心技术。 让模型&quot;先思考，再行动” 在传统大语言模型（如 GPT、Claude、Gemini）中，生成过程是： 也就是说，模型没有明确的&quot;思考阶段”——它一边预测单词，一边输出结果。这导致： 输出逻辑容易漂移（逻辑链断裂）； 多轮任务中容易遗忘之前的推理过程； 对复杂任务缺乏一致性和复盘能力。 GLM-4.7 打破了这种机制。它在架构中 显式加入了&quot;思考层（Thinking Layer）” ，让模型在输出前进行&quot;内部思考”，形成可持续的推理链。 三种思考模式 GLM-4.7 的创新点在于它同时具备三种思考层，这在当前所有主流大模型中是首次系统实现。 [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCREJyeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--828b6e385d098688648574a416bf43dfd8fcabf9/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCREJyeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--828b6e385d098688648574a416bf43dfd8fcabf9/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 💡 举例说明： [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCTjU1eEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--67721dc26c2386ad7567b883e3b7e7efcad6b7c1/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCTjU1eEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--67721dc26c2386ad7567b883e3b7e7efcad6b7c1/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 1. Interleaved Thinking：让模型&quot;分步思考” 每个响应或工具调用前，模型会自动生成一段&quot;隐性推理过程”（即思考块）。 在这一阶段，模型不产出可见内容，而进行目标分解、验证与计划生成。 效果：显著改善指令遵循率（instruction following）与结构化输出一致性。 也就是在生成答案前，GLM-4.7 会自动进行一个内部推理阶段： 分析任务目标； 制定推理路径； 预测潜在障碍； 再生成可见输出。 这让模型在代码生成、逻辑推理等复杂场景中输出更稳定、条理更清晰。 2. Preserved Thinking：让模型&quot;记住自己的思考” 传统模型的多轮对话存在&quot;遗忘问题”：每次生成新答案时，它不会真正记得上一次的推理逻辑，只依赖上下文文本。 GLM-4.7 则在系统中引入**&quot;推理状态缓存（Reasoning Memory）”<strong>，将思考链（Reasoning Trace）显式保留在内部上下文中，并在后续调用。 这意味着： 它不会重复犯同样的逻辑错误； 可以在任务中连续改进； 适合长时程任务（如代码项目、科研分析、论文撰写）。 📊 实验证明：Preserved Thinking 在多轮推理任务中减少约 20% 的逻辑漂移（drift rate） ，在 Terminal Bench 长链任务中带来约 +16.5% 性能增益 。 3. Turn-level Thinking：让用户&quot;控制思考” GLM-4.7 允许用户或系统控制每一轮的思考深度，用户可在每一轮启用或禁用思考层 轻量任务 （如问答、摘要） → 关闭思考层，加快响应； 复杂任务 （如数学推理、编程、多步规划） → 启用思考层，提升准确度； 混合任务 → 动态切换。 这一点让 GLM-4.7 成为一个</strong>&quot;可控推理系统”<strong>，在成本、速度与智能之间实现灵活平衡。 为什么这是重大突破？ ✅ 1. 从&quot;输出导向”到&quot;思维导向” 传统模型关注输出的质量； GLM-4.7 关注 思维过程的合理性与连贯性 。它不只是&quot;会说”，而是&quot;会想并能自证逻辑”。 ✅ 2. 从&quot;对话式 AI”向&quot;可控智能体”过渡 思考系统让 GLM-4.7 能够在智能体框架中执行更复杂的多步骤任务。它能： 理解任务目标； 拆解步骤； 调用工具； 保留上下文推理链； 自主完成执行闭环。 在 Claude Code、Roo Code、Cline 等智能体框架中的测试表明，GLM-4.7 的任务完成率明显优于前代（+10%～15%）。 ✅ 3. 让推理变得&quot;稳定、可复用、可解释” 由于推理链被显式保存，GLM-4.7 的输出具备： 稳定性 ：逻辑连贯、不易漂移； 可复用性 ：可延续推理结果，不必重复思考； 可解释性 ：可追踪模型的决策依据。 这为模型的安全性、可靠性和工程应用提供了新的基础。 GLM-4.7 有哪些重大升级？ 🧩 1. GLM-4.7 的编码能力得到了大幅的提升 [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCQnQveEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--e64de4cb433a893a17d3f4f7bc58709b2304b5bb/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D%5B%E5%9B%BE%E7%89%87">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCQnQveEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--e64de4cb433a893a17d3f4f7bc58709b2304b5bb/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png][图片</a>: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCQVoxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--a557a1470e3b7055a10aa728c1ea1f24823047e2/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCQVoxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--a557a1470e3b7055a10aa728c1ea1f24823047e2/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 🧠 它能&quot; 先思考再动手 ”，比以前更少出错。比如：在写函数前，它会先规划结构和逻辑，不会一上来就乱写。 这点非常接近人类开发者的思维方式。 🎨 2. GLM-4.7 不只是会&quot;写代码”，它还会&quot;设计界面”。 GLM-4.7 对生成内容的</strong>视觉一致性（Visual Consistency）**做了大幅优化： 自动生成结构化 HTML、CSS、JavaScript 代码； 幻灯片（Slides）生成时改进了排版与比例感； 生成网页具备现代化风格与可用性。 举例： 能生成 干净、现代感的网页 ； 能排版 美观的幻灯片和海报 ； 自动控制 布局、颜色和文字比例 ，视觉统一。 🛠️ 3. GLM-4.7 可以主动使用工具，比如上网搜索或调用外部 API。 在 BrowseComp 中，从 45.1% 提升至 52.0%； 支持多工具上下文融合（context-managed browsing 模式）； 在 τ²-Bench 中达到 87.4%，优于 GPT-5 (82.7)。 [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCRmwxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--27476327a2eb4485d74e0ab9d90a47ae107e90c6/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCRmwxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--27476327a2eb4485d74e0ab9d90a47ae107e90c6/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 它能： 打开网页自己查资料； 自动提取信息； 在回答问题时引用最新内容； 自动执行命令（例如：下载文件、处理数据等）。 🔢 4. GLM-4.7 的逻辑推理能力有大幅度提升： [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSnQxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--772565f462177332799947f7c50b3c1e6a26faaa/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSnQxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--772565f462177332799947f7c50b3c1e6a26faaa/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 🧮 表现效果： 能正确解答更复杂的数学题； 在写代码前能推导更长的逻辑链； 在解释问题时更清晰、有条理。 和 GPT-5、Claude、Gemini 比起来如何？ GLM-4.7 的综合表现介于 GPT-5 与 Claude 4.5 之间 ，在&quot;代码生成 + 思考机制 + 视觉输出”方面更具优势。 在推理能力上，GLM-4.7 的平均表现略低于 GPT-5 系列，但超过 Claude Sonnet 4.5 与 Kimi K2： [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCT1YxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--7a08ab04ac5225e87288f046c8c98af4f716310e/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCT1YxeEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--7a08ab04ac5225e87288f046c8c98af4f716310e/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 推理层面： 数学逻辑接近 GPT-5，高于 Claude 4.5。 编程层面： SWE-bench、Terminal Bench 提升显著，具备行业级可用性。 智能体层面： τ²-Bench 成绩领先，展示出真实任务闭环能力。 稳定性： 由于&quot;Preserved Thinking”，在长任务、复盘任务中表现极佳。 多语言与成本： 兼顾性能与性价比，是 2025 年底全球最具实用价值的开源模型之一。 [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSUI0eEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--1705820b32bf6de1eed4b1620d1e294209d7ea79/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSUI0eEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--1705820b32bf6de1eed4b1620d1e294209d7ea79/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> 使用方式（非常简单） 🌐 在线体验：👉 Z.ai 平台 切换模型为 GLM-4.7 🧰 API 调用：文档地址： GLM-4.7 API Guide 💾 本地部署： 可在 HuggingFace、ModelScope 下载模型权重 支持框架： vLLM 、 SGLang 兼容 OpenRouter 平台 💸 价格方案： GLM Coding Plan 用户自动升级至 GLM-4.7。相较 Claude Code 模型： 成本为其 1/7 ； 使用配额为其 3 倍 ； 编程任务性能达到 90% Claude 水平。 [图片: <a href="https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSVIveEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--cea85cf3704065f2fb46a3fc5910a6c2061b0b20/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png%5D">https://app.circle.so/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBCSVIveEFjPSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--cea85cf3704065f2fb46a3fc5910a6c2061b0b20/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2Q25OaGRtVnlld1k2Q25OMGNtbHdWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--c94871ba5479e24de62982019557cdcc73e92248/image.png]</a> GitHub： <a href="https://github.com/zai-org/GLM-4.5">https://github.com/zai-org/GLM-4.5</a> 模型下载： <a href="https://huggingface.co/zai-org/GLM-4.7">https://huggingface.co/zai-org/GLM-4.7</a> 技术报告： <a href="https://arxiv.org/abs/2508.06471">https://arxiv.org/abs/2508.06471</a></p><p>【14】OpenAI坦言AI浏览器难逃&quot;提示注入”威胁，拟通过自动化攻防长期抗衡
OpenAI 近日公开承认，具备代理（Agent）能力的 AI 浏览器在架构上存在天然的安全漏洞，目前很难彻底消除&quot;提示注入”(Prompt Injection)攻击的风险。这意味着，即便安全防护不断升级，这种攻击方式仍将是 AI 领域面临的一项长期技术挑战，而非一个可以被短期&quot;修复”的 Bug。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2025/1223/6390207678533243779773282.png%5D">https://pic.chinaz.com/2025/1223/6390207678533243779773282.png]</a> 自 OpenAI 于今年10月推出内置在 ChatGPT 中的 Atlas AI 浏览器 以来，安全隐患便备受关注。研究人员发现，攻击者只需在网页或文档中植入特定指令，就能在用户不知情的情况下操控浏览器的底层行为。由于 AI 代理拥有访问邮箱、执行支付等高权限，一旦遭受攻击，极易导致敏感数据泄露或误操作。 为了应对这一顽疾，OpenAI 正在尝试一种差异化的防御路径。他们开发了一个基于大模型的&quot;自动化攻击者”系统。该系统利用强化学习技术，模拟黑客行为对 AI 代理进行高频攻防演练。通过深入洞察模型内部的推理过程，这个&quot;机器人黑客”能发掘出人类测试者难以察觉的新型攻击路径，从而帮助开发团队在真实威胁发生前完成补丁修复。 行业专家指出，AI 浏览器的风险在于其&quot;自主权”与&quot;访问权限”的乘积。目前，包括 Google 和 Brave 在内的厂商也在寻求多层防御策略。OpenAI 建议用户，在现阶段应避免赋予 AI 代理过于宽泛的权限，例如在涉及发送邮件或发起支付等关键动作时，必须保留人工确认环节。</p><p>【15】🌇 Henge Finder：地图工具查街道与日落对齐（桌面优先；Stonehenge 并非典型 henge）
原标题： 《Henge Finder》 评分: 24 | 作者: recursecenter 💭 Stonehenge 都不是 henge，还要桌面才能看日落？ 🎯 讨论背景 Henge Finder 是一个在 GitHub（vritvo/henge_finder）上可见的开源网页项目，用来计算并在地图上显示太阳何时与街道轴线对齐，演示中借助 Google Maps 交互叠加红色对齐条来表示。讨论既包含考古学层面的术语澄清（henge 的学术定义与 Stonehenge 的误用），也涉及产品层面的体验评价：地图展示、日期计算逻辑以及对移动端的强制桌面提示。评论还给出具体城市案例（如曼哈顿的 Manhattanhenge 与旧金山 Sunset/Richmond 区的候选日期）并提出功能改进建议，例如增加日出/日落切换与考虑道路坡度对观测时刻的影响。 📌 讨论焦点 术语与史实澄清 评论集中纠正了关于&quot;henge”的常见误解：学术上 henge 指新石器时代的环形土构，特点是外侧堆土（bank）而壕沟（ditch）位于内侧，因此并非以防御为目的。多条评论明确指出天体对齐并不是 henge 的定义要件，直接引用&quot;celestial alignment has nothing to do with hengeness”来反驳把天文意义强加给所有 henge 的倾向。还有人指出 Stonehenge 在技术上并非典型的 henge，这一事实反而导致该术语来源具有讽刺性；并用 Thornborough Henges 等位置举例说明学术定义与大众认知的差距。 [来源1] [来源2] [来源3] [来源4] 工具功能、实现与移动端限制 多条评论描述了 Henge Finder 的功能细节：有一个 &quot;henge near me” 页面，利用 Google Maps 交互地图在选定城市上叠加随日期变化的红色对齐条以示意日落方向，并能输入地址检查对齐情况。页面会显示 street bearing（街道方位）、sun alignment 信息、坐标与下一个 henge 日期；项目 README 提到对齐发生在接近日落的时刻（文档写到&quot;last moment the sun is at 50 °”）。该项目在 GitHub（vritvo/henge_finder）开源，但站点对移动端做了粗暴的&quot;请用桌面/笔记本访问”提示，部分用户贴出在浏览器控制台移除 .mobile-block 元素并恢复样式的绕过命令来继续使用。 [来源1] [来源2] [来源3] [来源4] 用户体验、现场感受与改进建议 有人分享了亲历的 Manhattanhenge 场景：在曼哈顿走到 42 街时看到夕阳从建筑缝隙中穿过并发现大量摄影者，说明此类现象具有强烈的市民吸引力。评论中提出应增加日出/日落切换功能，因为部分街道有东向坡度，日出时的视觉效果可能更好，提示工具在计算时需考虑地形坡度与观测高度。这些反馈既是对功能的直接改进建议，也是对观测场景复杂性的提醒。 [来源1] [来源2] 城市案例与具体地理细节 评论举出具体城市示例来说明工具的实用性：在 Henge Finder 的演示中，2026-03-12 被标为旧金山 Sunset 与 Richmond 区按字母命名的多条大道（北至南如 Anza、Balboa、Cabrillo … Vicente、Wawona、Yorba）同时成为 henge 候选。这个例子显示出城市格网和街道命名规则会带来系统性的对齐机会，使得工具可用于提前发现某一街区的观测日期。作者与使用者也因此讨论了地图交互的趣味性与界面、兼容性问题。 [来源1] 📚 术语解释 henge: 新石器时代的一类环形土构，特点为外侧堆土（bank）而壕沟（ditch）位于内侧，通常不以防御为目的，天文对齐并非定义要素。 Manhattanhenge: 纽约曼哈顿的城市现象，指夕阳方向与曼哈顿按网格排列的街道轴线对齐，形成建筑缝隙中的落日景观，常吸引大量市民摄影。 street bearing（街道方位）: 街道相对于地理北（或磁北）的方位角，用来与太阳方位（azimuth）比对以判断是否发生轴线对齐。 Henge Finder（vritvo/henge_finder）: 一个开源网页工具（GitHub 仓库 vritvo/henge_finder），通过地址和地图计算并展示太阳与街道轴线对齐的时间、坐标与下次对齐日期，并在地图上以叠加条形标示对齐方向。 类别： Web | Science | Release | Henge Finder | hengefinder.rcdis.co | Manhattanhenge | Google Maps | sunset | alignment | Stonehenge | github.com/vritvo/henge_finder</p><p>【16】ChatGPT 版&quot;Spotify Wrapped”来了！测测你的年度 AI 称号是什么？
继音乐、社交软件之后，生成式 AI 领域也迎来了自己的&quot;年终总结”。OpenAI 正式宣布，将向特定市场的符合条件的消费者推出名为**&quot;与 ChatGPT 共度一年”（Your Year with ChatGPT）<strong>的年度回顾功能，旨在为用户提供个性化且具趣味性的使用轨迹报告。 [图片: OpenAI，人工智能，AI [object Object]<a href="https://pic.chinaz.com/picmap/202405110933330041_0.jpg%5D">https://pic.chinaz.com/picmap/202405110933330041_0.jpg]</a> 核心亮点与玩法 与广受欢迎的 Spotify Wrapped 类似，OpenAI 采用了极具视觉冲击力的图形设计。该功能会根据用户全年的对话习惯授予特定&quot;奖项”。例如，经常利用 AI 寻找解决方案或完善构思的用户，可能会获得</strong>&quot;创意调试员”**的趣味称号。 此外，ChatGPT 还会结合用户全年的核心兴趣主题，利用其生成能力定制 一首专属诗歌和一张总结图片 ，记录用户与 AI 互动的点滴。 [图片: QQ20251223-085138.png [object Object]<a href="https://pic.chinaz.com/2025/1223/6390207671401036893838595.png%5D">https://pic.chinaz.com/2025/1223/6390207671401036893838595.png]</a> 使用门槛与覆盖范围 支持人群: 面向美国、加拿大、英国、澳大利亚和新西兰的 Free、Plus 及 Pro 版 个人用户。 技术前提: 用户需开启&quot;参考保存的记忆”和&quot;参考聊天记录”选项，并达到 最低 的对话活动阈值。 暂不支持: 团队（Team）、企业(Enterprise)或教育(Edu)账户目前无法使用。 隐私与访问方式 OpenAI 强调，该体验遵循&quot;轻量级、隐私优先且用户可控”的原则。功能不会强制弹出，用户可以通过以下方式访问: [图片: QQ20251223-085109.png [object Object]<a href="https://pic.chinaz.com/2025/1223/6390207672415059875869100.png%5D">https://pic.chinaz.com/2025/1223/6390207672415059875869100.png]</a> 点击 ChatGPT **网页端或移动端（iOS/Android）**主屏幕的推广入口。 直接向机器人发送指令: &quot;查看我与 ChatGPT 的一年” 。 随着 ChatGPT 计划在2026年逐步引入更多元的内容边界，这种个性化的回顾功能无疑将成为观察人类与 AI 协作进化的重要窗口。</p><p>【17】易烊千玺的华为绿手机，真的AI了
易烊千玺的华为绿手机，真的AI了 [图片: <a href="http://www.qbitai.com/wp-content/themes/liangziwei/imagesnew/head.jpg%5D">http://www.qbitai.com/wp-content/themes/liangziwei/imagesnew/head.jpg]</a> 衡宇 2025-12-23 08:40:50 来源： 量子位 标准版也没躺平 衡宇 发自 深圳 量子位 | 公众号 QbitAI 易烊千玺现身深圳，手里拿的绿手机，几乎第一时间抢走了现场的全部注意力。 这就是华为nova系列最新推出的 nova 15 Ultra带感绿 （真的很吸睛的颜色）。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/ca663e498f36c2be7ab6b2a4fb322baf.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/ca663e498f36c2be7ab6b2a4fb322baf.webp]</a> nova 15系列这次的产品分层依旧非常清晰，共推出数字标准版、Pro版和Ultra版三款机型， 全系搭载HarmonyOS 6 。 该系列的Ultra和Pro版本在外观上采用横向立体堆叠设计，搭载双星镜头模组，就像有两只大眼睛。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/38a3ef70157227f7855c5583071197df.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/38a3ef70157227f7855c5583071197df.webp]</a> 同时 Pro版和Ultra版 首次升级麒麟9系芯片，性能定位向Mate、Pura系列看齐。 Ultra版本4199元起，Pro版本3499元起。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/c8fa563dc9204ea649237c6b240fdd45.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/c8fa563dc9204ea649237c6b240fdd45.webp]</a> [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/95433c65a27b256a6c54cc08110018d7.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/95433c65a27b256a6c54cc08110018d7.webp]</a> 数字标准版 则维持了更经典的单环加闪光灯设计，外形延续上一代风格。 标准版价格2699元起。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/aaddf5d2ca761f845cc8f69d915483a1.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/aaddf5d2ca761f845cc8f69d915483a1.webp]</a> nova 15系列，真的有点AI了 nova 15系列的AI能力几乎全部藏在具体场景里。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/a28e6782ab7f83645f1444a3d8432e80.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/a28e6782ab7f83645f1444a3d8432e80.webp]</a> 影像是最直观的一条线索 。 Ultra和Pro版本都首发搭载了前、后双红枫影像系统，通过多光谱感知与像素级算法参与色彩计算。 红枫原色镜头能在更宽广的光谱范围内，对全局光谱信息进行精准测量，色彩还原准确度大幅提升，拍出来的照片色彩更加真实。 前摄加入红枫原色镜头后，自拍出片效果会更好。 官方数据显示，色彩还原准确度提升了120%，空间分辨率提升10万倍。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/8913d0ffb0dc5461420531b4725a0ab6.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/8913d0ffb0dc5461420531b4725a0ab6.webp]</a> 用nova 15系列拍照的时候， AI会在拍照过程中提供构图辅助 ，助力用户出片。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/6e2a520a2169312c6a46ba98f01feeb5.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/6e2a520a2169312c6a46ba98f01feeb5.webp]</a> nova 15系列还首发了一个炒鸡实用的功能： AI沾色功能 。 去某地打卡拍照，如果天气不好出不了片，怎么办？ 可以在网上找张想要的天气图片，然后用这个功能把网图的色彩、风格&quot;沾”到自己的照片里来。 Be like—— [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/b6a38eec6c7ef5a797de0b0021df8e4e.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/b6a38eec6c7ef5a797de0b0021df8e4e.webp]</a> 小艺修图等鸿蒙AI能力 支持从拍照到修图全链路出片。 就拿修图来说，可以用大白话让AI帮忙修图了。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/01ad77abf542751600f29c355b01ca98.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/01ad77abf542751600f29c355b01ca98.webp]</a> 另一项更偏向内容创作的能力，是AI一键成片。 它把多张照片重新理解为一个素材集合，再由系统完成节奏、转场和动效的组合。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/5a6a05e23465c5b0a3ad6dad7b92b9fe.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/5a6a05e23465c5b0a3ad6dad7b92b9fe.webp]</a> 通话场景中，AI的存在感反而被刻意弱化。 通话摘要功能会在结束后自动生成要点，并同步到备忘录 （华为终端BG CEO何刚在现场调侃，这大概会成为很多老板最喜欢的功能）。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/96541141167723b6471e3cc0ff576a4c.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/96541141167723b6471e3cc0ff576a4c.webp]</a> 双向通话降噪则专门针对地铁、商场等高噪环境进行了优化。 值得一提的是安全相关能力。 nova 15系列 引入了亲情防诈功能 ，家人之间可以共享风险信息。 一旦有可疑来电，儿女可以远程帮老人协助挂断电话。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/afb94f76850d3699c561f6ed04ae56b3.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/afb94f76850d3699c561f6ed04ae56b3.webp]</a> 依旧高辨识度 外观，是华为nova系列最容易被一眼认出来的地方。 nova 15系列 延续&quot;年轻与辨识度”的外观设计主基调 。 2.5D直屏设计的Ultra版，推出了带感绿、好搭紫、零度白、幻夜黑四种颜色。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/668360c1312c22ab8ddfd19ef4635ac4.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/668360c1312c22ab8ddfd19ef4635ac4.webp]</a> 配有6500mAh电池，且 首次在nova系列引入50W无线超级快充 。 机身重量约209g，厚度仅6.8mm。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/18a88855c6d00c0dfcdd01787a0e67c0.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/18a88855c6d00c0dfcdd01787a0e67c0.webp]</a> 后置摄像头首次搭载由三颗5000万像素RYYB镜头组成的全RYYB红枫影像系统 ，整体规格一次拉满。 主摄支持10档可变光圈与光学防抖，同时配备红枫原色镜头，并引入多焦段自适应双闪光灯和激光对焦传感器，完整覆盖从成像到对焦的关键环节。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/6655cf74414eb18ab31a0509d73c8ba6.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/6655cf74414eb18ab31a0509d73c8ba6.webp]</a> 搭载昆仑玻璃和锦纤背板，支持IP68&#x26;IP69防尘防水。 划个小小的重点——1TB版本配有抗反光玄武钢化昆仑玻璃。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/985f7cb0f532fe859b0bf37efc69745e.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/985f7cb0f532fe859b0bf37efc69745e.webp]</a> 机身6.9mm的 Pro版本 同样也有四个颜色可选： 零度白 带感绿 （但和Ultra不是一种带感法） 好搭紫 幻夜黑 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/a32668912cdc8d28e4faf768205007af.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/a32668912cdc8d28e4faf768205007af.webp]</a> 这个版本的电池容量同样是6500mAh。 标准版长得和其它两个版本不太一样 ，但也保持了相当的辨识度。 根据华为实验室测试，整机性能相比上一代提升62% [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/0624923a80fcd4021ac9a71044bab3eb.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/0624923a80fcd4021ac9a71044bab3eb.webp]</a> 本月25号 ，该系列将正式发售。 版权所有，未经授权不得以任何形式转载及使用，违者必究。</p><p>【18】智谱IPO敲钟前，连夜把开源编程大模型SOTA了
智谱IPO敲钟前，连夜把开源编程大模型SOTA了 [图片: <a href="http://www.qbitai.com/wp-content/themes/liangziwei/imagesnew/head.jpg%5D">http://www.qbitai.com/wp-content/themes/liangziwei/imagesnew/head.jpg]</a> henry 2025-12-23 08:28:29 来源： 量子位 这波更新，满眼都是Coding，Coding，还是Coding 鱼羊 henry 发自 麦蒿寺 量子位 | 公众号 QbitAI 2025倒计时，新SOTA模型涌现没有放缓迹象。 一夜之间，编程SOTA模型易主，而且上线即开源，依然来自中国大模型公司—— 智谱AI，GLM-4.7。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/e54a0f23c639a235556bd3c4562da8d0.webp%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/e54a0f23c639a235556bd3c4562da8d0.webp]</a> 这波更新，技术报告里满眼都是 Coding ， Coding ，还是 Coding 。 而能力的提升，带来的最直观效果是： AIME 25和人类最后考试（HLE）等基准中，GLM-4.7分数超GPT-5.1； SWE-Bench分数达（73.8%，+5.8%），创开源新高。 官方Demo显示，写个植物大战僵尸不费劲： [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/eea2aa3ae1afe2e7fbb73042cbc91f0d.gif%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/eea2aa3ae1afe2e7fbb73042cbc91f0d.gif]</a> 总而言之，模型这么一发，双旦的节庆氛围一下到位了（doge）。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/5f4ad909da26ae5804766c11d18de218.png%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/5f4ad909da26ae5804766c11d18de218.png]</a> 官网Chatbot和API均已就为，现在就能在线开玩。 Demo来吧，展示 在前端生成质量上，GLM-4.7展现出明显升级：页面结构更干净、组件层级更清晰。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/53a92ff6fcabb2c98ab8c8abdc863b46.gif%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/53a92ff6fcabb2c98ab8c8abdc863b46.gif]</a> 相比GLM-4.6，更像是现代的Web UI，网友元素中更加美观。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/eeebe93471108dfea5669e73119ef141.gif%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/eeebe93471108dfea5669e73119ef141.gif]</a> 在PPT与视觉物料生成方面，GLM-4.7标题层级明确、元素尺寸更合理。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/21f8199cd5031a16939005a0dac50ad9.gif%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/21f8199cd5031a16939005a0dac50ad9.gif]</a> 在复杂几何结构与空间关系的表达上，GLM-4.7模型能够保持较好的结构一致性与细节稳定性。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/fa7511215570e837f0c5e745d6ede6b3.gif%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/fa7511215570e837f0c5e745d6ede6b3.gif]</a> 3D资产的生成质量也有显著提升。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/397bd1e27ca5eca68715dff56fee085a.gif%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/397bd1e27ca5eca68715dff56fee085a.gif]</a> 刷新开源SOTA 这次最新的模型主打编程，相较前代GLM-4.6，GLM-4.7在编码能力、交互体验与复杂推理等多个维度实现了系统性升级。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/0a76a1f3eb56b888f22ab553d8e37f4e.png%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/0a76a1f3eb56b888f22ab553d8e37f4e.png]</a> 复杂推理能力（Reasoning）：全面提升，HLE（含工具）42.8（+12.4 vs GLM-4.6），MMUL-Pro 84.3，GPQA-Diamond 85.7，数学与推理能力更稳更强。 核心编码能力（Code Agent）：多语言与终端任务显著增强，SWE-bench Verified 73.8（+5.8）、SWE-bench Multilingual 66.7（+12.9）、Terminal Bench 2.0 41.0（+16.5），支持&quot;先思考、再行动”模式。 工具使用能力（General Agent）：工具调用更高效，BrowseComp 52.0（+6.9）、BrowseComp w/ Context Management 67.5（+10.0）、τ²-Bench 87.4（+12.2），网页浏览与工具链管理表现更优。 此外，GLM-4.7在对话、创意写作、角色扮演等场景中同样有提升，系统性增强了编码、推理与工具使用能力。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/ace959a9637da3cd20e64ba20a9a9621.png%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/ace959a9637da3cd20e64ba20a9a9621.png]</a> 交错式思考和保留式思考 技术方面，GLM-4.7强化了自GLM-4.5起引入的 交错式思考 （Interleaved Thinking），并进一步引入了 保留式思考 （Preserved thinking）和 轮级思考 （Turn-level Thinking）。 交错式思考 GLM在工具调用之间、收到工具结果之后继续思考。 这让模型能够进行更复杂的分布推理，提升了指令遵从和生成质量： 在决定下一步行动前先解读每次的工具输出，把多次工具调用和推理步骤串联起来，并根据中间结果做出更细粒度的决策。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/26ab798aa6e77f50c464fa29c2f9f445.png%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/26ab798aa6e77f50c464fa29c2f9f445.png]</a> 保留式思考 在编码场景中，GLM-4.7引入了一种新的思考模式： 模型会自动在多回合对话中保留所有思考快，复用已有推理而不是从头重新推理。这减少了信息丢失和不一致性，使得模型更适用于 长程、复杂任务 。还能在真实任务中节省更多tokens。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/0dd89d37e8144f6a346234f258357799.png%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/0dd89d37e8144f6a346234f258357799.png]</a> 轮级思考 轮级思考是一种按轮控制推理计算的能力，即在同一个会话中，每一轮请求都可以独立选择开启/关闭思考。 这使得GLM-4.7具备以下优势： 更灵活的成本/时延控制：对&quot;问个事实/改个措辞”等轻量轮次可关闭思考，追求快速响应；对&quot;复杂规划/多约束推理/代码调试”等重任务轮次可开启思考，提升正确率与稳定性。 更顺滑的多轮体验：思考开关在会话内可随时切换，模型能在不同轮次间保持对话连贯与输出风格一致，让用户感觉&quot;聪明时更聪明、简单时更快”。 更适合Agent/工具调用场景：在需要快速执行的工具轮次可降低推理开销，在需要综合工具结果做决策的轮次再开启深度思考，实现效率与质量的动态平衡。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/819eb3e987f6fc0c07b4d0af416a8586.jpeg%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/819eb3e987f6fc0c07b4d0af416a8586.jpeg]</a> 更多技术详情，智谱官方也附上了详细技术报告。 BTW，智谱这个月还真上了&quot;节日限定优惠”。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/daa4880bce75272ca0cc8ed9c2f77d5f.png%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/daa4880bce75272ca0cc8ed9c2f77d5f.png]</a> 每月最低20元即可畅享GLM-4.7，用上Claude Pro套餐3倍用量。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/130b5fd296be81850e7de690d70f2392.png%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/130b5fd296be81850e7de690d70f2392.png]</a> 又是一位好价格屠夫呀。 [图片: <a href="https://i.qbitai.com/wp-content/uploads/replace/2025/12/9593ee79cd9e1e756b291ae01430b725.jpeg%5D">https://i.qbitai.com/wp-content/uploads/replace/2025/12/9593ee79cd9e1e756b291ae01430b725.jpeg]</a> 而且GLM-4.7的深夜炸场，也算是已经冲刺IPO上市的智谱，带来的最新技术证明。 目前智谱已经通过了港交所上市聆讯，IPO敲钟仅剩下最后100米。 而GLM-4.7可能也是智谱上市之前，最重要的模型更新了……吧？ 参考链接： [1]<a href="https://z.ai/blog/glm-4.7">https://z.ai/blog/glm-4.7</a> [2]<a href="https://x.com/Zai_org/status/2003156119087382683">https://x.com/Zai_org/status/2003156119087382683</a> 版权所有，未经授权不得以任何形式转载及使用，违者必究。</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2025/12/23 AI 日报 今日摘要 【1】exo 用日常设备在家运行你自己的AI集群 📱💻 🖥️⌚ 【2】iptv 来自世界各地的公开IPTV频道合集 【3】PayloadsAllTheThings 一份用于Web应用安全和渗透测试/CTF的有用载荷与绕过清单 【4】PentestGPT 一款GPT赋能的渗透测试工具 【5】skills Agent Skills的公共仓]]></description>
        </item>
      
  </channel>
</rss>