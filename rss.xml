<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI洞察日报 RSS Feed</title>
    <link></link>
    <description> 近 7 天的AI日报</description>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 28 Feb 2026 02:38:37 GMT</lastBuildDate>
    <atom:link href="https://yxxxxx1-ai-daily.gunzhao59.workers.dev/rss" rel="self" type="application/rss+xml" />
    
        <item>
          <title><![CDATA[2026-02-28日刊]]></title>
          <link>/2026-02/2026-02-28/</link>
          <guid>/2026-02/2026-02-28/</guid>
          <pubDate>Sat, 28 Feb 2026 10:38:36 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2026/2/28</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】🤨 最小 transformer 加两 10 位数：36、311、28 参数与可复现性争议
原标题： 《Smallest transformer that can add two 10-digit numbers》 评分: 34 | 作者: ks2048 💭 36 个参数就能学十位数相加？真的假的？ 🎯 讨论背景 原帖讨论一个号称能用极小 transformer 完成对两个 10 位数相加的实现，社区关注点集中在极小参数量的可行性与可复现性。评论中提到不同参数数字（如 28、36、311）和据称的 &gt;=99% 准确率，引发对手写权重、训练流程和实验透明度的质疑。讨论涉及技术细节：是否把该功能当作可替换的固定模块嵌入到 LLM（large language model）预训练流程、tokenize（分词）如何影响输入表示，以及单次 matmul（矩阵乘法）示例为何只是戏谑式简化。总体而言，争论横跨实现与定义层面：到底是演示可训练的最小模型，还是把算法包装成&quot;模型”以博眼球。 📌 讨论焦点 模块化与权重可替换性争论 有评论提出是否可以在 LLM（large language model）预训练前把这种单用途且权重固定的网络嵌入，以复用相同的推理代码并节省资源。另一条评论引用了一个判定标准：如果能替换权重并使用相同的推理代码则算&quot;合法”的模型，反之若推理代码与算法不可分离则不算模型，这将&quot;模型”与&quot;算法实现”区分开来。讨论还关注手写/固定权重（例如 36 个参数）与训练后权重（例如 311 个参数）之间的差异，并质疑是否有人从随机初始化开始训练该结构以验证其可学习性。总体关切在于模块化、固定权重与&quot;可替换权重”范式如何影响结果的解释与可复现性。 [来源1] [来源2] [来源3] 参数规模与可复现性怀疑 多位评论对参数计数和报告精度提出质疑：有人在 Twitter 上看到称只需 28 个参数的说法，而讨论中也出现了手写权重 36 个、训练后 311 个等不同数字。评论对&quot;&gt;=99% accuracy”感到惊讶并怀疑其可信度，尤其在演示被描述为&quot;vibe coded”（凭直觉/手工）且没有提交到 arXiv（预印本服务器）的情况下。评论者要求公开实现细节、训练设置与从随机初始化训练的实验结果，以便验证这些极小模型的可训练性与鲁棒性。社区强调僅有参数或准确率数字不足以说服人，必须有完整训练流程和可复现代码。 [来源1] [来源2] [来源3] 把简单矩阵乘法等同于 Transformer 的误解与笑话 有人以戏谑方式指出两个数相加在数学上可以用一次 matmul（矩阵乘法）实现，并举出 [A B] × [1;1] = [A +B] 的示例来讽刺过度简化的说法。随后有评论指出这是个玩笑，因为 transformer 在处理输入前会先 tokenize（分词/切片），随后在 token 表示上执行一系列 matmul、激活（如 ReLU）和 attention 操作，模型并不会直接&quot;看到”原始数字字符串。还有人把把任意 transformer 转换成紧凑低功耗门电路的设想质疑为对内部机制的过度抽象或误解。讨论提醒读者区分数学上单步线性代数运算与深度模型中输入编码和层级处理的差别。 [来源1] [来源2] [来源3] [来源4] [来源5] [来源6] 对演示包装与噱头的嘲讽 评论中有人讽刺性地建议把成果打包成 Electron（桌面应用框架）应用，以调侃将小实验商品化或展示化的趋势。另一条评论表达了对缺乏严谨评估（例如无论文支持、凭直觉实现）的疲惫，表示要把注意力留给更可靠的研究。这些反应反映出社区对噱头式展示和不透明报告的不满，倾向于优先要求可验证、可重复的技术说明而非表面参数游戏或花哨包装。 [来源1] [来源2] 📚 术语解释 transformer: transformer（Transformer）是一种基于 self-attention 的序列建模神经网络架构，依赖 token 表示、多层矩阵运算和注意力机制来处理文本或序列数据。 matmul: matmul 是 &#39;matrix multiplication&#39; 的简称，指矩阵乘法，深度学习中用于实现线性变换和前向推理的基本线性代数运算。 tokenize: tokenize（分词/切片）是将原始输入（如数字字符串或文本）拆分为模型可处理的 tokens 的过程，直接影响模型能否以合适的表示&quot;看见”输入。 hand-coded weights（手写/固定权重）: hand-coded weights 指由人或规则直接设定的网络权重，而非通过梯度训练得到的参数；常用于演示可否用固定参数实现某种计算。 params: params（parameters）指模型中的可学习参数数量，常用于衡量模型规模，但参数数量本身不能完全反映模型的可训练性或实际性能。</p><p>【2】🛡️ Anthropic 回应 Hegseth：称供应链风险指定仅限军事合同并拒绝被全面封杀
原标题： 《Not Found》 评分: 22 | 作者: surprisetalk 💭 是要把 Claude 当作核武机密管制吗？ 🎯 讨论背景 本讨论发端于 Anthropic 就公众人物 Pete Hegseth 对公司和其模型的评论所做的公开回应。声明援引了 10 USC 3252（美国法典第 10 编第 3252 节），并主张 supply chain risk designation 在法律上只可影响 Department of War 合同中对 Claude（Anthropic 的大型语言模型）的使用，而不应自动切断商业客户或个人用户的访问。评论者围绕法律条文、行政执行力与现实施压手段展开，提到可能被施压的环节包括国防承包商与为模型提供算力的云厂商（如 Google），以及政府以 restricted data 名义扩大管控的可能性。讨论同时涉及工程师的职业伦理、国家安全话语作为谈判工具的运用，以及司法先例能否实际遏制行政权力扩张。 📌 讨论焦点 支持与道德立场 多位评论者赞赏 Anthropic 公开承认无法准确预测强大模型被滥用的方式，认为这种透明与谨慎是一种负责任的公司姿态。有人把公司的声明形容为礼貌但坚决的反抗，认为在原则问题上不妥协会赢得公众信任并在长期竞争中占优。评论还把问题提升到个人职业伦理层面，建议若工作会直接助长监控或伤害无辜，应当认真考虑是否继续从事。简短的支持言论也表明这类立场能为公司赢得用户和舆论好感。 [来源1] [来源2] [来源3] [来源4] 法律边界与执行风险 Anthropic 的声明援引了 10 USC 3252，指出 supply chain risk designation 在法律上只能针对 Department of War 合同中对 Claude 的使用进行限制，不能自动影响公司对商业客户或个人用户的服务。评论者认为尽管法律文字有限，行政与政治手段仍能在实践中扩大影响力：政府可能通过强迫承包商切断合作、对提供算力的云供应商施压（例如 Google），甚至以将技术列为 restricted data 的方式实施更严厉的限制。有人提到历史上有律所因行政命令而诉诸法庭并胜诉，但也有评论对司法或制度能否制约行政滥权抱持怀疑，担心实际&quot;爆破半径”会比法律条文更大。总体观点既承认法律适用范围的狭窄，也对行政执行力和政治压力带来的实务风险表示忧虑。 [来源1] [来源2] [来源3] [来源4] 国家安全话语与谈判策略的怀疑 部分评论质疑官方以&quot;危害美国战士与平民”为由的表述，认为这种国家安全论调常被用作谈判策略而非单纯的技术评估。有人指出公开信件中使用&quot;爱国”或&quot;国家安全”论述，往往是为了在政治与舆论层面施压，对外界而言应把这些陈述看作谈判的一部分。评论还提醒，涉及 autonomous weapons（自主武器）等议题时，国家安全关切可能被选择性地引用，而对他国平民风险的忽视暴露了论述的双重标准。整体上，评论者建议区分技术风险评估与政治话语的工具性使用。 [来源1] [来源2] 监控、后门与工程师道德 有评论提出对政府是否已拥有对科技公司&quot;默认后门”的担忧，提到 NSA（美国国家安全局）或其他机构可能历史上或法律上有要求访问的先例，从而使所谓的管制具备现实可执行性。基于这种可能性，一些人主张工程师和技术从业者在选择项目时应考虑是否在帮助&quot;big brother”扩大可见性或能力，必要时应拒绝参与可能导致监控或武器化的工作。这些观点把技术合规问题与个人伦理责任联系起来，认为法律与政策不足以完全替代职业与道德判断。 [来源1] [来源2] 媒体标题、先例与升级风险 部分评论指出原帖或报道标题不准确，强调这次声明更像是向客户澄清针对 Hegseth 社交帖子的回应，而非政府政策的最终定论。讨论中也提到并非首例与行政当局对峙的情形——此前有律所针对行政命令提起诉讼并胜诉——但同时有人担心公开点名与指责会引发进一步升级，扩大政治博弈的范围。总体观点认为法律先例能提供一定保护，但公开对抗本身仍会带来额外风险与不确定性。 [来源1] [来源2] [来源3] 📚 术语解释 Claude: Anthropic 的大型语言模型（LLM），讨论中公司针对该模型的使用与法律影响为核心争议点。 10 USC 3252: 美国法典第 10 编第 3252 节，涉及国防部就供应链风险对供应商或技术作出指定的法律条款，法律适用主要限于国防合同范围。 supply chain risk designation: 供应链风险指定：一种行政或法律认定，用以在国防合同中对被视为风险的供应商或技术施加限制或附加条件。 restricted data: 限制数据（restricted data）：用于核技术等高度敏感信息的分类标签；若将软件或模型归入该类别，会触发严格访问控制和法律后果。 Executive Orders (EOs): 行政命令（EOs）：总统或行政机构发布的指令，可直接影响联邦政策与合同执行，历史上常成为司法审查对象。 government backdoor / 后门: 政府后门：指政府要求企业提供绕过加密或直接访问系统与数据的机制，此类要求在隐私、安全与法律上长期存在争议。 类别： AI | Policy | Business | Opinion | Anthropic | Claude | Pete Hegseth | supply chain risk designation | Department of War | claude.ai</p><p>【3】😬 &quot;We Will Not Be Divided”：Anthropic 员工团结誓言与伦理能否在现实中存活？
原标题： 《We Will Not Be Divided》 评分: 22 | 作者: BloondAndDoom 💭 真要等良心吃不起饭、公司才放弃利润吗？ 🎯 讨论背景 讨论源自一份题为 &quot;We Will Not Be Divided” 的公开宣言——来自 AI 公司内部人员的团结与伦理呼吁，评论里多次提到 Anthropic（AI 研究公司）和 xAI（AI 初创公司）。参与者以历史案例（例如 Google 在监控/监视项目上的让步）与对 DoD（美国国防部）或其他国家机构可能绕过企业伦理承诺的担忧为前提展开争论。讨论交织了对企业利润驱动本质的现实主义分析、对传播措辞与法律框架的策略性关注，以及能否把承诺扩大到更广泛人群或跨国推广的可行性评估。总体语境是技术从业者在 AI 军事化、监管压力与企业生存之间寻求平衡的焦虑与希望。 📌 讨论焦点 支持与团结：员工誓言与扩展签名的呼吁 若干评论对原文表示赞赏，称其勇敢、温暖并呼吁在当前形势下坚持这道德底线。有人明确建议扩大行动范围，提出在 xAI 等公司收集签名以填补可能出现的空位，认为行业内应当有一处能够坚持伦理的阵地。评论中的口号式呼声（如&quot;Hold this line”）反映出希望建立并守住一个示范性的道德立场的愿望。 [来源1] [来源2] [来源3] 现实主义与怀疑：公司能否兼顾道德与生存？ 不少评论怀疑企业在美国能否同时保持道德并生存，直言如果 Anthropic 倒下就会成为&quot;不能兼顾道德与成功”的证明。有人援引历史先例指出大公司往往会妥协，例如十年前 Google 在监控/监视相关项目上的让步，暗示伦理承诺易受商业或国家压力侵蚀。更激烈的观点认为公司本质受利润驱动（&quot;money is the only true God” 的论调），并警告公众舆论或选民可能会通过监管改变行业走向，同时提醒要为&quot;希望未能实现”的情形做准备。 [来源1] [来源2] [来源3] [来源4] 扩展承诺的可行性与国际挑战 部分评论讨论是否应把此类誓言扩展到所有美国人甚至全球，提出不应局限于某几家公司的员工。反对者指出全球推广难度极高，尤其是在中国、印度、俄罗斯或中东等政治环境迥异的地区，需要巨大的勇气与不同体制下的承受力。与此同时也有人认为开发者群体具有&quot;cybernetic”特质，行业内部仍有可能在跨国或跨公司层面形成某种共识或压力。 [来源1] [来源2] 措辞与政治框架问题 有人针对文本措辞提出策略性批评，指出使用诸如 &quot;Department of War” 等表述会无意中采用对方话语并在法律/政治层面预先让步。评论提醒在与军事化或政府政策对立时应注意术语的准确性，以免在论证或公众传播中丧失立场正当性。这种关注不是空泛的语义争辩，而是对传播效果和法律框架敏感性的实际策略性建议。 [来源1] 对军方绕行的担忧与讽刺调侃 部分评论以讽刺或调侃表达对军方或政府会绕过企业伦理承诺的悲观，例如戏言&quot;DoD ^HW will just use DeepSeek”，暗指美国国防部会自研或采购替代工具。与此同时也有轻松或怀旧的梗（如&quot;He will not divide us!”、对 Club Penguin 与 Roblox 的比较），这些笑话既是情绪发泄也反映社区的无奈与疲惫。总体上，这类评论把注意力从理想化的企业自律拉回到国家机器与现实政治能否被企业承诺左右的问题上。 [来源1] [来源2] [来源3] [来源4] [来源5] 类别： AI | Work | Product | Opinion | AI | notdivided.org | Google</p><p>【4】A statement on the comments from Secretary of War Pete Hegseth. <a href="https://anthropic.com/news/statement-comments-secretary-war">https://anthropic.com/news/statement-comments-secretary-war</a>
A statement on the comments from Secretary of War Pete Hegseth. <a href="https://anthropic.com/news/statement-comments-secretary-war">https://anthropic.com/news/statement-comments-secretary-war</a></p><p>【5】打破英伟达垄断！Meta签署数两百亿美元大单，改租谷歌TPU自研AI模型
在AI芯片领域，一场旨在&quot;去英伟达化”的巨头博弈正在上演。社交媒体巨头Meta近日与谷歌达成了一项跨年度、价值达数十亿美元的重磅协议，计划租用谷歌自研的张量处理单元（TPU）来开发其新一代AI模型。 这一动作直接挑战了英伟达在AI芯片市场的统治地位。长期以来，英伟达一直是Meta训练模型时的 首选 供应商，Meta甚至在几天前刚宣布要从英伟达和AMD购买数百万个GPU。然而，Meta此次&quot;脚踏两只船”租用谷歌TPU，不仅是为了缓解算力焦虑，更是为了在自研数据中心中探索除GPU之外的替代方案，据悉Meta甚至考虑从明年开始直接购买TPU。 谷歌的&quot;算盘”：既是客户，也是对手 这场交易背后的逻辑颇为微妙。谷歌云高管已设定目标，计划通过销售TPU夺取英伟达约10%的年收入（约 200 亿美元）。为了实现这一目标，谷歌不仅与投资机构合作对外租赁TPU，更试图通过差异化竞争吸引像OpenAI、Meta这样的大客户。 有趣的是，由于云端用户对GPU的需求依然强劲，谷歌本身仍是英伟达 最大 的客户之一。它必须一边斥巨资购买英伟达的 最新 芯片以保持云市场竞争力，一边推销自家的TPU来蚕食英伟达的市场份额。 市场连锁反应：倒逼芯片降价 AI芯片市场的这种&quot;内卷”对下游开发者而言显然是件好事。据行业消息称，正是因为TPU等替代品的存在，OpenAI在与英伟达的谈判中成功压低了30%的采购价格。 随着Meta等巨头开始大规模转向多元化算力布局，英伟达一家独大的局面正面临前所未有的压力。这场关于算力底座的&quot;军备竞赛”，正从单纯的产能比拼演变为架构与生态的全面较量。</p><p>【6】​AI音乐也疯狂！Suno付费订阅突破 200 万，年收入冲向 3 亿美元大关
AI音乐生成领域正迎来爆发式增长。近日，知名AI音乐创作平台Suno的联合创始人兼首席执行官Mikey Shulman披露了公司的 最新 经营数据：Suno目前的付费订阅用户数已正式突破 200 万 ，年经常性收入（ARR）更是达到了惊人的 3 亿美元 。 回顾三个月前，Suno在完成2. 5 亿美元融资时的估值为24. 5 亿美元，当时披露的年收入仅为 2 亿美元。这意味着在短短一个季度内，Suno的营收规模就实现了**50%**的跨越式增长。 Suno之所以能快速出圈，核心在于其极低的创作门槛。用户只需输入简单的自然语言提示词，AI就能在几秒钟内生成旋律优美、人声逼真的完整歌曲。 这种&quot;让每个人都能写歌”的能力已经开始重塑音乐产业。例如， 31 岁的密西西比州用户Telisha Jones通过Suno将自己的诗歌转变成了R&#x26;B金曲《How Was I Supposed to Know》，不仅在社交媒体上走红，更获得了一份价值 300 万美元 的唱片合约。 尽管发展迅猛，Suno也面临着来自传统音乐行业的挑战。包括Billie Eilish、Katy Perry在内的多位 顶级 音乐人曾公开抵制AI对音乐作品的侵权。此前，多家唱片公司也因版权问题对Suno提起诉讼。 不过，局面正在发生积极变化。华纳音乐集团近期已与Suno达成和解，并签署了授权协议，允许Suno使用其曲库中的音乐来训练新的AI模型。这意味着AI音乐平台正在从行业的&quot;搅局者”转变为&quot;合作伙伴”。</p><p>【7】Claude Code 下个版本将新增两项 Skills: /simplify 和 /batch 1. /simplify 作用：在代码变更之后，自动调用多个并行 Agent，对代码进行质量提升、性能调优，并...
Claude Code 下个版本将新增两项 Skills: /simplify 和 /batch 1. /simplify 作用：在代码变更之后，自动调用多个并行 Agent，对代码进行质量提升、性能调优，并确保符合 CLAUDE. md 的规范。 使用方式：在完成一次代码修改后，直接对 Claude 说 &quot;hey claude make this code change then run /simplify”。 核心作用：把原本需要人工反复 review、优化、合规检查的工作，变成一键并行自动化处理，大幅减少 PR 合并前的&quot;打磨”时间。 2. /batch 作用：支持交互式规划 + 并行批量执行的大规模代码迁移。 · 先由用户与主 Agent 交互式制定迁移计划； · 随后自动生成数十个独立 Agent，每个 Agent 负责迁移的一部分； · 每个 Agent 都在完全隔离的 git worktree 中运行； · 完成本地测试后，才自动创建 PR。 使用示例： · &quot;/batch migrate src/ from Solid to React” · &quot;/batch migrate from jest to vite” 核心作用：让过去需要数天甚至数周的手动重构（框架升级、库替换、目录迁移等），变成几分钟到几小时的自动化并行作业，且安全性更高。 [图片: <a href="https://pbs.twimg.com/media/HCNfbWHbEAAJ5Sk?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/HCNfbWHbEAAJ5Sk?format=jpg&#x26;name=orig]</a> Boris Cherny: In the next version of Claude Code.. We&#39;re introducing two new Skills: /simplify and /batch. I have been using both daily, and am excited to share them with everyone. Combined, these kills automate much of the work it used to take to (1) shepherd a pull request to production [图片: <a href="https://pbs.twimg.com/media/HCMgWZ2bUAA2hq9?format=png&#x26;name=orig%5D">https://pbs.twimg.com/media/HCMgWZ2bUAA2hq9?format=png&#x26;name=orig]</a></p><p>【8】学会像 Agent 一样看：Claude Code 工具设计实践 来自 Claude Code 开发者 @trq212，记录了 Anthropic 团队在开发 Claude Code 过程中关于 Agent 工具设计 的实...
学会像 Agent 一样看：Claude Code 工具设计实践 来自 Claude Code 开发者 @trq212，记录了 Anthropic 团队在开发 Claude Code 过程中关于 Agent 工具设计 的实践经验，有一个很核心的观点「开发者需要学会&quot;像 Agent 一样看世界&quot;」 第一层：工具设计的基本框架 如何为 Agent 设计动作空间？看一个数学题的比喻： · 纸笔：最低门槛，受限于手动计算 · 计算器：更强，需要知道如何操作 · 高级功能计算机：最强大，需要会编程 指向一个设计原则：工具应当与使用者的能力相匹配。给一个不会编程的人一台电脑，不如给他一个计算器。同理，给模型的工具必须是它能理解和有效调用的。 这里隐含了一个重要判断——工具不是越多越好，也不是越通用越好，要&quot;shaped to its own abilities&quot;。 第二层：AskUserQuestion 工具的三次迭代 尝试 1：在 ExitPlanTool 中附加问题参数 最省事的做法——复用现有工具。但失败了，原因是语义冲突：一个工具同时承担&quot;输出计划&quot;和&quot;提出疑问&quot;两个职责，模型会困惑。如果用户的回答推翻了计划怎么办？模型是否需要再调用一次？一个工具承载两个意图，会让模型无法形成清晰的调用决策。 尝试 2：修改输出格式（结构化 Markdown） 思路是让模型在普通文本输出中嵌入特定格式的问题，然后由前端解析。这是最&quot;通用&quot;的方案，不需要新增工具。但模型的输出不够稳定——会多加句子、遗漏选项、改变格式。自由文本输出的可靠性不足以支撑结构化交互。 尝试 3：独立的 AskUserQuestion Tool 最终方案是创建专用工具，在 plan mode 中尤其鼓励使用。调用时弹出模态框，阻塞 Agent 循环直到用户作答。 这个方案成功的关键在于三点： · 结构化输出——工具的参数 schema 强制模型给出选项，而非自由发挥 · 可组合性——可以在 Agent SDK 和 Skills 中引用 · 模型的自然倾向——&quot;Claude seemed to like calling this tool&quot;，模型对这个工具有良好的调用直觉 最后一点尤其值得注意。Thariq 明确说：&quot;Even the best designed tool doesn&#39;t work if Claude doesn&#39;t understand how to call it.&quot; 工具设计不仅是工程问题，还是与模型认知特性的匹配问题。 第三层：工具需要随模型能力进化 TodoWrite 到 Task Tool 的演变揭示了一条重要规律：曾经必要的工具，可能随着模型进步反而成为约束。 早期模型容易&quot;忘记&quot;待办事项，所以需要 TodoWrite 来追踪任务，并且每 5 轮插入系统提醒。但随着模型能力提升： · 模型不再需要被提醒 Todo 列表 · 系统提醒反而让模型过于僵化地遵循列表，而不是灵活调整 · Opus 4.5 对 subagent 的调度能力大幅提升，但 Todo 列表无法在多个 subagent 之间协调 于是 TodoWrite 被 Task Tool 取代。Task Tool 的核心转变是：从&quot;帮模型记住事情&quot;变为&quot;帮 Agent 之间通信&quot;——支持依赖关系、跨 subagent 同步、动态增删任务。 这里的教训很直接：定期回顾你对工具的假设。模型在变，你的工具也必须跟着变。 第四层：从 RAG 到自主搜索——上下文构建的范式转移 阶段 1：RAG 向量数据库 -&gt; 被动接收上下文，需要索引和配置，环境兼容性差 阶段 2：Grep 工具 -&gt; 模型主动搜索代码库，自己构建上下文 阶段 3：渐进式披露 -&gt; 模型读取 Skill 文件，文件中引用其他文件，模型递归地展开搜索链条 这个演进的本质是：从&quot;给模型喂上下文&quot;到&quot;让模型自己找上下文&quot;。随着模型推理能力增强，它越来越擅长判断自己缺什么信息、去哪里找、找到后如何利用。 第五层：渐进式披露——不加工具也能扩展能力 Claude Code 目前约有 20 个工具，团队对新增工具的门槛很高，因为每多一个工具就多一个模型需要权衡的选项。 以&quot;Claude Code 自身使用说明&quot;为例： · 写入系统提示词：用户很少问这类问题，常驻上下文造成 context rot · 给模型文档链接让它自行加载：模型会加载大量结果，污染上下文 · 专用 Guide subagent：由 subagent 搜索文档并只返回精准答案 最终方案是 Guide subagent：不增加新工具，而是通过 subagent + 专用指令来扩展能力。这就是 Progressive Disclosure 的应用——在模型需要的时候，才逐层展开信息，而不是一次性塞入所有可能用到的知识。 这个思路对所有 Agent 开发者都有参考价值：能用信息架构解决的问题，就不要用新工具解决。 对 Agent 开发者的启示 以 Claude Code 为案例，方法论适用于所有 Agent 系统的构建： · 先理解模型的能力边界，再设计工具，而非反过来 · 一个工具只做一件事，语义清晰，边界分明 · 结构化胜过自由文本，尤其在需要可靠输出的场景 · 渐进披露优于一次性加载，信息架构本身就是一种工具 · 定期审视既有工具，模型在进化，工具也必须跟上 · 读模型的输出——这是理解模型&quot;如何看世界&quot;的唯一途径 正如 Thariq 所言，这是一门手艺（art），不是一套公式（science）。核心方法论只有一句话：学会像 Agent 一样看。 [图片: <a href="https://pbs.twimg.com/media/HCNayNbbEAAij9O?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/HCNayNbbEAAij9O?format=jpg&#x26;name=orig]</a> Thariq: <a href="http://x.com/i/article/2027446899310313472">http://x.com/i/article/2027446899310313472</a></p><p>【9】群众使用龙虾的目的如此朴实（显然是不能实现的）。软件的增量市场不在给人提供服务，而在给Agent提供服务。 例如给Agent提供的免费搜索API里加广告也不是不能接...
群众使用龙虾的目的如此朴实（显然是不能实现的）。软件的增量市场不在给人提供服务，而在给Agent提供服务。 例如给Agent提供的免费搜索API里加广告也不是不能接受，免费有广告，付费高质量。 [图片: <a href="https://pbs.twimg.com/media/HCNXUHbbwAEsCCY?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/HCNXUHbbwAEsCCY?format=jpg&#x26;name=orig]</a></p><p>【10】新成为 尼日利亚 数字居民 😂 ChatGPT Plus 订阅仅需 ¥50/月
新成为 尼日利亚 数字居民 😂 ChatGPT Plus 订阅仅需 ¥50/月 [图片: <a href="https://pbs.twimg.com/media/HCNVmSVbEAIOlFN?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/HCNVmSVbEAIOlFN?format=jpg&#x26;name=orig]</a></p><p>【11】我最喜欢看的 YouTube 频道之一，这周被HubSpot收购了 频道主理人 @thepatwalls 要举办一场线上的分享，有兴趣的可以去看看 8年前，Starter Story在一家小小的星...
我最喜欢看的 YouTube 频道之一，这周被HubSpot收购了 频道主理人 @thepatwalls 要举办一场线上的分享，有兴趣的可以去看看 8年前，Starter Story在一家小小的星巴克开始。 这将是唯一一次帕特·沃尔斯现场深入讲解真正让它具有吸引力的因素，以及创业者在最初几年犯下的那些悄然限制他们潜力的错误。 如果你现在正在创业，这次会议可能会为你节省数年的时光。 <a href="https://www.youtube.com/watch?v=v-uhjlMg9L0">https://www.youtube.com/watch?v=v-uhjlMg9L0</a></p><p>【12】最近在用网易的 LobsterAI，看更新日志他们这段时间在优化 Skills，内置了文档处理、前端设计、浏览器自动化、网络搜索、甚至有找电影资源这些模块，场景现成，...
最近在用网易的 LobsterAI，看更新日志他们这段时间在优化 Skills，内置了文档处理、前端设计、浏览器自动化、网络搜索、甚至有找电影资源这些模块，场景现成，不少场景一句话就能跑通。 这次试了个有意思的组合，最近对太平年这部剧很感兴趣，想把五代十国这段历史补一补，就直接丢了一个提示词：「把五代十国的脉络和关键知识点整理成一份 PDF，信息密度高一点，顺便帮我查一下太平年是否有云盘网络资源」。它调用了 web-search、pdf、films-search 三个 Skills，PDF 直接生成出来了，脉络清晰，排版也还不错；资源那边也真的搜出了下载地址，省掉了自己去各个网站翻的时间。 Skills 省掉的是拼工具链、写脚本、洗数据的时间。对工程师来说，就是把以前要搭工作流的事变成直接调用，去重、格式化、摘要也一并处理。组合起来能做的事情更多，比如盯着某个竞品每周的更新动态，用 web-search 抓完，直接用 playwright 提取关键变更，最后生成一份竞品周报，整条链路在一个地方跑完。感兴趣的可以从自己最高频的重复场景开始跑，推荐去玩玩 LobsterAI 最新的 Skills 功能。 <a href="https://lobsterai.youdao.com">https://lobsterai.youdao.com</a> [视频: <a href="https://video.twimg.com/amplify_video/2027401115231567872/vid/avc1/2680x1856/Xa4FuBHMywDL4LGg.mp4?tag=21%5D">https://video.twimg.com/amplify_video/2027401115231567872/vid/avc1/2680x1856/Xa4FuBHMywDL4LGg.mp4?tag=21]</a></p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2026/2/28 AI 日报 今日摘要 【1】🤨 最小 transformer 加两 10 位数：36、311、28 参数与可复现性争议 原标题： 《Smallest transformer that can add two 10-digit numbers》 评分: 34 | 作者: ks2048 💭 36 个参数就能学十位数相加？真的假的？ 🎯 讨论背景 原帖讨论一个号称]]></description>
        </item>
      
        <item>
          <title><![CDATA[2026-02-24日刊]]></title>
          <link>/2026-02/2026-02-24/</link>
          <guid>/2026-02/2026-02-24/</guid>
          <pubDate>Tue, 24 Feb 2026 11:13:15 GMT</pubDate>
          <content:encoded><![CDATA[<h2>AI洞察日报 2026/2/24</h2><blockquote><p><code>AI 日报</code></p></blockquote><h3>今日摘要</h3><p>【1】X 平台悄然测试&quot;AI 生成”标签，违规者或面临封号
随着生成式 AI 内容在社交媒体上的泛滥，平台监管正进入&quot;强硬期”。 知名独立应用程序研究员 Nima Owji 近日爆料， X 平台 （原推特）正在秘密测试一项名为&quot;AI 生成”（Made with AI）的内容标签功能，旨在透明化平台上的虚假或合成信息。 [图片: xAI，马斯克，人工智能，AI [object Object]<a href="https://pic.chinaz.com/picmap/202307180849462170_0.jpg%5D">https://pic.chinaz.com/picmap/202307180849462170_0.jpg]</a> AIbase 了解到，该功能目前被整合在&quot;内容披露”控制项下。当创作者发布内容时，可以选择开启该标签，系统随后会在贴文显著位置提醒阅览者：此内容是使用人工智能工具生成的。这标志着X 平台在应对 AI 深度伪造和误导性信息方面迈出了实质性的一步。 值得警惕的是，这项功能可能并非&quot;选修课”。根据研究员的预测，一旦该功能正式上线，X 平台极有可能强制要求创作者对 AI 参与的内容进行主动标注。对于那些试图&quot;以假乱真”且拒不标注的用户，平台或将出台严厉的惩罚措施，包括但不限于贴文限流、账号禁言，甚至 永久 封号。 目前，包括 Meta、YouTube 在内的主流社交平台已纷纷推行类似的AI 生成内容标签制度。 AIbase 认为，X 平台此举是为了在日益复杂的舆论环境中重新建立信息信用。对于广大内容创作者而言，未来的创作准则将更加透明：利用 AI 提高效率可以，但必须给读者留出知情权。</p><p>【2】火狐 Firefox 148 版来了！一键禁用AI功能，提升你的浏览体验
在追求更加纯粹的网络体验的过程中，Mozilla 正式发布了火狐 Firefox 浏览器的 最新 稳定版 ——148 版本。此次更新的一个亮点是新增的 &quot;AI 控制” 面板，这项功能允许用户轻松禁用或自定义浏览器中的 AI 功能，旨在满足用户对于隐私和简洁浏览的需求。 除了 AI 控制，Firefox 148 版本还引入了更为强大的内置翻译功能。现在，用户可以在繁体中文和越南语之间进行无缝互译，这对于需要多语言支持的用户来说，无疑是一大便利。此外，浏览器在无障碍访问方面也做出了改进，屏幕阅读器能够更准确地读取 PDF 中的数学公式，进一步提升了对残障人士的友好度。 在备份功能方面，这一版本专门针对 Windows 10 和 11 进行了优化，确保用户在 &quot;关闭时清除历史记录” 设置下也能流畅使用。同时，Firefox 148 解决了图像拖拽的问题，并修复了可能导致语言包失效的漏洞。对于用户的数据隐私，Mozilla 做出了积极的调整：远程功能的更新已经与遥测数据解绑，用户不再需要分享任何数据就能接收更新，这无疑让人倍感安心。 值得注意的是，Firefox 115.33 将是 Windows 7、8 和 8.1 用户的最后一次安全更新，而在 2026 年 2 月后，Firefox 将停止对这些旧版 Windows 的支持，用户需及时更新至 最新 系统以继续享受浏览器的安全服务。 总的来说，Firefox 148 版本不仅为用户提供了更多的控制权和隐私保护，还增强了多语言支持及无障碍功能，让更多用户能够享受到更流畅、更安全的浏览体验。 划重点： 🌐 新增 &quot;AI 控制” 面板，用户可一键禁用或自定义 AI 功能。 📚 强化内置翻译，支持繁体中文和越南语互译，提升用户多语言体验。 🔒 远程更新与数据分享解绑，用户可安心使用，不再担心隐私问题。</p><p>【3】高通全球首发AI软硬件解决方案，助力沙特数据中心智能化升级！
近日，高通首席执行官安蒙（Cristiano Amon）宣布，该公司的首批机架级 AI 软硬件解决方案已经顺利运抵沙特阿拉伯，并开始向当地合作伙伴 HUMAIN 的数据中心交付。这一系统的基础是 2023 年推出的 Cloud AI 100 Ultra 技术，专为应对边缘计算到云端的混合 AI 工作负载而优化。 据了解，这套解决方案的商用版本预计将在 3 月正式上线。HUMAIN 计划在 第一 阶段部署 1024 个 AI100 加速器，这一规模不仅是高通在全球市场上的重要布局，也是对 AI 技术在实际应用中的巨大信心。值得一提的是，这一创新的应用首个客户是全球知名的 Adobe，显示出高通在行业中的影响力与前瞻性。 AI 技术正在迅速改变各个行业的面貌，从自动化到智能分析，其潜力无疑是巨大的。高通的 AI 软硬件解决方案不仅能够提升数据处理的效率，还能为客户提供更智能的决策支持。随着这一技术的推广，预计将会在多个领域带来深远的变革。 高通的此项举措，不仅为沙特阿拉伯的数据中心带来了先进的技术支持，也进一步证明了高通在全球科技领域的领导地位。未来，随着 AI 技术的不断发展与应用，我们可以期待更多的创新方案为我们的生活和工作带来便利。 划重点： 🌟 高通首批机架级 AI 解决方案已抵达沙特，将助力当地数据中心智能化升级。 🚀 这套系统基于 AI 100 Ultra 技术，专为边缘与云端混合 AI 工作负载设计。 📈 HUMAIN 计划首阶段部署 1024 个 AI100 加速器，首个客户为 Adobe。</p><p>【4】​谷歌宣布为全美 600 万名教师提供免费 Gemini AI 培训
为了在 AI 教育领域占据先机，谷歌正试图将旗下的 AI 工具深度嵌入到基础教育体系中。 谷歌近日联合教育组织 ISTE 与 ASCD 正式推出一项大规模公益计划，旨在为全美 600 万名教师提供免费的 Gemini AI 技能培训。 这项计划的核心在于提升教育工作者的数字素养。 AIbase 了解到，培训课程不仅涵盖了谷歌旗舰 AI 产品Gemini的使用技巧，还重点推介了智能笔记工具 NotebookLM 。通过具体的课堂示例，谷歌希望帮助教师掌握如何利用 AI 辅助教学，并指导全美约 7400 万名学生在学习中安全、合规地使用人工智能。 这种大规模的免费培训背后，不仅是公益之举，更蕴含着深远的生态战略。正如业内分析指出，通过免费培训让教师群体产生工具依赖，谷歌能更有效地让学生在学生时代就熟悉其 AI 生态。相比 OpenAI 和 Anthropic 侧重于与大学合作提供会员折扣的策略，谷歌此次直接深入 K-12（基础教育）阶段的教师群体，覆盖面更为广泛。 目前，该计划预计将在未来几个月内正式启动。有兴趣的教师可以直接通过谷歌官方渠道报名参与。随着 AI 工具在校园的普及，这场关于未来用户习惯的&quot;圈地运动”已在教育一线全面铺开。</p><p>【5】ATM 背后的大脑被 AI 攻克!Claude Code 剑指 COBOL，IBM 一夜市值蒸发13%
周一，全球科技界的目光聚焦于一场&quot;新老对决”。随着 Anthropic 宣布其 Claude Code 工具实现重大突破，能够自动化改造运行 COBOL 语言的老旧系统，长期垄断该领域的蓝巨人 IBM 股价应声大跌 13.2% ，报收每股223.35美元，创下近期单日 最大 跌幅。 [图片: Anthropic、克劳德 [object Object]<a href="https://pic.chinaz.com/picmap/202310180948538535_0.jpg%5D">https://pic.chinaz.com/picmap/202310180948538535_0.jpg]</a> COBOL:支撑世界的&quot;数字古董” 作为上世纪50年代的产物，COBOL 至今仍是全球金融、民航和政府系统的底层基石。据 Anthropic 数据显示，美国约 95% 的 ATM 交易 仍依赖 COBOL 运行。长期以来，这类系统的维护与现代化改造不仅成本 极高 ，且面临开发者老龄化、后继无人的尴尬局面。 Claude Code:精准手术，根治&quot;技术债” Anthropic 表示，AI 已经扭转了改造旧代码&quot;成本高于重写”的逻辑困局。Claude Code 的核心优势在于: 自动化探索: 瞬间梳理数千行代码间的复杂依赖关系，而人类专家可能需要数月。 文档生成: 自动为缺乏维护记录的老旧系统生成完整的工作流程文档。 风险识别: 精准定位隐藏在代码库深处的&quot;技术债”风险点。 市场震荡:AI 正成为行业估值的&quot;收割机” IBM 的大跌反映了投资者对传统企业数字化转型业务被 AI 替代的极度担忧。目前，IBM 股价今年累计跌幅已超 24% 。 这种&quot;AI 扰动”并非个例。上周五，由于 Anthropic 发布了代码安全扫描功能 Claude Code Security ，已导致多家网络安全公司股价集体跳水。市场分析认为，AI 正在从&quot;辅助工具”进化为直接切入核心业务的&quot;重构者”，那些依赖遗留系统维护和高壁垒安全服务的传统模式正面临前所未有的生存危机。</p><p>【6】​OpenAI 秘密开发中端套餐：ChatGPT Pro Lite 曝光，月费 100 美元
在20美元的 Plus 套餐和200美元的 Pro 套餐之间，OpenAI 似乎正准备填补一块巨大的市场空白。 开发者 Tibor Blaho 近日在 ChatGPT 的结账页面代码中发现了一项名为&quot;Pro Lite”的新订阅计划，其定价精准锁定在每月100美元。 [图片: image.png [object Object]<a href="https://pic.chinaz.com/2026/0224/6390752463205462875282477.png%5D">https://pic.chinaz.com/2026/0224/6390752463205462875282477.png]</a> 这一新档位并非空穴来风。早前在 OpenAI 社区论坛中，就有大量用户呼吁推出一个价格适中且配额充足的&quot;中端版本”。从目前流出的页面描述来看，Pro Lite 将为用户提供 OpenAI 顶级 模型的&quot;无限访问权”，并包含无限制的 高级 语音功能以及图像、视频生成配额。 对于开发者和研究人员而言，Pro Lite 最具吸引力的可能在于其性能表现。报道指出，该计划将提供具有&quot;优先速度”的 Codex 编程代理访问权限。根据代码片段推测，Pro Lite 提供给用户的&quot;深度推理模型”使用配额，预计将达到 Plus 套餐的3至5倍。 尽管 OpenAI 尚未正式官宣，但从结账页面的&quot;开发草稿”迹象来看，该方案已进入测试阶段。 AIbase 认为，Pro Lite 的推出将极大程度缓解专业用户&quot;Plus 不够用、Pro 太贵”的尴尬处境。通过这种阶梯式的定价策略，OpenAI 正试图通过差异化服务，将更广泛的自由职业者和中小型技术团队纳入其付费生态圈。</p><p>【7】system-prompts-and-models-of-ai-tools
完整增强代码、Claude Code、Cluely、CodeBuddy、Comet、Cursor、Devin AI、Junie、Kiro、Leap.new、Lovable、Manus、NotionAI、Orchids.app、Perplexity、Poke、Qoder、Replit、Same.dev、Trae、Traycer AI、VSCode Agent、Warp.dev、Windsurf、Xcode、Z.ai Code、Dia 与 v0。（以及其他开源）系统提示词、内部工具与 AI 模型</p><p>【8】skills</p><p>【9】OpenBB
面向分析师、量化交易员和 AI 代理的金融数据平台。</p><p>【10】Agent-Skills-for-Context-Engineering
一个全面的代理技能集合，用于上下文工程、多代理架构和生产级代理系统。适用于构建、优化或调试需要高效上下文管理的代理系统。</p><p>【11】prompts.chat
又名 Awesome ChatGPT 提示词。分享、发现和收集来自社区的提示词。免费且开源 —— 可为您的组织自托管，确保完全隐私。</p><p>【12】stable-diffusion
一种潜在的文本到图像扩散模型</p><p>【13】这两天 Vibe 了一个网页直播项目，有比较复杂的直播推流 SRS，HLS 视频切片 CF CDN 缓存，前端视频补帧等复杂的架构。我是真手敲不出来，以前也没有过相关架构的...
这两天 Vibe 了一个网页直播项目，有比较复杂的直播推流 SRS，HLS 视频切片 CF CDN 缓存，前端视频补帧等复杂的架构。我是真手敲不出来，以前也没有过相关架构的开发经验。 但在 AI 的协助下，最终实现了，这过程让我清晰的认识到自己的经验价值在哪里有所体现。 可我在想，如果 AI 能一次做对呢？ 大帅老猿: 老程序员的价值仅仅只在 AI 还无法一次做对时起作用。 这就是编程小白VibeCoding和老程序员的核心差距，但要注意，这个差距在 AI 的无限进化里被快速的拉近。</p><p>【14】今年除了玩AI，还要多学习提升审美。 除了视觉之美，还有构架之美，系统之美。 Taste is all you need！
今年除了玩AI，还要多学习提升审美。 除了视觉之美，还有构架之美，系统之美。 Taste is all you need！ [图片: <a href="https://pbs.twimg.com/media/HB43-NObQAAAwJb?format=jpg&#x26;name=orig%5D">https://pbs.twimg.com/media/HB43-NObQAAAwJb?format=jpg&#x26;name=orig]</a></p><p>【15】老程序员的价值仅仅只在 AI 还无法一次做对时起作用。 这就是编程小白VibeCoding和老程序员的核心差距，但要注意，这个差距在 AI 的无限进化里被快速的拉近。
老程序员的价值仅仅只在 AI 还无法一次做对时起作用。 这就是编程小白VibeCoding和老程序员的核心差距，但要注意，这个差距在 AI 的无限进化里被快速的拉近。</p><p>【16】Antigravity 一直 cat /dev/null ，真 TM 沙雕啊
Antigravity 一直 cat /dev/null ，真 TM 沙雕啊</p><p>【17】之前给香香做过一个全是别人发给她的&quot;你真的超棒”拼图，她每次伤心的时候就发给她。
之前给香香做过一个全是别人发给她的&quot;你真的超棒”拼图，她每次伤心的时候就发给她。 Asuka小能猫: 我有一个怪癖，我会把别人伤害我、诽谤我的话全部收集在一起，没事的时候一遍遍反复观看。在心理学称为&quot;暴露疗法”，当你一遍遍主动暴露在让你恐惧、痛苦的事情上后，这些事情便再也伤害不到你。 第一遍看到这些话的时候会愤怒、会心痛，也会躯体化和想哭，深呼吸，再多看几遍的时候只会觉得荒诞可笑。</p><p>【18】着凉了，早上醒来头是蒙的🙂‍↔️
着凉了，早上醒来头是蒙的🙂‍↔️</p>]]></content:encoded>
          <description><![CDATA[AI洞察日报 2026/2/24 AI 日报 今日摘要 【1】X 平台悄然测试&quot;AI 生成”标签，违规者或面临封号 随着生成式 AI 内容在社交媒体上的泛滥，平台监管正进入&quot;强硬期”。 知名独立应用程序研究员 Nima Owji 近日爆料， X 平台 （原推特）正在秘密测试一项名为&quot;AI 生成”（Made with AI）的内容标签功能，旨在透明化平台上的虚假或合成信]]></description>
        </item>
      
  </channel>
</rss>